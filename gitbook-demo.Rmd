--- 
title: "Métodos quantitativos em Psicologia com R"
author: "[Luis Anunciação (PUC-Rio), PhD](mailto: luisfca@gmail.com)"
date: "`r Sys.Date()`"
always_allow_html: yes
description: This book was written for undergraduate level students on Quantitative Methods at the Pontifical Catholic University of Rio de Janeiro (PUC-Rio). The primary goal of this book is to provide a short and to-the-point exposition on the essentials of statistics. To a lesser degree, the mathematical modeling of statistical questions will be addressed. I expect this book can also help students who enroll for laboratory-based statistics and anyone who wants to learn R.
documentclass: book
github-repo: cjvanlissa/gitbook-demo
link-citations: yes
bibliography:
- book.bib
- packages.bib
csl: apa.csl
site: bookdown::bookdown_site
biblio-style: apalike
---

```{r}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE,
                      warning = FALSE,
                      fig.align="center")
```


# Prefácio

![](./img/capa_jolie.png)

## A proposta
  

Este livro nasceu como um dos principais e mais frutíferos frutos das aulas de graduação e pós-graduação ministradas por mim em alguns locais, mas com maior intensidade na PUC-Rio, UFRJ e IBNeuro. Por bastante tempo, nas aulas de estatística aplicada à Psicologia e Bioestatística, eu recorri a diferentes livros que, cada qual a sua maneira, apresentavam conceitos de pesquisa,  técnicas estatísticas e análise de dados. No entanto, acabei percebendo (ou tendo a impressão) de que a maior parte dos livros utilizados nessas duas áreas apresentavam a estatística por diferentes atalhos pedagógicos que, consequentemente, geravam a noção de que a área da pesquisa e a área da estatística são distantes, bem como que toda estatística se resume apenas a testes de hipóteses sem nenhum relacionamento entre si.   

Além disso, eu também sentia falta de um livro que pudesse trabalhar com dados reais e previamente publicados, o que ainda é bastante escasso mesmo atualmente. Dessa maneira, nos últimos anos, eu fui sentindo cada vez mais a necessidade de apresentar os conceitos de pesquisa e técnicas estatísticas de forma integrada, contanto com dados reais e seguindo por uma metodologia de aula que pudesse ser pragmática, mas sem reforçar vícios inadequados sobre conceitos de estatística.  

O pragmatismo é fundamental para que o estudante consiga, rapidamente, entender os procedimentos relacionados à análise de dados e implementar técnicas estatísticas para tomar decisões. Acredito que quão antes o estudante entender a utilidade da estatística, maior é a probabilidade dele vir a gostar da área. No entanto, é também necessário ter uma atenção para que pragmatismo não seja muito acentuado e ofereça uma falsa impressão de que toda estatística se resume à utilização de programas de análise de dados.
Isso posto, este livro é fruto de um grande esforço que tem a proposta de ser um manual técnico, em que são apresentados conceitos de pesquisa e análises estatísticas realizadas no R e no JASP. Em cada capítulo, o estudante terá a oportunidade de acessar:  

1. Uma pesquisa, explicitando o problema que ela se propôs a resolver   
2. O artigo publicado com os resultados   
3. A base de dados em formato R ou CSV para reprodução das análises  
4. O conjunto de procedimentos estatísticos utilizados  
5. Recursos extras para aprofundamento em tópicos específicos  
6. Exercícios que podem auxiliar no entendimento do conteúdo, quase sempre retirados de provas externas    

A ideia do livro é oferecer ao estudante um ambiente em que ele possa resolver um problema real, utilizando as técnicas e métodos estatísticos como ferramentas para tomada de decisão. Será possível notar que o livro tem maior foco na utilização da <u>estatística na ciência</u>, em vez da <u>ciência da estatística</u>, que será apenas pontualmente detalhada. De forma geral, espera-se que o livro permita que o estudante aprenda a resolver os problemas e não as ferramentas.  

Espero que este livro possa ser útil a estudantes de graduação e pós-graduação, agradável a leitores de estatística como de Psicologia e um recurso importante para outros docentes que, eventualmente, precisem de um material de apoio.  



## Objetivo 

O livro tem como objetivos (1) apresentar, (2) discutir e (3) operacionalizar conceitos de pesquisa e análises estatística de dados a partir de pesquisas publicadas e dados reais. Espera-se que qualquer o estudante consiga realizar todas as ações descritas no decorrer dos capítulos de maneira guiada e intuitiva. As sintaxes utilizadas no ambiente R e as telas de execução do JASP são integralmente disponíveis.  


## Público-alvo

Este livro foi desenvolvido de maneira mais focada a estudantes de Psicologia e Bioestatística. Nesse sentido, as pesquisas e exemplos utilizados são mais aderentes a essas duas áresa. No entanto, como parte dos conceitos e análises implementadas no livro são interdisciplinares, espera-se que que estudantes de áreas como educação, administração e economia também possam ter proveito do livro.  


## Formato do livro

O livro foi pensando para ter uma estrutura linear, formada por capítulos autossuficientes e desenvolvidos para responder questões específicas e pontuais. Acredito que, assim, ele possa atender tanto estudantes interessados em ler a obra inteira, como aqueles que buscam informações mais específicas sobre um tópico particular.  

Esse formato adotado tende a gerar uma percepção diferente entre aqueles que consultarem apenas um capítulo ou outro e aqueles que lerem o conteúdo por completo. Isso ocorre pois, como muitos testes estatísticos são entendidos como casos particulares de outros modelos, alguns fragmentos que podem parecer destoantes durante uma leitura inicial, tornam-se articulados para aqueles que lerem o trabalho inteiro ou se dispuserem a uma releitura de partes específicas.  

Muitos capítulos recebem o nome de testes de hipóteses (ex: Teste T ou Regressão). Isso foi intencional e visa auxiliar estudantes que precisem apenas de informações pontuais, bem como tende a enfrequecer a ideia de uma relação ponto a ponto tipicamente feita entre testes estatísticos e delineamentos específicos.  

## Como usar este livro  

O livro é formado por capítulos teóricos e capítulos voltados à análise de dados. Os capítulos teóricos reúnem alguns conceitos fundamentais de pesquisa e estatística, tais como tipos de variáveis, delineamento de pesquisa e técnicas de amostragem. Estes capítulos foram escritos pensando em alunos de graduação do curso de Psicologia. Tenho a impressão que esses capítulos não possuem muito apelo, apesar de importantes.     

Os capítulos analíticos são focados em testes de hipóteses e contam com uma metodologia direta ao ponto, em que atividades similares às realizadas nos artigos são demonstradas. Estes capítulos foram desenvolvidos para estudantes de pós-graduação. Acredito que esses capítulos serão bastante acessados.  


## Bases de dados  

Todas as bases de dados utilizadas neste livro são *Open Science*. Isso significa que elas são universalmente acessíveis e decorrentes de pesquisas empíricas com artigos publicados. Eventualmente, alguns ajustes foram feitos às bases para torná-las mais acessíveis ou remover características de identificação.   

As bases em R tem formato .RData e as bases para o JASP tem formato .CSV.  

Todo material pode ser acessado em https://github.com/anovabr/mqt/tree/master/bases 


## O R e os pacotes  

O livro é integralmente desenvolvido pelo recurso de "programação letrada" no R Markdown, ou seja, ele entrelaça aspectos textuais e linhas de código. Em todos os capítulos, as funções nativas do R e do Tidyverse serão utilizadas. Caso alguém queira reproduzir as análises, será necessário apenas executar as linhas de código disponíveis no decorrer do livro.  

O `tidyverse` costuma ter atualizações frequentes. Caso um alerta de `deprecated` seja apresentado, isso significa que a função utilizada foi parcialmente desativada, o que não costuma impactar nas análises.


## JASP   

O JASP é um programa gratuito que tem sido cada vez mais utilizado em Psicologia. Ele é feito integralmente por código aberto e sua interface é bastante amigável e intuitiva. Ao instalar o JASP, o R também será instalado em seu computador e ficará no pano de fundo. Dessa maneira, todas as ações feitas por *Point and Click* no JASP, serão convertidas em linhas de código no R e apresentadas de maneira dinâmica no JASP. 

![](./img/capa_r_jasp.png)

Em todos os capítulos, telas do JASP serão apresentadas para que seja possível a reprodução integral de algumas análises. Da mesma forma que qualquer pacotes estatístico, o JASP é atualizado frequentemente. Esse livro contou com a versão 0.14.1 e espero que futuras atualizações não comprometam a proposta do livro.  

## Outros recursos

Em cada um dos capítulos, aplicações da estatística e referências bibliográficas serão apresentadas. Tenha em mente que há um debate intenso em diferentes conceitos de estatística, da mesma forma que muitas condições computacionais podem aparecer durante a execução das análises propostas. Eu recomendo fortemente a comunidade [stackoverflow](https://stackoverflow.com/) como um recurso pedagógico para auxiliar em ambos os cenários.  

Quetões relacionadas aos capítulos são listadas de forma a conectar o conteúdo do livro com exigências balizadas por critérios externos, tal como o ENADE e bancas de concurso.  


## Preço 

## Capa   
 
Por tradição, livros de Ciência de Dados e Estatística utilizam a imagem de algum animal na capa. Há livros com cachorros, papagaios, peixes, Carangueiros, Lagartos, etc. Esse livro não foge dessa regra e tem como capa a Jolie, a minha cachorrinha com a Anna. Ela foi indispensável para o <u>atraso</u> ao término deste livro.  


## Versão do livro

Como todos os livros, este também tem uma história de desenvolvimento. A tabela abaixo apresenta a versão, a data de lançamento e algumas características importantes.   

| Versão   |      Data         |  Características
|:---------|:-------------     | :-------------
| Beta 1   |  Fevereiro, 2020 | Primeira versão. Baixa revisão textual e dos conceitos estatísticos. Erros são esperados. A utilização deve ser feita apenas de maneira incipiente   

## Agradecimentos e revisões técnicas

Nenhum homem é uma ilha. Este livro só foi possível graças a um conjunto de pessoas que auxiliaram e fizeram uma profunda revisão do texto. Meus sinceros agradecimentos a (ao):  
J. Landeira-Fernandez, PUC-Rio  
Regina Albanense, CONRE  
Cristiano Fernandes, PUC-Rio  
Danilo Assis Pereira, IBNeuro  
Ana Carolina de Almeida Portugal, UFRJ   
Alunos da PUC-Rio, UFRJ, IBNeuro e ANOVA  






<!--chapter:end:index.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Programas estatísticos  


```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar os programas estatísticos utilizados durante o livro      
2. Discutir características do R, tidyverse e seus pacotes     
3. Discutir características do JASP      
```
 
Programas estatísticos são ferramentas indispensáveis tanto na gestão, como na análise dos dados resultantes de uma pesquisa. Eles servem para otimizar o tempo gasto nas etapas analíticas de uma pesquisa, apesar de, em menor escala, permitirem a execução de análises inadequadas. No dia a dia de um pesquisador, apenas muito raramente as análises são feitas manualmente. Dessa maneira, o conhecimento de programas de análise de dados faz parte das competências esperadas para quem deseja ou precisa trabalhar com estatística.  

Atualmente, há muitos programas e pacotes estatísticos disponíveis para uso. Acredito que a maioria deles tenham mais similaridades do que diferenças e produzam resultados confiáveis. Neste livro, o R e o JASP serão utilizados e algumas de suas características serão descritas neste capítulo.  


## O R 


O R é uma linguagem de programação focada em análises estatísticas, que vem ganhando popularidade entre pesquisadores e cientistas. Este livro foi integralmente feito e baseado no ambiente R que, apesar de ainda não ser o programa mais frequente em Psicologia, apresenta diversas vantagens em comparação aos programas mais usuais.


* o R e todos os seus pacotes e otimizações são gratuitos.   
    
* o R é uma linguagem de programação desenvolvida especificamente para Estatística.  
    + Diferente de uma linguagem mais geral (por exemplo, Python) ou de um programa *point and click*, o R é uma linguagem focada em análise estatística. Ao se programar utilizando o R, o usuário tem controle total das ações realizadas e dos resultados obtidos. Assim, raramente o R apresentará resultados excessivos e distantes das análises solicitadas. Apesar disso poder assustar no início, acredito que essa característica seja essencial e, inclusive, serve como um excelente auxílio pedagógico para para que o estudante planeje adequadamente as análises de interesse, em vez de apenas selecionar parte de um *output* padronizado, como ocorre com o SPSS.  
    
      
* O R é um programa de nicho em Estatística. Essa característica faz com que ele seja absolutamente adaptado para o dia a dia em estatística, incluindo não apenas análises descritivas e inferenciais, mas também análises para simulação e controle de resultados.  
    
+ O R permite o desenvolvimento de interfaces web e aplicativos.     

* O R tem diversos pacotes.  
    + Pacotes são complementos que permitem otimizar as análises que o R faz. A comunidade R tem um exército de pacotes, que além de gratuitos, foram verificados publicamente. O ambiente CRAN (*The Comprehensive R Archive Network*) é o local em que estes pacotes estão alocados. Neste livro, todos os capítulos contam com pacotes específicos, que permitiram que análises complexas fossem realizadas com poucos comandos.   
  
    
* O R possui uma enorme comunidade de apoio.  
    + Os usuários do R formam uma rede muito dinâmica e que oferece grande apoio em caso das mais diversas dúvidas. A comunidade  [stackoverflow](https://stackoverflow.com/) talvez seja a mais voluma e reúne pessoas de todas as nacionalidades.  


Para baixar o R, é necessário ir no site [https://cran.r-project.org/](https://cran.r-project.org/). Em seguida, para baixar o R Studio, é necessário acessar [https://rstudio.com/](https://rstudio.com/).

## Tidyverse  

O Tidyverse é um ambiente de pacotes. Eles funcionam de maneira totalmente integrada e permitem que a estrutura da programação seja mais intuitiva e próxima à forma pela qual pensamos. No Tidyverse, os códigos seguem a lógica de sujeito + verbo e permitem uma programação encadeada, ao se utilizar a ligação *pipe* (`%>%`). Ao instalar o tidyverse `install.package("tidyvese")`, os pacotes abaixo ficam disponíveis no R.


![](./img/tidyverse_website.PNG)


## Dificuldades esperadas  
Algumas dificuldades são esperadas quando se trabalha programação no geral e com o R especificamente. Apesar do R e seus pacotes oferecem excelentes ferramentas para análise de dados, algumas condições descritivas são demasiadamente custosas. Por exemplo, enquanto realizar algumas tabelas e gráficos no Excel é tremendamente fácil, as vezes o R exige diversas linhas de código para isso. 

Nesse sentido, na relação entre dificuldade e complexidade, o R sai na frente em tarefas complexas (como exemplo, estimar os coeficientes de um modelo não-linear), mas talvez perca em tarefas fáceis (por exemplo, gerar uma tabela de contingência). A Figura a seguir apresenta esta relação comparando as análises feitas no R e no Excel.

![](./img/excel_r.PNG)

Além disso, o R traz uma outra barreira importante em aspectos que envolvam o ensino de estatística, especialmente na graduação. Como o R é uma linguagem de programação, o estudante teria de aprender a programar antes de conseguir entender conceitos de pesquisa e a utilidade da estatística. Isso poderia impactar negativamente na motivação do estudante, principalmente àqueles com uma aversão *a priori* da matéria, 

Em situações como esta, talvez o ideal seja começar motivando o estudante a entender como a estatística é uma ferramenta importante para tomar decisões para, só depois e lentamente, apresentar aspectos matemáticos e computacionais.

## Verbos do dplyr

Entre os pacotes do ambiente tidyverse, o dplyr é o que será mais utilizado. Este pacote funciona de maneira muito intuitiva, em que as funções dependem de uma estrutura `sujeito %>% verbo(complemento)`. Essa é uma diferença importante em relação ao R Base. Por exemplo, no R Base é necessário executar `names(dataset)` para verificar as variáveis de um conjunto de dados. Pelo dplyr deve-se utilizar `dataset %>% names`.

O dplyr funciona a partir de verbos declarativos e os principais estão listados na tabela a seguir. As sintaxes deixadas no decorrer do livro também permitem uma melhor apreensão das funcionalidades. 



| Verbo         | Ação          
| :------------ | :----------
| glimpse       | Inspeciona os dados 
| count         | Conta os níveis de uma variável 
| select        | seleciona uma variável específica 
| filter        | Filtra os resultados por um nível específico de uma variável 
| group_by      | Agrupa os resultados por níveis de uma variávei específica  
| summarise     | Apresenta sumários (com medidas estatísticas)  
| mutate        | Cria novas variáveis ou altera as existentes
| arrange       | Organiza a apresentação dos resultados  
| left_join     | Junta bases ou colunas  
| pivot_longer  | Transforma uma base larga em longa  
| pivot_wider   | Transforma uma base longa em larga  

*Nota: Em alguns momentos, em função da praticidade computacional, algumas sintaxes vão contar com o formato base do R.*

É importante ficar atento às atualizações do dplyr e do sistema tidyverse como um todo. Eventualmente, mudanças podem ocorrer e impossibilitar (ou dificultar) a reprodução de rotinas antigas.   

## O JASP  

O JASP é um programa gratuito, com uma interface amigável, *point and click* e altamente versátil para a maioria das análises realizadas. A versão utilizada neste livro é a 0.14.1. O JASP foi desenvolvido por um time de psicólogos e estatísticos liderados pelo Prof. Eric-Jan Wagenmakers, da Universidade de Amsterdam. Isso talvez explique o motivo pelo qual o JASP vem sendo cada vez mais utilizado em análises de dados psicológicos e na docência de matérias relacionadas a métodos estatísticos.

Para baixar o JASP, é necessário acessar [https://jasp-stats.org/download/](https://jasp-stats.org/download/).  


![](./img/cap_jasp_interface.png)

Quando se instala o JASP no computador, se instala também o R. Todas as ações feitas no JASP se transformam em linhas de código que são enviadas ao R e, em seguida, retornam pro JASP e são apresentadas na tela. Isso ocorre instantanemanete e não há nenhum incômodo para o usuário. Na maioria das vezes, computadores pessoais conseguem rodar o JASP sem grandes problemas.

![](./img/capa_r_jasp.png)

O idioma oficial do JASP é o inglês e, nesta versão, não pode ser alterado. Para fazer qualquer análise, é necessário carregar um arquivo de dados. Isso pode ser feito no símbolo das três linhas, localizado na parte superior à esquerda.

![](./img/cap_jasp_abrir.png)

A opção `open` permite que se acesse algum diretório local específico ou se baixe os dados diretos da plataforma *Open Science Framework (OSF)*. Esta versão do JASP aceita, majoritariamente, arquivos em CSV, que indica que os dados são separados por vírgulas.

![](./img/cap_jasp_abrir2.png)

Ao abrir algum arquivo de dados, o JASP irá apresentar os dados no centro do programa e as opções de análise na parte superior. Tenha atenção que essas telas podem variar de versão para versão. 

Em relação aos dados, quase sempre o formato utilizado é o largo. Neste formato, cada coluna representa uma variável, cada linha representa um caso e cada célula (ou vetor) apresenta um valor específico.  

![](./img/cap_jasp_dados.png)
O JASP adota uma simbologia específica para definir a escala (ou nível) de medida das variáveis. Isso pode ser visto no símbolo ao lado dos nomes das variáveis. Para alterar o nível, basta clicar sobre o símbolo. 

![](./img/cap_jasp_tipo_de_dados.png)

É possível também alterar valores e rótulos das variáveis. Para isso, basta clicar no centro da variável. Uma seção na parte de cima do programa será exibida. Para fechar, é necessário clicar no X ao lado direito.     

![](./img/cap_jasp_alterar_valores.png)

Na parte superior, o JASP oferece as análises possíveis. As opções podem variar de versão para versão, mas as principais tendem a ser as seguintes.

![](./img/cap_jasp_features.png)


É possível adicionar módulos e complementos no JASP. Essas adições funcionam de maneira análoga aos pacotes do R. Para fazer isso, basta clicar na cruz azul ao lado direito.

![](./img/cap_jasp_adicionar_modulos.png)


Uma barra ao lado direito irá ser exibida. Qualquer opção pode ser selecionada e, ao fazer isso, novos botões irão aparecer na parte superior do programa. 

![](./img/cap_jasp_adicionar_modulos2.png)

Finalmente, para salvar o trabalho realizado em uma sessão, deve-se clicar na símbolo de três linhas azuis e, em seguida, clicar em `Save as` e selecionar a pasta.. Por padrão, o formato do arquivo ser.a *.jasp.

![](./img/cap_jasp_salvar.png)



## Resumo  
::: {.explore}
1. Há muitos programas e pacotes de estatística. Neste livro, o R e o JASP serão utilizados.  
2. O R oferece é gratuito e um ambiente de programação e o tidyverse servirá como principal interface.  
3. O JASP tem recebido grande atenção especialmente em Psicologia e as análises também serão feitas nele.  
::: 

<!--chapter:end:01-programas_estatisticos.Rmd-->

---
output:
  word_document: default
  html_document: default
---
# Aspectos gerais  


```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar conceitos transversais encontrados em pesquisa e estatística    
2. Descrever as variáveis em função de seu relacionamento, escala de medida e capacidade numérica  
3. Introduzir o debate sobre a escala de medida em Psicologia  
4. Apresentar as duas principais áreas da estatística
```
 
```{block, type="glossario"}
<U>**GLOSSÁRIO**</U>   
**Pesquisa**: Procedimento racional e sistemático de investigação que visa proporcionar respostas específicas a um conjunto de problemas propostos.  
**Modelo teórico**: Representação visual, matemática, computacional ou experimental de um sistema de ideias, eventos ou fenômenos.  
**Instrumentos científicos**: Ferramentas que permitem amplificar o fenômeno de interesse, além de acessar aspectos da realidade que não podem ser percebidos diretamente.  
**Variável aleatória**: É uma variável que está associada a uma distribuição de probabilidade.  
**Variável**: Termo genérico usado para se referir às características que estão sendo investigadas ou para se referir às variáveis aleatórias.   
**Variável Independente (VI)**: Característica que esta sendo manipulada. Entende-se que ela influencia, afetam ou determinam outras variáveis.  
**Variável dependente (VD)**:   Variável que sofre efeito da VI. Seus valores dependem dos níveis da VI.  
**Delineamento de pesquisa** Forma de esquematizar o planejamento da pesquisa, especialmente considerando o acesso e controle das variáveis, bem como a coleta e análise de dados.   
```


Quando as pessoas começam seus estudos em estatística, parece haver uma falsa crença de que a estatística é uma área exclusivamente desenvolvida para analisar dados obtidos em uma pesquisa. Este pensamento acaba por produzir uma dicotomia entre pesquisa e estatística, fazendo com que algumas pessoas pensem que as atividades feitas em estatística somente começam após o termino de uma pesquisa. No entanto, isso não é verdade. Apesar da análise de dados ser uma tarefa intensamente feita em estatística, a atuação desta ciência é muito mais mais ampla do que apenas isso e ocorre em todas as etapas de uma pesquisa.    

Em linhas gerais, a estatística é a ciência que fornece os princípios e a metodologia para <u>coleta</u>, <u>organização</u>, <u>apresentação</u>, <u>resumo</u>, <u>tratamento</u>, <u>análise</u> e <u>interpretação de dados</u>. O mnemônico <mark>CORRETA</mark> quase sempre ajuda a fixar esta definição, já que C se refere à coleta, O se refere à organização, R se refere à resumo, T se refere à tratamento e A se refere à análise, incluindo aspectos descritivos, inferenciais e suas respectivas interpretações, que serão discutidas posteriormente. Assim, aprender estatística da forma "correta" é muito importante no meio acadêmico e científico.   


::: {.warning}
**Atenção**: A estatística atua em todas as etapas da pesquisa, incluindo o planejamento, execução e análises. O mnemônico CORRETA auxilia a lembrar as principais atividades desempenhadas pela estatística.     
:::


Uma vez que o conjunto de atividades possíveis em estatística é bastante longo, é possível distinguir acadêmicos cujos interesses são mais relacionados à <mark>estatística como ciência</marK> daqueles cujos interessem recaem mais na utilização da <mark>estatística na ciência</mark>. Com frequência, estudantes do bacharelado de estatística ou matémática tendem a fazer parte do primeiro grupo, enquanto estudantes de áreas mais aplicadas, incluindo aqui Psicologia, tendem a fazer parte do segundo grupo. Apesar dos conceitos principais da estatística serem os mesmos, essa distinção serve como uma bussóla metodológica para orientar a forma pela qual esses conceitos serão introduzidos e discutidos.

Isso posto, os subtópicos a seguir introduzem conceitos gerais e importantes que costumam ser apresentados antes mesmo de aspectos mais voltados à análise de dados. Uma vez que esses conceitos são transversais, é possível também encontrar essa discussão em livros de métodos de pesquisa e história da ciência. 

A apresentação e descrição desses temas será feita de maneira sucinta. As referências bibliográficas dispostas ao fim do capítulo servem para o aprofundamento teórico entre aqueles interessados.   


## Os objetivos de uma pesquisa 

Uma pesquisa é um procedimento racional e sistemático de investigação que visa proporcionar respostas específicas a um conjunto de problemas propostos [@gil2002]. Toda pesquisa depende da eleição de problemas, bem como da coleta e análise de dados.

Uma das principais condições a se definir antes de se iniciar uma pesquisa é o seu objetivo geral. Neste sentido, é possível listar 3 grandes grupos de pesquisas, que são as (1) pesquisas exploratórias, (2) pesquisas descritivas e (3) pesquisas explicativas. A tabela a seguir sintetiza as principais características de cada um desses tipos.    


  | Tipo de Pesquisa| Quando é feita                                             | Características principais               
  | :-----------    | :-----------                                               | :-----------                        
  | Exploratória    | Há pouco ou nenhum conhecimento sobre o tema de interesse. | Não há hipóteses definidas previamente. Os resultados proporcionam maior familiaridade com o problema, apesar de frágeis e pouco generalizáveis.  
  | Descritiva      | Os fenômenos e objetos já são mais conhecidos. Hipóteses sobre suas características e eventuais relacionamentos podem ser feitas. | Técnicas de coleta de dados mais padronizadas tendem a ser empregadas. Testes de hipóteses são feitos, bem como técnicas estatísticas descritivas e que visem comparar características entre grupos e pessoas diferentes.     
   | Explicativa    | Há maior conhecimento sobre o tema de interesse e a finalidade é indicar possíveis relações de causa e efeito | O delineamento experimental tende a ser implementado, o que será explicado posteriormente     
 

É possível notar que o objetivo da pesquisa indica um pouco a maturidade da área cientifica em questão e a recenticidade que o fenômeno a ser estudado representa. Apesar de não ser uma regra geral, pesquisas exploratórias tendem a ser feitas por ciências mais novas e/ou para estudar fenômenos e objetos em que há pouco conhecimento científico sobre. Tenha atenção que a baixa quantidade de conhecimento se refere a aspectos acadêmicos e científicos, e não a quatidade de conhecimento que os autores da pesquisa apresentam sobre seu objeto de investigação. 

Muitas pesquisas em Psicologia são exploratórias. Explorar quantas e quais funções executivas estão presentes em crianças com autismo [@Skogli2020] ou quais são as atitudes de professores em relação ao ensino de ciência [@Jones1994] retratam bem pesquisas exploratórias. No entanto, mesmo áreas com maior maturidade científica podem realizar pesquisas exploratórias quando o fenômeno a ser estudado é recente. Por exemplo, a eventual relação entre o Zica Vírus e o desenvolvimento de microcefalia nos anos 2015 proporcionou a realização de muitas pesquisas exploratórias em biologia e medicina. 


Pesquisas com objetivos descritivos indicam que o fenômeno ou objeto investigado já é mais conhecido pela comunidade científica. Elas são úteis para apresentar o perfil de determinado fenômeno ou objeto, bem como verificar a relação entre variáveis. As pesquisa de intenção de votos, survey sobre opiniões e atitudes sociais e indicadores de prevalência de condições de saúde retratam bem este tipo de pesquisa. 


Pesquisas explicativas visam identificar os fatores que determinam ou que contribuem para a ocorrência dos fenômenos [@gil2002]. Esse é o tipo de pesquisa que mais aprofunda o conhecimento da realidade e, consequentemente, é a mais complexa de ser realizada. Estudar fenômenos termodinâmicos, tal como a transformação de um tipo de energia em outra, ou como o processo de detecção de um estímulo se dá [Madsen1988] ou qual é o efeito de programas de televisão na agressividade de crianças [-@Bandura1961] retratam pesquisas explicativas.   

## A dimensão temporal de uma pesquisa

A unidade de tempo de uma pesquisa é um fator importante a ser definido antes de sua execução e a pesquisa pode ser transversal ou longitudinal. Estudos transversais são também chamados de *Cross-sectional* e descrevem uma situação ou fenômeno em um momento específico do tempo. Estudos longitudinais são também chamados de *follow-up* e  contam com uma seqüência temporal previamente definida. A imagem a seguir apresenta este conceito.

![](./img/cap_transversal_longitudinal.png)


A realização de cada tipo de estudo é atrealada à pergunta a qual ele visa responder. A tabela abaixo apresesenta algumas características.



  | Característica | Transversal          | Longitudinal             
  | :-----------   | :----------          | :-----------                        
  | Duração        | Um único momento.      | Múltiplos momentos.
  | Amostra        | Varia em cada estudo.       | Mesmos participantes.  
  | Resultados     | Mostram uma fotografia momentâna.      | Indicam detalhes da mudança das variáveis.  
  | Vantagens      | - Tende a ser mais barata.<br>-Rápida.<br>-Participantes são mais fáceis de serem amostrados.<br>- Menos condições burocráticas (Comissão ética, etc). | -Mudanças podem ser descritas.<br>-Maior detalhamento dos resultados.<br>-Pode indicar causalidade<br>
  | Desvantagens   | -Pouco nível de detalhamento.<br>-Impossibilidade de analisar mudanças.<br>-Dificuldade de verificar aspectos de causalidade. | -Consome tempo e dinheiro para execução.<br>-Perda amostral tende a ocorrer com frequência.<br>-Maior burocracia (Comissão ética, etc).<br>-Definição de intervalo de tempo difícil.  


Com regularidade, pesquisas longitudinais se aproximam mais de objetivos explicativos, enquanto pesquisas transversais são mais próximas a objetivos exploratórios e descritivos.  


## conceitos fundamentais   
- *L. Anunciação & J. Landeira-Fernandez* 


Existem alguns conceitos muito utilizados em pesquisa e estatística que servem como fundações da maior parte dos métodos e técnicas implementados quando se deseja investigar um determinado fenômeno ou objeto através do método científico. Apesar de manuais técnicos divergirem em quantos e quais conceitos podem ser entendidos como fundamentais em pesquisa e estatística, existe grande concordância em relação à (1) realidade e modelo e (2) constante e variáveis. Ambos serão introduzidos a seguir.     

### Modelos científicos

Quando uma pesquisa é feita, ela visa responder uma pergunta específica sobre um fenômeno ou objeto, tal como apresentado anteriormente. Muitas perguntas são possíveis a depender da área de interesse do investigador, bem como de sua época. Físicos e astrônomos do século XVI queriam investigar a organização do sistema solar, economistas do século XVIII tinham interesse em investigar a relação entre recursos e rendimentos financeiros e, mais recentemente, psicólogos do século XX se debruçaram a estudar o efeito da escolaridade no desenvolvimento de habilidades cognitivas. Esses três exemplos remontam à teoria heliocêntrica, a lei dos retornos marginais decrescentes e a teoria da reserva cognitiva.  

Apesar da diferença entre os interesses, uma característica compartilhada nestas pesquisas é a impossibilidade ou improbabilidade de se investigar diretamente a realidade. No exemplo da astronomia isso parece ser bastante claro, já que mesmo que pesquisas em física tenham características mais mecanicistas, só atualmente que o acesso mais preciso da realidade foi possível e permitiu responder melhor essa questão. Além disso, na grande maioria das pesquisas, os fenômenos e objetos de interesse não são sistemas fechados. Isso significa que não é possível ou viável controlar todos os fatores relacionados ao que se tem interesse de estudar. Por exemplo, quando se investiga como a escolaridade impacta nas habilidades cognitivas, os resultados podem (ou não) responder apenas inicialmente sobre um dos fatores relacionado às habilidades cognitivas, mas não todos.

Entre as maneiras desenvolvidas por cientistas para lidar com esta situação estão a <u>construção de modelos teóricos</u> e <u>instrumentos de medida</u>. Modelos teóricos científicos são representações da realidade e podem ser criados sob perspectiva visual, matemática, computacional ou experimental [@Weisberg2013]. Eles tendem a ser sistemas fechados e visam reproduzir, precisamente, o fenômeno ou objeto de interesse. A qualidade desses modelos pode variar e entre as principais características positivas de um modelo com alta aderência à realidade estão a possibilidade de se realizar simulações e também fazer predições com ele [@Heidemann2016]. 

A figura a seguir apresenta algumas características dos modelos científicos.  

![](./img/cap_modelos_cientificos.png)


Em um modelo ideal, aquilo que fosse descoberto a partir dele, ocorreria identicamente na realidade. Evidentemente, modelos ideais não existem na grande maioria das áreas científicas, o que leva à conclusão de que os modelos são absolutamente essenciais à pesquisa, apesar de possuírem limitações [@Putnam1980; @Feigelson1992; @Firgg2020]. Por exemplo, engenheiros utilizam modelos computacionais com muita frequência para verificar itens de segurança de um carro; economistas utilizam modelos matemáticos (e também jogos!) para investigar características da tomada de decisão e psicólogos utilizam modelos experimentais e matemáticos para investigar transtornos mentais e desenvolvimento de funções emocionais e cognitivas.   


Ainda neste sentido, mapas cartográficos ilustram bem a importância dos modelos. Apesar de todos os mapas disponíveis distorcerem um pouco a área e localização dos continentes, a utilização deles é fundamental tanto na ciência como no dia-a-dia das pessoas. Na figura a seguir, o mapa à esquerda apresenta a projeção de Marcator, que é a mais utilizada nos livros. À direta, a projeção de Peters, que apesar de não ser tão utilizada, é a que melhor organiza o tamanho e o local dos continentes.   

![](./img/cap_mapas.png) 

 
Além disso, quase sempre, o registro que temos da realidade é baseado em nossos órgãos sensoriais que, por sua vez, são influenciados pela cultura em que estamos inseridos e pela aprendizagem prévia pela qual passamos. Com isso é fácil notar que existe um grande hiato entre a realidade e nossa percepção da realidade. Os instrumentos de medida, por sua vez, são recursos tecnológicos que permitem uma avaliação mais detalhada do fenômeno ou do objeto de investigação, além de gerarem dados que podem ser analisados, comparados e compartilhados. Todas as áreas científicas criam e refinam instrumentos de medida e há autores que sugerem que a existência e a qualidade de tais recursos indicam o quão madura e desenvolvida uma área se encontra, uma vez que os instrumentos são condições centrais no processo científico [@Bergenholtz2018]. Apesar de grande variabilidade em relação à acurácia e precisão dos instrumentos, relógios, bússolas, réguas e testes psicológicos permitem um acesso mais detalhado de um fenômeno ou objeto de interesse.


![](./img/cap_instrumentos.png) 

Dessa maneira, a principal proposta dos instrumentos de medida é a captura da realidade sem interferência ou ruídos e, em seguida, a produção de dados confiáveis sobre o fenômeno ou objeto estudado. Existe uma grande translação entre modelos teóricos e instrumentos de medida. Apesar de não ser uma regra geral, muitas áreas científicas primeiro constroem modelos teóricos e o processo de medida ocorre nestes modelos. Por exemplo, há um conjunto de modelos psicológicos visando entender como ocorre o esquecimento que, por sua vez, permitiram desenvolver testes e escalas específicas para isso.   


Uma dos exemplos mais interessantes sobre a limitação que nossos sentidos possuem ao capturar a realidade e a importância do desenvolvimento de instrumentos de medida é percepção que temos do sol. A maioria das representações feitas do sol o apresentam como amarelo, quando na verdade ele é branco. Isso ocorre em função da atmosfera do planeta Terra e de diferentes gases presentes no céu.   

![](./img/cap_sol.png) 


Isso posto, o desenvolvimento de modelos teóricos e de instrumentos de medida são atividades essenciais de pesquisadores e cientistas para lidar com a impossibilidade ou improbabilidade de acessar a realidade de forma direta, bem como pela limitação perceptual que temos. Como Popper comenta no livro "Os dois problemas fundamentais da teoria do conhecimento", essas características fazem com que cientistas quase nunca digam que estão em busca da verdade, mas sim que estão em busca de evidências sobre um determinado fenômeno ou objeto.

### Variáveis  

O segundo conceito fundamental pode ser entendido pela dicotomia entre variáveis e constantes. De maneira geral, um fenômeno constante não apresenta dispersão em seus valores. Basta uma única medição para que o comportamento de um fenômeno constante possa ser capturado. Em oposição, fenômenos variáveis podem assumir quaisquer valores em suas características. Enquanto a velocidade da luz e do som é, respectivamente, 324 m/s e 299.792 m/s; a renda, altura ou inteligência das pessoas pode variar bastante. Essa dicotomia poderia também ser vista pelo conceito de modelos determinísticos e probabilísticos ou, superficialmente, em diferenças entre ciências naturais e ciências humanas. Modelos determinísticos são aqueles que as condições iniciais determinam os resultados, enquanto modelos probabilísticos são os que associam probabilidades aos resultados. Em ciências naturais recorre-se menos à noção de probabilidade, enquanto em ciências humanas este é um conceito central.   

Em estatística e pesquisa, o termo variável pode ser entendido tanto de uma maneira bastante informal, como de uma forma mais rigorosa. Informalmente, uma variável é um símbolo que representa uma característica de um determinado objeto, tal como peso, altura, inteligência ou renda. Como essa característica pode apresentar quaisquer, dá-se o nome de variável. No entanto, formalmente em estatística, quando o termo variável é utilizado, o que está em jogo é o conceito de <u>variável aleatória</u>. Por sua vez, este conceito se refere à uma classe de variáveis em que o conjunto possível de suas realizações (ou seja, seus valores ou desfechos) ocorrem de acordo com uma distribuição de probabilidade [@everitt2002cambridge]. Em estatística, uma variável aleatória é uma função que associa elementos do espaço amostral ao conjunto de números reais. 

::: {.warning}
**Atenção**: Uma variável é um símbolo que representa uma característica. Uma variável aleatória é uma variável que possui uma distribuição de probabilidade.       
:::

Dessa maneira, o estudo das variáveis (aleatórias) é central em estatística, seja tanto para análises descritiva, como inferenciais.   

As variáveis podem ser organizadas por seu <u>relacionamento em uma pesquisa</u>, seu <u>nível ou escala de medida</u> e sua <u>capacidade informacional</u>.  


No que se refere ao relacionamento entre as variáveis, inicialmente, é possível classificá-las em independentes e dependentes. Variáveis independentes são abreviadas pela sigla VI e também são chamadas de antecedentes, preditores, fatores ou variáveis manipuladas ou de entrada. Variáveis dependentes são abreviadas por VD e também são chamadas de consequentes, previstas, desfechos ou variáveis medidas ou de saída.   


Os termos VI e VD explicitam que ambas as variáveis são conectadas e que <u>a VI gera ou causa a VD</u>. É justamente por isso que representações matemáticas apresentam a VI por X e a VD por Y, tal como no estudo de funções.  

![](./img/cap_vi_vd1.png)  

Em alguns fenômenos naturais, é relativamente fácil identificar a VI e a VD. Por exemplo, quanto mais profundo uma pessoa mergulha no mar, mais gelada a água fica. Neste caso, a profundidade seria a VI, enquanto a temperatura da água seria a VD. Da mesma forma, quanto mais alto um avião viaja, menor é a pressão atmosférica. Nesse outro exemplo, a altitude é a VI e a pressão atmosférica é a VD. 

![](./img/cap_vivd_fisica.png) 


No entanto, esses exemplos descritos são oportunos e têm apenas finalidade pedagógica. Na realidade, a definição de VI e VD nem sempre é fácil e, especialmente em ciências humanas e da saúde, isso se torna ainda mais sutil. É possível definir a VI e VD por condições temporais, lógicas ou teóricas [@BabbieEarlR1990], bem como é possível desenvolver pesquisas com características específicas para que essa relação possa ser definida com acurácia, e consequentemente, corretamente medida. 


Como exemplos de uma condição temporal, uma pessoa pode estar interessada em investigar a influência do sexo (VI) na escolha profissional (VD) ou o efeito de um medicamento (VI) na dor de cabeça (VD). Nesses dois casos, os efeitos não podem alterar as causas. Uma escolha profissional não faz com que a pessoa altere seu sexo, bem como a dor de cabeça é uma condição que antecede a tomada do medicamento. 

Em relação à condição lógica (as vezes chamada de quase-temporal), é possível que alguém queira investigar como a escolaridade afeta o preconceito. Neste caso, é viável assumir que a escolaridade é a VI e o preconceito é a VD. Entretanto, alguém pode sugerir que pessoas mais ou menos preconceituosas se dedicam de maneira diferente em atividades acadêmicas, invertendo essa relação de causalidade.   

Finalmente, uma organização teórica ocorre quando se pretende investigar os efeitos da ansiedade na depressão ou do casamento no bem estar pessoal. A eleição da ansiedade como VI foi uma escolha do pesquisador e não, necessariamente, uma condição temporal ou lógica. Da mesma forma, eleger o casamento como VI é uma escolha feita para responder a uma determinada questão. 


A figura a seguir traz um diagrama inicial destes conceitos, utilizando um esquema em que as horas de estudo teriam efeito sobre a nota da prova.  


![](./img/cap_vi_vd.png) 


É importante notar que a ideia de uma única variável impactando ou causando diretamente uma outra variável é quase metafórica. Para que isso pudesse ocorrer tanto em fenômenos físicos como em quaisquer outros, seria necessário que todas as possíveis fontes de influência existentes neste relacionamento fossem controladas ou suprimidas [@Dumsday2012]. Essa noção de controle total é visto pelo termo *ceteris paribus*, que é uma expressão em latim que significa "tudo o mais constante". Muitas vezes, em pesquisa e estatística, este termo é utilizado quando alguns ajustes são implementados em modelos estatísticos para tentar expressar a ideia de uma causalidade parcial, em que a VI impactaria a VD de uma determinada forma, caso tudo o mais fosse controlado [@Fennell2005]. Evidentemente, há fenômenos sociais que parecem obedecer à certa regularidade e o termo "fato estilizado" tende a ser empregado nestas situações [@Hirschman2016].  


Ao se pensar nas condições em que a VI e VD estejam definidas, é fácil notar que existe um conjunto grande de outras variáveis que podem impactar neste relacionamento. Essas variáveis recebem muitos nomes e o termo <u>variáveis estranhas</u> (VEs) pode servir para designá-las. A imagem a seguir ilustra algumas das variáveis que poderiam impactar na relação entre horas de estudo e notas na prova, previamente assumidas como VI e VD.  
 

![](./img/cap_variavel_estranha.png)

É possível afirmar que em todos os relacionamentos entre duas variáveis, sempre haverá um conjunto de outras variáveis impactando nesta relação. justamente por isso é que cientistas quase nunca digam que estão absolutamente certos de uma determinada condição ou assunto. Na maioria das vezes, como também ilustrado por Popper no livro "Os dois problemas fundamentais da teoria do conhecimento",  cientistas tendem a substituir a palavra certeza por probabilidade.


Para conseguir mapeaer adequadamente o quanto e como outras variáveis impactam no relacionamento VI-VD em um estudo, é necessário ter claro o objetivo que a pesquisa possui, mas também o delineamento implementado para sua execução, o que será descrito a seguir.


### Delineamentos de pesquisa

O termo delineamento diz respeito a etapa de planejamento de pesquisa em que se "considera o ambiente em que são coletados os dados e as formas de controle das variáveis envolvidas" [@gil2002]. Dessa forma, o delineamento funciona como um manual técnico.  É durante esta etapa que o pesquisador terá a oportunidade de eleger as maneiras pelas quais ele irá executar seu estudo e mapear as principais características e limitações existentes. 



Existem diferentes classificações dos delineamentos de pesquisa e cada área tem particularidades. É importante atentar que definir claramente o tipo de delineamento é essencial, já que os objetivos da pesquisa e as análises estatísticas a serem feitas são conectadas a ele. Em Psicologia, costuma-se organizar os delineamentos em observacionais, correlacionais e experimentais. As vezes, o termo delineamento descritivo é utilizado em vez de observacional [@stangor2010]. Por sua vez, em epidemiologia, saúde pública e bioestatística, os delineamentos costumam ser divididos em experimentais e observacionais [@friis2013; @glantz2014]. Apesar das diferenças de nomenclaturas, a lógica por detrás dos delineamentos é bastante atrelada à possibilidade e viabilidade de uma manipulação ativa da VI. 


Em Psicologia, a tabela abaixo é bastante utilizada:

  | Delineamento    | Característica                              | Vantagens                 |  Limitações    
  | :-----------    | :-----------                                | :-----------              |  :-----------      
  | Observacional   | -Apenas 1 grupo é necessário.<br>-Descrever um determinado fenômeno ou objeto. | -Oferece uma foto de um objeto ou fenômeno que tende a ser precisa.<br>-Permite que novos estudos sejam conduzidos.<br>-Tende a ser mais barato do que outros delineamentos.<br>-As vezes, só é possível fazer este delineamento.  |  -Não acessa o relacionamento entre duas ou mais variáveis.    
  | Correlacional    | -Apenas 1 grupo é necessário.<br>-Permite estudar a natureza e a força do relacionamento entre duas variáveis.<br>-As vezes, só é possível fazer este delineamento. | -É possível testar hipóteses sobre este relacionamento e fazer previsões de resultados futuros.<br>-Não é necessário ambientes ou intervenções específicas. | -Não permite indicar causalidade entre os fenômenos ou objetos estudados.    
  | Experimental     | -São necessários 2 grupos em que os participantes sejam alocados de maneira aleatória.<br>-Existe uma manipulação intencional da VI<br>-nem participantes nem pesquisadores sabem quem está em cada grupo (duplo cego).  | -A aleatorização evita que as variáveis estranhas gerem vieses.<br>-A aleatorização aumenta a probabilidade de ambos os grupos terem participantes com características similares<br>-A comparação entre os grupos permite conclusões sobre causalidade, se assumidas algumas condições. |  -Impossível, impraticável ou até mesmo antiético em algumas situações, especialmente as clínicas.<br>-O custo envolvido costuma ser alto.<br>-O tamanho amostral tende a ser pequeno.<br>-Há uma baixa possibilidade de generalização em pesquisas laboratoriais.


Em Epidemiologia, saúde pública e bioestatística, costuma-se unir o delineamento observacional e correlacional. Assim, apenas o delineamento observacional e experimental são definidos, apesar de características virtualmente similares. Pessoalmente, acredito que esta definição evita alguns equívocos, como o de achar que em delineamentos observacionais não é possível realizar correlações ou comparações entre grupos.  


Todos os delineamentos possuem características específicas e um conjunto de vantagens e limitações, que serão apresentadas a seguir.

### Delineamentos observacionais (e correlacionais)  

Em delineamentos observacionais (ou observacionais e correlacionais), o pesquisador não intervém nos fenômenos estudados. Ou seja, não há uma manipulação da VI. Estudos que utilizam tal delineamento quase sempre contam com um único grupo e os resultados produzidos auxiliam no entendimento inicial do fenômeno interesse, bem como podem indicar o perfil de relacionamento entre variáveis.     

Uma vez que não há a formação de grupos específicos seguindo um rigoroso controle da VI, o pesquisador deve mapear adequadamente todas as possíveis variáveis estranhas presentes no relacionamento entre VI e VD <u>antes</u> da pesquisa. Assim, na etapa de coleta de dados, ele poderá acessar essas variáveis para, futuramente, implementar controles estatísticos que reduzam distorções que este delineamento gera nos dados. Por exemplo, quando artigos biomédicos comentam que os resultados de um medicamento são efetivos para os participantes, controlando pela idade e sexo, essa conclusão é bem próxima de resultados obtidos por pesquisas cujos delineamentos foram observacionais.     

::: {.warning}
**Atenção**: Em delineamentos observacionais, o mapeamento e acesso de variáveis estranhas auxiliam o pesquisador a implementar técnicas estatísticas que reduzam as distorções que este delineamento costuma produzir aos dados.     
:::

Nota-se que, apesar de diversas técnicas estatísticas Serem utilizadas neste delineamento, não é possível falar sobre relação de causa e efeito. Apesar desta limitação, há muitas situações em que apenas este delineamento é possível. Por exemplo, estudar os impactos de um desastre natural (furacão, terremoto, etc) na percepção de segurança das pessoas, avaliar o comportamento de grupos em instituições totais, como prisões e hospícios ou as condições relacionadas ao aleitamento materno.  

Uma vez que as eventuais variáveis estranhas foram previamente acessadas durante a coleta de dados, elas deixam de ser estranhas e tornam-se variáveis passíveis de ánalises. A natureza e o local em que essas variáveis impactam no relacionamento entre a VI e a VD indicam se elas serão classificadas como intervenientes, mediadoras ou moderadoras [@Rooney2019; @hayes2013].  

O termo variável interveniente é bastante circunscrito à Psicologia. Ele tende a ser empregado para caracterizar condições psicológicas, como motivação ou neuroticismo. Assim, este é o termo empregado quando as variáveis estranhas são fatores psicológicos.  


Quando esta variável é uma consequência da VI e também impacta a VD, o termo <u>variável mediadora</u> costuma ser empregado. Por exemplo, ao se investigar a relação entre idade (VI) e acidentes de trânsito (VD), pode-se sugerir que pessoas mais velhas tendem a apresentar menor capacidade visual. Por sua vez, essa limitação visual pode gerar acidentes de transito [@Rhodes2011]. Neste sentido, a variável "capacidade visual" é uma variável mediadora.  

![](./img/cap_mediacao.png)


Quando esta variável interfere no relacionamento entre a VI e a VD, podendo alterar sua natureza e intensidade, mas não é gerada pela VI, o termo <u>variável moderadora</u> pode ser utilizado. Por exemplo, a relação entre a satisfação de um cliente (X) e sua lealdade à marca (Y) é moderada pela sua renda [@Sugianto2017]. Pessoas muito satisfeitas com um produto podem ser mais ou menos leais à marca a depender de sua renda disponível. 

A relação entre horas trabalhadas (X) e quantidade de produção (Y) é moderada pela qualidade do equipamento utilizado. É possível que alguém gaste muitas horas de trabalho, mas não consiga produzir absolutamente nada, se os equipamentos disponíveis funcionarem de maneira irregular. Com frequência, medicos sugerem que ao tomar medicamentos antigripais, não se deve ingerir álcool. Nesse sentido, os efeitos do medicamento (X) nos sintomas da gripe (Y) podem inclusive ser opostos em função do álcool, que age de forma moderadora.  

No exemplo prévio sobre o efeito da idade (X) em acidentes de trânsito (Y), sabe-se hoje que o sexo se comporta como uma variável moderadora neste relacionamento. A literatura indica que pessoas mais novas, quando homens, tem uma alta probabilidade de se envolverem em acidentes de trânsito, especialmente os mais intensos ou graves [@Amarasingha2014; @PRB2006].  

  
![](./img/cap_moderacao.png)

Finalmente, é também possível identificar variáveis estranhas que interfiram tanto na VI como na VD, mas que não foram previamente mapeadas ou acessadas durante a coleta de dados. Nestes casos, é típico chamá-las de "terceira variável" ou "variável de confundimento", bem como chamar a relação entre VI e VD de "espúria". Por exemplo, existe uma alta correlação entre venda de sorvete (X) e morte por mordida de tubarão (Y). No entanto, essa é uma relação espúria, uma vez que é a variável "temperatura" que impacta tanto na VI como na VD. Da mesma maneira, existe uma alta correlação entre quantidade de bares e igrejas nas cidades, mas ambos os fenômenos são explicados pela densidade populacional do local.  

![](./img/cap_confundimento.png)

Talvez quando mais novo(a), alguém tenha lhe dito que as cegonhas traziam os bebês. Isso não é verdade, apesar de ser um ótimo exemplo de variável de confundimento. A relação entre número de ninhos de cegonha (X) e número de bebes nascidos (Y) é confundida pela temperatura do local 9 meses atrás [@Matthews2000]. Cegonhas e seres humanos tem seus filhos ou filhotes na mesma época. Curiosamente, como as cegonhas por vezes constroem seus ninhos em telhados de casas, especialmente as com chaminés por conta do calor, as pessoas acreditavam que se uma cegonha fizesse o ninho em seu telhado, isso indicaria que o casal iria ter um filho. Em alguns países, se achava também que deixar doces na janela seria uma maneira de informar as cegonhas que a casa estava pronta para ter um bebê.


![](./img/cap_cegonha.png)


A literatura é bastante rica de exemplos para tais condições, mas também de discussões e debates acadêmicos sobre esses conceitos. A tabela a seguir reúne esforços e exemplifica onde tais conceitos são implementados.  


  | Relacionamento       |  Exemplo   
  | :-----------         | :---------------------------------------------------------------------------------------------------|   
  | Moderação            | Relação entre ansiedade (X) e performance (Y), o tipo de atividade poderia ser uma variável moderadora    
  | Moderação            | Relação entre efeito de um remédio (X) e sintomas de resfriado (Y), a ingestão de álcool poderia ser uma variável moderadora    
  | Moderação            | Relação entre idade (X) e problemas cognitivos (Y), a escolaridade poderia ser uma variável moderadora    
  | Moderação            | Relação entre stress (X) e depressão(Y), o suporte social poderia ser uma variável moderadora    
  | Mediação             | Relação entre idade (X) e uso de mídias sociais (Y), a quantidade de tempo livre pode ser mediadora   
  | Mediação             | Relação entre quantidade de hora de trabalho (X) e desgaste (Y), o retorno financeiro poderia ser mediador   
  | Mediação             | Relação entre conscienciosidade (X) e saúde (Y), comportamentos saudáveis poderia ser mediador   

*Nota: A definição de variável mediadora e moderadora pode ser tornar mais difícil, como é visto no caso entre idade e problemas cognitivos, já que a escolaridade costuma depender também da idade*



Em síntese, a principal característica de estudos com delineamentos observacionais é a <u>não</u> manipulação da VI por parte do pesquisador. 


Como outros exemplos, pode-se listar estudos em que se objetivou investigar os hábitos, práticas e produtividade de pesquisadores [@Wenke2017], a alimentação durante a pandemia [@Amatori2020] ou aspectos epidemiológicos de transtornos mentais de universitários brasileiros, portugueses e espanhóis [@AfonsoJunior2020].

### Delineamentos experimentais    

De maneira geral, delineamentos experimentais representam o melhor exemplo de uma pesquisa científica, além de serem os mais prestigiados no meio acadêmico [@gil2002]. Apesar destes delineamentos poderem apresentar pequenas distinções, o formato mais típico é marcado pelas seguintes características: (1) dois grupos de uma mesma população são formados de maneira aleatória, (2) deve haver uma manipulação intencional do pesquisador sobre a VI e (3) nem o participante, nem o pesquisador sabem em que grupo cada um está, o que é chamado de duplo-cego. 

Cada um desses elementos confere uma propriedade importante para este delineamento. Inicialmente, a formação de dois grupos é uma condição de base deste delineamento e o diferencia de delineamentos observacionais. Nestes últimos, a composição de grupos também pode ocorrer, mas quase sempre após a coleta de dados e para responder questões estatísticas. A alocação dos participantes em ambos os grupos de maneira aleatória assegura que as variáveis estranhas terão impacto equânime em ambos os grupos, além de aumentar a probabilidade de os grupos serão formados por participantes com características similares.  

A segunda característica é a atitude ativa do pesquisador. Neste delineamento, a VI será manipulada e apenas um grupo será exposto a ela, enquanto outro não. O grupo em que a VI será inserida é, tradicionalmente, chamado de experimental, enquanto o outro é chamado de controle.

Finalmente, como nem o pesquisador nem o participante sabem quem está em cada grupo, isso inibe que os participantes tentem mudar de grupo e reduzem o impacto que as expectativas do pesquisador e/ou do participante possam ter sobre os resultados. 

A figura a seguir apresesenta estas características.


![](./img/cap_experimento.png)

É possível notar que o delineamento experimental é, de longe, o que melhor consegue mapear as VIs, VDs, bem como controlar efetivamente as VEs. Essas vantagens dão força para resultados que visem expressar relações de causa e efeito, mas também geram muitas dificuldades. De fato, para arguir sobre causalidade, é necessário precedência temporal, eliminação de explicações alternativas, que a VI sempre esteja presente (necessidade) e que sempre impacte na VD (suficiência). 


Além disso, há algumas condições que limitam ou impedem a execução deste delineamento. O custo para sua realização tende a ser bastante elevado, o tamanho amostral é frequentemente pequeno e pesquisas laboratoriais costumam reproduzir mal o cotidiano das pessoas, diminuindo a capacidade de generalização dos resultados. Para aumentar a capacidade de generalização dos resultados, por vezes, tenta-se implementar este delineamento em ambientes naturalísticos (ou ecológicos). No entanto, apesar de vantagens, isso quebra o princípio da aleatoridade, impactando negativamente para o controle das variáveis estranhas.

Quando as pesquisas são feitas em condições clínicas, a perda e morte experimental são frequentes e muitas condições éticas emergem, impedindo a implementação deste delineamento. Por exemplo, avaliar diferentes situações em relação à amamentação materna (um grupo de mães amamenta seus filhos e outro não), o impacto de desastres naturais no comportamento das pessoas ou o efeito de mudanças abruptas legislativas e sociais na interação entre grupos retratam tal condição. 


Em epidemiologia e saúde pública, este delineamento é também chamado de *Randomized Controlled Trial (RCT)* ou Ensaio Clínico Randomizado. Especialmente nestas áreas, existem diversas situações em que em a VI foi <u>selecionada</u> em vez de manipulada. Quando isso ocorre, o delineamento passa a ser chamado de quase-experimental.


A literatura oferece bons exemplos sobre este delineamento. O psicólogo Albert Bandura [-@Bandura1961] teve o interesse de estudar o efeito da exposição à violência no comportamento agressivo durante a interação social de crianças e, para isso, desenvolveu um delineamento experimental. Ele dividiu as crianças em grupos específicos, em que 1 grupo via uma televisão que passava adultos agredindo um boneco João Bobo e outro via cenas neutras. Os comportamentos agressivos eram avaliados durante o momento do recreio, que ocorria imediatamente após as crianças terem visto televisão. Um grupo de psicólogos visou comparar dois programas de intevenção escolar em um grupo de 164 crianças em vulnerabilidade econômica nos EUA e, para isso, uma parte frequentou aulas de apoio e outra continuou com o ensino usual [@Feil2020]. 
Finalmente, os economistas Redzo e Paul Frijters [-@Mujcic2020] quisem veriricar o efeito da cor de pele na probabilidade de receber uma carona de ônibus. Para isso, eles utilizaram um delineamento quase-experimental, em que atores pretos e brancos entravam em ônibus de uma mesma empresa e perguntavam ao motorista, de uma maneira padronizada, se poderiam viajar de graça 2 estações. A concordância ou não dos motoristas foram tabuladas e, depois, comparadas.



## Considerações sobre escalas de medida e o processo de mensuração em Psicologia
- *L. Anunciação & J. Landeira-Fernandez*  


A existência de um fenômeno é condicionada à uma determinada quantidade. Como atribuído à Thorndike [-@Thorndike1914], “Se algo existe, ele tem de existir em uma certa quantidade e se uma determinada quantidade existe, ela pode ser mensurada”. Assim, tal como em outras ciências, o processo de mensuração é absolutamente vital à Psicologia. Isso pode ser demonstrado tanto pela implementação de técnicas estatísticas para modelar fenômenos psicológico, como pelas lentes de uma das áreas mais voltadas ao desenvolvimento de instrumentos, que é a Psicometria. Entretanto, nunca faltaram céticos de diferentes locais questionando se fenômenos psicológicos poderiam, de fato, ser medidos e uma das primeiras e mais estáveis respostas sobre esse questionamento ocorreu em 1946, com a publicação intitulada “On the theory of scales of measurement” do psicólogo e psicofísico Stanley Stevens.  

Este trabalho apresentou algumas conclusões que até hoje são importantes e que tocam, principalmente (1) à definição de medida, (2) o conceito de escalas (níveis) de medida e (3) à condição da mensuração de fenômenos psicológicos. Inicialmente, Stevens parafraseou N.R. Campbell ao entender que a “mensuração, em sentido mais amplo, é definida como a atribuição de números a objetos ou eventos de acordo com algumas regras” [@Stevens1946, p.677].  

Uma vez feito isso, ele concluiu que esses números são atribuídos (ou existem) em função da possibilidade de  realização de operações estatísticas e matemáticas com eles. Duas regras gerais são subjacentes neste conceito: a primeira é que a as operações possíveis para cada escala são as que se mantêm invariantes para as transformações matemáticas que cada um dos níveis de mensuração aceita e a segunda é que é necessário que haja um isomorfismo (as vezes, apresentado como s(x)) entre os entre os objetos que estão sendo medidos e os números atribuídos a eles.   

Em função destas condições, Stevens descreve quatro escalas que se apresentam hierarquicamente como: (i) nominal, (ii) ordinal, (iii) intervalar e (iv) de razão. Desde o trabalho de Stevens, essa relação entre o valor numérico e o objeto para o qual este valor foi utilizado atraiu ao menos dois grupos de pesquisadores, que são aqueles que possuem um interesse mais voltado à análise de informação que este número ou esta escala traz e, neste sentido, tentam responder à pergunta “O que este número está informando” e os que possuem um maior interesse em desenvolver tratamentos estatísticos a tais números ou escalas e, analogamente, tentam responder à pergunta “Como que se trata estatisticamente tais números?”.  

Posto isso, este seção realiza uma síntese deste conceito, bem como apresenta as descrições de cada uma das escalas, especialmente a partir de uma orientação mais pragmática, suas condições de uso e uma breve contextualização atual.

### Escala nominal

Essa escala é a mais primitiva de todas e a única regra relacionada ao processo de mensuração é que o número atribuído a um determinado objeto ou evento deve ser exclusivo, não sendo possível atribuir um mesmo número a diferentes eventos ou objetos. É importante destacar que os números aqui são arbitrários e, além disso, não refletem grandezas ou magnitudes.  

Nessa escala, só é possível contagens e proporções. Em relação a aspectos estatísticos, é possível obter apenas a moda dos valores. Exemplos concretos são: o número da camisa dos jogadores de futebol, atribuir o valor 1 para homens e 2 para mulheres ou 1 para psicólogos, 2 para geógrafos e 3 para pedagogos.  

É importante notar existem livros e manuais que consideram que quando há apenas dois valores possíveis para o objeto ou evento, o ideal é chamar essa escala de “dicotômica”, “binária” ou “dummy”, mas isso varia bastante em função da área e o consenso não é fácil. Por exemplo, em estudos em ciências sociais, é possível encontrar autores chamando a classificação de sexo biológico (por exemplo, 1 para homens e 2 para mulheres) de variável binária; já em estudos epidemiológicos, é frequente à atribuição do valor “1” para um grupo de pessoas com uma determinada doença e “0” para um grupo de pessoas sem esta doença (apesar disso poder ser entendido como ordinal em alguns casos) e, finalmente, em estudos em economia, por vezes os pesquisadores utilizam o valor “1” para indicar algo de interesse (por exemplo, desempregado) e “0” para caso contrário.  

Tirando essas particularidades, é fundamental entender que os números atribuídos à essa escala são arbitrários e apenas identificam objetos ou eventos.

### Escala ordinal

Nessa escala, os números respeitam uma relação de ordem ranqueada e essa é a regra pela qual os números são atribuídos aos eventos ou objetos.  

É importante ter em perspectiva que essa escala pode ser utilizada pragmaticamente em uma pesquisa mesmo quando o fenômeno que está sendo estudado é facilmente compreendido dentro de uma escala superior, como será visto. Por exemplo, é plenamente possível que um psicólogo meça o tempo de reação de um grupo de pessoas e depois tenha criado categorias ordenadas, como “lento (1)”, “esperado (2)” e “rápido (3)”. Em função disso, alguns livros tentam dividir essa escala a partir de uma origem objeto ou evento que está sendo medido e utilizam de termos como “origem natural” e “origem não natural”, que não serão utilizados aqui (Pasquali, 1998).
Nessa escala, além da contagem, proporções e moda, é também possível identificar mínimo, máximo e amplitude. Exemplos concretos são a Escala de dureza dos metais (Escala de Mohs), o nível de satisfação de uma empresa, onde 1 é baixo, 2 é moderadamente satisfeito e 3 é alto e a posição ao fim de uma corrida, podendo ser o primeiro lugar, segundo ou terceiro.   

### Escala intervalar  

Os números aqui assumem um aspecto propriamente quantitativo e, em outras palavras, quase sempre o número não segue nem uma relação arbitrária (por exemplo, 1 para homens e 2 para mulheres), nem tampouco uma convenção informal (por exemplo, 1 para ensino fundamental e 2 para ensino médio), mas é obtido a partir de um processo em que se contou com a utilização de instrumentos de medida.
Nessa escala, as distâncias entre as categorias são iguais, apesar do valor zero ser uma conveniência. Dessa maneira, a diferença entre categorias será sempre relacional e jamais absoluta. Assim, nesse nível, é possível ter propriedades aditivas, mas não multiplicativas. Considerando unidades arbitrárias, é possível falar que a diferença entre 30 e 29 (1 unidade) é a mesma que entre 15 e 14 (1 unidade). No entanto, no que diz respeito à magnitude do que está sendo medido, nessa escala não é possível falar que 30 unidades é o dobro de 15 unidades.  

Nessa escala, além da contagem, proporções, moda, identificar mínimo, máximo e amplitude, é possível tirar diferenças e fazer adições, bem como calcular a média, a variância e o desvio-padrão dos resultados. 
Exemplos concretos são o calendário que utilizamos. Repare que utilizamos “AC” (antes de Cristo) e “DC” depois de Cristo, estipulando um zero arbitrário; a temperatura sendo medida por graus Célsius ou Fahrenheit, já que cada uma dessas medidas tem um ponto 0 arbitrário. Aproveitando o exemplo da temperatura para ilustrar mais detalhadamente o que significa “0” arbitrário, o valor “0o C” na escala célsius se refere à temperatura que a água congela, enquanto “100o C” se refere à temperatura em que a água entre em ebulição. Em Fahrenheit, esse valor é o “32 o F” e  “212 o C”. 

![](./img/cap_escala_medida_farenheit1.png) 

   
Apesar de haver a possibilidade de conversão de uma escala para outra, repare que não é possível utilizar a propriedade multiplicativa. Por exemplo, enquanto numericamente 30 x 2 = 60, afirmar que 30º C x 2 = 60º C é incorreto. Na verdade, 30º C se refere a 86º F e 60º C se refere a 140º F.  

 ![](./img/cap_escala_medida_farenheit2.png) 
 
 
Assim, apesar de ser intuitivo pensar que se um ambiente tem 32 graus célsius, ele está o dobro de quente de um ambiente que está 16º celsius, isso não é correto.   

### Escala de razão   

Aqui há um 0 absoluto e todas as operações previamente podem ser feitas, bem como o produto das categorias. Escalas de razão são mais encontradas na física. Nessa escala, além das capacidades matemáticas previamente descritas, é possível implementar propriedades multiplicativas. Raramente, essa escala será utilizada em um processo de avaliação psicológica. Entretanto, algumas pesquisas costumam utilizar variáveis que pertencem à escala de razão, como pesquisas em psicofísica que medem o tempo de “tempo de reação” ou pesquisas em neuropsicologia da atenção que medem a “quantidade de botões apertados em um minuto”. É importante novamente alertar que mesmo que essa medida tenha um 0 absoluto (por exemplo, uma pessoa não apertou nenhum botão ao fim de um minuo), isso não significa em nada que o fenômeno psicológico subjacente seja inexistente ou ausente.

### Síntese das características de cada escala

Como exposto logo ao início, os números presentes em cada uma das escalas podem ser entendidos tanto por seus aspectos de informação como pelos procedimentos estatísticos a eles associados. Ambas as iniciativas possuem sua importância e são associadas entre si. Os gráficos expostos abaixo apresentam ambos os conceitos.


![](./img/cap_escala_medida_informacao.png) 


![](./img/cap_escala_medida_analises.png)



### As escalas de Stevens e uma tentativa de agrupamento

Apesar de Stevens ter, fundamentalmente, criado quatro escalas em que sempre haverá números associados a objetos a partir de sua capacidade matemática, teóricos posteriores tentaram agrupar essas quatro escalas em dois conjuntos específicos que costumam ser feitos seguindo este critério: uma vez que a escala nominal e ordinal utilizam os números de uma maneira assegurada apenas por convenção, muitos livros e autores as agrupam como “qualitativas”. Por contraste, como a escala intervalar e de razão são obtidas, majoritariamente, por processos que contam com instrumentos de medida, elas quase sempre são agrupadas como “quantitativas”.   

Mesmo que hoje em dia esse agrupamento seja bastante corriqueiro, origem desta iniciativa é algo incerta. Há sugestão que ela tenha começado pelo trabalho de investigação semiótica de Charles Sanders Peirce. Esse filósofo julgava que a ciência avançava em dez níveis distintos e progressivos, começando por um ícone possível (fancy), passando por um pensamento, um objeto, um símbolo numérico, uma quantidade e uma relação [@smart1999, p.289]. Infelizmente, essa classificação pode gerar uma divisão desnecessária dentro do próprio conceito desenvolvido por Stevens, além de gerar bastante confusão, já que o termo “pesquisa qualitativa” não costuma se referir às escalas de medida, mas sim à uma área que mais recentemente emergiu com uma forma metodológica distinta e, eventualmente, até mesmo crítica às iniciativas de medida e mensuração. Além disso, o termo “quantitativa” atribuído apenas à escala intervalar e de razão pode dar a impressão inadequada de que não se usa números nas escalas nominais ou ordinais. Finalmente, é importante frisar que há livros que utilizam o termo “categórica” para “qualitativa” e “propriamente numérico” para “quantitativa”, aumentando algo mais os cenários de confusão. A imagem a seguir apresenta esta tentativa.
	 
![](./img/cap_escala_medida_agrupamento.png)



### Variáveis discretas ou contínuas

A iniciativa de classificar as variáveis e, consequentemente, escalas de medida não foi apenas feita em estudos psicológicos. Evidentemente, áreas como matemática, probabilidade e estatística também tiveram (e ainda possuem) interesse em classificar as variáveis e uma das maneiras pelas quais isso é feito diz respeito à forma como os valores se apresentam, especialmente em sua capacidade informacional [@morettin_bussab_2010].  

Qualquer variável cujo resultado só possa descreve uma quantidade contável, em que os valores potenciais podem ser enumerados em uma ordem é chamada de discreta e é caracterizada por uma função de massa probabilidade (em inglês, probability mass function). Por sua vez, uma variável cujos valores potenciais não podem ser enumerados em uma ordem inequívoca é chamada de contínua e tem uma função de densidade de probabilidade (em inglês probability density function). Um atalho cognitivo bastante frequente apesar de apenas parcialmente correto pode auxiliar: variáveis discretas costumam ter valores inteiros, tal como número de filhos, caixas de remédios vendidas por uma farmácia e vezes que um paciente buscou auxílio médio; por sua vez, as variáveis continuar reúnem números fracionários, tal como a altura dos filhos, o retorno financeiro em Reais que a venda dos remédios e o tempo gasto em cada em cada consulta média.  

Quando se tenta fazer uma comparação entre a classificação de escalas de medida  desenvolvida por Stevens e a classificação das variáveis em discretas e contínuas, é possível considerar que a escala intervalar e de razão podem também ser entendidas como discretas e continuas. Excepcionalmente e apenas para fins de modelagem estatística, as variáveis classificadas como nominais e ordinais podem ser entendidas também como discreta [@Borgatta1980; @privitera2016, p.20]


### Hierarquia da classificação e a importância desses conceitos hoje em dia  

Uma vez que as escalas dependem das capacidades matemáticas associadas, uma escala de maior nível pode ser convertida em uma escala hierarquicamente inferior. Isso foi previamente apresentado na escala ordinal com o exemplo de tempo de resposta. Esse processo de transformação costuma ser chamado de “categorização” e pode ser facilmente visto em outros exemplos. Por exemplo, a altura das pessoas (razão, contínua) pode ser classificada em baixas ou altas e a temperatura em Kelvin (razão, contínua) pode tanto ser entendida de maneira intervalar (Celsius, por exemplo), ordinal (muito frio, frio, quente, muito quente) ou (agradável e desagradável).  

Apesar dessas classificações de escalas/níveis de medida terem importância acadêmica, em situações de análise de dados, quase nunca a diferenciação entre os 4 níveis de medida tem relevância ou utilidade. Além disso, o próprio Stevens, tempos depois, em 1959, reviu algo de sua classificação e reconheceu que as regras de invariância também permitiam uma nova escala, chamada de “log-intervalar” [@stevens1959]. Essa escala quase nunca presente em livros didáticos.   

Além disso, como programas estatísticos são frequentemente utilizados para realizar procedimentos de análises de dados, eventualmente eles sequer utilizam as mesmas nomenclaturas ou apenas entendem as variáveis como discretas ou contínuas. Mesmo na academia, autores como D. Howell consideram que esse aspecto da medida tem apenas relevância histórica, sendo irrelevante hoje em dia [@howell2011, p. 18].  

Finalmente, a partir da tentativa de desenvolver ou aperfeiçoar o isomorfismo entre relações empíricas e relações algébricas, em que houvessem regras bem definidas articulando os números às coisas (tal como visto em Campbell), e que tivessem propriedades matemáticas específicas e bem definidas (tal como visto em Stevens) outras classificações foram surgindo. Entre eles, a Teoria representacional da medição (Patrick Suppes) e a Teoria da Medida Aditiva Conjunta (TMAC) [@Michell1993]. 

### Em qual escala devemos classificar os testes psicológicos  

Psicólogos e outros cientistas comportamentais utilizam com frequência instrumentos de medida para acessar variáveis como atenção, memória, personalidade e inteligência. De maneira análoga às outras áreas empíricas, esses instrumentos geram resultados numéricos que, por sua vez, são utilizados para as mais diferentes finalidades.   

Da mesma forma que para maioria dos fenômenos medidos, o nível de medida não é inerente aos dados [@Velleman1993]. Com isso, o debate sobre qual nível de medida devem ser entendido os números obtidos por instrumentos psicológicos parece estar sempre aberto. Uma primeira resposta veio do próprio Stevens, que assumindo que as operações possíveis em cada escala devem ser invariantes comentou que: 

> A maioria das escalas usadas amplamente e efetivamente por psicólogos são ordinais. De maneira estrita, médias e desvios-padrão não devem ser utilizados nessas escalas, uma vez que para essas estatísticas se deva saber algo mais do que a ordem relativa dos dados. Por outro lado, pode-se evocar uma espécie de confirmação pragmática para esse uso ‘ilegal’ da estatística: em inúmeras situações o seu uso conduziu a resultados frutuosos (Stevens, 1946, p. 679, aspas do autor original).  

Já no meio acadêmico, é bem possível que ninguém consideraria que os resultados obtidos por um processo de testagem psicológica sejam nominais ou de razão. Entretanto, há bastante divergência em relação quanto ao nível ordinal ou intervalar. Excetuando os que julgam que os resultados estão entre esses dois níveis, há aqueles que julgam que a escala ordinal é a adequada para qualquer instrumento psicológico. Para esses autores, não seria possível sequer somar ou diminuir os valores obtidos em itens de um teste de inteligência ou inventário de atitude. Eventualmente, decisões como essa são bastante rígidas e só mais recentemente, principalmente pelo incremento do poder computacional, essas decisões tiveram contrapartida analítica (Análise Rasch e Teoria de Resposta ao Item, por exemplo). 
Apesar de rígida, essa consideração tem fundamento, já que pela hierarquia dos níveis de medida, só é possível um processo descendente (razão para intervalar, etc) e não ascendente (intervalar para razão, por exemplo). Isso também pode tanto ser visto em instrumentos do tipo questionários e instrumentos com respostas certas e erradas. Uma vez que a escala intervalar assume equidistância entre os valores, considerar que as distâncias de itens Likert (concordo totalmente a discordo totalmente) ou Tipo-Likert (nada a muito) são iguais é uma justificativa bastante frágil. Já em instrumentos de inteligência, também seria pouco adequado assumir que a diferença de 1 ponto traria a mesma informação isomórfica entre uma pessoa que teve 80 pontos e outra 79 pontos em um teste de inteligência e entre uma pessoa que obteve 130 pontos e outra que obteve 129 pontos neste mesmo teste.  

Em outro sentido, um grupo maior de acadêmicos consideram os resultados obtidos por um processo de testagem como intervalares e, consequentemente, utilizam técnicas estatísticas mais robustas para os dados. Essa condição quase sempre era justificada de maneira pragmática, vem ganhando maior sustentação hoje em dia, especialmente em estudos de simulação, em que os pesquisadores criam a possibilidade de comparar resultados estatísticos obtidos considerando os dados ou como ordinais ou como intervalares [@Wu2017].  

Dessa forma, uma vez que esse tema ainda reflete uma questão em aberta, respostas definitivas não são possíveis (nem desejáveis), colocando sobre o pesquisador a justificativa analítica e teórica das decisões por ele tomadas.



## Principais áreas da estatística 

A estatística pode ser dividida em duas áreas interligadas: estatística descritiva e estatística inferencial. O objetivo da estatística descritiva é apresentar sínteses e resumos dos resultados de uma pesquisa pela utilização de gráficos e tabelas. Não é proposta dessa área fazer generalizações ou extrapolar os resultados obtidos a objetos ou pessoas não investigadas durante a coleta de dados. Por contraste, a estatística inferencial visa extrapolar os dados e fazer generalizações que toquem toda população de onde aquela mostra foi retirada e é representativa. Dessa maneira, o principal objetivo da estatística inferencial é, de fato, fazer inferências. 

Essa divisão é certamente mais didática do que pragmática e, com muita frequência, ambas as áreas estão presentes em uma pesquisa. No entanto, alguns pontos merecem destaque:

1. A estatística descritiva surgiu antes que a inferencial. A etimologia da palavra talvez ajude a entender. Estatística vem da palavra estado e este sempre teve interesse em saber quantos eram os cidadãos de um determinado local para, entre outras atividades, taxá-los. Assim, aspectos descritivos antecedem os inferenciais. Por sua vez, a estatística inferencial guarda origem e proximidade com a teoria dos jogos e, consequentemente, isso ajuda a entender o motivo pelo qual a maioria dos exemplos inferenciais envolvem jogos de azar.

2. A estatística (inferencial) tem duas "escolas" ou "formas de pensamento". A estatística frequentista e a estatística bayesiana. Aspectos fundamentais que tocam à definição de probabilidade são diferentes, bem como a definição de dados e parâmetros também o são. Pela perspectiva histórica, a estatística bayesiana é mais antiga que a frequentista. No entanto, a proporção de uso da estatística frequentista é mais frequente.

3. A relação entre estatística e Machine Learning é relativamente recente. Apesar de grande interface e do fato que as análises realizadas em estatística e ML encontram resultados virtualmente idênticos, há diferentes argumentos sugerindo que as áreas têm objetivos diferentes (o que eu não necessariamente concordo). Neste livro, técnicas e análises de Machine Learning não serão apresentadas.


![](./img/cap_areas_estatistica.png) 



## Resumo  
::: {.explore}
1. A estatística está totalmente integrada ao planejamento, execução e análise de dados de uma pesquisa  
2. As pesquisas apresentam objetivos, dimensões temporais e procedimentos específicos para coleta de dados  
3. Em relação ao objetivo, uma pesquisa pode ser exploratória, descritiva ou explicativa   
4. Em relação à dimensão temporal, uma pesquisa pode ser transversal ou longitudinal  
5. Em relação ao delineamento, uma pesquisa pode ser observacional ou experimental  
6. Cientistas contróem modelos teóricos pela impossibilidade de acessar diretamente seu objeto ou fenômeno de investigação   
7. As variáveis são características que podem apresentar quaisquer valores    
8. A VI também é chamada de preditora, enquanto a VD é chamada de prevista    
9. Em todo relacionameto bivariado, outros fatores estão envolvidos  e são chamados de variáveis estranhas   
10. Com muita frequência, em ciência se substitui os termos certeza e verdade por evidência e probabilidade.
::: 


## Questões  

<div class="question">

1. (ENADE,2015) O profissional de marketing de uma empresade cosméticos foi encarregado de redesenhar o aparelho de depilação feminino comercializado por essa empresa. Para tanto, o profissional fez uma pesquisa de mercado utilizando entrevistase discussões em grupo (grupo focal) com mulheres de segmentos diferentes do mercado-alvo potencial do produto, tendo em vista que a depilação é considerada uma experiência pessoalpelas mulheres. Esta é uma pesquisa exploratória.<br>a) Verdadeiro<br>b) Falso
 
</div>

<div class="mirror">Gabarito: 1b</div>

<!--chapter:end:02-aspectos_gerais.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# Estatística Descritiva

```{r base pesquisa_espanha e pacotes, include = FALSE }

load("~/anovabr/mqt/bases/Base R - Pesquisa mapfre.RData") #base

library(tidyverse)
library(pander)
library(janitor)
library(gridExtra) #plot together

```


```{block, type="objectives"}
**Objetivos do capítulo**  
1. Introduzir conceitos importantes em estatística descritiva  
2. Apresentar tabelas e gráficos  
3. Apresentar funções do dplyr e ggplot    
4. Apresentar um módulo específico do JASP   
5. Sugerir heurísticas ou regras gerais na criação de gráficos  
```

Quando pesquisadores e acadêmicos fazem seus estudos, com muita frequência, eles obtêm um grande conjunto de dados, sendo pouco informativo ou até mesmo inviável apresentar detalhadamente todos eles. A estatística descritiva oferece uma diversidade de ferramentas que auxiliam a organizar, descrever, resumir e apresentar os dados obtidos, de forma que os resultados sejam mais fáceis de serem compreendidos e analisados e, consequentemente, que a pesquisa possa ser melhor compreendida por todos os seus leitores.     


::: {.warning}
**Atenção**: A estatística descritiva dispõe de inúmeras ferramentas para auxiliar na gestão e apresentação de dados.    
:::


Frequentemente, a massa de dados obtidos em uma pesquisa é resumida por alguns números específicos, que possuem certas propriedades estatísticas, e conseguem sintetizar adequadamente o volume de dados. Por sua vez, esses números são úteis em análises que possam ser necessárias e serão descritos em outra seção deste capítulo.   

Na apresentação dos dados, é possível utilizar <u>informações textuais</u>, <u>tabelas</u> e <u>gráficos</u>. Tabelas e textos permitem agrupar e detalhar os resultados e, com isso, torná-los mais precisos e detalhados. Entretanto, esse aprofundamento pode também dificultar o entendimento geral do estudo. Por sua vez, gráficos geram sumários descritivos, em que é possível ter um entendimento rápido dos principais resultados. Eles também podem incorporar elementos adicionais, que possibilitam uma primeira análise inferencial, tal como barras de erro e intervalos de confiança. Dependendo do tipo de gráfico, além da apresentação de resultados descritivos, é possível também expor <u>diferenças</u> entre grupos ou  <u>relações</u> entre variáveis.   

Apesar dessas vantagens, algumas limitações podem ser encontradas nos gráficos. Uma vez que os eles condensam um grande conjunto de resultados em uma apresentação mais simples, eles podem dificultar um pouco no entendimento geral das conclusões obtidas pela pesquisa e, ocasionalmente, distorcer os resultados. 


No geral, cada uma dessa formas de apresentar os resultados de uma peaquisa traz consigo vantagens e desvantagens, listadas a seguir:  


  | Tabelas                                          | Gráficos                   
  | :-----------                                     | :-----------                        
  | **Vantagens**      
  | Auxiliam a organizar os resultados               | Condensam vários resultados      
  | Permitem detalhar e aprofundar os resultados     | Auxiliam a identificar padrões nos resultados        
  | Apresentam os resultados de maneira mais precisa | Auxiliam a visualizar o relacionamento entre variáveis      
  | Buscadores (google, etc) encontram os resultados | Permitem confirmar ou não suposiÇões incialmente feitas sobre os dados    
  |                                                  | Fáceis de serem entendidos quando bem feitos      
  | **Limitações**      
  | Podem dificultar o entendimento dos resultados  | Podem simplificar demasiadamente os resultados        
  |                                                 | Podem distorcer severamente os resultados quando mal feitos        


 
É importante atentar que em todas estas técnicas, mas especialmente nas gráficas, deve-se evitar gerar distorções ao entendimento e interpretação dos resultados. Há casos de pessoas e profissionais que chegaram a sofrer sanções jurídicas por distorções intencionais em apresentação estatísticas. Há recomendações nacionais e internacionais que visam auxiliar no desenvolvimento de gráficos e tabelas e, com grande frequência, periódicos e editoras também exigem formatos específicos na apresentação dos resultados. 
 
## Tabelas   

As tabelas são recursos estatísticos que permitem a apresentação dos resultados de uma pesquisa de maneira resumida, reunida e objetiva. É possível utilizá-las para apresentação de apenas uma ou múltiplas variáveis, que podem ser categóricas ou contínuas. Todas as tabelas precisam de títulos e, eventualmente, algumas notas podem auxiliar no entendimento dos resultados.   

O formato padronizado para desenvolvimento de tabelas costuma variar de revista para revista No entanto, é possível notar que, quase sempre, os números são arredondados em 2 casas decimais e apenas as linhas possuem bordas. A imagem abaixo apresenta uma tabela construida pelas recomendações da American Psychological Association (APA).

![](./img/cap_desc_tabela.png)



## Gráficos  

Gráficos são representações visuais utilizadas para exibir dados. Da mesma forma que tabelas, eles podem ser formados por uma ou múltiplas variáveis. Quando uma única variável é apresentada em um gráfico, sua finalidade tende a ser apenas descritiva. Quando duas ou mais variáveis são apresentadas, eles auxiliam a comparar os resultados entre grupos ou explorar o relacionamento entre variáveis.  

Se bem feitos, os gráficos são extremamente úteis e auxiliam o rápido entendimento dos resultados obtidos em uma pesquisa. Como aponta Morettin e Bussab [-@morettin_bussab_2010], eles possibilitam:   

(a) Buscar padrões e relações;     
(b) Confirmar (ou não) certas expectativas que se tinha sobre os dados;   
(c) Descobrir novos fenômenos;  
(d) Confirmar (ou não) suposições feitas sobre os procedimentos estatísticos usados; e  
(e) Apresentar resultados de modo mais rápido e fácil.  

É sempre importante que o gráfico tenha um título e uma escala e, quando necessário, notas complementares. 


A maioria dos gráficos são construídos em um plano com um eixo horizontal (abcissas) e um vertical (ordenadas). Quando há apenas uma variável para apresentar, o eixo X irá reunir os níveis ou possíveis valores desta variável, enquanto o eixo Y irá apresentar suas contagens, proporções ou densidade. Quando há duas variáveis, o eixo X será utilizado para apresentar os níveis ou possíveis valores da variável independente, enquanto o Y apresentará os valores médios encontrados na variável dependente, tal como apresenatdo a seguir.   

![](./img/cap_grafico_tutorial.png)

Quando há mais de uma variável independente, um agrupador ou cluster deverá ser apresentado. Com frequência, o eixo X recebe a variável independente com mais níveis, enquanto o agrupador recebe as outras. A imagem a seguir descreve este cenário.    

![](./img/cap_grafico_tutorial2.png)

Há diferentes heurísticas que auxiliam na escolha de um gráfico adequado para apresentar os resultados de uma pesquisa. De forma geral, essa escolha pode ser pautada por duas perguntas:  

1. <mark>Quantas</mark> variáveis serão apresentadas ?  
2. Qual o <mark>nível de medida</mark> da variável (ou variával independente quando há duas ou mais)?  

Com isso, o diagrama abaixo oferece uma árvore de decisão funcional.


![](./img/cap_como_fazer_graficos.png)
  
*Nota: Nessa apresentação, pragmaticamente as variáveis categóricas são tratadas como discretas.*

A imagem a seguir ilutra alguns desses gráficos. Suas características serão apresentadas em seguida. 


![](./img/cap_graficos.png) 


A apresentação de gráficos tende a seguir um desenvolvimento hierárquico. Inicialmente, gráficos univariados para variáveis categóricas e contínuas são criados. Em seguida, gráficos apresentando diferenças e relações entre grupos e variáveis são feitos.  Na seção [Pesquisa](#pesquisa), diferentes gráficos serão gerados para ilustrar o processo.   

## Medidas de posição e dispersão  

Uma vez que é pragamaticamente inviável apresentar detalhadamente todos os dados obtidos em uma pesquisa, há um conjunto de números podem ser utilizados para <u>resumir</u> todo o conjunto. Eles costumam ser chamadados de números-síntese, medidas resumo, medidas estatísticas ou apenas estatísticas e podem ser agrupados em <u>medidas de posição</u> e <u>medidas de dispersão</u>, que serão descritas a seguir.

<mark>Medidas de posição</mark>: São valores que representam a concentração dos dados observados. Podem ser divididas em medidas de tendência central, medidas separatrizes e medidas de posição relativa. 

As medidas de tendência central (MTC) indicam o valor em torno do qual uma grande proporção de outros valores está centralizada. As MTC mais usadas são a moda, a média e a mediana. 

As separatrizes também são chamadas de quantis ou medidas de ordenamento. Elas são valores que indicam posições em uma distribuição ordenada acumulada dos dados. Os principais quantis utilizados são os quartis (divisão dos dados em 4 partes iguais), decis (divisão em 10 partes iguais) e percentis (divisão em 100 partes iguais). 


As medidas de posição relativa são as vezes chamadas de Escore padrão. Elas são valores que indicam as posições que cada valor do conjunto de dados em relação a todos os dados. O Escore Z, o Escore T e o Escore QI tendem a ser classificados como como medidas de posição de relativa e são bastante utilizados em Psicometria. 


É possível notar que essa divisão tão detalhada pode gerar inconsistências e é raramente utilizada na prática. No dia a dia, as medidas de tendência central abrangem pragmaticamente todas as medidas de posição.  

<Mark>Medidas de dispersão </mark>. Também chamadas de medidas de variabilidade ou afastamento. São Valores que indicam o quão dispersa se encontra a distribuição dos valores em relação à alguma medida de tendência central. Entre as medidas de dispersão, estão a amplitude, a amplitude (ou intervalo) interquartil, a variância, o desvio-padrão e o coeficiente de variação. Em Psicologia, o desvio-padrão e a amplitude interquartil (também chamado de intervalo interquartil) são as mais utilizada.  


O diagrama abaixo apresenta estas informações.


![](./img/cap_desc_medidas_posicao_dispersao.png)



Como previamente comentado, esse detalhamento tem pouco sentido prático na maioria das pesquisas. Apenas em raras exceções, como em Psicometria, é que discussões sobre percentis e Escores Z são feitas. Assim, apesar do esforço feito para reunir as principais medidas estatísticas utilizadas, a organização apresentada no diagrama a seguir traz maior utilidade.


![](./img/cap_desc_medidas_posicao_dispersao2.png)

As principais medidas serão agora apresentadas de uma maneira simples. Esse formato é proposital, uma vez que a proposta do livro é discutir tais conceitos pela apresentação de pesquisas específicas e previamente publicadas.  


## Média

A média é a MTC mais comum e mais intuitiva. Seu valor representa o “centro de gravidade” da distribuição, descrevendo a maior concentração dos valores em torno dela. Assim, ela resume o conjunto de dados e pode ser utilizada para substituir os outros valores, o que é especialmente útil quando há casos ausentes.  

Para ilustrar, imagine a seguinte situacão. 10 pacientes foram avaliados por um teste de inteligência e apresentaram os resultados abaixo descritos:  

```{r, echo = FALSE }
set.seed(1)
rnorm(11, mean = 100, sd = 15) %>% pander()
```

A média indicará o valor central da distribuição em relação à distância entre os outros valores.

```{r, echo = FALSE }
set.seed(1)
mean(rnorm(11, mean = 100, sd = 15)) %>% pander()
```
   
Caso uma tabela seja apresentada e nela seja calculada a distância de todos os valores em relação à média, os resultados seriam assim:

```{r, echo = FALSE }
set.seed(1)
rnorm(11, mean = 100, sd = 15) %>% data.frame() %>% setNames(., c("Resultado")) %>% 
mutate(media = mean(Resultado)) %>% 
mutate(distancia = Resultado-media) %>% 
pander()
```
Somando as distâncias, o resultado será `0`, indicando que elas se anulam e que a média é o centro da distribuição.

```{r, echo = FALSE }
set.seed(1)
rnorm(11, mean = 100, sd = 15) %>% 
  data.frame() %>% setNames(., c("Resultado")) %>% 
  mutate(media = mean(Resultado)) %>% 
  mutate(distancia = Resultado-media) %>%
  mutate_if(is.numeric, round, 1) %>% 
  mutate(media = as.character(media)) %>% 
  janitor::adorn_totals() %>% 
  pander()
```

A tabela a seguir apresenta algumas características vantajosas e possíveis limitações da média.


  | Vantagem                           | Limitação                          |  
  | :-----------                       | :-----------                       | 
  | É intuitiva                        | Sensível                           | 
  | Algebricamente tratável            | Não adequada a dados nominais      | 
  | Estimador não viesado              |                                    | 
  | Sensível                           |                                    | 

*Nota: Uma medida sensível significa que ela é influenciada por todos os outros valores.*

<mark>Exemplo de aplicações</mark>: Praticamente, em todas as pesqusias se utiliza a média para resumir os volume de dados obtidos. Como exemplos em Psicologia, a média de valores de inventários e testes psicológicos, a média do tempo de reação que um participante demora para responder à uma atividade específica e a média de consultas clínicas que em média um profissional realiza.    


## Mediana

A mediana é uma medida que representa o centro do conjunto de dados quando se considera a quantidade de elementos presentes. Portanto, a mediana divide a quantidade de dados em duas partes iguais, em que 50% dos dados estão abaixo dela e 50% dos dados estão acima dela. A mediana pode ser classificada tanto como uma medida de tendência central, como uma separatriz [@neto2010].  

Dessa forma, os resultados da mediana são iguais aos resultados do 2º quartil, 5º decil e percentil 50. Comparada com a média, os resultados obtido pela mediana são mais robustos ou resistentes aos valores atípicos ou anômalos, apesar de menos intuitivos.  

Para dividir a distribuição em duas partes iguais, a realização da mediana precisa de alguns procedimentos. Repare que abaixo estão os mesmo resultados apresentados na seção da média:


```{r, echo = FALSE }
set.seed(1)
rnorm(11, mean = 100, sd = 15) %>% pander()
```

Para o cálculo da mediana, é necessário organizar essa série de valores de maneira ascendente (chamado de rol) e localizar o resultado ao centro. Nesse caso, o valor ao centro é `104.9` . Note que este valor divide os dados em duas partes iguais de elementos abaixo ou acima dele.


```{r, echo = FALSE }
set.seed(1)
rnorm(11, mean = 100, sd = 15) %>% sort(.) %>% pander()
```

Caso a quantidade de elementos seja impar, a localização da mediana é mais fácil. Caso esta quantidade seja par, a mediana será calculada pela média aritmética dos dois elementos centrais.

A tabela a seguir descreve algumas características vantajosas e possíveis limitações da mediana.


  | Vantagem                                                   | Limitação                          |  
  | :-----------                                               | :-----------                       | 
  | Resistente a valor anômalos/Outliers                       | Não representa todos os valores    | 
  | Adequada para dados ordinais, intervalares e de razão      | Não adequada a dados nominais      | 
  |                                                            | Pouco adequada a tratamentos algébricos futuros     | 


<mark>Exemplo de aplicações</mark>: Situações em que a distribuição é muito assimétrica. Variáveis econômicas como salário e pobreza costumam trabalhar com a mediana dos dados.    

## Moda  

A moda é a realização mais frequente de um conjunto de dados. Salvo algumas exceções, a moda não costuma ser utilizada em análises estatísticas, uma vez que representa mal o conjunto de dados.  

<mark>Exemplo de aplicações</mark>: Situações em saúde pública, como a idade mais típica que uma menina tem o primeiro filho, dia e/ou horário modal de Admissão em um hospital. Situações economômicas de determinação de salários mínimos, eventualmente, também pode contar com resultados modais.  


## Amplitude

A amplitude é uma medida de dispersão que indica a variabilidade dos dados. O procedimento para seu cálculo é a subtração entre o maior e o menor valor de um conjunto de dados.  

## Amplitude interquartil

A amplitude interquartil também é chamada de intervalo interquartil. Essa medida apresenta a variabilidade dos dados de maneira insensível a valores extremos. Ela é computada pela subtração do primeiro quartil (Q1) pelo terceiro quartil (Q3), ou seja, `Q3-Q1`. Os quartis são medidas que indicam posições de separação no conjunto ordenado de dados.  

O primeiro quartil indica o valor onde estão até 25% dos dados, o segundo quartil tem o mesmo valor da mediana e o terceiro quartil indica o valor onde estão até 75% dos dados. 

Como a amplitude interquartil considera apenas a variabilidade em torno do centro, ela é uma medida considerada mais estável ou robusta quando comparada a outras medidas de dispersão.

## Variância e Desvio-padrão

A variância e o desvio-padrão são duas medidas de dispersão frequentemente utilizadas em estatística de maneira intercambiável. 

A variância indica a variabilidade quadrática de um conjunto de dados, considerando todos os valores da distribuição. Pela sua estrutura matemática, seu resultado expressa o desvio <u>quadrático</u> médio e, com isso, seu valor <u>não</u> está na mesma unidade dos dados originais.  

A variância é uma medida fundamental no estudo das famílias de distribuições de probabilidades e análises estatísticas. No entanto, na prática, ela é pouco usada para descrever a variabilidade dos dados e acaba sendo usada apenas de forma transitória para o cálculo do desvio-padrão. 

O desvio-padrão indica a variação dos valores em torno da média, e como seus resultados são calculados pela raiz quadrada da variância, o desvio-padrão está na mesma unidade dos dados originais. Dessa forma, o desvio-padrão tem uma melhor característica descritiva.  

Em síntese, enquanto a variância possui maior importância em aspectos matemáticos relacionados às famílias de distribuições de probabilidade, o desvio-padrão tem melhor adequação descritiva de um conjunto de dados.  Conceitualmente, as equações a seguir descrevem à variância amostral (à esquerda) e o desvio-padrão amostral (à direita):

\begin{equation}
  \begin{split}
    S^2 = \sqrt\frac{\sum\limits_{i=1}^N (X -\mu)^2}{N-1}
  \end{split}
\qquad\qquad
  \begin{split}
    S = \frac{\sum\limits_{i=1}^N (X -\mu)^2}{N-1}
  \end{split}
\end{equation}


Após estas apresentações teóricas, espera-se que seja possível apresentar a pesquisa a seguir, bem como implementar parte dos conceitos nos dados obtidos.  



## Pesquisa
  
<div class="alert alert-warning">
  <strong>Base:</strong> [Base R - Pesquisa mapfre.RData](https://github.com/anovabr/mqt/raw/master/bases/Base%20R%20-%20Pesquisa%20mapfre.RData)
</div>  

Neste capítulo, vamos utilizar a pesquisa intitulada ["Depression and Anxiety Symptoms in a Representative Sample of Undergraduate Students in Spain, Portugal, and Brazil"](https://doi.org/10.1590/0102.3772e36412 ). Nessa pesquisa, sou o coautor e o pesquisador responsável para correspondência. O objetivo deste estudo foi desenvolver um mapa epidemiológico de sintomas de ansiedade e depressão em universitários em três países, bem como investigar possíveis relações entre tais condições de saúde e fatores sociodemográficos. Para acessar eventuais transtornos depressivos, o Inventário Beck de Depressão (BDI) foi utilizado e para acessar condições de ansiedade, o Inventário Beck de Ansiedade (BAI) foi utilizado. Em ambos os inventários, valores altos sugerem que condições de agravo à saúde mental podem estar presentes.  

Um diferencial importante do trabalho foi a seleção amostral. Partiu-se de uma amostra estratificada (probabilística) dos estudantes de três universidades, PUC-Rio (Brasil), Universidade de Extremadura (Espanha) e Universidade de Coimbra (Portugal). Isso permitiu ter maior validade externa dos resultados.


## Execução no R 

Inicialmente, é necessário carregar a base de dados previamente descrita para o ambiente R. Este procedimento será necessário para todos os capítulos do livro. Frequentemente, uma primeira tabela informativa começa descrevendo as variáveis categóricas, que deve apresentar suas contagens e proporções. Nesta pesquisa de agora, tanto a variável <u>country</u> como <u>sex</u> são categóricas e serão utilizadas.  

como três países fizeram parte da pesquisa, os dados serão agrupados por eles. O desenvolvimento desta tabela pode ser feito com pacote `janitor`, tal como demonstrado a seguir.

```{r}
Dataset %>% 
  tabyl(country) %>% 
  adorn_totals() %>% 
  pander()
```

A adição de um um outro agrupador relacionado ao sexo é também importante. Note que existem casos ausentes nesta variável. Isso ocorre com bastante frequência e há diferentes estratégias para lidar com isso, que serão discutidas em momento oportuno. Para que valores ausentes não sejam apresentados, a função `filter` será implementada.  É importante atentar que os dados ausentes <u>não</u> foram excluídos. Eles apenas não são apresentados.   

```{r}
Dataset %>% 
  filter(!is.na(sex)) %>% 
  tabyl(sex, country) %>% 
  adorn_totals() %>% 
  pander()
```

Para apresentar a quantidade total de participantes, bem como a quantidade e a porcentagem de homens e mulheres por país, a codificação torna-se um pouco mais densa. A tabela a seguir reproduz parcialmente a tabela 1 do artigo publicado.  

```{r}
Dataset %>%
  filter(!is.na(sex)) %>% 
  tabyl(country, sex) %>%
  adorn_totals(c("row", "col")) %>%
  adorn_percentages("row") %>% 
  adorn_pct_formatting(rounding = "half up", digits = 0) %>%
  adorn_ns() %>%
  pander()
```
Enquanto as tabelas com variáveis categóricas apresentam contagens e suas respectivas porcentagens, tabelas para variáveis contínuas costumam utilizar medidas de posição e dispersão. A média e a mediana são os sumários mais utilizados para indicar a posição ou a concentração dos dados. Por sua vez, o desvio-padrão e a amplitude ou intervalo interquartil são utilizados para indicar o afastamento dos dados dessas medidas de posição.   

O R oferece muitos pacotes especializados em tabelas descritivas, cada qual com características positivas e limitadoras. Neste capítulo, o pacote `arsenal` será utilizado.   


De maneira análoga à construção da primeira tabela deste capítuo, os valores do BDI e do BAI serão apresentados em função do país do participante.

```{r, results = "asis" }
arsenal::tableby(country ~ bdi_sum + bai_sum, test = FALSE, data = Dataset) %>% summary()
```

É também possível reunir tais resultados a partir do sexo do participante.

```{r, results = "asis" }
arsenal::tableby(sex ~ bdi_sum + bai_sum, test = FALSE, data = Dataset) %>% summary()
```

A apresentação agrupando pelo país e sexo do participante é possível e reúne mais informações. A tabela encontra-se abaixo:  

```{r, results = "asis" }
arsenal::tableby(interaction(sex ,country) ~ bdi_sum + bai_sum, 
                 control=arsenal::tableby.control(test=FALSE, total=FALSE),
                 data = Dataset) %>% summary()
```


## Gráficos

Como previamente exposto, os gráficos são excelentes recursos visuais para apresentação dos resultados obtidos em uma pesquisa. No R, a principal máquina gráfica é o `ggplot.` Para executar um gráfico, pelo menos 3 argumentos são necessários:

1. O banco dados `(data = )`,      
2. O aspecto estético, que permite diferentes complementos `aes(x = , y = , fill = , color = , group = , shape = )`,  
3. O aspecto geométrico, que varia em função do gráfico a ser apresentado `geom_ ` 

É possível também adicionar outros argumentos, como:  

4. Transformações estatísticas `stat_summary`  
5. Facetas para dividir a visualização `facet_`  
6. Sistema de coordenadas `coord_`  
7. Temas específicos `theme_ `  

É importante notar que apesar dos argumentos utilizados na sintaxe serem similares aos utilizados em toda família tidyverse, a ligação `%>%` é substituída pelo `+`. 




## 1 variável discreta

Quando há apenas uma variável discreta (incluindo aqui as categóricas), os gráficos apresentam a distribuição dos dados por contagens e/ou proporções. Para esta apresentação, se recomenda a utilização do <u>gráfico de barras</u>, <u>colunas</u> ou <u>setor</u>. 

O gráfico de barras abaixo apresenta a contagem absoluta dos participantes pesquisados em cada país.

```{r}
ggplot(Dataset, aes(x = country)) +
  geom_bar() +
  labs(x = "País", title = "Número de participantes nos países investigados")
```

Esse gráfico permite um primeiro entendimento da distribuição dos dados. No entanto, a simples contagem de valores pode gerar uma percepção diferente caso a pesquisa tenha muitos ou poucos sujeitos. Para evitar isso, sugere-se a apresentar as proporções em vez das contagens.  

A mudança da contagem para proporções pode ser feita por um recurso do pacote `scales`. A adição dos valores textuais às colunas tende e auxiliar a visualização.


```{r}
ggplot(Dataset, aes(x = country, y = ..prop.., group = 1)) + 
  geom_bar(stat = "count") +
  geom_text(aes(label=scales::percent(round(..prop..,2)), 
                y=..prop..), stat= "count", color = "white", size = 3, position = position_stack(vjust = 0.5)) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "País", title = "Proporção de participantes em cada país investigado")
```

O gráfico de setor (as vezes chamado de polar, pizza ou torta) é também uma opção. O aspecto principal desse gráfico é o tamanho proporcional dos segmentos.

```{r}
Dataset %>% 
  count(country) %>% 
  mutate(pct = n/sum(n)) %>% 
  ggplot(., aes(x="", y= pct, fill=country)) +
  geom_col() +
  geom_text(aes(label = scales::percent(round(pct,3))), position = position_stack(vjust = 0.5))+
  coord_polar(theta = "y") +
  labs(title = "Proporção de participantes em cada país")
```


## 1 variável contínua

Quando uma única variável deve ser apresentada e ela é continua, os melhores gráficos para apresentar a distribuição dos dados são o histograma, densidade (kernel) e o boxplot.

Abaixo um histograma da idade dos participantes.

```{r, warning=FALSE }
ggplot(Dataset, aes(x = age)) +
  geom_histogram(bins = 30, color = "black", fill = "#56B4E9") +
  labs(title = "Distribuição da idade dos participantes")
```

   
O histograma é formado por diversas barras unidas, possibilitando ter um entendimento dos intervalos entre cada um dos valores.

Abaixo um gráfico de densidade da idade:
  
```{r, warning=FALSE }
ggplot(Dataset, aes(x = age)) +
  geom_density(fill = "#56B4E9") +
  labs(title = "Distribuição da idade dos participantes")
```

De maneira um pouco distinta do histograma, o gráfico de densidade ajusta uma curva aos dados. Com isso, este gráfico permite explorar a distribuição de probabilidade subjacente aos dados, o que será discutido futuramente.  

Todas as distribuições de variáveis possuem uma localização, uma dispersão e um formato. De uma maneira mais direta, tanto o histograma como o gráfico de densidade retratam bem o <u>formato</u> da distribuição. Nesse caso, trata-se de uma assimetria positiva ou à direita. Esse tipo de assimetria é reconhecido pela cauda arrastada à direita.   


Por sua vez, o boxplot dessa mesma variável pode ser criado: 

```{r, warning=FALSE }
ggplot(Dataset, aes(y = age, x = "")) +
  geom_boxplot(fill = "#56B4E9") +
  labs(title = "Distribuição da idade dos participantes")
```

O boxplot é também chamado de "diagrama de caixa e bigode" e foi desenvolvido pelo matemático John W. Tukey na década de 1960. Este gráfico apresenta vantagens em comparação com os outros apresentados até agora, que são:  

* Ele apresenta o formato da distribuição,   
* Na parte inferior da caixa, ele apresenta o valor do primeiro quartil, indicando os 25% dos dados abaixo ou até ele,      
* Na linha mais espessa dentro da caixa, ele apresenta  a mediana dos resultados (ou segundo quartil),     
* Na parte superior da caixa, ele apresenta o valor do terceiro quartil, indicando os 75% dos dados que abaixo ou até ele,    
* A área da caixa apresenta 50% dos dados, que estão situados entre o primeiro e o terceiro quartil,    
* As linhas abaixo e acima da caixa são chamadas de bigodes e indicam os valores mínimos e máximos sem considerar dados anômalos ou *outliers*,  
* Os valores acima ou abaixo da linhas indicam dados anômalos. 

O cálculo da linha vertical que forma o bigode do gráfico é feito por `Q1 - 1.5*IQR` e `Q3 + 1.5*IQR`. Consiedra-se que os valores acima ou abaixo deste ponto são anômalos. Por definição, os *outliers* são sempre poucos, mesmo que isso possa ser um pouco contraintuitivo nesta apresentação de agora. 

Apesar de ser um pouco difícil de se visualizar ao início, os resultados apresentados nesses três gráficos são os mesmos, tal como demonstrado a seguir.   

```{r, warning = FALSE}
gridExtra::grid.arrange(
  #Grafico 1
  ggplot(Dataset, aes(x = age)) +
    geom_histogram(aes(y=..density..), alpha=0.5, 
                   position="identity") + 
    geom_density(alpha=.8, fill = "#56B4E9"),
  #Grafico 2
  ggplot(Dataset, aes(y = age, x = "")) +
  geom_boxplot(fill = "#56B4E9") + labs(x = "") +
  coord_flip(),
  top = "Distribuição da idade dos participantes" #título
)
```


## 2 variáveis com VI discreta (e VD contínua)  

Quando duas variáveis são apresentadas, os gráficos permitem explorar diferenças entre grupos ou relação entre variáveis. Quando a VI é discreta, gráficos de barras, colunas ou boxplots apresentam as <u>diferenças</u> entre os grupos. 

O gráfico de colunas abaixo apresenta os resultados médios do Inventário Beck de Ansiedade nos 3 países investigados. 

```{r, warning=FALSE }
ggplot(Dataset, aes(x = country, y = bai_sum)) +
  geom_bar(stat = "summary", fun = mean,fill = "#56B4E9") 
```

Tal como exposto, é possível adicionar outros elementos a este gráfico para que uma primeira apreensão inferencial seja possível. Nesse sentido, o gráfico abaixo apresenta também as barras de erro.


```{r, warning=FALSE }
ggplot(Dataset, aes(x = country, y = bai_sum)) +
  geom_bar(stat = "summary", fun = mean,fill = "#56B4E9") +
  stat_summary(geom = "errorbar",fun.data = mean_se, width = .5) 
```

O boxplot a seguir também é um gráfico indicado. É importante notar que esse gráfico, em um primeiro momento, <u>não</u> traz informações sobre a média dos grupos, mas sim sobre a <u>distribuição</u> dos resultados. No entanto, como esse gráfico é bastante informativo, uma primeira noção inferencial já pode também ser feita.   


```{r, warning=FALSE }
ggplot(Dataset, aes(x = country, y = bai_sum)) +
  geom_boxplot(fill = "#56B4E9")
```


## 2 variáveis com VI contínua (e VD contínua)  

Quando tanto a VI como a VD são contínuas, os gráficos apresentam a relação entre as variáveis. Tanto o gráfico de pontos como o de dispersão são indicados, uma vez que eles são virtualmente identicos. No `ggplot`, o argumento `geom_point` (à esquerda) e `geom_jitter` (à direita) são possíveis. 

```{r, warning=FALSE }
gridExtra::grid.arrange(
  #Grafico 1
  ggplot(Dataset, aes(x = age, y = bai_sum)) +
  geom_point(color = "#56B4E9"),
  
  #Grafico 2
  ggplot(Dataset, aes(x = age, y = bai_sum)) +
  geom_jitter(color= "#56B4E9"),
  nrow=1
)
```


De maneira análoga aos elementos extras que podem ser apresentados em gráficos com VIs discretas, uma reta de regressão amostral (FRA) costuma ser adicionadas em gráficos em que a VI é contínua. Essa reta oferece uma primeira apreensão inferencial. No capítulo sobre modelos de regressão, esse conceito será novamente revisitado. A seguir, segue um exemplo.    

```{r, warning=FALSE }
ggplot(Dataset, aes(x = age, y = bai_sum)) +
  geom_jitter(color = "#56B4E9") +
  geom_smooth(method = "lm")
```

## Outros gráficos e configurações

Os gráficos demonstrados costumam a ser os mais frequentes. Entrentanto, é possível construir gráficos com uma maior complexidade, que reunam diversas variáveis ao mesmo tempo. Evidentemente, a realização destes gráficos só tem sentido quando eles são relacionados ao problema de pesquisa estudado e não sobrecarreguem ou distorçam a visualização e entendimento dos resultados. 

Frequentemente, essas informações adicionais são feitas pela inclusão de <u>clusters</u> ou <u>agrupamentos</u>. Isso é tanto possível em gráficos cuja VI seja discreta quanto contínua.

No exemplo abaixo, o gráfico dos resultados do Inventário Beck de Ansiedade entre os 3 países investigados (VI discreta) agora está agrupado pelo sexo do participante.

```{r}
Dataset %>% 
  filter(!is.na(sex)) %>% 
  ggplot(., aes(x = country, y = bai_sum, fill = sex)) +
  geom_bar(stat = "summary", position = "dodge") +
  stat_summary(geom="errorbar", fun.data = mean_se, position = position_dodge(0.95), width = .5) 
```
   
Este gráfico traz uma informação importante sobre os resultados de homens e mulheres nos três países. Além disso, as barras de erro ajudam em um primeiro entendimento de possíveis diferenças significativas. Esse conceito irá ser revisitado em capítulos subsequentes.   

No exemplo abaixo, a relação entre idade e pontuação no Inventário Beck de Ansiedade está agora agrupada pelo sexo do participante.

```{r}
Dataset %>% 
  filter(!is.na(sex)) %>% 
  ggplot(., aes(x = age, y = bai_sum, color = sex)) +
  geom_jitter() +
  geom_smooth(method = "lm") 
```
    
Neste gráfico de agora, é possível perceber que os a relação entre a idade e os resultados do Inventário Beck de Ansiedade é muito pequena e isso parece valer tanto para homens como para mulheres. Especialmente no capítulo de correlação, esse assunto será revisitado e parte dos termos utilizados aqui será alterado.  

Por sua vez, situações em que há uma grande quantidade de variáveis apresentadas tendem a tornar os resultados difíceis de serem entendidos. O gráfico abaixo tenta traduzir essa condição, criando uma visualização de difícil entendimento justamente pelo excesso de variáveis presentes.    

```{r}
Dataset %>% 
  filter(!is.na(sex), !is.na(curso_ou_ano)) %>% 
  ggplot(., aes(x = age, y = bai_sum, fill = factor(curso_ou_ano), color = sex, shape = country)) +
  geom_jitter() +
  geom_smooth(method = "lm") 
```

Espera-se que seja possível constatar que este gráfico é <mark>totalmente inadequado</mark>. Ele é carregado de informações, permite um baixo entendimento dos resultados da pesquisa e, eventualmente, pode gerar conclusões incorretas ou viesadas.    

## Execução no JASP  

Da mesma forma que feito no R, será necessário carregar a [base](https://osf.io/e639b/) para o JASP. Durante todos os capítulos, esse procedimento de importação será requisitado.    


## Tabelas  

Após ter a base disposta no JASP, para gerar tabelas e gráficos, será necessário acessar a opção `Descriptives`. O JASP tratará todas as variáveis com um símbolo de diagrama de venn ou barras como categórias e todas as variáveis com símbolo de régua como contínuas.  

![](./img/cap_desc_jasp_descritivo.png)
  
Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, quando há duas ou mais variáveis para serem analisadas, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/cap_desc_jasp_descritivo2.png)

Isto posto, as análises feitas no ambiente R serão parcialmente reproduzidas.  

Inicialmente, uma tabela descrevendo os participantes em cada um dos país é importante para apresentar ao leitor algumas das principais características da amostra. Para fazer isso, será necessário levar a variável <u>country</u> para a seção `Variables` e clicar em `Frequency tables (nominal and ordinal)`.


![](./img/cap_desc_jasp_proporcao.png)

Por padrão o JASP irá apresentar as contagens (frequências absolutas) e as proporções. A parte mais à esquerda da tabela descreverá os dados considerando todos os valores presentes na base. A parte mais à direita irá apresentar apenas os dados válidos, que <u>não consideram casos ausentes</u>. É importante antentar que o JASP <u>não</u> exclui estes casos. Ele apenas não os mostra.


Para verificar a frequência e a proporção de homens e mulheres na amostra, será necessário colocar também a variável <u>sex</u> na opção `Variables`. Não é preciso retirar a variável <u>country</u> antes de fazer isso. O JASP irá apresentar ambas as tabelas de maneira empilhada.


![](./img/cap_desc_jasp_proporcao_duas_variaveis.png)


Para fazer uma tabela agrupando tanto <u>country</u>, como <u>sex</u>, é necessário arrastar uma das variáveis que estão em `Variables` para o espaço `Split`.   

Em uma tabela em que se descreve a contagem e porcentagem de homens e mulheres em cada um dos três países de maneira independente, é necessário preencher o `Split` com a variável <u>country</u>. O JASP aceita que se arraste a variável de um local para o outro e, ao fazer isso, todas as contas serão automaticamente atualizadas.

![](./img/cap_desc_jasp_proporcao_duas_variaveis_split.png) 

É possível perceber que as variáveis categóricas são descritas por suas frequências e proporções. Por sua vez, variáveis contínuas costumam ser resumidas por medidas de posição e dispersão, tal como a média e o desvio-padrão. Como exemplo, para calcular tais medidas estatísticas dos valores do BDI e do BAI em função do país do participante, é necessário deixar a variável <u>country</u> em `Split` e levar as variáveis <u>bdi_sum</u> e <u>bai_sum</u> para `Variables`. 

![](./img/cap_desc_jasp_proporcao_duas_variaveis_split2.png) 

Dessa vez, não é necessário ativar a opção `Frequency tables (nominal and ordinal)`. O símbolo de régua ao lado das variáveis <u>bdi_sum</u> e <u>bai_sum</u> indicam que elas são contínuas. O símbolo de diagrama de Venn ao lado de <u>country</u>, por sua vez, indica que ela é categórica.


Para fazer essas análises considerando <u>sex</u> como agrupador, será necessário substituir <u>country</u> por <u>sex</u> no espaço de `Split`.

![](./img/cap_desc_jasp_proporcao_duas_variaveis_split3.png) 

Nesta versão do JASP, não é possível colocar duas variáveis como agrupadoras. Dessa maneira, a reprodução das tabelas feitas anteriormente no ambiente R é apenas parcial.  

## Gráficos

O JASP é um exelente programa para gerar gráficos. Tal como previamente apresentado, a criação de um gráfico apropriado dependerá da finalidade desejada, bem como da quantidade de variáveis que devem ser apresentadas e o nível de medida da VI, especialmente em análises bi ou multivariadas.   

O JASP pode fazer gráficos tanto seção `Descriptives` como após análise de dados específicas. Na seção `Descriptives`, será necessário primeiro arrastar as variáveis de interesse para seus respectivos lugares e, em seguida, clicar na opção `Plot`.


![](./img/cap_desc_jasp_graficos.png) 


## 1 variável discreta      


Para este tipo de variável, gráfico de barras, colunas e setor são indicados. Para realizar um gráfico de barras, é necessário colocar a variável de interesse em `Variables` e, dentro de `Plots`, clicar em `Distribuiton plots`. O JASP organiza as barras de ordem crescente. No exemplo abaixo, a variável <u>country</u> é apresentada.  


![](./img/cap_desc_jasp_grafico_barras.png)

Para realizar um gráfico de setor, basta selecionar a opção `Pie Charts`. A visualização ocorrerá automaticamente. Uma vantagem deste gráfico é a apresentação proporcional dos elementos gráficos, em vez de contagens. Infelizmente, nesta versão do JASP, não é possível adicionar um rótulo com a porcentagem de cada cateogoria.  


![](./img/cap_desc_jasp_grafico_setor.png)


O JASP permite customizar as cores de alguns gráficos. Para fazer isso, basta clicar em `Color Palette` e escolher entre as opções disponíveis. Existem algumas possibilidades e recomendo optar por aquelas que permitem que pessoas com limitações visuais possam também se beneficiar. Entretanto, apenas como demonstração, o tema `ggplot2` é apresentado abaixo.  

![](./img/cap_desc_jasp_grafico_setor2.png)

## 1 variável contínua  

Histogramas, gráficos de densidade e boxplots costumam ser indicados para variáveis contínuas. Para o JASP fazer tais gráficos, é necessário que o espaço `Variables` seja preenchido por alguma variável que tenha o símbolo da régua ao lado. A variável <u>age</u> é um bom exemplo.   

Ao colocá-la neste local e marcar a opção `Distribution plots`, um histograma será automaticamente apresentado.  


![](./img/cap_desc_jasp_grafico_histograma.png)


É possível adicionar a densidade de maneira sobreposta ao histograma clicando em `Display density`. Ambos os gráficos são importantes para verificar o formato da distribuição dos dados. Neste caso, a distribuição é assimétrica à direita.   

![](./img/cap_desc_jasp_grafico_densidade.png)

Por sua vez, o boxplot pode ser criado ao se clicar na opção `Boxplots` e, em seguida, `Boxplot element`. 


![](./img/cap_desc_jasp_grafico_boxplot.png)


É possível customizar o boxplot. Além disso, o JASP permite criar outros gráficos que vem sendo mais utilizados recentemente, como o gráfico de violino.  Isso não será demonstrado aqui, mas para fazer isso, basta ativar as opções desejadas na seção `Customizable plots`.

Tal como discutido anteriormente,o boxplot apresenta vantagens em comparação com os outros gráficos apresentados até agora, que são:  


* Ele apresenta o formato da distribuição,   
* Na parte inferior da caixa, ele apresenta o valor do primeiro quartil, indicando os 25% dos dados abaixo ou até ele,      
* Na linha mais espessa dentro da caixa, ele apresenta  a mediana dos resultados (ou segundo quartil),     
* Na parte superior da caixa, ele apresenta o valor do terceiro quartil, indicando os 75% dos dados que abaixo ou até ele,    
* A área da caixa apresenta 50% dos dados, que estão situados entre o primeiro e o terceiro quartil,    
* As linhas abaixo e acima da caixa são chamadas de bigodes e indicam os valores mínimos e máximos sem considerar dados anômalos ou *outliers*,  
* Os valores acima ou abaixo da linhas indicam dados anômalos. 


## 2 variáveis com VI discreta (e VD contínua)

Para situações em que há duas variáveis, a VI é tratada como discreta e a VD é contínua, gráficos de barras, colunas ou boxplots são indicados. Esses gráficos permitem verificar diferenças entre grupos. Nesta versão do JASP, apenas o boxplot pode ser feito. Para verificar, por exemplo, a distribuição dos resultados do <u>bai_sum</u> em função do <u>país</u>, é necessário levar às variáveis a seus respectivos locais e, em seguida, solicitar ao JASP o boxplot.  

![](./img/cap_desc_jasp_grafico_boxplot_grupo.png)


## 2 variáveis com VI contínua (e VD contínua)

Quando há duas variáveis contínuas, tanto o gráfico de pontos como de dispersão são possíveis. Esses gráficos permitem verificar o relacionamento entre variáveis. Para fazer isso, é necessário incluir ambas as variáveis de interesse para o espaço `Variables`. Por exemplo, <u>age</u> e <u>bai_sum</u>.

![](./img/cap_desc_jasp_grafico_scatter1.png)

Após clicar na opção `Plots`, é possível tanto marcar a opção `Scatter Plots`, como a opção `Correlation Plots`.

![](./img/cap_desc_jasp_grafico_scatter2.png)

A escolha de cada gráfico é relacionada com os elementos que devem (ou não) serem incluídos na apresentação. Na opção `Scatter Plot`, o gráfico irá exibir os pontos dos respectivos pares ordenados das variáveis X e Y, suas densidade e também adicionar uma reta de regressão. Este último conceito será revisitado no capítulo de regressão. 

Um aspecto visualmente importante é a eleição de qual variável irá em X. Com bastante frequência, deve-se inserir a VI (mesmo que teórica) em X, enquanto a VD em Y. Isso é feito alterando a ordem das variáveis em `Variables`. 


![](./img/cap_desc_jasp_grafico_scatter3.png)

## Outros gráficos e configurações

O JASP é bastante versátil na realização de gráficos e permite que mais variáveis sejam inseridas. Há também um módulo (`Module`) chamado `Visual Modeling`, que permite uma grande customização de gráficos. Para acessá-lo, é necessário clicar na cruz azul, tal como destacado no quadrado roxo da imagem abaixo.  

![](./img/cap_desc_jasp_modules.png)

Na lista de opções, é necessário ativar `Visual Modeling`. Ao fazer isso, o icone será ativado na barra de ferramentas. 


![](./img/cap_desc_jasp_visual_modeling.png)

Com isso feito, dentro de `Visual Modeling`, a opção `Flexplot` oferece uma melhora substancial aos gráficos que o JASP executa. Agora é possível, por exemplo, fazer um gráfico incluindo um <u>cluster</u> ou <u>agrupamento</u>, em que os resultados do Inventário Beck de Ansiedade são apresentados tanto em função dos países investigados, como do sexo do participante.


![](./img/cap_desc_jasp_flexplot.png)


Uma série de outras opções e combinações podem ser feitas ao clicar em `Options` e `Plot Labels`. Elas não serão apresentadas nesta seção.


## Resumo  

::: {.explore}
Este capítulo apresentou os aspectos tabulares e gráficos corriqueiramente encontrados em pesquisas de Psicologia e áreas congêneres. Entre os pontos principais, estão os seguintes:  

1. Medidas de posição e dispersão são fundamentais na apresentação dos resultados de uma pesquisa   
2. Variáveis categóricas são resumidas por contagens e proporções. Variáveis contínuas por suas médias e desvios-padrão  
3. Tabelas e gráficos devem ser claros ao leitor, sem criar viés ou distorção dos resultados  
4. As tabelas são muito úteis para uma apresentação detalhada dos resultados  
5. Gráficos condensam um grande volume de dados de uma forma mais facilmente interpretável    
6. A heurística típica em gráficos solicita responder a quantidade e a natureza das variáveis a serem apresenadas   
:::  


## Questões  

<div class="question">

1. Trata-se de um círculo dividido por fatias cujos ângulos internos são proporcionais às partes envolvidas. Este é um gráfico:<br>a) De colunas<br>b) Histograma<br>c)De Setor<br>d) Boxplot<br>e)Barras
1. É uma medida de posição para variáveis propriamente numéricase que é obtida somando-se todos os valores observados e dividindo-se o resultado pelo número de observações<br>a) Mediana<br>b) Média<br>c) Moda<br>d) Desvio-padrão<br>e) Amplitude interquartil 
1. (ENADE, Biomedicina - 2010) Para apresentarem gráficos dados referentes à distribuição de frequências de um grupo de medições, pode-se aplicar um modelo semelhante ao estabelecido na figura abaixo, na qual o pesquisador verifica a variação de anticorpos em relação a uma coorte populacional específica.<br>![](./img/exercicio_histograma.png)<br>a) Gráfico de setores, que demonstra a variação de anticorpos na abscissa Y e de população na ordenada X.<br> b) Histograma, que demonstra variações de anticorpos na abscissa X e de população na ordenada Y <br> c) Gráfico de tendência central, que demonstra variações de anticorpos na abscissa X e de população na ordenada Y.<br> d) Gráficos de dispersão, que demonstra a tendência central das médias de concentração dos valores de anticorpos na população.<br> e) Gráfico de linhas, que demonstra a tendência central baseada na mediana das concentrações de anticorpos na população. 
</div>   

<div class="mirror">Gabarito: 1-c; 2-b; 3-b,</div>


<!--chapter:end:03-estatistica_descritiva.Rmd-->

---
output:
  word_document: default
  html_document: default
---
# Qui quadrado

```{r base e pacotes qui quadrado, include = FALSE }

load(file="~/anovabr/mqt/bases/Base R TDAH Arruda.RData") #base
rm(list=setdiff(ls(), "ds_selected"))


library(tidyverse)
```

```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar o teste Qui-quadrado  
2. Diferenciar o Qui-quadrado de aderência, homogeneidade e independência  
3. Realizar gráficos relacionados à distribuição de porcentagens     
4. Apresentar e interpretar métricas de tamanho do efeito  
5. Dar exemplos relacionados à escrita dos resultados  
```


O Teste Qui-quadrado é um teste não-paramétrico utilizado, basicamente, para três finalidades específicas, que são:      
(1) verificar as distribuições de probabilidades de cada categoria de uma variável em relação a um valor teórico esperado (aderência),   
(2) verificar se as distribuições das categorias são as mesmas para diferentes subpopulações de interesse (homogeneidade) e   
(3) verificar se duas variáveis categóricas são independentes (independência).   

Apesar da diferenças em relação às perguntas de pesquisa, o sistema matemático é o mesmo:



$$\chi^2=\sum_{k=1}^{n} \frac{(O_k - E_k)^2}{E_k}$$
onde:  
$K$ se refere a quantidade de classes  
$O$ é o valor observado de uma determinada classe  
$E$ é o valor esperado desta classe  


Pela fórmula, é possível deduzir que quanto maior for a discrepância entre as frequências observadas empiricamente (O) e as frequências esperadas (E), maior será a estatística de teste e, consequentemente, menor será o valor de P. É também possível entender o Qui-quadrado como um caso particular de uma regressão logística, o que será abordado em outro capítulo.  

Se assume os seguintes pressupostos funcionais à execução de um Qui-quadrado:  

*(i)* Os dados são aleatórios e representativos da população  
*(ii)* as variáveis analisadas são categóricas (e.g., sexo, nível de escolaridade, grau de uma doença)  
*(iii)* Todas as frequências esperadas são maiores ou iguais a 1  
*(iv)* No máximo, apenas 20% das frequências esperadas são inferiores a 5.  


A tabela abaixo descreve as condições de análise, com exemplos ilustrativos:


  | Versão do teste | Variáveis         | Exemplo                                                                                       
  | :-----------    | :-----------      | :-----------                                                                                   
  | Aderência (Goodness of fit) | 1 categórica | -Verificar se a proporção de caras e coroas é de 50% cada <br> -Verificar se a proporção das cores de chocolates M&M são aderentes ao que a empresa afirma                                  
  | Homogeneidade   | 2 categóricas     | -Verificar se a proporção de homens e mulheres que gostam de uma marca de celular é similar<br>-Testar se o uso de anabolizante é homogêneo em atletas de diferentes modalidades esportivas        
  | Independência   | 2 categóricas     | -Verificar se o sexo e a escolha do curso de graduação são independentes<br>-Testar se classe social e local de interesse para uma viagem são independentes                         

*Nota: O Qui-quadrado de aderência também é chamado de "qualidade do ajuste" ou "bondade". Estas são traduções tipicamente feitas para "goodnes of fit". Como todas as análises são realizadas de uma maneira virtualmente idêntica, essas distinções são mais teóricas do que práticas. O Qui-quadrado de aderência tem uma proposta parecida com a ANOVA de uma via.*


Apesar de colateral à esta apresentação, o teste Qui-quadrado tem uma curiosidade que remonta o seu desenvolvimento e explica parte da desavença que Pearson tinha com Fisher. As primeiras publicações do Qui-quadrado ocorreram em 1900 e 1904 por Karl Pearson [@Pearson1900]. Ronald Fisher detectou um erro no cálculo dos graus de liberdade e rapidamente divulgou isso, o que gerou um enorme descontentamento de Pearson [@BAIRD1983].


## Pesquisa
  
<div class="alert alert-warning">
  <strong>Base: </strong> [Base R TDAH Arruda.Rdata](https://github.com/anovabr/mqt/raw/master/bases/Base%20R%20TDAH%20Arruda.RData)
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada "Parent-reported diagnosis of Attention Deficit Hyperactivity Disorder and psychostimulant use among children and adolescents: a population-based nationwide study", que está em avaliação pela revista "Social Psychiatry and Psychiatric Epidemiology (SPPE)". Neste trabalho, tivemos o objetivo de verificar aspectos epidemiológicos do Transtorno do Déficit de Atenção com Hiperatividade (TDAH) em uma amostra representativa de crianças e adolescentes brasileiros, bem como explorar eventuais associações entre o sexo do participante e o diagnóstico de TDAH.  

Neste momento, vamos seguir apenas com o Qui-quadrado de independência, que foi o utilizado neste artigo. Como exposto no decorrer de outros capítulos, o teste de hipóteses começa pela formulação conceitual das hipóteses. Apesar de ser possível estipular $H_0$ e $H_a$ a partir de equações específicas, a apresentação será textual/substantiva.


$$H_0: Não\ há\ associação\ entre\ sexo\ e\ TDAH \\ H_a: Há\ associação\ entre\ sexo\ e\ TDAH \\ \alpha = 0.05$$



::: {.warning}
**Atenção**: Com frequência, testes de hipóteses são divididos naqueles que verificam "associação" entre variáveis e naqueles que verificam "diferenças" entre grupos. Conceitualmente, o Qui-quadrado investiga associação entre variáveis, mesmo que sua formulação matemática seja feita computando a diferença entre o valor observado e o valor esperado. A apresentação das hipóteses de forma apenas textual visou também evitar possíveis confusões.
:::


## Execução no R

A apresentação de tabelas e gráficos são fundamentais antes da realização formal do teste de hipótese. Para apresentar a possível relação entre ambas as variáveis, a tabela de contingência é adequada. O pacote `descr` é um bom recurso para esta apresentação.

Apesar do Qui-quadrado não eleger uma VI e uma VD, quase sempre as linhas são utilizadas para apresentar a variável de maior interesse (neste caso, sexo) e as colunas para indicar o critério ou o eventual desfecho (neste caso, ter ou não TDAH).   

A porcentagem nas linhas e o valor esperado (em caso de independência entre as variáveis) auxiliam bastante na descrição dos resultados.   


```{r}
descr::CrossTable(ds_selected$sex_male,ds_selected$adhd_parent,
           expected = T, prop.c = F, prop.chisq = F, prop.t = F) %>% 
  pander::pander()
```

É possível verificar que existe uma discrepância entre os valores esperados e observados, em que o diagnóstico parece estar mais presente em meninos do que em meninas. No entanto, essas observações são apenas iniciais.

Em seguida, a criação de um gráfico de barras oferece um bom recurso para visualizar os dados. Repare que a barra azul, que representa a porcentagem de TDAH, parece se comportar de maneira diferente nos grupos, o que também havia sido detectado na tabela anterior.   

```{r}
ggplot(ds_selected, aes(x= sex_male, fill = adhd_parent)) +
  geom_bar(position = "fill") +
  coord_flip() +
  labs(x = "sexo", y = "Proporção", fill = "TDAH")
```
  
Com isto feito, é possível proceder ao cálculo do Qui-quadrado, tal como feito a seguir.    

```{r}
descr::CrossTable(ds_selected$sex_male,ds_selected$adhd_parent,chisq = T)$CST %>% pander::pander()
```
  
Os resultados deixam claro que que é possível rejeitar a hipótese nula, uma vez que o valor de P é menor do que o nível de significância previamente estipulado (0.05). Isso sugere que existe uma associação entre o sexo do participante e o diagnóstico de TDAH.  

::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::

No teste Qui-quadrado, os principais pressupostos a ser investigados são a <mark>inexistência de células com valores esperados iguais a 0</mark> e <mark>no máximo 20% dos valores esperados serem inferiores a 5</mark>. Ambos podem ser checados na tabela exposta anteriormente e foram atendidos.  
   
Eventualmente, quando os pressupostos são violados, há sugestão de fazer correções nos resultados, implementar técnicas de bootstrapping e contar com outros testes (Fisher's Exact Test, por exemplo) [@Campbell2007]. Eventualmente, colapsar categorias é uma prática comum, apesar de receber críticas da literatura.  


## Tamanho do efeito  

Como apresentado no decorrer dos outros capítulos, os valores de P quase nunca são informativos sobre a <u>relevância</u> dos resultados. Por sua vez, o tamanho do efeito é uma medida objetiva e padronizada sobre um efeito observado e, com isso, é mais atrelada à importância da descoberta na pesquisa.  

O tamanho do efeito mais utilizado no ambiente das análises de Qui-quadrado é o V de Cramer. Esta estatística gera valores 0-1 e é dada da seguinte maneira:

$$V=\sqrt\frac{\chi^2}{n*df^`}$$
Em que:  
$\chi^2$ = valor do Qui quadrado obtido  
$n$ = tamanho da amostra  
$df^`$ menor valor entre (Linhas - 1) ou (Colunas - 1) da tabela de contingências  


A função `CramerV`do pacote `rcompanion` gera esses resultados.

```{r}
rcompanion::cramerV(ds_selected$sex_male,ds_selected$adhd_parent)
```


A interpretação é baseada nos graus de liberdade do Qui-quadrado e é feita da seguinte maneira:  


  | Graus de liberdade  | Pequeno     | Médio       |  Grande     
  | :-----------        | :-----------| :-----------|:-----------      
  | 1$^*$               | 0.1         | 0.3        |  0.5         
  | 2                   | 0.07        | 0.21       |  0.35        
  | 3                   | 0.06        | 0.17       |  0.29        

*Nota: $^*$ Na maioria das vezes, o Teste Qui-quadrado conta com tabelas 2x2, o que gera 1 grau de liberdade. Assim, essa é a  interpretação mais utilizada na literatura.*  


## Execução no JASP

Para executar o Qui-quadrado no JASP, será necessário carregar a base [ADHD 2020 after processing.csv](https://osf.io/zj4c2/download). Com os dados devidamente importados para o programa, a apresentação de tabelas e gráficos auxiliam o pesquisador a verificar padrões diferentes nos dados. Para executar isso, é necessário acessar a seção `Descriptives`:


![](./img/jasp_descriptives.png)
Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadoras. Apesar do Qui-quadrado não trabalhar com os conceitos de VI e VD, na prática, a lista `Variables` irá reunir a possível variável dependente, enquanto a possível variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/cap_x2_primeira_tabela.png)

É necessário inserir a variável <u>sex_male</u> para `Split` e a variável <u>adhd_parent</u> para `Variables`. Para tabela ser apresentada corretamente, deve-se  selecionar a opção `Frequency tables`.

![](./img/cap_x2_descritivo.png)


O gráfico de barras pode ser acessado clicando na opção `Plots` e, em seguida, `Distribution plots`, em `Basic plots`. Esse resultado é um recurso a mais para sondar os dados.  

![](./img/cap_x2_grafico.png)

Para execução do Qui-quadrado (de associação), a tabela de contingência deve ser feita. Isso é realizado ao clicar em `Frequencies` e, em seguida, `Contigency tables`. 


![](./img/cap_x2_interface.png)
Nesta seção, será necessário indicar a variável que irá nas linhas e nas colunas. Apesar do Qui-quadrado não trabalhar com os conceitos de VI e VD, quase sempre se utiliza as linhas para inserir a variável que é, teoricamente, a VI, enquanto a VD teórica é inserida na parte colunas.

![](./img/cap_x2_interface2.png)


Ao inserir a variável <u>sexo</u> para as linhas e a variável <u>diagnóstico</u> para as colunas, a tabela de contingência será novamente feita e o Qui-quadrado será automaticamente calculado. 

![](./img/cap_x2_resultados.png)


Os resultados inferenciais de interesse estão na parte inferior da apresentação e são os mesmos obtidos na etapa de execução com o R. A estatística Qui-quadrado foi `41.6`, com `1`  grau de liberdade e `p < 0.001`. Estes valores estão dispostos no retângulo roxo na imagem a seguir.  

![](./img/cap_x2_resultados2.png)

::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::

A validade dos resultados depende dos pressupostos. Além disso, o tamanho do efeito precisa ser calculado para indicar a relevância dos achados. Para verificar <mark>se existem células cujos valores esperados sejam iguais a 0</mark> e se <mark>no máximo 20% dos valores esperados são inferiores a 5</mark>, é necessário clicar em `Cells`.  


![](./img/cap_x2_pressupostos.png)

Há dois blocos específicos, `Counts` e `Percentages`. Em `Counts`, é necessário selecionar `Expected`. Em `Percenatges`, é necessário selecionar `Row`. Com isso feito, os resultados poderão ser melhor analisados.

![](./img/cap_x2_pressupostos2.png)

Para adicionar a medida de tamanho de efeito, é necessário ir em `Statistics` e, em seguida, clicar em `Cramer's V`.

![](./img/cap_x2_tamanho_do_efeito.png)


Após estas etapas realizadas, é possível analisar integralmente os resultados, em que o valor de P e o tamanho do efeito podem ser interpretados.  


![](./img/cap_x2_tabela.png)

Caso os pressupostos tenham sido violados, o JASP oferece algumas saídas, tal como a correção de Yates.


![](./img/cap_x2_yates.png)

## Escrita dos resultados


O principal achado desta pesquisa é que há uma associação entre o sexo da criança (masculino e feminino) e o diagnóstico de TDAH. Esta evidência já é bastante consolidada na literatura psicológica e biomédica. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  
  
A associação entre o sexo do participante e sua condição clínica (ter ou não TDAH) foi investigada por um Teste Qui-quadrado de independência. Os resultados indicaram que ambas as variáveis são associadas (X2(1) = 41.605). O tamanho do efeito foi calculado pelo V de Cramer, que se mostrou pequeno 0.07.
```  


## Resumo  
::: {.explore}
1. O Qui-quadrado pode ser utilizado para um conjunto de análises realizadas em variáveis categóricas.  
2. Apesar de diferenças conceituais, o formato matemático é o mesmo.  
3. O tamanho do efeito apresenta interpretações que podem variar em função dos graus de liberdade.  
:::  


## Pesquisas adicionais  

1. Are Attitudes Towards Smoking Different for Males and Females? (DOI: 10.1136/tc.2.3.201)    
Nesta pesquisa, cerca de 19378 participantes que eram fumantes, ex-fumantes ou que não fumavam indicavam se concordavam que o fumo poderia provocar doenças. Os resultados indicaram que houve uma associação significativa entre o perfil de consumo de cigarro e a concorância com a afirmativa. Apesar da maioria ter responder afirmativamente que hábitos de fumo podem gerar doenças, a quantidade de participantes fumantes que concordaram com isso foi significativamente menor do que a esperada. 
 
2. The Gender Gap in STEM Fields: The Impact of the Gender Stereotype of Math and Science on Secondary Students' Career Aspirations (DOI: 10.3389/feduc.2019.00060)
Neste estudo, 1364 estudantes do ensino médio (na Suíça) responderam sobre suas aspirações para o curso de graduação. Houve uma associação significativa entre o sexo do participante seu interesse por áreas de ciências e tecnologia. A frequência de mulheres interessadas na área foi menor do que a esperada, enquanto a frequência dos homens foi superior à esperada.  
  
3. Intrinsic honesty and the prevalence of rule violations across societies (DOI: 10.1038/nature17160)
Nesta pesquisa, 2568 participantes de diferentes países participaram de uma atividade que consistia em jogar um dado dentro de um copo e falar o número que saiu para o pesquisador. Apenas o participante poderia ver o número e não havia nenhuma forma do pesquisador conferir se o número falado pelo participante era o número que, de fato, havia saído. Por características probabilísticas, se espera que cada uma das faces do dado seja igualmente selecionada. Assim, a ocorrência de uma alta proporção de valores altos indicaria desonestidade. O Qui-quadrado utilizado foi o de aderência.   



<!--chapter:end:04-qui_quadrado.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# Tipos de amostragem

```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar aspectos relacionados à população e amostra    
2. Introduzir as principais questões sobre processos de composição amostral    
3. Introduzir procedimentos probabilísticos e não-probabilísticos para composição amostral   
4. Apresentar o raciocínio geral do cálculo do tamanho amostral   
5. Descrever como processos de amostragem, delineamento e análises são importantes em uma pesquisa  
```


```{block, type="glossario"}
<U>**GLOSSÁRIO**</U>   
**População**: Conjunto de objetos que apresentam, ao menos, uma característica em comum.  
**Amostra**: Parte da população. A principal característica de uma amostra é sua representatividade da população.  
**Unidade amostral**: Varia em função do interesse da pesquisa. Em Psicologia, quase sempre é um indivíduo, mas é possível ser uma família, uma empresa, etc.   
**Característica populacional**: Aspecto de interesse a ser acessado ou medido.  
**Censo**: Pesquisa em que todos os elementos da população são acessados.  
**Erro amostral**: Diferença entre o resultado obtido na amostra e o valor verdadeiro populacional.  

```


Ao se planejar e executar uma pesquisa, além de se ter claro os problemas científicos de interesse, é necessário eleger a população que participará do estudo. A população é determinada como todos os membros de um grupo bem definido. Dessa forma, a população é composta por um conjunto de objetos que apresentam, ao menos, uma característica em comum. Em Psicologia, com muita frequência, a população é formada por indivíduos. No entanto, a depender da área, ela pode ser formada por empresas,  árvores, animais, etc.

A população pode ser classificada como finita ou infinita e, a depender de alguns delineamentos de pesquisa, também pode ser entendida como população-alvo ou população externa. Em relação à população ser finita ou infinita, estudantes de métodos quantitativos ou pacientes que um psicólogo atende no ano atual ilustram uma população finita. Por contraste, nascimentos em uma cidade, produção de uma máquina ou horas de duração que uma lâmpada apresenta demonstram uma população infinita. A população externa é definida como todos os indivíduos que se deseja generalizar os resultados de uma pesquisa, tal como brasileiros adultos, enquanto a população alvo são aqueles que a pesquisa tem maior capacidade inferencial, tal como adultos do estado do Rio de Janeiro.   

Quando um estudo é feito considerando todos os participantes de interesse, ele é chamado de censitário. Entretanto, há muitas situações em que isso é impossível, como visto anteriormente. Mesmo quando possível, o custo, o aceso e o tempo necessário para uma pesquisa deste tipo tendem a impossibilitar sua execução. Para resolver este problema, é necessário reunir um conjunto menor da população e, neste novo grupo - chamado de amostra - fazer a pesquisa.   

Apesar desses conceitos parecerem distantes, isso é feito no dia a dia de todas as pessoas. Em exames médicos, não se retira todo o sangue do corpo para verificar algumas características específicas. Da mesma maneira, toma-se apenas um pouco de vinho para verificar sua qualidade ou, quando se cozinha uma sopa, é bem típico provar apenas uma colher dela para checar se o tempero está adequado ou não. 

![](./img/cap_amostra_desenhos.png)


Em estatística, a área da Amostragem é a que se ocupa da composição de uma amostra e dispõe de diferentes técnicas e procedimentos. A composição da amostra depende de critérios de <u>qualidade e quantidade</u> que, sob formato de perguntas, transformam-se nas seguintes questões que devem ser respondidas antes da pesquisa:    

1) Qual tipo de amostragem será utilizada (qualidade) e   
2) Quantos elementos serão necessários para compor a amostra (quantidade)?   

Em relação ao tipo (também chamado de Plano amostral), uma amostra pode ser composta por métodos probabilísticos e não-probabilísticos. Métodos probabilísticos são aqueles em que a seleção dos participantes ocorre de maneira aleatória, ou seja, de uma forma que cada elemento da população tenha uma probabilidade conhecida de fazer parte da amostra. Por oposição, métodos não-probabilísticos ocorrem por uma escolha deliberada dos elementos da amostra.   


Métodos probabilísticos têm clara vantagem em comparação aos não-probabilísticos. Uma vez que a amostra que será composta terá, em proporção, todas as características qualitativas e quantitativas da população, os participantes do estudo representam adequadamente a população e, com isso, processos de generalização tornam-se mais adequados. No entanto, a composição de uma amostra com tal propriedades impõe dificuldades, uma vez que depende do conhecimento populacional, bem como de um investimento em tempo e recursos que tende a ser elevado.

::: {.warning}
**Atenção**: Pesquisas que contam com amostras representativas permitem que os resultados obtidos sejam generalizados à população de onde a amostra foi extraída.  
:::


Amostras formadas por seleção não-probabilística são pouco capazes de estender os resultados obtidos à população de interesse. No entanto, esse tipo de metodologia é mais rápida e menos custosa do que a probabilística. Em situações em que se desconhece a população de interesse ou quando não há necessidade de generalizações, ela é uma opção adequada. A tabela a seguir apresenta algumas vantagens, desvantagens e aplicações de ambas as metodologias.

| Amostragem probabilística 	|                   	
|--------------------------	|-------------------------------	
| Vantagem                  	| - Seleção aleatória.<br>-Elimina o erro sistemático e o viés de seleção.<br>- Representa bem as características populacionais de interesse.<br>-Permite generalização à amostra.  
| Desvantagem               	| - É necessário conhecer e definir bem a população de interesse.<br>- Custosa.<br>- De difícil acesso, as vezes.<br>- Tende a ser pouco atualizada para mudanças de nomes (ex: casamento) ou mudanças geográficas.<br>- Há situações em que é impossível (ex: verificar a população de usuários de crack).  
| Exemplo                   	| Quase sempre, pesquisas em que há um valor financeiro associado ou estatísticas oficiais<br>-Pesquisas de intenção de votos<br>-Pesquisa epidemiológica sobre saúde mental no Brasil
| **Amostragem não-probabilística** 	|                   	
| Vantagem                  	| - Relativamente fácil de se planejar e executar.<br>- Tende a ser mais barata do que métodos probabilísticos.  
| Desvantagem               	| - Costuma representar mal a população.<br>- Baixa ou ausente capacidade de generalização 
| Exemplo                   	| - Pesquisas feitas com coleta de dados online

 

## Amostragem aleatória simples

É o processo mais elementar. O método se fundamenta no princípio de que todos os membros de uma população têm a mesma probabilidade de serem incluídos na amostra. Para fazer este tipo de procedimento, cada participante da população "recebe" um número. Este número é sorteado em um procedimento que, as vezes, é chamado de loteria. A amostra é formada pelos participantes sorteados.

![](./img/cap_aas.png)

**Vantagens**: Evita o erro sistemático e viés de seleção. Tende a ser simples de se planejar e comunicar aos outros.    
**Desvantagens**: Tende a ter execução complexa e cara. Eventualmente, pode não representar bem subgrupos populacionais.    

## Amostragem aleatória sistemática 

É uma variação da amostragem simples. Após a identificação dos participantes, Um determinado critério é eleito (por exemplo, a cada 5) e a seleção segue este formato.  

![](./img/cap_a_sistematica.png)


**Vantagens**: Mais rápida de se implementar do que a amostragem aleatória simples  
**Desvantagem**:  Eventualmente, pode não representar bem subgrupos populacionais. A ordenação dos participantes pode ser igual a uma ordenação existente, mas desconhecida, na população. Por exemplo, em uma lista de colégio, todos os estudantes com algum tipo de dificuldade recebem números ímpares e o critério de seleção da amostra seja feita, também, por números ímpares.  

## Amostragem estratificada

Neste tipo de amostragem, a população é dividida em subpopulações em função de características em comum, o que é chamado de estrato. Em seguida, cada participante recebe uma identificação dentro de seu estrato e o processo de amostragem aleatória simples é feito dentro em cada estrato. Atente que é possível que os participantes recebam os mesmos números. Por exemplo, se no estrato 1 há 100 pessoas, os números irão de 1 a 100 dentro deste estrato. Se no segundo estrato há também 100 pessoas, os participantes deste estrato também receberão números de 1 a 100. Com muita frequência, as características de interesse na população são desbalanceadas e, com isso, os estratos e a amostra também serão desbalanceados. Por exemplo, se há cerca de 80% de mulheres em uma determinada população, é esperado que a amostra tenha proporção similares de mulheres. 

![](./img/cap_a_estratificada.png)

Em uma pesquisa de nosso grupo, este tipo de amostragem foi feita. O nome da pesquisa é *Depression and Anxiety Symptoms in a Representative Sample
of Undergraduate Students in Spain, Portugal, and Brazil*. Em alguns capítulos, a base desta pesquisa é utilizada.  


**Vantagens**:   
**Desvantagem**:    

## Amostragem por conglomerados

Neste tipo de amostragem, a população encontra-se localizada - naturalmente - em conglomerados. Estes conglomerados podem ser ruas, bairros ou empresas, por exemplo e são assumidos como heterogêneos. Os conglomerados recebem identificações que, por sua vez, são sorteadas. Todos os participantes dos conglomerados sorteados devem ser acessados. 

![](./img/cap_a_conglomerado.png)

**Vantagens**: Quando a identificação dos elementos da população é difícil, os conglomerados aparecem como solução. A população já está dividida naturalmente.  
**Desvantagens**: Os estratos não serem homogêneos entre eles.    


## Amostragem por conveniência  
Neste tipo de amostragem, a amostra é feita pelos participantes que o pesquisador tem maior acesso.  

**Vantagens**: Fácil de se coletar, acessível e tende a crescer rapidamente.   
**Desvantagens**: Pode representar mal a população e, consequentemente, ter viés. Apesar de possível, a generalização é desaconselhada.

## Amostragem por auto-seleção  

Neste tipo de amostragem, os participantes voluntariamente solicitam participar da pesquisa. Isso tende a acontecer em pesquisas em que a coleta de dados é feita online (ex: google survey ou survey monkey) e também em estudos sobre novos medicamentos.  

Vantagens: Relativamente mais fácil de se coletar.  
Desvantagem: similar à amostragem por conveniência.      

## Amostragem intencional  
Neste tipo de amostragem, o pesquisador decide quem irá compor a amostra. É bem frequente em estudos psicométricos de validação de testes psicológicos. Neste tipo de pesquisa, existe uma etapa em que especialistas são convidados para opinar sobre características dos testes.  

Vantagens: Relativamente fácil de se identificar os juízes.  
**Desvantagens**: similar à amostragem por conveniência. Além disso, o tamanho amostral tende a ser baixo.  

## Amostragem por bola de neve
Neste tipo de amostragem, o pesquisador identifica um participante de interesse que, consequentemente, indica outros participantes para pesquisa. Por exemplo, caso deseje-se avaliar a saúde mental de usuários de cocaína, o pesquisador poderia identificar a primeira pessoa a ser avaliada que, em seguida, indicaria outras possíveis participantes.  

**Vantagens**: Pode ser implementada de maneira fácil e o crescimento amostral tende a ocorrer rapidamente.  
**Desvantagens**: similar à amostragem por conveniência.   


## Amostragem por quotas  

Este tipo de amostragem tende a ter um rigor mais elevado dentro das técnicas não-probabilísticas. Na amostragem por quotas (ou cotas), o pesquisador define classes populacionais e, em seguida, determinar a proporção da população para cada classe. Pode ser utilizada em situações em que não se tem muitas informações sobre características populacionais para fazer uma técnicas probabilística, mas sabe-se o suficiente para criar classes. Eventualmente, pesquisas eleitorais e análise de mercado podem contar com esta técnica.  

**Vantagens**: Pode ser implementada de maneira fácil e tende a ser executada rapidamente. Apresenta um maior rigor dentro do conjunto dos métodos não-probabilísticos.   
**Desvantagens**: similar à amostragem por conveniência. 


## O cálculo do tamanho amostral

Após decidir qual é o tipo de plano amostral, é necessário que o pesquisador defina quantos participantes irão compor a amostra. Se relativamente poucos participantes de uma população forem amostrados, os resultados podem distorcer o fenômeno investigado. Por contraste, se uma quantidade maior do que a necessária de participantes for amostrada, este excesso pode representar custos desnecessários e também distorcer as conclusões de algumas análises que serão apresentadas no decorrer do livro. 

Existem diferentes formas de se realizar o cálculo do tamanho da amostra. No entanto, todas as maneiras costumam depender das seguintes condições:

- Da variabilidade do fenômeno a ser investigado (maior variabilidade, maior amostra).  
- Do interesse do pesquisador.  
- Do tamanho da população.   
- Do nível de confiança estatística.  
- Do erro máximo que o pesquisador deseja correr.  
- Do tipo de amostragem.
- Das possíveis perdas de elementos da amostra.



Uma das principais características da população que entra em cena para computar um tamanho amostral é a <u>variabilidade do fenômeno a ser investigado</u>. Populações homogêneas tendem a precisar de amostras com menos elementos. Por oposição, fenômenos heterogêneos solicitam que o tamanho amostral seja maior. A variabilidade pode ser determinada pela literatura prévia e estudo piloto.  

O <u>interesse do pesquisador</u> pode ser apenas descritivo ou guiado pela execução de testes de hipótese. Quando descritivo, há um sistema fechado de equações que auxiliam no cálculo amostral. Quando teste de hipóteses são desejados, quase sempre, pesquisadores contam com heurísticas acadêmicas e também fazem um cálculo chamado "de poder do teste". Este cálculo visa otimizar o tamanho da amostra para que nem erros do tipo 1 ou 2 ocorram.

O <u>tamanho populacional</u> é uma importante característica para definição da amostra. Para populações pequenas, a amostra abrange quase que a totalidade dos elementos. Em populações maiores isso não costuma ocorrer. A relação entre tamanho populacional e tamanho amostral costuma ser apresentado por uma função logarítmica, tal como descrito abaixo.

```{r, echo = FALSE, cache=TRUE }
library(tidyverse)
data.frame(populacao = seq(500:200000)) %>% 
  mutate(amostra =82.029*log(populacao)-246.42) %>% 
  ggplot(., aes(x = populacao, y = amostra)) + 
  geom_point() +
  ylim(0,850) +
  labs(x = "Tamanho populacional", y = "Tamanho amostral") +
  theme_bw()
```


O <u>nível de confiança</u> é a probabilidade que o intervalo estimado contenha o parâmetro populacional.

O <u> erro máximo que o pesquisador deseja correr</u> é materializado pela diferença esperada entre o parâmetro da população e o resultado a ser obtido pela pesquisa. Com frequência, a margem de erro  varia de 3 a 5% Os conceitos de nível de confiança e erro são conectados.

O <u>tipo de amostragem</u> e as <u> possíveis perdas de elementos da amostra</u> também impactam o tamanho amostral. Frequentemente, amostras são calculadas assumindo a Amostragem Aleatória Simples e, em seguida, os números são ajustados por tipos específicos. Finalmente, perdas amostrais são esperadas e tenta-se acrescentar este número ao plano amostral antes da coleta de dados.

É possível unir todos os conceitos em equações específicas para o cálculo do tamanho amostral. As fórmulas variam e seria pouco efetivo tentar apresentar todas as fórmulas ou eleger uma ou outra equação de maior uso para colocar nesta parte. Desta maneira, deixo o artigo intitulado "A lógica da determinação do tamanho da amostra em investigações Epidemiológicas" como principal referência deste tópico.  


## Amostragem e sua relação com os resultados   


```{block, type="glossario"}
<U>**GLOSSÁRIO**</U>   
**Validade externa**: O grau ou a extensão em que os resultados de um estudo podem ser generalizados para outras pessoas e grupos.  
**Riscos à validade externa**: Amostra não representativa da população de interesse, Seleção dos participantes de maneira artificial ou inadequada, Tamanho amostral inadequado.   
**Viés de não-resposta**: Viés que ocorre quando participantes selecionados para participar da pesquisa não a respondem. Pode ocorrer tanto em amostragens probabilísticas como não-probabilísticas, especialmente em situacões em que o tema é social ou afetivamente carregado.  
```


Quando uma pesquisa é feita, raramente sua finalidade é apenas descritiva, ou seja, de detalhamento dos resultados somente para os participantes amostrados. Com muita frequência, o interesse do pesquisador é conseguir generalizar os resultados obtidos pela amostra à população que ela representa. A capacidade de generalizar os resultados é chamado de <u>Validade externa</u> de uma pesquisa e depende pesadamente do tipo de amostragem definido. Na verdade, toda mecânica por detrás de análises inferenciais assumem que os dados vieram de uma amostra aleatória (representativa). Quando amostras não representativas são acessadas, vieses são esperados.   

Um exemplo bastante ilustrativo é o relatório intitulado *"The Hite Report"*, de Shere Hite, que foi conduzido e publicado na década de 1970 nos Estados Unidos. Este trabalho visou oferecer uma radiografia sobre a sexualidade e a vida conjugal feminina das norte americanas e se tornou um *best-seller* quase que imediatamente após publicado.   

![](./img/cap_importancia_amostragem.png)

Nesta pesquisa, Shere Hite enviou carca de 100.000 cartas para mulheres localizadas em todos os Estados Unidos perguntando questões sobre "Satisfação conjugal" e "Traição". Os resultados indicaram que 98% das mulheres estavam insatisfeitas em seus casamentos e que 75% delas estavam tendo ou tiveram relações extraconjugal enquanto casadas.   

Quando o trabalho foi cuidadosamente analisado, foi identificado que dos 100.000 questionários enviados, cerca de 4% retornou. Esse cenário deixou claro que, além da amostra não ter sido representativa da população de mulheres americanas, os resultados foram pesadamente influenciados pelo <u>viés de não-resposta</u>. Em outras palavras, é possível sugerir que apenas o grupo de pessoas insatisfeitas respondeu ao questionário e seus resultados são significativamente diferentes daquele grupo que não foi representado, que é a maioria e, provavelmente, formado por pessoas felizes em seus casamentos.  

## Amostragem, delineamento e generalização      

```{block, type="glossario"}
<U>**GLOSSÁRIO**</U>   
**Validade interna**: Grau em que os resultados de um estudo possam ser atribuídos ao delineamento e não a erros ou outros fatores não controlados.  
**Riscos à validade interna**: Tipo de amostragem utilizada, ausência de randomização dos participantes, Ausência de duplo-cego, Maturação e histórico dos participantes.     
```


É bastante típico que pesquisadores iniciem uma pesquisa para explorar ou responder um problema específico. Em Psicologia, os problemas tendem a se dividir naqueles em que características individuais são o alvo e naqueles em que aspectos sociais recebem maior atenção. Por exemplo, explorar as características de personalidade de pessoas que decidem não ter filho [@Neal2021], as atitudes sociais sobre a participação feminina em alguns trabalhoso [@Bursztyn2018] ou a relação ente nível socioeconômico e empatia social [@Piff2012], parcialmente exemplificam tais iniciativas. 

Apesar dos interesses diferirem, a grande maioria dos pesquisadores tem muito cuidado na hora de eleger o delineamento da pesquisa, fazer a coleta de dados e, em seguida, analisá-los. Erros ou fragilidades metodológicas durante tais etapa podem limitar ou impossibilitar a validade dos resultados. No entanto, esta validade em questão é chamada de <u>Validade interna</u>, que se relaciona majoritariamente com o nível de controle imposto durante a coleta de dados e a possibilidade de estabelecer relações entre variáveis, especialmente relações de causalidade.   


Dessa maneira, assumindo que o interesse de uma pesquisa seja conseguir explicar um determinado problema científico, mas também generalizar os resultados obtidos à população, <u>tão importante como ter um delineamento de pesquisa adequado para coletar os dados</u> (validade interna) é ter um <u>plano amostral que possibilite a generalização dos achados</u> (validade externa). Não é possível maximizar, ao mesmo tempo, a validade interna e a validade externa. Entretanto, o balanceamento de ambas as condições deve ser feito em função das perguntas de pesquisa propostas. 

A imagem a seguir visa integrar os conceitos de amostragem, delineamento e generalização. 

![](./img/cap_amostra_delineamento.png)

Em síntese, três condições são importantes em uma pesquisa:  

(1) O plano amostral, que indica o grau em que os resultados serão generalizáveis; 
(2) O delineamento de pesquisa, que auxilia em verificar relacionamento entre variáveis e   
(3) O tipo de análise estatística implementa, que como a pergunta de pesquisa será trabalhada por modelos probabilísticos.   




<!--chapter:end:04-tipo_de_amostragem.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: inline
---

# Estatística Inferencial



```{block, type="objectives"}
**Objetivos do capítulo**  
1. Introduzir alguns conceitos de estatística inferencial  
2. Apresentar os procedimentos feitos durante o Teste de Significância de Hipótese Nula (NHST)   
3. Discutir condições particulares sobre valores de P      
4. Oferecer leituras complementares sobre os tópicos  
```

Um dos principais objetivos ao se fazer uma pesquisa é conseguir generalizar as descobertas feitas no estudo para toda a população de onde os participantes pertencem Essa tarefa faz parte dos objetivos da estatística inferencial, que se ocupa majoritariamente com desenvolver estimativas sobre os parâmetros populacionais e testar hipóteses. 


Como apresentado em outros capítulos, a população pode ser formada por indivíduos, famílias, etc e é comumeiramente classificada em "população-alvo" e "população externa". A população-alvo é formada por aqueles indivíduos não amostrados, mas que o estudo pode generalizar os resultados. A população externa é formada por todos aqueles em que há a intenção de generalizar os resultados, mesmo que apresente características algo distintas dos indivíduos amostrados.

Em uma pesquisa de nosso grupo [@AfonsoJunior2020], nós contamos com uma amostra aleatória de estudantes universitários de uma universidade do Rio de Janeiro e estudamos algumas de suas características epidemiológicas. Neste caso, a população-alvo poderia ser entendida como todos os estudantes universitários da cidade do Rio de Janeiro, enquanto a população externa poderia ser formada por todos os estudantes universitários do Brasil. 


![](./img/cap_inferencia_amostra_populacao.png)


O processo para estimar parâmetros envolve algumas etapas e, apesar de importantes, são quase sempre secundários em Psicologia e muitas áreas científicas. Na grande maioria dos casos, Psicólogos e outros profissionais de áreas científicas fazem uma pesquisa visando testar hipóteses sobre seu objeto de investigação. Dessa forma, como testes de hipóteses figuram como os principais protagonistas da estatística inferencial, eles terão também destaque neste  capítulo.  



## NHST (Teste de Significância de Hipótese Nula)


```{block, type="glossario"}
<U>**GLOSSÁRIO**</U>   
**Parâmetro**: Valor que descreve uma característica da população. Esse valor é fixo e desconhecido. Sua representação é feita por letras gregas.  
**Estatística**: Valor que descreve uma característica da amostra. Esse valor é aleatório e calculado através dos dados coletados.  É apresentado por letras romanas.  
**Inferência**: Processo pelo qual, através de modelos estatísticos, se tiram-se conclusões sobre características da população a partir dos dados amostrais e permite fazer generalizações e previsões a respeito da população. Técnicas inferenciais permitem a estimativa dos parâmetros populacionais e testar hipóteses.  
**Modelo estatístico**:  Sistema de equações que descreve ou representa o possível processo gerador de dados do conjunto de dados em análise.    
**NHST**: Sigla que representa Teste de Significância de Hipótese Nula (em Inglês, Null Hypothesis Significance Testing)
```


::: {.warning}
**Atenção**: É extramamente difícil conseguir falar sobre este conceito em uma linguagem simples para todos, mas ao mesmo tempo sem inconsistências estatísticas. Algumas notas são deixadas durante a seção visando atingir este objetivo.     
:::


A sigla NHST se refere ao Teste de Significância de Hipótese Nula, que é o procedimento mais utilizado quando pesquisadores desejam testar hipóteses de pesquisa utilizando recursos da estatística. Subjacente a todo o processo, esta o pressuposto de que é possível transformar perguntas científicas em modelos probabilísticos e, com isso, utilizar a linguagem estatística para lidar com tais questões [@Curley013].

![](./img/cap_inferencia_modelos_estatisticos.png)



Existem diferentes maneiras de introduzir o tema e as subseções a seguir o apresentará descrevendo cada um dos termos que compõem a sigla por uma forma pragmática. Com algumas sutis diferenças, esses procedimentos e suas interpretações são similares em todas as áreas da teoria de decisão, tal como Teoria de Detecção de Sinal e diagnóstico médico, o que foi discutido por um trabalho meu recente.  

Algo colateral ao aspecto pragmatico, a forma pela qual os testes de hipóteses são feitos hoje é uma mistura entre a forma pela qual Ronald Fisher pensava ser a correta e a maneira pela qual Jerzy Neyman e Egon Pearson defendia ser a adequada.  

### A primeira etapa: a hipótese  

Na maioria das vezes, quando uma pesquisa é feita, ela visa testar uma hipótese. Por sua vez, uma hipótese é uma conjectura, uma suposição sobre o estado das coisas feita pelo pesquisador e usualmente pensada no presente do indicativo (ex: há) ou no futuro do pretérito (ex: haveria). Em ingles, há o habito de tratar uma hipótese de pesquisa como *Educated Guess*, tendo em vista que ela costuma ser feita de maneira cuidadosa e após alguma reflexão sobre o tema de interesse. As hipóteses podem ser classificadas como substantivas ou estatísticas.   

Uma hipótese substantiva é uma formulação textual e semântica sobre determinado fenômeno. Ou seja, é uma frase, tal como "haveria uma relação entre nível de atividade física e bem-estar psicológico", ou "o tratamento psicofarmacológico melhora quadros de depressão" ou ainda que "o tipo de colégio - público ou privado - influencia nos resultados de alunos em provas nacionais". A hipótese estatística, por sua vez, visa operacionalizar a hipótese substantiva e, com isso, é uma afirmação conjectural, em termos quantitativos, das relações estatísticas da hipótese substantiva (p. 46), o que será apresentado em seguida. 

![](./img/cap_inferencia_tipos_hipoteses.png)

Ao se fazer uma pesquisa, as hipóteses estatísticas podem ser divididas em Hipótese nula, representada por $H_0$ e Hipótese alternativa, representada por $H_1$ ou $H_a$.

Muitas pesquisas podem ser feitas e, consequentemente, muitas hipóteses construídas. Em Psicologia, quase sempre as hipóteses de interesse verificam diferenças entre grupos ou relacionamento entre variáveis e, por sua frequência na literatura, serão apresentadas aqui.  

Em pesquisas com esta finalidade, a hipótese nula é a mais conservadora sobre determinado fenômeno. Ela advoga que pela ausência de padrões, pela inexistência de um relacionamento de causa e efeito, de associação entre variáveis ou de diferença entre grupos. Em termo gerais, a hipótese nula define que qualquer condição observada na população/natureza pode ser melhor explicada pelo acaso.   

Por contraste, a hipótese alternativa apoia relação de causalidade entre variáveis, ou que determinado fator apresenta relacionamento com outro ou que existe diferenças entre grupos, etc. Em linhas gerais, a hipótese nula costuma ser definida como aquilo que o pesquisador não acredita (em ingles, chama-se de *Straw person Principle*) e a hipótese alternativa tende a ser a hipótese que o pesquisador previamente assumiu para motivar sua coleta de dados. 

Em estatística frequentista, por um apoio epistemológico, a hipótese nula é assumida como verdadeira antes mesmo de qualquer procedimento de coleta e análise de dados. Note que ao assumi-la como verdadeira, isso não significa afirmar que ela seja, de fato, verdadeira. Essa suposição tem origem em discussões clássicas em estatística e, pragmaticamente, a hipótese nula é o que pesquisadores desejam falsear ou refutar na maioria das vezes em suas investigações [@Lecoutre2014]. 

Apesar da definição textual da hipótese ser de fácil entendimento para todos, ele não tem utilidade para etapa de coleta de dados. Dessa forma, esse formato textual é substuído pelo formato estatístico. Por exemplo, se uma determinada pesquisa é feita sob hipótese de que "um determinado antidepressivo auxilia na melhora de pacientes deprimidos", isso tende a gerar a hipótese alternativa que pode ser lida como: "em média, pessoas deprimidas do grupo que usou o medicamento tem resultados mais baixos em uma escala de depressão quando constrastado com o grupo que não usou o medicamento". Conceitualmente:

$$\underbrace{O \,grupo \,que \,tomou \,antidepressivo \,terá \,menos \,depressão}_\text{Hipótese  substantiva}$$

$$H_0: \mu_{grupo (1)} = \mu_{grupo (2)} \\ \underbrace{H_a: \mu_{grupo (1)} < \mu_{grupo (2)}}_\text{Hipóteses estatísticas}$$

Neste tipo de formulação estatística, a hipótese nula necessariamente será formada pelo sinal de igual ($=$), enquanto a hipótese alternativa poderá ser diferente ($\neq$), maior ($>$) ou menor ($<$). Tecnicamente, isso costuma alterar levemente etapas analíticas, que são descritas em outros capítulos.  

É importante introjetar duas condições. A primeira é que o pesquisador não testa diretamente a hipótese substantiva, mas sim a hipótese estatística, que tenta operacionalizar a primeira. A segunda característica é que, em estatística frequentista, por mais importante que seja a hipótese alternatviva -- afinal, foi ela que motivou a pesquisa -- ela não é testada diratamente. De fato, se assume que a hipótese nula seja verdadeira por princípio e, em seguida, compara-se o quão compatível os resultados obtidos são à tal hipótese.


::: {.warning}
**Atenção**: O pesquisador tende a fazer uma pesquisa para verificar a adequação de sua hipótese ($H_a$). Entretanto, o mecânica da estatística frequentista testa o quão os resultados são compatíveis ou não com a hipótese nula.     
:::

Com tais explicações feitas, a primeira parte da sigla "NH" (de Null Hypothesis Significance Testing) foi apresentada.


## Nível de significância   

Toda pesquisa tem erros. Como visto anteriormente, em estatística frequentista, a hipótese nula é definida como verdadeira inicialmente. Dessa maneira, o nível de significância (denotado pela letra $\alpha$) é definido como o máximo erro tolerável [@Greenland2019] da probabilidade de se rejeitar a hipótese nula quando ela é, de fato, verdadeira. Ele deve ser estipulado <u>antes</u> da coleta e análise de dados e, por ser uma probabilidade, compreende valores entre 0 e 1. 

Apesar deste nível ser uma escolha do pesquisador, quanto maior ele for, mais facilmente a hipótese nula será rejeitada. No extremo, se o nível de significância for 1, todos os resultados irão concluir pela rejeição da hipótese nula. Por oposição, se o nível de significância for igual a 0, a hipótese nula jamais seria rejeitada, mesmo quando falsa.  

Em estatística frequentista, é convencional estipular o nível de significância em 5% (0.05) ou 1% (0.01). Em algumas ocasiões, 10% (0.1) como nível de significância é aceito, mesmo que isso possa gerar uma maior dificuldade na publicação. Apesar desses números não serem mágicos, a origem dos 5% remonta a Ronald Fisher, que no trabalho "*Statistical Methods for Research Workers*" (1925), deixou uma tabela com indicando quais seriam os resultados esperados tendo como critério este nível.

O nível de significância é importante pois ele é associado com o conceito de erros. Quando se rejeita uma hipótese nula verdadeira, da-se o nome de erro do tipo I. Em pesquisas médicas, esse é erro é chamado de "falso positivo" e, em psicofísica, de "falso alarme". 

Entende-se também que é possível que a hipótese nula não seja rejeitada mesmo quando ela é falsa. Esse é o erro do tipo II (2), que também é chamado de "falso negativo" em pesquisas médicas ou "perda" em psicofísica. Note que o erro do tipo 2 e alguns conceitos derivados não se conectam tão diretamente com o conceito de nível de significância. Isso ocorre pois esse conceito não é bem uma defesa de Ronald Fisher, mas foi introjetado posteriormente por Jerzy Neyman e Egon Pearson [@cohen2013explaining]. 

A tabela de tomada de decisão a seguir, uma matriz de confusão, é a mais tradicionalmente usada para ilustrar esse conceito. 


![](./img/cap_inferencia_tabela_decisao.png)
*Nota: Ronald Fisher tinha bastante resistência à ideia do erro do tipo II ou também aos intervalos de confiança. Essa tabela é uma junção pragmática de sua forma de entender testes de hipóteses e da forma de Jerzy Neyman e  Egan Pearson. A hipótese nula é assumida como verdeira e não <u>provada</u> ou <u>refutada</u> como tal.*


Existe um *trade-off*, ou relação de perde-ganha, entre o erro do tipo I e o erro do tipo II. Aumentar o erro do tipo I leva à diminuição do erro do tipo II. Desta forma, o pesquisador deverá pesar as consequências do erro do tipo I (falsos positivos) e também as consequências do erro do tipo II (falsos negativos) durante a testagem de hipótese.  

Ao fim desta seção, outro exemplo será dado para tornar esta tabela mais palatável. Com isto posto, a terceira parte da sigla "S" é considerada apresentada.



## O teste estatístico  

A testagem estatística pode ser entendida como uma maneira formal de modelar os dados e verificar a probabilidade de se obter determinados resultados assumindo a hipótese nula como verdadeira. De maneira mais direta, é uma ferramenta de auxílio para contrastar hipóteses, permitindo rejeitar ou não a hipótese nula, a partir de um nível de significância fixo previamente definido [@Lecoutre2014]. Com isso, ao se implementar testes estatísticos, se possibilita ter inferências sobre aspectos populacionais a partir dos resultados amostrais.  

Pragmaticamente, após a definição da hipótese nula e alternativa, bem como o nível de significância, testes estatísticos são calculados com base nos dados e seus resultados auxiliam a rejeitar ou falhar em rejeitar a hipótese nula. A estatística dispõe de um exército de testes estatísticos (ex: Teste T, Teste de Kruskal-Walis, etc), que tendem a ser classificados por muitos critérios, como o tipo de distribuição de algumas variáveis ou a natureza da VI/VD, etc. 

Apesar dessa estratégia ser comumeiramente feita não apenas em Psicologia, ela pode levar à falsa percepção de que os testes estatísticos são mutuamente exclusivos e que há uma fórmula de bolo padronizada em que cada situação de pesquisa necessita de um teste específico e não outro.

Neste livro, mesmo nos capítulos em que testes estatísticos são descritos, essas condições serão um pouco desafiadas. O que é fundamental ter conhecimento é que: 

(1) Todo teste estatístico assume alguns pressupostos, que devem ser sempre testados;   
(2) Os testes produzirão um valor numérico, que é um sumário estatístico chamado de estatística de teste, representado por letras como T ou $\chi^2$;    
(3) Esta estatística de teste é uma variável aleatória com algumas propriedades específicas;  
(4) Apesar da importância destes resultados, eles são sempre transformados em um valor de P. Por sua vez,       
(5) O valor de P é usado como critério de tomada de decisão.



## O valor de P

Após definir da hipótese nula e alternativa, bem como o nível de significância e execução do teste estatístico, um valor de P será apresentado. Ele é o critério mais comumente empregado para tomada de decisão em estatística frequentista e apresenta as seguintes condições:

(1) Seu valor é uma probabilidade e, portanto, compreende valores entre 0 e 1;   
(2) Seu valor é obtido por um modelo estatístico que é assumido como adequado e bem específicado;   
(3) Seu valor indica a probabilidade de se obter uma estatística de teste igual ou ainda mais extrema que observada assumindo a hipótese nula como verdadeira;    
(3) Seu valor indica a compatibilidade dos resultados obtidos e os esperados assumindo a hipótese nula verdadeira;     
(4) Quando o valor de P é baixo, isso possibilita que o pesquisador conclua pela rejeição da hipótese nula;     
(5) Quando o valor de P é alto, isso impede que a hipótese nula seja rejeitada.     

Como valores baixos ou altos são relativos, em estatística frequentista, se considera que a rejeição da hipótese nula ocorre apenas quando o valor de p é menor do que o valor previamente estipulado no nível de significância. Neste sentido, a tomada de decisão segue uma regra discreta, que é:

$$P<\alpha \Rightarrow \ Rejeitar \, H_0 \\P 	\geq \alpha \Rightarrow \ Falhar \,em \,Rejeitar $$



É importante notar que rejeitar $H_0$ não significa aceitar $H_a$. Esse erro é frequente e é chamado de *Modus Tolens* [@Trafimow2019]. Repare que neste procedimento sequer há a necessidade de $H_a$. Além disso, os valores de P se referem às estatisticas de teste obtidas durante etapas analíticas. Eles não se referem à teoria científica que motivou a pesquisa e, desta forma, rejeitar $H_0$ também não significa falar que uma teoria foi provada.   

Finalmente, falhar em rejeitar $H_0$ não prova que ela é verdadeira. É possível apenas concluir que ainda não existem evidências sólidas para rejeitá-la. Aceitá-la significa cair num erro chamado de *Argumentum ad Ignorantiam*, em que as pessoas tendem a achar que algo que não foi provado como falso é, consequentemente, algo verdadeiro. 


Com isso, a última letra "T" de NHST, foi descrita.


## O tamanho do efeito  

Os valores de P são importantes como uma medida de força de evidência contra a hipótese nula, bem como permitem que os parâmetros (populacionais) sejam estimados pelos resultados amostrais. Por estas características, eles são importantes em testes de hipóteses e devem sempre ser relatados. No entanto, pragmaticamente, seus resultados são discretos (sim ou não) e <u>não</u> respondem diretamente as questões ou hipóteses que motivaram a execução da pesquisa, apesar de auxiliarem na tomada de decisão [@Goodman1999]. 


Medidas chamadas de Tamanho do efeito foram mais recentemente desenvolvidas tentando ofercer um indicador <u>contínuo</u> que visam responder a magnitude, relevância ou importância dos resultados, especialmente, quando se investiga diferenças entre dois grupos. 


Em todas as pesquisas amostrais, apenas uma parte da população foi acessada. Neste sentido, como parte da população não foi investigada, qualquer processo de generalização dos resultados pode incorrer em erros inferenciais. Uma vez que a estatística assume que a hipótese nula é, a priori, verdadeira, o erro que primeiro pode aparecer no processo de inferência ocorre quando o pesquisador rejeita a hipótese nula de maneira incorreta. Como a hipótese nula tende a apoiar, por exemplo, que não há diferença entre grupos, ao rejeitar incorretamente

 

## Um exemplo intuitivo   

Muitas áreas que trabalham com a noção de incerteza e erro fazem uso de recursos da Teoria da Decisão. A Teoria da Decisão é uma área interdisciplinar que visa descrever e explicar os processos subjacentes à escolha, com larga aplicação em testes de hipótese, detecção de sinal, exames médicos e avaliação psicológica.  


Dessa maneira, apesar de pequenas modificações de simbologia e nomenclatura, a tabela de tomada de decisão apresentada anteriormente costuma se repetir em todas essas áreas para a mesma finalidade: equacionar os custos dos erros e acertos possíveis. 

Isso posto, exames médicos talvez representem a melhor forma de entender este processo de tomada de decisão. Imagine que duas pessoas resolvam fazer exame para verificar se estão ou não grávidas. O resultado do exame tem uma grande importância, já que ele servirá de evidência para que ambas as pessoas planejem suas vidas daqui para frente. 

Apesar de assumirmos intuitivamente que exames médicos, no geral, são muito acurados, é importante introjetarmos que eles podem apresentar resultados incorretos ou distorcidos. Isso acontece pois estes exames não medem diretamente o fenômeno de interesse, mas apenas sinais mais ou menos específicos de determinada condição. No caso da gravidez, esses exames costumam verificar o nível do Beta HCG, que atua como um marcador bioquímico importante relacionado à gravidez e algumas outras condições.  

É possível aproximar este exemplo pedagógico às hipóteses estatísticas descritas. Repare que <u>na realidade</u>, é possível estar ou não gravida. No entanto, na modelagem <u>estatística</u>, se assume inicialmente que a hipótese nula é verdadeira. Neste sentido, uma vez que a hipótese nula apoia a inexistência de padrões, sinais, eventos (etc), <u>não estar</u> grávida é a hipótese definida como verdadeira prelimiarmente.  

O resultado do exame pode indicar que a pessoa está gravida ou que não está grávida. No jargão metrológico, esses resultados são chamados de "Positivo" e "Negativo", respectivamente. Conectando este elemento com a modelagem estatística, se o exame concluir que a pessoa está gravida, isso significa que ele <u>rejeitou a hipótese nula</u>. Em outras palavras, resultados positivos neste exemplo são resultados que rejeitam a hipótese nula. Por oposição, se o exame concluir que a pessoa não está grávida, ele teve um resultado negativo. Pela modelagem estatística, esse tipo de resultado <u>falhou em rejeitar a hipótese nula</u>.

![](./img/cap_inferencia_tabela_decisao2.png)


## O que não te contaram sobre inferência estatística   
 
Conforme previamente exposto, introduzir o conceito de teste de significância de hipótese nula em uma linguagem que seja estatisticamente correta e, ao mesmo tempo, facilmente capturável por todos é uma tarefa que parece já nascer fracassada. Há farta literatura indicando isso. Cerca de 90% dos pricipais livros-texto em Psicologia apresentam conceitos equivocados sobre teste de hipóteses [@Cassidy2019], o que tambem é frequente em escolas médicas [@OcaaRiola2016; Greenwood2015] e uma das justificativas da dificuldade em reproduzir ou replicar resultados previamente publicados [@Motulsky2014].


É provável que tais entraves quase universais e já bem enraizados na docência de estatística aplicada ocorram também em outras áreas e, provavelmente, uma revisão crítica deste próprio texto tal como está apontaria limitações ou inadequações. Tendo essa condição como base, a listagem de tópicos a seguir visa, ao menos, reduzir que algumas inconsistências sobre testes de hipóteses sejam mantidas ou reforçadas.    


**Condições metodológicas**


- De acordo com a teoria Popperiana, uma teoria ou hipótese jamais podem ser provadas. Só é possível gerar evidências que a corroborem provisoriamente ou a rejeitem. Como diz Einstein “No amount of experimentation can ever prove me right, but a single experiment can prove me wrong”. Assim, nenhum resultado obtido em pesquisas deve ser visto como uma prova cabal ou perfeita de uma teoria.   

- A hipótese nula não necessariamente é zero. É possível que ela defina outros valores. O termo *Nil* é usado para expressar $H_0$ quando ela é zero.   

- O valor de P não pressupõe hipótese alternativa. Ele é uma medida de quão compatível são os dados assumindo a hipótese nula como verdadeira.   

- A maioria dos testes inferenciais nada mais são do que modelos de regressão. As chamadas variações ou alternativas não-paramétricas tendem a ser modelos de regressão em dados ordenados.  

- O valor de P depende exclusivamente da hipótese nula e pode ser representado tanto em sentido possibilístico ou, com restrições e muitas discussões acadêmicas, como uma probabilidade condicional.   

- Tem pouco ou nenhum sentido verificar a normalidade da variável dependente antes de performar um teste estatístico. A grande maioria dos testes estatísticos são versões reduzidas de modelos lineares. Assim, testar a normalidade da variável dependente não é um pressuposto de Teste T ou ANOVA. A normalidade desses modelos estatísticos são assumidas aos resíduos.  


- O Teorema Central do Limite e a Lei dos Grandes Números são fundamentais na teoria da inferência, mesmo que não tenham sido abordado diretamente aqui.

- Técnicas de bootstrapping e estatística robusta lidam bem com a violação de alguns pressupostos.   

- Teste paramétrico não significa que a distribuição é normal, mas apenas que são caracterizados por uma família de distribuições indexada por um parâmetro. Neste testes, o formato da distribuição dos dados é importante e eles visam estimar parâmetros (populacionais). O modelo exponencial ou de Poisson, por exemplo, são paramétrico.

- Testes não-paramétrico são melhores descritos como livres de distribuição, já que a distribuição dos dados não é uma preocupação de análise. 


**Condições históricas**

- A proposta de uma tabela de confusão para equacionar o processo de tomada de decisão é uma mistura estranha entre as formas de entender os testes de significância de Ronald Fisher e o Teste de Hipóteses de Neyman e Pearson. Há um excelente capítulo intitulado *The Fisher, Neyman–Pearson and Jeffreys Views of Statistical Tests* indicando passagens históricas sobre a relação agressiva e conturbada entre eles [@Lecoutre2014].   


**Grandes debates**    

- A violação dos modelos estatísticos costuma ocorrer com relativa frequência em Psicologia. Há uma intensa discussão sobre as consequências disso, incluindo posicionamentos que sugerem que a crise de replicação é em função disso e posicionamentos que julgam que a violação dos pressupostos tem pouco ou nenhum impacto na maioria das vezes. 

- Parece haver uma ênfase muito grande em verificar pressupostos de modelos compactos (Teste T), que não é acompanhada em modelos mais complexos.  

## Questões  

<div class="question">

1. (Retirado de Business Statistics) Qual das sentenças é verdadeira<br>a) A hipótese nula não é testada. A hipótese alternativa é testada.<br>b) A hipótese nula é testada. A hipótese alternativa não é testada.<br>c) Ambas as hipóteses (nula e alternativa) são testadas.<br>d) Ambas as hipóteses (nula e alternativa) não são testadas<br>e) Todas as opções.


1. (Retirado de TJ-MS, Técnico de Nível Superior - Estatístico). Teste de Hipótese compõe um conjunto de regras de decisão para aceitar ou rejeitar uma hipótese estatística com base em dados amostrais. A respeito do Teste de Hipótese, avalie as considerações a seguir.<br>I. A hipótese utilizada como referência no teste é a hipótese nula, representada pela sigla H0.<br>II. A construção da região crítica é feita sob a premissa de que a hipótese utilizada como referência é falsa.<br>III. Ao se testar a hipótese utilizada como referência, está sujeito a cometer dois tipos de erros: rejeitar a hipótese quando ela é verdadeira, ou não rejeitar a hipótese quando ela é falsa.<br>IV. Em caso de teste para diferença entre médias de duas populações normais, a hipótese alternativa assumira a igualdade entre as duas médias.<br> V. Na construção da região crítica com teste bilateral, o nível de significância deve ser dividido entre as duas áreas de rejeição.    
É CORRETO apenas o que se afirma em:<br>a)	I, III e V.<br>B)	II, III e V.<br>C)	I, II e III.<br>D)	III, IV e V.<br>E)	IV e V.

1. (Retirado de Business Statistics) O nível de significância é<br>a) A probabilidade mínima de rejeição da hipótese nula.<br>b) A probabilidade máxima de rejeição da hipótese nula.<br>c) A probabilidade mínima da rejeição da hipótese alternativa.<br>d) A probabilidade máxima da rejeição da hipótese alternativa.<br>e) Todas as opções.

1. (Retirado de Analista Estatística, CNMP, FCC, 2014) Com relação a testes de hipóteses estatísticas e denominando H0 como sendo a hipótese nula e H1 a hipótese alternativa, a definição de potência de um teste corresponde à probabilidade de:<br>a) não rejeitar H0, quando H0 é verdadeira.<br>b) não rejeitar H0, quando H0 é falsa.<br>c) não rejeitar H0, independentemente de H0 ser falsa ou verdadeira.<br>d) rejeitar H0, quando H0 é verdadeira.<br>e) rejeitar H0, quando H0 é falsa.  

1. (Retirado de Economista, Petrobrás, CESGRANRIO, 2010) No caso de um teste estatístico clássico, com a hipótese nula H0 e a alternativa H1, cometer o erro do tipo II consiste em:<br>a) rejeitar H0, sendo H0 verdadeiro.<br>b) aceitar H0, sendo H0 falso.<br>c) aceitar H1, sendo H1 verdadeiro.<br>d) rejeitar H1, sendo H1 falso.<br>e) aceitar H0 e aceitar H1.

 
</div>
<div class="mirror">Gabarito: 1-b; 2-a; 3-b; 4-e; 5-b</div>



## Pesquisas adicionais  

Como este capítulo apresentou tanto aspectos pragmáticos, como alguns eventos históricos sobre inferência estatística e testes de hipótese, seria possível listar inúmeras referências de qualidade como recursos adicionais. Entretanto, vou optar por apenas algumas obras que eu costumo acessar várias vezes para reler.

1. On some assumptions of the null hypothesis statistical testing (DOI: 10.1177/0013164416667979)
Este é um trabalho de Alexandre Patriota que é uma referência na aplicação e docência em estatística. A discussão sobre valor de P como probabilidade condicional é importante e merece uma atenção.  

2. Fisher,Neyman-PearsonorNHST?Atutorialforteachingdatatesting (DOI: 10.3389/fpsyg.2015.00223)  
Este é um trabalho interessante que oferece algumas estratégias de docência sobre testes de hipótese. Uma característica bastante positiva deste trabalho é sua diferenciação dos procedimentos do teste de significância de Fisher e o teste de hipóteses de Neyman-Pearson

3. Statistical tests,  P values,  confidence intervals,  and power: a guide to misinterpretations (10.1007/s10654-016-0149-3)
Este é um trabalho muito interessante que descreve as principais rotinas feitas em testes de hipóteses, mas também 25 equívocos frequentes que pesquisadores fazem ao interpretar os valores de P.   




<!--chapter:end:05-estatistica_inferencial.Rmd-->

# Teste T

```{r base e pacotes Teste T, include = FALSE }
load(file="~/anovabr/mqt/bases/Livro - R - ASQ SE 12 e 18.RData")

library(tidyverse)
library(pander)
library(knitr) #tables and graphs
library(kableExtra) #tables with different styles


```

```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar o Teste T  
2. Discutir os pressupostos de execução do Teste T  
3. Realizar gráficos relacionados à comparação de médias  
4. Apresentar e interpretar métricas de tamanho do efeito  
5. Dar exemplos relacionados à escrita dos resultados   
6. Apresentar testes robustos e não paramétricos   
```

O Teste T é um teste estatístico frequentemente utilizado para testar hipóteses sobre <u>diferenças entre até duas médias</u>. É possível usar o Teste T para (1) comparar a média de uma amostra com a média populacional (*one sample t test*), (2) para comparar duas médias amostrais (*two sample t test*) ou (3) para comparar duas médias de uma mesma amostra que foi investigada em dois momentos do tempo (*paired ou matched t test*). Por utilizar dados amostrais da média para estimar a média populacional (parâmetro $\mu$), ele é considerado um teste parâmetrico.   

Como todo teste inferencial, o Teste T é um modelo estatístico, com os seguintes pressupostos:  

*(i)* Os dados são aleatórios e representativos da população  
*(ii)* a variável dependente é contínua  
*(iii)* Os resíduos do modelo são normalmente distribuídos      

Quando há o interesse de utilizar o Teste T para comparar os resultados de dois grupos, é também necessário que: 

*(iv)* ambos os grupos sejam independentes (ou seja, grupos exaustivos e excludentes)  
*(v)* A variância residuais seja homogênea (princípio da homocedasticidade)  

Quando se utiliza o Teste T pareado, o princípio da independência não é mais solicitado, mas é necessário que:  

*(vi)* o tamanho amostral seja o mesmo nos grupos   


Uma vez que o Teste T é adequado para diferentes objetivos de pesquisa, a tabela a seguir reúne alguns exemplos.
  
  | Teste T para    | Exemplo                                                                                       
  | :-----------    | :-----------                                                                                   
  | Uma amostra | -Verificar se o peso médio dos bebês de uma maternidade é similar ao esperado na população <br> -Testar se a frequência respiratória de atletas de corrida difere da de outros atletas  
  | Dois grupos independentes | -Verificar se o nível de anticorpos é diferente entre pessoas vacinadas e não vacinadas <br> -Verificar se os resultados da prova do ENEM são diferentes em estudantes da rede pública ou privada de ensino  
  | Pareado | -Verificar se um programa de reforço escolar melhorou as notas de conjunto de alunos<br>-Testar se uma mudança arquitetônica em uma loja impactou em suas vendas


Eventualmente, quando os pressupostos do modelo são violados, a literatura mais tradicional recomenda que ajustes ou testes não-paramétricos com propostas parecidas possam ser implementados. A tabela abaixo concatena os testes estatísticos relacionados para fins de comparação com outros trabalhos. Há também autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, argumentando que os dados têm nível de medida "ordinal".


  | Versão do teste | Um grupo           | Dois grupos independentes |  Grupos pareados    
  | :-----------    | :-----------       | :-----------              |  :-----------      
  | Paramétrica     | One-sample  t test | Two-samples t test        |  Paired t test
  | Não-paramétrica | Signed rank test   | Mann-whitney              |  Wilcoxon


*Nota: Existe um intenso debate sobre a utilização de testes paramétricos e não-paramétricos em Psicologia. Algo pouco comentado, apesar de ser o aspecto mais importante em minha opinião, é que a hipótese testada em um teste paramétrico é diferente da teste da testada em um não-paramétrico. Ou seja, a substituição de um teste estatístico por outro, necessariamente, muda a hipótese de pesquisa investigada. O Teste T não assume normalidade da variável dependente, mas sim normalidade dos resíduos do modelo probabilístico, que será explicado em seguida* 

Apenas por um preâmbulo histórico, a origem do Teste T remonta o artigo publicado em 1908 por William Gosset. Na época, em função de seu trabalho na cervejaria Guiness, ele não assinou o artigo. Na publicação, ele utilizou o pseudônimo *Student*, motivo pelo qual o Teste T também é chamado de Teste T de Student. Há muitas versões sobre o que levou Gosset a se apresentar como *Student*, mas parece que isso se deu em função de um caderno em que ele tomava notas, cuja capa tinha escrito *The Student's Notebook*.  

É importante notar que estudantes de Psicologia e profissionais que trabalham com avaliação psicológica costumam ser deparados com uma métrica chamada "T score" (Escore T, as vezes), desenvolvido em 1939 por um professor de Psicologia (William Anderson McCall). Tenha em mente que essa métrica não tem relação com os procedimentos inferenciais relacionados ao Teste T a não ser uma similaridade de nome [@Krus1977]. 


## Pesquisa
  
<div class="alert alert-warning">
  <strong>Base: </strong> [Livro - R - ASQ SE 12 e 18](https://github.com/anovabr/mqt/raw/master/bases/Livro%20-%20R%20-%20ASQ%20SE%2012%20e%2018.RData)  
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada [“Confirmatory analysis and normative tables for the Brazilian Ages and Stages Questionnaires: Social–Emotional”](https://onlinelibrary.wiley.com/doi/abs/10.1111/cch.12649), publicada em 2019 na Child Care Health Development. Esse trabalho teve dois objetivos. O primeiro visou confirmar a estrutura fatorial de um instrumento utilizado para avaliar possíveis atrasos no desenvolvimento de competências sociais e emocionais (ASQ:SE) e o segundo visou desenvolver tabelas normativas para comparar meninos e meninas. Essa é uma pesquisa muito importante, visto que conta com uma base de dados robusta (mais de 50 mil participantes) e faz interface entre psicometria, avaliação psicológica e políticas públicas.


Abaixo, há a escrita de hipóteses utilizada para comparar os resultados de meninos e meninas, bem como o nível de significância adotado na análise.

$$H_0: \mu_{meninos} - \mu_{meninas} = 0 \\ H_a: \mu_{meninos} - \mu_{meninas} \neq 0 \\ \alpha = 0.05$$



## Execução no R  


No ambiente R, a primeira etapa importante é assegurar que a base de dados tenha o resultado relacionado às competências sociais e emocionais das crianças. Esse valor será computado pela soma de todos os itens da escala. No dplyr, isso é feito pela integração da função `mutate` com a `select` e será executado às crianças com 12 (`asq_12months`) e 18 meses (`asq_18months`). 

```{r}
asq_12months <- asq_12months %>% 
  mutate(total_12 = rowSums(select(., starts_with("q_")), na.rm = TRUE))

asq_18months <- asq_18months %>% 
  mutate(total_18 = rowSums(select(., starts_with("q_")), na.rm = TRUE))

```

Em seguida, <mark>iremos começar pelos 12 meses</mark>. O processo de testagem da hipótese é feito preliminarmente de maneira tabular e gráfica e, em seguida, pela implementação do teste específico e verificação de seus pressupostos. A tabela a seguir apresenta as principais características estatísticas dos resultados:


```{r}
asq_12months %>%
  group_by(sex) %>% 
  summarise_at(vars(total_12), lst(n=~n(),media=mean, DP=sd)) %>% pander()
```

Em seguida, a realização de um gráfico é bastante informativa para apresentação dos resultados. Apesar desse recurso não ser decisivo na tomada de decisão, ele auxilia a visualização da distribuição da variável que temos interesse, bem como oferece um entendimento inicial dos resultados.

Uma vez que a VI é tratada como discreta e a VD é continua, tanto o gráfico de colunas/barras como o histograma/densidade são úteis. O gráfico de barras tem uma vantagem de ser possível adicionar barras de erros, que já apresentam uma primeira evidência inferencial. Por sua vez, histogramas e gráficos de densidade descrevem bem o formato da distribuição de dados.  


```{r}
gridExtra::grid.arrange(
  #plot 1 
  ggplot(asq_12months, aes(x = sex, y = total_12, fill = sex)) +
    geom_bar(stat = "summary", fun = mean) +
    stat_summary(fun.data = mean_se, geom = "errorbar", width = .2),
  #plot 2
    ggplot(asq_12months, aes(x = total_12, fill = sex)) + 
    geom_density(color = NA, alpha=.6)
)
```

Os achados preliminares indicam que os resultados de meninos e meninas é ligeiramente diferente. No entanto, é necessário a execução da testagem formal desta hipótese. 

A função `t.test` é nativa do R o vetor `t_test_12_m` será criado.

```{r}
t_test_12m <- t.test(total_12 ~ sex, var.equal = T, data = asq_12months)
```

A tabela a seguir apresenta os resultados.  

```{r}
t_test_12m %>% pander::pander(., split.table = Inf)
```

Os achados trazem a média de ambos os grupos (`r round(t_test_12m$estimate[1],2)` e `r round(t_test_12m$estimate[2],2)`), a estatística do teste (`r round(t_test_12m$statistic,2)`), chamada de T calculado, os graus de liberdade (`r t_test_12m$parameter`) e o valor de p (`r round(t_test_12m$p.value,2)`). 

Repare que como <mark>o valor de p é superior ao valor estipulado do nível de significância (0.05), falha-se em rejeitar a hipótese nula</mark>. Nesse sentido, apesar dos resultados serem numericamente distintos, eles não são estatisticamente significativos (na população).

::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::


Um aspecto importante é que a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.

<mark> Normalidade</mark>: O Teste T é um caso especial de um modelo de regressão, o que será detalhado em outro capítulo. Dessa maneira, a normalidade que deve ser testada é a dos <u>resíduos</u> deste modelo. Isso pode ser aproximado testando a distribuição <u>condicional</u> dos resultados, ou seja, testando cada grupo independentemente. Tenha atenção que não é necessário testar a variável dependente como um todo. Caso os resultados sejam significativos, os dados serão aproximadamente bimodais e, consequentemente, não serão normalmente distribuídos.  

A normalidade pode ser avaliada graficamente por QQ plots e por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera.

O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis contra os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se sobrepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade.

```{r}
ggplot(asq_12months, aes(sample = total_12)) + 
  stat_qq() + 
  stat_qq_line() +
  facet_wrap(~sex)
```

Apesar do gráfico já ter sido bastante claro e sugerir fortemente desvio da normalidade em ambos os grupos, o teste formal é importante. O Shapiro-wilk costuma ser utilizado neste caso, uma vez que ele reúne diferentes características positivas no balanço entre erro do tipo 1 e 2 [@Yap2011]. A hipótese nula desse teste assume que a variável de interesse tem distribuição (aproximadamente) normal. Assim, rejeitar a hipótese nula sugere que esse princípio foi violado e, com isso, o Teste T pode gerar resultados distorcidos.


```{r}
asq_12months %>% 
  group_by(sex) %>% 
  summarise(shapiro = shapiro.test(total_12)$p.value) %>% pander::pander()
```

De maneira convergente ao gráfico, o Shapiro-wilk também apontou que o princípio da normalidade foi violado.  


<mark>Homocedasticidade</mark>: A homogeneidade ou igualdade das variâncias pode ser testada visualmente, pelo teste Breusch-pagan, Levene ou Bartlett. De maneira análoga ao Shapiro-wilk, estes últimos assumem como hipótese nula a homogeneidade das variâncias. Consequentemente, a rejeição desse pressuposto pode também trazer resultados distorcidos ao resultado do Teste T. Diferentemente do pressuposto da normalidade, o pressuposto da homocedasticidade foi preservado, tal como apresentado abaixo:  


```{r}
car::leveneTest(total_12 ~ sex, data = asq_12months) %>% pander::pander()
```
  
Após testar estes pressupostos, é importante avaliar o quanto a interpretação originalmente deve ser mantida. Existem diferentes recomendações sobre o que fazer quando os pressupostos são violados. Entre elas, assumir essa condição e justificar a utilização do Teste T, transformar a distribuição da variável de interesse, usar versões robustas do Teste T, usar testes não-paramétricos com objetivos próximos ao Teste T ou eleger algum modelo estatístico mais adequado à distribuição empírica obtida pelos dados.   

Parte dessas recomendações serão demonstradas a seguir.

---

Com este teste inicial concluído, é também possível verificar se existem diferenças em idades mais avançadas, <u>tal como 18 meses</u>. A sintaxe é customizável e torna-se fácil testar a hipótese da diferença apenas modificando a hipótese e a sintaxe. A tabela a seguir apresenta as principais medidas estatísticas:

```{r}
asq_18months %>%
  group_by(sex) %>% 
  summarise_at(vars(total_18), lst(n=~n(),media=mean, DP=sd)) %>% pander()
```

Por sua vez, o gráfico a seguir traz o padrão dos resultados aos 18 meses.  


```{r}
gridExtra::grid.arrange(
  ggplot(asq_18months, aes(x = sex, y = total_18, fill = sex)) +
  geom_bar(stat = "summary", fun=mean) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .2),

  ggplot(asq_18months, aes(x = total_18, fill = sex)) + 
  geom_density(color = NA, alpha=.6))
```

Tal como feito anteriormente, a realização do Teste T e a verificação de seus pressupostos devem ser realizadas.   

Em relação aos resultados do Teste T, eles indicaram que ambos os grupos tem resultados médios significativamente diferentes. Meninos apresentam resultados mais elevados (M = 27.53, DP = 21.81) do que meninas (M = 24.95, DP = 21.81).  


```{r}
t_test_18m <- t.test(total_18 ~ sex, var.equal = T,data = asq_18months)
t_test_18m %>% pander::pander(., split.table = Inf)
```

Diferentemente do anterior, agora o resultado foi significativo (p < 0.01), trazendo evidências que permitem concluir pela rejeição da hipótese nula. Da mesma forma que feito anteriormente, a verificação dos pressupostos é um elemento fundamental para validade da interpretação dos resultados. Uma vez que tais testes foram demonstrados na seção anterior, eles não serão reproduzidos agora. No entanto, dessa vez, a normalidade e a homocedasticidade foram violadas, fazendo que com as interpretações tornem-se frágeis, apesar de possíveis.  

Isso posto, é importante ter uma atenção especial ao conceito subjacente à significância estatística. Um resultado que rejeita a hipótese nula, <u>de forma alguma</u>, deve ser entendido como "aceitação da hipótese alternativa" ou como evidência de causalidade, especialmente em delineamentos transversais.  

::: {.warning}
**Atenção**: Nunca se aceita a hipótese nula ou a hipótese alternativa. Como Fisher (1931, p. 16) comenta, a hipótese nula nunca é provada ou estabelecida, mas é possivelmente refutada. Da mesma forma, rejeitar a hipótese nula não se refere à aceitar a alternativa, mas tão somente que os dados são incompatíveis à hipótese nula.    
:::

É fundamental lembrar que o valor de P se refere à probabilidade de encontrar a estatística de teste calculada, ou uma ainda mais exterma, assumindo que a hipótese nula é verdadeira [@Wasserstein2016]. Apesar de algo contraintuitivo, é assim que a estatística frequentista funciona.

## Tamanho do efeito  

Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da <u>relevância clínica</u> dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde.

Existem duas famílias principais no ambiente do tamanho do efeito, que são a família "d" e a família "r". Quando comparamos médias, usamos o d de Cohen para calcular a distância entre as médias das distribuições sobrepostas.

A interpretação é a seguinte:

  | Cohen's d      | Interpretação         
  | :-----         | :-----     
  | d < 0.2        | Irrelevante
  | d $\geq$ 0.2   | Pequeno
  | d $\geq$ 0.5   | Moderado      
  | d $\geq$ 0.8   | Grande 
    

Para executar este teste no R, é possível contar com o pacote `effsize`, tal como demonstrado abaixo:    

```{r}
effsize::cohen.d(total_18 ~ sex, data = asq_18months)
```

Com esse conjunto de dados, o tamanho do efeito foi irrelevante, indicando que a diferença dos resultados não apresenta uma relevância clínica importante. 

## Execução no JASP

Nesta parte, apenas a base de crianças com 18 meses será utilizada. Ela está disponível com o nome de [ds_18.csv](https://osf.io/xr2sq/). Da mesma maneira que foi feito no R, a apresentação de tabelas e gráficos auxiliam o pesquisador a verificar padrões nos dados. Para fazer tais procedimentos, é necessário ir até a seção `Descriptives`, como ilustrado a seguir.  


![](./img/jasp_descriptives.png)

Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadoras. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/jasp_descriptives2.png)

Isto posto, será necessário arrastar as variáveis de interesse aos seus respectivos locais. Neste caso, o <u>total_18</u> para parte das VDs, enquanto <u>sex</u> para a VI. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização.   


![](./img/cap_testet_tabela_descritiva.png)

Em seguida, ao clicar na opção `Plots`, será possível selecionar o `Boxplot`. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da <u>distribuição dos resultados</u> das crianças de 18 meses em função do <u>sexo</u> delas.


![](./img/cap_testet_tabela.png)

Para execução do Teste T, deve-se clicar em `T-Test` e, em seguida, `Independent samples T-test`. 

![](./img/cap_testet_interface1.png)

Ao realizar tais ações, a tela a ser exibida será próxima à imagem a seguir:


![](./img/cap_testet_interface.png)

Repare que a `Grouping variable` é o local onde a VI deverá ser colocada, enquanto a `Variables` é o local onde a VD irá ser inserida. É possível ter apenas uma VI, enquanto diferentes VDs podem ser inseridas na seção `Variables` para serem analisadas <mark>independentemente </mark>.  

Neste caso de agora, a VI é <u>sex</u> e a VD é <u>total_18</u>. Ao inseri-las em seus locais específicos, o JASP automaticamente irá fazer o Teste T e apresentar os resultados. Pragmaticamente, o valor de P costuma ser utilizado para decisões estatísticas e ele está destacado pelo quadrado roxo na imagem a seguir. 


![](./img/cap_testet_resultados_iniciais.png)


::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::


Entretanto, da mesma forma como apresentado no ambiente R, a interpretação deste resultado <u>não pode ser feita de uma forma automática</u>. É necessário saber se os pressupostos foram ou não atendidos, além de calcular o tamanho do efeito. Para verificar os pressupostos, será necessário utilizar as opções dispostas na parte inferior à esquerda do programa. Na imagem abaixo, elas foram destacadas pelo retângulo roxo.  

![](./img/cap_testet_pressupostos.png)

É necessário marcar as duas opções para que os testes sejam realizados. Os resultados são os mesmos já obtidos pelo R e indicam que ambos os pressupostos foram violados, sugerindo uma interpretação bastante cautelosa dos achados.

![](./img/cap_testet_pressupostos2.png)



Para inserir o tamanho do efeito ao lado do Teste T, é necessário clicar em `Effect size` e `Cohen's d`, ambos localizados na parte superior do JASP.

![](./img/cap_testet_tamanho_do_efeito.png)

Com estas informações marcadas, agora os resultados podem ser analisados em conjunto. O valor de P irá indicar se a hipótese nula foi rejeitada ou não. O tamanho do efeito indicará a relevância ou importância prática dos resultados.  


![](./img/cap_testet_resultados.png)

::: {.warning}
**Atenção**: Nunca se aceita a hipótese nula ou a hipótese alternativa. Como Fisher (1931, p. 16) comenta, a hipótese nula nunca é provada ou estabelecida, mas é possivelmente refutada. Da mesma forma, rejeitar a hipótese nula não se refere à aceitar a alternativa, mas tão somente que os dados são incompatíveis à hipótese nula.    
:::


Os resultados obtidos pelo JASP são idênticos aos do R. Eventualmente, a diferença em relação ao sinal (+ ou -) é devida a codificação feita pelos programas e nada interfere na interpretação dos resultados.



## Escrita dos resultados


O primeiro achado foi que meninos e meninas não apresentaram diferenças em seus resultados médios quando tinham 12 meses. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados dos participantes foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 12 meses de idade. Os resultados mostraram que os valores médios de meninos e meninas não são significativamente diferentes (t(1039) = 0.37, p = 0.71). Dessa maneira, as diferenças encontradas podem ser mais bem explicadas por outras fontes de variações. 
```

Em seguida, verificamos que essa diferença é significativa aos 18 meses e abaixo uma outra sugestão de escrita.  

```{block, type="writing"}
**Como escrever os resultados**  

Os dados dos participantes foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 18 meses de idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, DP = 21.8) e meninas (M = 24.9, DP = 20.3) são significativamente diferentes (t(5725) = 4.62, p < 0.01), apesar do tamanho do efeito ser irrelevante (d = 0.12). 
```  

## Versão robusta do Teste T

::: {.warning}
**Atenção**: Um aspecto importante e que  não costuma ser discutido com tanta frequência é que a modificação do teste estatístico utilizado pode modificar a hipótese da pesquisa. A decisão de alterar ou não o teste inferencial deve ser feita com justificativa teórica por parte do pesquisador.
:::

Em muitas situações, os pressupostos do Teste T são violados. Parte da literatura argumenta que o Teste T é robusto o suficiente para lidar com isso [@Lumley2002], enquanto outra parte sugere que é melhor optar por versões com médias aparadas, técnicas não-paramétricas [@Field2017] ou outros modelos estatísticos.    

Quando a homocedasticidade é violada, o <u>Welch test</u> pode ser utilizado. Este teste é considerado uma versão robusta do Teste T, já que lida bem com variâncias distintas nos grupos.   


O tamanho do efeito do Welch test é também o d de Cohen e, por isso, não será novamente calculado nesta seção.  


### Execução no R


Para executar o O Welch-test no R, deve-se alterar a sintaxe, estipulando `var.equal = F` na sintaxe previamente exposta. Na verdade, o R executa o Welch test de maneira automática quando faz o Teste T. Dessa maneira, ao se remover este argumento por completo, o Teste T robusto será calculado. Existem outras soluções disponíveis no pacote `WRS`, que não serão implementadas neste livro. 


O Welch-test será calculado considerando as crianças com <u>18 meses</u>.

```{r}
t.test(total_18 ~ sex,data = asq_18months) %>% pander::pander(., split.table = Inf)
```


Repare que a estatística de teste e os graus de liberdade são diferentes. No entanto, os resultados são virtualmente os mesmos obtidos anteriormente, indicando que os grupos apresentam valores significativamente distintos. A escrita dos resultados é a mesma da apresentada.


### Execução no JASP  

No JASP, é possível acessar a versão robusta clicando em `Welch`, embaixo do `Student`, que já é previamente marcado.

![](./img/cap_testet_welch.png)

A interpretação e escrita dos achados é a mesma realizada anteriormente. 

## Mann-whitney

O teste de Wilcoxon-Mann-Whitney costuma ser chamado de versão não-paramétrica do Teste T. No entanto, <mark>isso não é totalmente verdadeiro</mark>. O Teste T e o Mann-Whitney testam hipóteses diferentes. Enquanto o Teste T compara médias, o Mann-whitney compara os valores ranqueados (postos). Nota-se que ele não é um teste para comparar medianas e que isso só ocorre em condições restritas.

Com muita frequência, o Mann-Whitney costuma ser eleito como um forte candidato para substituir o teste T quando seus pressupostos são violados. No entanto, conforme comentando, este teste responde a uma hipótese apenas próxima daquela que o Teste T trabalha. 


### Execução No R

Para executar o Mann-Whitney, é possível utilizar a função `wilcox.test`. As conclusões estatística são virtualmente identicas às obtidas previamente, em que foi possível rejeitar a hipótese nula.


```{r}
mann_whiyney_18m <- wilcox.test(total_18 ~ sex, data = asq_18months)
mann_whiyney_18m %>% pander::pander()
```


### Tamanho do efeito

O tamanho do efeito também pode ser calculado por $Z/\sqrt{(n)}$. O output padrão do R não oferece a informação de `Z`, mas o pacote `coin` dispõe dessa métrica.

```{r}
coin::statistic(coin::wilcox_test(total_18 ~ sex, data = asq_18months))
```

Plugando este valor na fórmula, o tamanho do efeito é aproximadamente `0.06`.


### Execução no JASP

No JASP, é necessário marcar a opção `Mann-Whitney` no lugar da opção `Student`, que é a definida por padrão. O JASP utiliza a correlação rank-bisserial como método padrão para relatar o tamanho do efeito para o teste de Mann-Whitney.

![](./img/cap_testet_mw.png)


### Escrita dos resultados  

A literatura não é muito concordante em como escrever os resultados do Mann-Whitney e abaixo há uma sugestão.  

```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados pelo teste Wilcoxon-Mann-Whitney para investigar as diferenças nos resultados do desenvolvimento entre meninos (Mdn = 25, IQR = 30, M = 27.53, DP = 21.61) e meninas (Mdn = 20, IQR = 25, M = 24.95, DP = 20.34) com 18 meses de idade. Os resultados indicaram que os resultados foram significativos (W = 4368187, p < 0.01), mas com efeito negligenciável (0.12). 
```  



## Teste T e regressão

Conforme alertado ao início do capítulo, o Teste T é um caso particular de um modelo de regressão, em que há uma única variável independente com dois níveis e uma variável dependente contínua. No capítulo sobre modelos de regressão, alguns conceitos tendem a ficar mais claros. 

Neste modelo, $b_0$ (intercepto) é o grupo <u>referência</u> que recebeu o valor 0. Já $b_1$ (inclinação) é a diferença entre os valores do grupo definido para o intercepto e o outro grupo, que recebeu o valor de 1 e é chamado de <u>comparação</u>. Caso isso não tenha sido explicitamente definido, ao se usar o R, será necessário codificar a variável como <u>fator</u>.

O exemplo abaixo ilustra os resultados utilizando a base `asq_18months`. 


```{r}
lm(total_18 ~ sex, data = asq_18months) %>%
  olsrr::ols_regress()
```


Em função da ordem alfabética, o R atribuiu os meninos (`male`) como intercepto e, consequentemente, como grupo referência. Assim, o valor de $b_0$ é o valor médio obtido pelos dos meninos (`27.53`). A inclinação $b_1$ é a diferença entre os valores dos meninos e das meninas (`24.95-27.53`).Nesse caso, o valor é `-2.58`. A estatística F é equivalente a $t^2$ do Teste T em sua versão tradicional, que assume variâncias iguais entre grupos.

Assim, torna-se mais intuitivo mostrar que a <u>normalidade no Teste T se refere à normalidade dos resíduos deste modelo de regressão</u>. Isso pode ser visualmente pela análise de um QQ plot, tal como a seguir.

```{r}
olsrr::ols_plot_resid_qq(lm(total_18 ~ sex, data = asq_18months))
```
  
Ou por testes estatísticos formais, como o Shapiro-wilk, Anderson-Darling e Jarque Bera. Em todos eles, a hipótese nula é de que os resíduos são normalmente distribuídos e idealmente não se deve rejeitá-la. Uma vez que o Shapiro-wilk não lida bem mais de 500 valores residuais, abaixo segue a execução do Anderson-Darling.

```{r}
nortest::ad.test(lm(total_18 ~ sex, data = asq_18months)$residuals)
```

Os resultados foram convergentes ao alcançados durante o capítulo, indicando pela violação da normalidade.  

A homocedasticidade pode ser investigada também por um gráfico dos resíduos contra os valores ajustados, tal como abaixo.

```{r}
olsrr::ols_plot_resid_fit(lm(total_18 ~ sex, data = asq_18months))
```

O teste de Levene, de Bartlett ou de Breusch-Pagan também oferecem recursos para tal análise.   

```{r}
olsrr::ols_test_breusch_pagan(lm(total_18 ~ sex, data = asq_18months))
```

Os achados também concluem pela rejeição da homocedasticidade, tal como foi previamente apresentado. Mais detalhes sobre modelos de regressão são apresentados em capítulos específicos.  

## Resumo  

::: {.explore}
1. O Teste T é um teste paramétrico que visa comparar até duas médias  
2. Gráfico de barras ou boxplots são extremamente úteis para verificar os resultados   
3. O Teste T é um caso particular de um modelo de regressão  
4. Os pressupostos do Teste T devem ser checados para verificar a validade da interpretação dos resultados   
5. Quando os pressupostos são violados, o pesquisador deverá tomar decisões sobre a manutenção, modificação ou substituição deste teste por outro  
6. A mudança da modelagem estatística, necessariamente, modifica a hipótese testada e isso deve ser levado em consideração   
7. O tamanho do efeito é uma métrica importante e realizada pelo d de Cohen   
::: 


## Pesquisas adicionais  

1. Are Women Really More Talkative Than Men? (DOI: 10.1126/science.1139940)    
Nesta pesquisa, 96 participantes (210 mulheres and 186 homens) foram investigados entre 1998 e 2004. Os pesquisadores deram para todos um tipo de gravador de voz que eles deveriam utilizar diariamente. Ao fim, a média de palavras produzidas por homens e mulheres foram comparadas. 

2. O diferencial de desempenho escolar entre escolas públicas e privadas no Brasil (DOI: 10.1590/0103-6351/1564)
Este trabalho apresenta uma análise dos resultados de provas de matemática e língua portuguesa do Sistema de Avaliação da Educação Básica. As provas são feitas por alunos do ensino fundamental de escolas públicas ou privadas. Diferentes análises foram feitas, indicando que, em média, alunos de escolas privadas tem resultados superiores.   

3. Gender Differences in Multiple-Choice Tests: The Role of Differential Guessing Tendencies (DOI: 10.1111/j.1745-3984.1991.tb00341.x)  
Nesta pesquisa, objetivou-se verificar a diferença no perfil cognitivo e padrão de respostas ao acaso de homens e mulheres. Para isso, 302 mulheres e 302 homens foram selecionados aleatoriamente de uma universidade em Jerusalem e, em seguida, fizeram um conjunto de testes cognitivos.

Última modificação: `r format(Sys.time(), '%d %B, %Y')`

<!--chapter:end:05-teste_t.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# ANOVA


```{r, include = FALSE }
load("~/anovabr/mqt/bases/Livro - R - TEG.RData")
library(tidyverse)
library(emmeans) #posthoc
library(pander)
```

```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar a ANOVA   
2. Discutir seus diferentes tipos, incluindo ANOVA de 1 via, 2 vias e Fatorial    
3. Apresentar gráficos e tabelas com comparações de grupos   
4. Apresentar e discutir testes Post hoc  
5. Dar exemplos relacionados à escrita dos resultados  
 
```


A ANOVA representa um conjunto de procedimentos estatísticos muito utilizado para verificar <u>diferenças médias entre diversos grupos</u> e, portanto, é considera um procedimento paramétrico. Pragmaticamente, é possível entender ANOVA como um super Teste T ou também um caso particular de um modelo de regressão. Uma vez que a ANOVA verifica a diferença entre todos os grupos e combinações lineares de maneira simultânea, ele é classificada como um *Omnibus test*. A relação entre a ANOVA e o Teste T será abordado na seção [Post hoc](#post-hoc).

Alguns autores indicam que a ANOVA é a técnica inferencial mais utilizada em Psicologia [@Chartier2008; @Howell2011]. Se por um aspecto, isso é extremamente vantajoso, uma vez que estreita a relação entre Psicologia e Estatística; por outro, isso parece ter contribuído para criação e manutenção de diferentes conceitos equivocados sobre a ANOVA. 

Conceitualmente, a ANOVA é um modelo linear, tal que:

\[y_i = b_0 + b_1X{_1}_i + \dots + b_pX{_p}_i + e_i\]

$y_i$ representa a variável dependente      
$b_0$ é o intercepto (coeficiente linear)   
$b_p$ é a inclinação (coeficiente angular)  
$X_p$ é a variável independente em questão  
$e_i$ é o erro/resíduo   

Os seguintes pressupostos dos modelos lineares são mantidos, que são:


*(i)* Os dados são aleatórios e representativos da população  
*(ii)* A variável dependente é contínua  
*(iii)* Os resíduos são normalmente distribuídos  
*(iv)* Os resíduos são independentes uns dos outros   
*(v)* A variância dos resíduos é constante  

Operacionalmente, o erro representa <u>todos os fatores de pesquisa</u> e problemas de medição que afetam o resultado, além das variáveis independentes consideradas na modelagem.

::: {.warning}
**Atenção**: Diferente de outros modelos, a linearidade dos resíduos não é formalmente um pressuposto a ser testado na ANOVA. Isso ocorre pois a VI é categórica em vez de contínua.
:::

Eventualmente, quando os pressupostos do modelo são violados, a literatura mais tradicional recomenda que ajustes ou testes não-paramétricos com propostas parecidas possam ser implementados. A tabela abaixo concatena os testes estatísticos relacionados para fins de comparação com outros trabalhos. Há também autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, argumentando que os dados têm nível de medida "ordinal".


  | Estatística     | Um ou mais fatores            |  Medidas repetidas              |  
  | :-----------    | :-----------                  | :-----------                    |        
  | Paramétrica     | ANOVA de k via(s)/Fatorial    |  ANOVA de medidas repetidas     |   
  | Não-paramétrica | Kruskal-Wallis                |  Teste de Friedman ou Page Test |   


A ANOVA tem diversos termos bastante específicos e utilizados em sua modelagem que serão descritos a seguir,

## Glossário  

Diferentes termos são empregados em uma ANOVA e em modelos próximos. A legenda a seguir visa auxiliar no entendimento de cada um deles e aproximar o leitor a conceitos amplos utilizados em modelos lineares.


```{block, type="glossario"}
<U>**GLOSSÁRIO**</U>   
**ANOVA**:  Análise da variância.    
**Via**: Variável independente, variável fonte, variável preditora, tratamento.  
**Fator**: Sinônimo de via.      
**Desfecho**: Variável dependente, variável critério.      
**Níveis**: Grupos, classes, condições, categorias da variável independente.    
**Efeito principal**: Efeito da variável independente em questão (controlanddo pelas outras no modelo).    
**Efeito de interação**: Efeito do termo de interação entre duas ou mais variáveis independentes. Quando significativo, não se interpreta os efeitos principais.   
**Efeito simples**: Efeito de uma variável independente em um nível (específico) de outra variável independente.  
**ANCOVA**: Análise de covariância, onde se controla os resultados por uma variável contínua.  
**MANOVA**: Análise multivariada de variância, onde se estende a ANOVA para incluir duas variáveis dependentes. É um modelo multivariado.    
```


Por heurística, se escreve os delineamentos estudados por uma ANOVA com $\eta$. Por exemplo, se o interesse for verificar o efeito da escolaridade (fundamental, médio e superior) em um determinado desfecho, isso é entendido como uma ANOVA de 1 via. Caso o interesse seja verificar o efeito da escolaridade, mas também do sexo (masculino ou feminino), a representação será $\eta =  3 \times 2$. Isso significa que a ANOVA tem dois fatores (escolaridade e sexo), o primeiro fator tem três níveis e o segundo tem 2 níveis. 


A tabela a seguir resume as denominações encontradas na literatura:


  | Número de VDs | Uma VI                    |  2 ou mais VIs (sem interação)       | 2 ou mais VIs (com interação)  
  | :-----------| :-----------              | :-----------                         | :-----------          
  | 1 VD      | ANOVA de 1 via (*one way*)  |  ANOVA 2 (ou mais)  vias (*multi way*) |   ANOVA Fatorial
  | 2 ou mais VDs | MANOVA     

## Pesquisa
  
<div class="alert alert-warning">
  <strong>Base: </strong> [Livro - R - TEG](https://github.com/anovabr/mqt/raw/master/bases/Livro%20-%20R%20-%20TEG.RData)
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada ["A relação entre o nível de Empreendedorismo (TEG) e os aspectos sociodemográficos dos Taxistas cooperados da cidade de Santo André/São Paulo, Brasil"](https://www.metodista.br/revistas/revistas-metodista/index.php/REGS/article/view/6453), publicada em 2016 na Revista Eletrônica de Gestão e Serviços, em que sou coautor. O objetivo dessa pesquisa foi identificar o nível de empreendedorismo em 147 taxistas de Santo André/SP, bem como averiguá-lo em associação aos aspectos sociodemográficos. Muitas perguntas teóricas foram feitas neste trabalho e uma foi verificar o quanto os níveis de escolaridade poderiam impactar o empreendedorismo.  


## ANOVA de 1 via

Em uma ANOVA de 1 via, há apenas um fator com três ou mais níveis. Conceitualmente, temos:

\[y_i = b_0 + b_1X{_1}_i + e_i\]

$y_i$ representa a variável dependente      
$b_0$ é o intercepto (coeficiente linear)   
$X_1$ é a variável independente em questão  
$b_1$ é a inclinação (coeficiente angular)  
$e_i$ é o erro/resíduo   


A pergunta que temos neste trabalho é sobre o possível efeito da `escolaridade` (fundamental, médio, etc) na Tendência Empreendedora Geral (`teg`).    


## Execução no R

Ao trabalhar no R, é <u>fundamental</u> se certificar que os tipos das variáveis estão corretamente definidos em função da escala de medida utilizada. Erros nessa etapa podem gerar resultados absolutamente incorretos. A escolaridade é uma variável categórica (ordinal, tratada como discreta) e é necessário definir claramente isso ao R antes da análise propriamente dita. 

::: {.warning}
**Atenção**: Tenha atenção à codificação computacional que o R atribuiu à variável de interesse. Erros nesta etapa podem impactar severamente os resultados.   
:::



Isso pode ser feito pela função `case_when` e `levels`. O `case_when` irá usar os valores originalmente presentes nessa variável para computar uma nova variável categórica. O `levels` deixará claro a ordem de cada categoria, o que é útil para que os gráficos sejam feitos corretamente.  

Uma vez que os itens de um instrumento sociodemográfico devem levar em consideração o contexto das pessoas avaliadas as categorias de escolaridade foram definidas da seguinte maneira: Primário significa escolaridade até o 5º ano, ginásio significa escolaridade até o 9º ano e colegial é equivalente ao ensino médio.

```{r }
dados_teg <- dados_teg %>% 
  mutate(escolaridade_fct = factor(case_when(
      escolaridade == 1 ~ "primario",
      escolaridade == 2 ~ "ginasio",
      escolaridade == 3 ~ "Colegial",
      escolaridade == 4 ~ "superior"), 
      levels=c("primario","ginasio","Colegial","superior")))
```

Os resultados descritivos devem ser calculados. A média irá apresentar a concentração dos dados, enquanto o desvio-padrão apresentará o afastamento dos valores em torno da respectiva média. 

```{r}
dados_teg %>% 
  group_by(escolaridade_fct) %>% 
  summarise_at(vars(teg), lst(n=~n(),mean,sd)) %>% 
  pander() 
```
    
Tal como ilustrado no decorrer dos outros capítulos, gráficos são fundamentais para entendimento do relacionamento entre as variáveis. Uma vez que a escolaridade (VI) é tratada como discreta e a TEG (VD) é contínua, um gráfico de barras é adequado. A inclusão das barras de erro permite uma compreensão inferencial inicial.

```{r, message=FALSE}
ggplot(dados_teg, aes(x=escolaridade_fct, y = teg, fill = escolaridade_fct)) +
  geom_bar(stat = "summary", fun = mean) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  theme(legend.position = "none")
```


Ambos os resultados já permitem identificar algumas caracteríticas gerais. Primeiro, quão maior a escolaridade, maior o valor obtido na escala. Segundo, algumas barras de erros estão superpostas e outras não, o que nos leva à conclusão preliminar de que resultados significativos estarão presentes na próxima etapa, que é a modelagem formal dessa hipótese. 

Para realizar a ANOVA, é possível contar com a função `lm` ou `aov`. Aqui, a escolha da `lm` foi apenas por conveniência e o vetor `mod_escolaridade` irá armazenar os resultados.

```{r}
mod_escolaridade <- lm(teg ~ escolaridade_fct, dados_teg)
```


Para apresentação, a função `apa.aov.table` do pacote `apatables` pode ser utilizada. Este pacote gera uma tabela parecida com a dos programas estatísticos comerciais e apresenta os principais elementos interpretáveis de uma ANOVA. A tabela a seguir sintetiza tais características.  



  | Fonte de variação | Soma dos Quadrados| Graus de liberdade  |  Quadrado médio | Estatística F | 
  | :-----------      | :-----------      | :-----------        |  :-----------   | :-----------  |  
  | Fator             | Entre (SSB)       | K-1                 |  MSB = SSB/(K-1) | F = MSB/MSW    | 
  | Resíduo           | Dentro (SSW)      | N-K                 |  MSW = SSW/(N-K) |                |
  | Total             | Total (SQT)       | N-1                 |  


Aqui, K significa quantidade de categorias dentro de um fator e N significa a quantidade de observações consideradas. As siglas em inglês são utilizadas para apresentar a "Soma dos quadrados entre os grupos" (SSB), "Soma dos quadrados dentro dos grupos" (SSW), "Quadrado médio entre grupos" (MSB) e "Quadrado médio dentro dos grupos" (MSW). 

```{r, warning=FALSE }
apaTables::apa.aov.table(mod_escolaridade)$table_body %>% pander(., split.table = Inf)
```


Existe uma convenção utilizada para apresentar os resultados expostos na tabela acima, que é:  

$$F(df_{between}, \, df_{within}) = F, P, \eta^2, 90\% \,CI \, [min, \, max]$$

Neste caso, como há 4 grupos de escolaridade, $df_{between}: 4-1=3$. No total, 147 participantes apresentam dados completos e portanto $df_{within}: 147-4 = 143$. Com isso, a apresentação fica F(3,143) = 8.23, p < 0.01, $\eta_p^2$ = 0.15, 90% CI [.06, .22]. A última parte do resultado é uma medida de tamanho do efeito, que terá a interpretação apresentada e discutida na próxima seção.

::: {.warning}
**Atenção**: Jamais apresente p = 0.00. Apresente até 3 casas decimais no valor de P ou, quando necessário, apresente p < 0.001.
:::


Pelos resultados, é possível inicialmente concluir que existe um efeito significativo da escolaridade nos resultados da TEG. Como a ANOVA é um *omnibus test*, ainda não é possível identificar em qual dos níveis ou combinações este efeito ocorre, o que será feito em momento oportuno.



::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::

Um aspecto importante é que a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.


<mark>Normalidade</mark>: A ANOVA tem como um dos pressupostos a normalidade da distribuição dos resíduos. Isso pode ser feito de diferentes maneiras e abaixo há um QQ plot. Caso ambas as linhas estejam sobrepostas, isso gera evidências que o pressuposto foi atendido. Neste caso, se nota que os desvios não foram tão acentuados, apesar de existirem. Se a análise fosse apenas via QQ plot, provavelmente se consideraria este pressuposto como atendido.   

```{r }
olsrr::ols_plot_resid_qq(mod_escolaridade)
```
   
Além da apresentacão gráfica, existem testes estatísticos desenvolvidos especificamente para tal finalidade. Entre eles, há o Shapiro-wilk, Anderson-Darling e Jarque Bera. A hipótese nula de todos estes testes considera que os resíduos são normalmente distribuídos.

```{r}
shapiro.test(residuals(mod_escolaridade))
```

De maneira diferente à conclusão gráfica, o teste concluiu pela rejeição da normalidade.


<mark>Homocedasticidade</mark>: Este pressuposto pode ser testado por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico, tal como o gráfico a seguir.

```{r}
olsrr::ols_plot_resid_fit(mod_escolaridade)
```

O teste de Levene, de Bartlett ou de Breusch-Pagan podem também serem utilzados de maneira formal. Eles estipulam $H_0$ como homocedasticidade que, idealmente, não deve ser rejeitada.

```{r}
car::leveneTest(mod_escolaridade)
```
Os resultados indicaram que a homocedasticidade foi preservada.  

<mark>Independência</mark>: Esse pressupostos frequentemente não é testado na ANOVA, apesar de ser uma exigência dos modelos lineares. De fato, uma vez que espera-se que os grupos sejam mutuamente excludentes, teria pouco sentido acreditar que os resíduos não fossem independentes. 

Após esses procedimentos feitos, é necessário calcular o tamanho do efeito.  

## Tamanho do efeito  


Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde.

No ambiente da ANOVA, 3 medidas costumem ser utilizadas para tamanho do efeito, que são:  

eta quadrado ($\eta^2$),  
eta quadrado parcial ($\eta_p^2$) e   
ômega quadrado ($\omega^2$).  


A ideia dessas medidas é verificar a variância explicada que o modelo testado apresenta quando comparado com um modelo simples, que conta apenas com a média. Em uma ANOVA de uma via, o $\eta^2$ e o $\eta_p^2$ possuem o mesmo valor. Esses conceitos serão revisitados no capítulo de regressão linear. 

No caso de agora, o $\eta^2$ e o $\eta_p^2$ indicam a proporção da variabilidade dos resultados do TEG que pode ser atribuídos à escolaridade. 


A interpretação pode ser feita da seguinte maneira:  

  | ηp2             | Interpretação              
  | :-----------    | :-----------      
  | ηp2 < 0.01      | Irrelevante    
  | ηp2 $\geq$ 0.01 | Pequeno     
  | ηp2 $\geq$ 0.06 | Moderado      
  | ηp2 $\geq$ 0.14 | Grande     


O tamanho do efeito foi calculado automaticamente pelo R e está na tabela anterior. 

## Execução no JASP

A base utilizada será a [base_csv_teg_processed](https://osf.io/gxbdc/). A primeira etapa da análise é a adequação das variáveis que serão trabalhadas. Isso é importante para criação de tabelas e gráficos. Para ajustar a ordenação dos níveis de <u>Escolaridade</u>, será necessário clicar <u>no centro</u> da variável <u>escolaridade_fct</u>, selecionar o grupo desejado (no caso, <u>primário</u>) e clicar na seta para que ele seja o primeiro grupos.

![](./img/cap_anova_ordem_variaveis.png)

A ordem dos níveis deve ser a utilizada durante a pesquisa: primário, ginásio, colegial e superior. É importante relembrar que esses termos se dão em função do público que foi avaliado nessa pesquisa. Para fechar esta parte superior, basta clicar no `X` embaixo das setas, destacado no quadrado roxo.  

![](./img/cap_anova_ordem_variaveis2.png)

Após feito isso, da mesma forma que foi feita no R, a apresentação de tabelas e gráficos auxiliam o pesquisador a verificar padrões nos dados. Para fazer os gráficos, é necessário clicar em `Descriptives`.

![](./img/jasp_descriptives.png)


Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadoras. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/jasp_descriptives2.png)


Agora é necessário arrastar as variáveis de interesse aos seus respectivos locais. Neste caso, o <u>teg</u> para parte das VDs, enquanto <u>escolaridade_fct</u> para a VI. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização.   

![](./img/cap_anova_descritivo.png)

Em seguida, ao clicar na opção `Plots`, será possível selecionar o `Boxplot` e `Boxplot element`. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da <u>distribuição dos resultados</u> de empreendedorismo em função dos <u>níveis de escolaridade</u>.


![](./img/cap_anova_descritivo2.png)

Os resultados tabulares e gráficos são idênticos. Preliminarmente, as evidências sugerem que pessoas com mais anos de ensino aparentam ter maior nível de empreendedorismo. No entanto, isso precisa ser testado formalmente.  

Para execução da ANOVA, deve-se clicar em `ANOVA` e, em seguida, `Classical` e `ANOVA`.  

![](./img/cap_anova_interface.png)

Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir:

![](./img/cap_anova_interface2.png)


O espaço de `Fixed factors` é o local onde a VI deverá ser colocada, enquanto o `Dependent Variable` é o local onde a VD irá ser inserida. Para realizar a ANOVA de uma via, é necessário inserir a <u>escolaridade_fct</u> e o <u>teg</u>, respectivamente, em `Fixed factors` e `Dependent Variable`.

O JASP automaticamente irá realizar as contas e apresentar os resultados. Pragmaticamente, o valor de P é o indicador costumeiramente utilizado para tomar decisões inferenciais. Neste caso, <u>como o valor de p foi menor do que o nível de significância escolhido, rejeita-se a hipótese nula</u>. Apesar de importante, este resultado será apenas interpretado ao fim desta seção.

![](./img/cap_anova_resultados_iniciais.png)

::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::

Da mesma forma como apresentado antes, a interpretação deste achado <u>não pode ser feita de uma forma automática</u>. É necessário saber se os pressupostos do modelo foram ou não atendidos, bem como calcular o tamanho do efeito. Estas opções estão dispostas na parte inferior à esquerda do programa, intitulada como `Assumptions checks`.  

![](./img/cap_anova_assumptions.png)

A <mark>normalidade</mark> é feita por um QQ plot. Idealmente, as linhas devem estar sobrepostas no QQ plot para assumir a normalidade da distribuição dos resíduos. 

A <mark>homocedasticidade</mark> é formalmente testada pelo Teste de Levene. O valor de p <u>deve ser superior</u> ao nível de significância eleito (quase sempre, 0.05) para considerar a homogeneidade das variâncias.

![](./img/cap_anova_assumptions2.png)
Neste caso, há a impressão visual de que a normalidade está mantida, bem como a homocedasticidade. É importante perceber que esta versão do JASP não oferece um teste formal para testar a normalidade dos resíduos de uma ANOVA, tal como feito no R na seção anterior.


Após testar estes pressupostos, é necessário verificar o quanto a interpretação originalmente deve ser mantida. Existem diferentes recomendações sobre o que fazer quando os pressupostos são violados. Entre eles,  assumir essa condição e justificar a utilização da ANOVA, transformar a distribuição da variável de interesse, usar versões robustas da ANOVA, usar testes não-paramétricos com objetivos próximos à ANOVA ou eleger algum modelo estatístico mais adequado à distribuição empírica obtida pelos dados. No JASP, as técnicas `Brown-Forsythe` e `Welch` são disponíveis para corrigir a violação do pressuposto de homocedasticidade.


Como exposto previamente, o tamanho do efeito uma medida objetiva e padronizada da magnitude de um efeito observado. Assim, é sempre muito importante calculá-lo e interpretá-lo. Para inserir o tamanho do efeito na seção de resultados, é necessário clicar em `Estimatives of effect size` e `eta quadrado` ($\eta^2$). 

Após isso feito, o valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença.


![](./img/cap_anova_resultados.png)



## Escrita dos resultados

O principal achado foi que os resultados médios de empreendedorismo foram significativamente influenciados pelo nível de escolaridade dos participantes. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados a partir de uma ANOVA de uma via que verificou o efeito da escolaridade no empreendedorismo, medido por um escala específica. Foi possível concluir que a escolaridade tem efeito significativo (F(3, 143) = 8.23, p < 0.01, ηp2 = 0.15, 90% CI [.06, .22]) nos níveis de empreendedorismo.
```


Repare que este resultado é bastante informativo, mas não deixa claro quais são os níveis de escolaridade que impactam significativamente o nível de empreendedorismo Para responder à esta questão mais específica, é necessário realizar uma análise chamada de Post hoc, descrita a seguir. 

## Post hoc


O termo post hoc é uma expressão em latim e significa "após isso", que já sugere em qual momento ocorre a sua participação nos procedimentos analíticos. Quando uma ANOVA é significativa, quase sempre há o interesse de se investigar todas as comparações entre os níveis da VI para identificar em qual delas resultados significativos podem ocorrer. Essa série de testes pareados são chamados de testes Post hoc.   

É importante alertar que os resultados significativos da ANOVA  não reflete que, necessariamente, haverá diferenças significativas <u>entre as médias dos grupos</u>. Tecnicamente, a diferença pode ocorrer em qualquer comparação possível, como grupo 1 contra grupos 2 + grupo 3 ou grupo 2 contra grupo 1 + grupo 3. Com isso, é possível perceber que o resultado geral da ANOVA e a execução de testes post hoc respondem questões diferentes. 

Na verdade, é possível inclusive realizar qualquer comparação entre os níveis da VI sem sequer realizar a ANOVA, desde que os resultados sejam devidamente corrigidos e alguns pressupostos sobre os contrastes sejam previamente assumidos. Delineamentos de comparações planejadas costumam proceder desta maneira.



::: {.warning}
**Atenção**: ANOVA e testes Post hoc respondem a questões diferentes. É possível ter uma ANOVA significativa e testes Post hoc não significativos. A ANOVA é um teste que verifica todos os níveis de forma simultânea, enquanto testes Post hoc fazem comparações específicas.  
:::


Tendo em vista vez que realizar uma ANOVA não é tecnicamente necessário para comparações pareadas, é possível se perguntar qual é, então, a necessidade da realização da ANOVA ou, até mesmo, Por que não é possível testar as diferenças usando múltiplos Testes T ?    

Historicamente, a ANOVA era um recurso muito importante em uma época em que o poder computacional era mais limitado. Seus resultados iriam indicar se comparações múltiplas deveriam ser feitas ou não. Hoje em dia, sua realização ocorre mais para que o pesquisador (i) consiga implementar computacionalmente todas as comparações pareadas entre as categorias da variável independente e, em seguida, (ii) corrija a distorção que o valor de P apresenta em cada comparação.  

Quando se compara todos os níveis variável independente, é esperado que haja uma inflação do erro do tipo 1. Isso é chamado *experiment‑wise Type I error rate* e ocorre pela estrutura do nível de significância, que é a seguinte:
$$\alpha_{total}=1-(1-\alpha)^C$$
Onde:   

$\alpha_{total}$: Indica o nível de significância total das comparações   
$\alpha$: Indica o nível de significância nominal (quase sempre, 0.05)   
$C$: Indica quantas comparações são feitas   


Para encontrar $C$ e ajustar o valor de P, é necessário calcular a quantidade de comparações. Isso pode ser feito da seguinte maneira:

$$J*(\frac{J-1}2)$$ 
onde:
 
 $J$ é a quantidade de níveis da variável


No caso da pesquisa apresentada agora, como se deseja comparar todos os níveis de <u>escolaridade</u>, a conta seria a seguinte:  

$$4*(\frac{3}{2})\\=6$$


Existem muitas técnicas disponíveis para ajustar o valor de P. Elas costumam ser agrupadas em função da sua robustez à violação da homocedasticidade e por seu perfil ser liberal ou conservador. O termo liberal significa que a correção do valor de P é pequena ou quase nula, enquanto o termo conservado significa que a correção é mais rigorosa. É importante que a técnica consiga minimizar o erro do tipo 1 (falso positivo) sem maximizar o erro do tipo 2 (falso negativo).



## Execução no R

Para executar as comparações pareadas, o pacote `emmeans` será utilizado. A mecânica do por detrás do post hoc se dá em dois passos. Primeiro, o pacote compara todos os níveis presentes na VI dois a dois. Em seguida, o valor de P obtido é ajustado por alguma técnica específica. 


Para fins práticos, vamos utilizar uma técnica considerada bastante conservadora, chamada de Bonferroni. Nesta correção, o valor de p encontrado em cada uma das comparações é multiplicado pela quantidade de comparações feitas. Este procedimento faz com que o Valor de P encontrado em cada comparação seja igual ao que seria obtido pelo nível de significância nominal. 

A.história desta técnica tem aspectos curiosos A correção de Bonferroni não foi desenvolvida pelo matemático italiano Carlo Emilio Bonferroni. Na verdade, ela foi inicialmente implementada por uma estaticista americana, chamada Olive Jean Dunn, que utilizou conceitos da desigualdade de Bonferroni para isso.   

O resultado das comparações dois a dois será armazenado em um objeto específico, nomeado como `post_hoc_escolaridade`. Isso será útil para apresentar sumários e gráficos.


```{r}
post_hoc_escolaridade <- emmeans(mod_escolaridade, "escolaridade_fct") %>% 
  pairs(., reverse = TRUE, adjust = "bonferroni")
```


A apresentação tabular é fundamental e traz as estatísticas inferenciais de interesse. Nesta tabela, o valor de P apresentado na coluna `p.value` é o corrigido pelas comparações feitas.

```{r}
post_hoc_escolaridade %>% data.frame() %>% pander()
```


O gráfico das comparações com barras de erro proporciona uma conclusão mais rápida e simples para todas as comparações. Para interpretar o gráfico, é necessário ter como referência o valor 0 no eixo horizontal e, em seguida, verificar todas as comparações no eixo vertical. Quando alguma comparação toca o valor 0, isso indica que os grupos <u>não</u> são significativamente diferentes. Quando isso não ocorre, é possível sugerir que há diferença nos grupos.

```{r}
CI <- confint(post_hoc_escolaridade)
ggplot(mapping = aes(contrast, estimate)) +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) +
  geom_point(data = summary(post_hoc_escolaridade)) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_size(trans = "reverse") + 
  coord_flip()
```


De forma geral, as comparações `Superior - Primário`, `Superior - Ginásio` e `Superior - Colegial` são significativas. Em todas elas, os resultados da TEG foram mais elevados nos participantes com ensino superior.  

No início desta seção, foi comentando que o controle do erro do tipo 1 era uma vantagem da realização deste procedimento, que inclui não apenas fazer uma ANOVA, mas calcular quantas comparações existem entre os níveis da VI e corrigir os resultados dos valores de P. 

Um exemplo pode ser útil a este momento. A correção implementada no teste post hoc  concluiu que a comparação entre `colegial - primário` não é significativa. Nesta comparação, o valor de p foi de `0.102`. No entanto, caso um Teste T tivesse sido realizado selecionando apenas esta comparação, os resultados seriam significativos (`0.01`), tal como demonstrado a seguir:

```{r}
dados_teg %>% 
  filter(escolaridade_fct == "Colegial" | escolaridade_fct == "ginasio") %>% 
  {t.test(teg ~ escolaridade_fct, var.equal = T, data = .)$p.value} %>% pander()
```


::: {.warning}
**Atenção**: Não se deve fazer múltiplos Testes T para comparar três ou mais grupos. O valor de P obtido pelo Teste T aumentará o erro do tipo 1.
:::

A interpretação dos resultados agora pode ser feita considerando o valor de P, o tamanho do efeito e as comparações pareadas.

## Execução no JASP  


Assumindo que a ANOVA já foi realizada e interpretada, o Post hoc poderá ser feito. Para executá-lo no JASP, é necessário clicar em `Post Hoc tests`, na parte esquerda inferior do programa. Ao fazer isso, um conjunto de novas opções ficará disponível logo abaixo da opção.  


![](./img/cap_anova_posthoc_interface.png)

Em seguida, basta colocar ao lado direito a variável de interesse (<u>escolaridade_fct</u>). O JASP automaticamente irá realizar todas as comparações principais e corrigir o valor de P. O padrão do JASP é a correção de `Tukey`, que pode ser alterada clicando em `Correction`.

![](./img/cap_anova_posthoc_resultados.png)

Mesmo sem implementar a correção de Bonferroni, os achados são virtualmente idênticos aos obtidos anteriormente pelo R. Possíveis diferenças de sinal (+ ou -) ocorrem pela codificação das variáveis e não impactam em nada a interpretação dos achados.   

A interpretação dos resultados agora pode ser feita considerando o valor de P, o tamanho do efeito e as comparações pareadas.

![](./img/cap_anova_posthoc_resultados2.png)  


Eventualmente, a apresentação de um gráfico de diferenças oferece um recurso visual adicional e importante para auxiliar no entendimento dos achados. Além do gráfico feito inicialmente na seção `Descriptives`, esta seção do JASP tembém permite que um gráfico seja construído. Para fazer isso, é necessário clicar em `Descriptive plots`.

![](./img/cap_anova_posthoc_plots.png)


Em seguida, é necessário levar a variável <u>escolaridade_fct</u> para o `Horizontal axis`, marcar a opção `Display Error bars` e `Standard error`. O resultado será como abaixo.  

![](./img/cap_anova_posthoc_plots2.png)


## Escrita dos resultados  


A escrita dos resultados deve informar os resultados da ANOVA e das comparações pareadas. É importante apresentar os valores de P corrigidos e, sempre que possível, as interpretações teóricas. Abaixo há uma sugesão com estilo baseado nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados a partir de uma ANOVA de uma via que verificou o efeito da escolaridade no empreendedorismo, medido por um escala específica. Foi possível concluir que a escolaridade é um fator significativo nos resultados (F(3, 143) = 8.23, p < 0.01, ηp2 = 0.15, 90% CI [.06, .22]). As comparações pareadas foram ajustadas pela técnica de Bonferroni e mostraram que os participantes com ensino superior apresentam pontuação significativamente mais alta do que àqueles com o primário (Δ = 7.16, p < 0.001), ginásio (Δ = 5.07, p < 0.001) e colegial (Δ = 2.96, p < 0.05).
```  


## Resumo  
::: {.explore}
1. A ANOVA de uma via pode tanto ser entendida como um super Teste T, como um caso particular de um modelo de regressão  
2. Testes post hoc e resultados globais da ANOVA não respondem às mesmas perguntas  
3. As comparações pareadas devem proteger a inflação do erro do tipo 1, sem gerar o erro do tipo 2  
::: 


## Pesquisas adicionais  

1. Cognitive Processes and Memory Differences in Recall and Recognition in Adults    
Nesta pesquisa, cerca de 150 estudantes foram apresentados a um filme e depois tiveram que lembrar algumas cenas. Três grupos distintos foram formados. Em um grupo, uma recordação com pistas foi implementada, em outro, técnicas de reconhecimento foram utilizadas e o terceiro grupo teve de fazer uma recordação livre, sem nenhum suporte adicional. 

---

## Pesquisa

  
<div class="alert alert-warning">
  <strong>Base: </strong> [Base - MEMORE 2020 Automated model selection](https://github.com/anovabr/mqt/raw/master/bases/Base%20-%20MEMORE%202020%20Automated%20model%20selection.RData)
</div> 

Nas próximas seções, a pesquisa intitulada ["Propriedades psicométricas de instrumento de Memória Visual de Curto Prazo (MEMORE)"](https://www.neuropsicolatina.org/index.php/Neuropsicologia_Latinoamericana/article/view/545) será parcialmente utilizada. Esse artigo foi publicado em 2020 e eu sou o primeiro autor. Nesta pesquisa, apresentamos algumas propriedades psicométricas de um teste psicológico desenvolvido para avaliar aspectos da memória de curto prazo (MEMORE), bem como análises estatísticas que visaram investigar o efeito de características psicológicas nos resultados obtidos pelos participantes neste teste específico.  


## ANOVA de 2 vias

```{r, include = FALSE }
load(file="~/anovabr/mqt/bases/Base - MEMORE 2020 Automated model selection.RData")
rm(list=setdiff(ls(), "ds"))
```

Em grande parte das vezes, o interesse do pesquisador é o de investigar como múltiplos fatores impactam a variável de desfecho. Quando se aumenta o número de variáveis independentes no modelo, consequentemente se aumenta a quantidade de vias ou fatores que a ANOVA possui. Na pesquisa de agora, como o interesse foi investigar o efeito da <u>escolaridade</u> e da <u>faixa etária</u>, trata-se de uma ANOVA de 2 vias. 


Na ANOVA de 2 vias, dois modelos principais podem ser calculados. O primeiro é chamado de "modelo aditivo", em que <u>não</u> se estipulam interações entre os fatores. O segundo modelo é denominado como "não aditivo" ou "saturado" e ocorre quando uma interação entre os fatores é definida. O termo "saturado" tende a gerar confusão e deve ser evitado, uma vez sua definição varia de área para área. Nesta seção, será apresentado o modelo aditivo, enquanto na seção ANOVA fatorial, o modelo não aditivo será descrito. 

::: {.warning}
**Atenção**: Uma ANOVA de duas vias é chamada de aditiva quando tem apenas efeitos principais. Quando há interação, ela é chamada de não aditiva ou saturada. O termo saturada pode gerar confusão com outras definições.  
:::

Conceitualmente, na ANOVA de duas vias sem interação, temos:

\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + ei\]

$y_i$ representa a variável dependente      
$b_0$ é o intercepto (coeficiente linear)   
$b_1$ é a inclinação da primeira VI   
$X_1$ é a primeira variável independente     
$b_2$ é a inclinação da segunda VI   
$X_2$ é a segunda variável independente    
$e_i$ é o erro/resíduo  
  

## Execução no R


A modelagem no R segue o mesmo padrão da feita anteriormente, iniciando pela codificação dos dados. É importante frisar que erros nesta etapa podem distorcer totalmente os resultados. Na variável <u>faixa etária</u> há  rótulos para cada intervalo, tornando a interpretação bastante fácil e intuitiva. Na variável <u>escolaridade</u>, se utilizou valores de 1 a 3 para identificar o ensino fundamental, médio e superior.

```{r}
ds <- ds %>% 
  mutate(escolaridade_grupo = factor(escolaridade_grupo),
         faixa_etaria = factor(faixa_etaria))
```

Os dados apresentam casos ausentes na variável <u>faxa etária</u> e <u>escolaridade</u>. Muitas ações podem ser feitas para lidar com esta condição. No entanto, apenas para finalidade pedagógica, esses valores não serão utilizados nestas análises de agora.

```{r}
ds <- ds %>% 
  filter(!is.na(faixa_etaria) & !is.na(escolaridade_grupo))
```

A apresentação de tabelas e gráficos que possibilitem uma primeira descrição dos dados é importante e deve ser realizado. A tabela a seguir tem um formato 5x3. Nela, as linhas apresentam os níveis da <u>faixa etária</u> e as colunas apresentam os níveis da <u>escolaridade</u>, com seus respectivos resultados.

```{r}
ds %>% 
  group_by(escolaridade_grupo, faixa_etaria) %>% 
  summarise_at(vars(memore_total), lst(n=~n(), mean, sd)) %>%  
  pivot_wider(names_from = escolaridade_grupo, #indexador unico
              names_sep = "_",  #pode ser removido
              values_from = c(n:sd)) %>%  #organizar valores
  pander(., split.table = Inf)
```

Gráficos específicos com relações bivariadas ajudam em uma primeira sondagem dos padrões. Na imagem a seguir, o primeiro gráfico apresenta a relação entre os resultados e os níveis de escolaridade, enquanto o segundo gráfico apresenta a relação que os resultados possuem com a faixa etária dos participantes.  

```{r, message=FALSE}
gridExtra::grid.arrange(
  ggplot(ds, aes(x=escolaridade_grupo, y = memore_total, fill = escolaridade_grupo)) +
    geom_bar(stat = "summary") +
    stat_summary(fun.data = mean_se, geom = "errorbar") +
    theme(legend.position = "none"),
  
  ggplot(ds, aes(x = faixa_etaria, y = memore_total, group = 1)) +
  stat_summary(geom = "line", fun = mean, size=1.0) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .2))

```
   
Por sua vez, gráficos mais complexos, que reúnem mais informações, também são úteis. Repare que a ideia principal da apresentação a seguir é descrever a influência da faixa etária e o nível de escolaridade nos resultados em um único gráfico. Conforme explicitado no capítulo sobre estatística descritiva, o eixo X é utilizado pela variável com mais níveis (faixa etária), enquanto o agrupador reúne a variável com menos níveis (escolaridade).    

```{r}
ggplot(ds, aes(x = faixa_etaria, y = memore_total, color = escolaridade_grupo, group  = escolaridade_grupo)) +
  stat_summary(geom = "line", fun = mean, size = 1) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .2) +
  theme(legend.position = "bottom")
```
  
É importante ter atenção que este gráfico não é necessariamente o melhor para uma ANOVA de 2 vias (aditiva), uma vez que pode sugerir algum relacionamento entre as variáveis independentes. Esse aspecto será melhor debatido na seção de [ANOVA Fatorial](#anova_fatorial).    

É possível analisar descritivamente cada um dos resultados. Entretanto, para tomar decisões inferenciais, é necessário a realização da modelagem formal. Os passos devem ser exatamente os mesmos aos performados anteriormente, incluindo a verificação de pressupostos e interpretação dos resultados. Para realizar a ANOVA de duas vias, é possível contar com a função `lm` ou `aov`. Aqui, a escolha da `lm` foi apenas por conveniência. O vetor `mod_escolaridade_faixa_etaria` irá armazenar os resultados.


```{r}
mod_escolaridade_faixa_etaria <- lm(memore_total ~ escolaridade_grupo + faixa_etaria, ds)
```


A tabela padronizada da ANOVA de duas vias, disponível na maioria dos programas comerciais, é a seguinte:


  | Preditor      | Soma dos Quadrados| Graus de liberdade |  Quadrado médio             | Estat. F       | 
  | :-----------  | :-----------      | :-----------       |  :-----------               | :-----------   |  
  | Fator (A)     | Entre (SS(A))     | K(A)-1             |  MS(A) = SS(A)/(K-1)          | F = MS(A)/MSW  | 
  | Fator (B)     | Entre (SS(B))     | K(B)-1             |  MS(B) = SS(B)/(K-1)          | F = MS(B)/MSW  | 
  | Resíduo       | Dentro (SSW)      | N-1-(df(A)+df(B))  |  MSW = SSW/(N-1-(df(A)+df(B)))|                |


Posto isso, os resultados obtidos são:

```{r }
apaTables::apa.aov.table(mod_escolaridade_faixa_etaria)$table_body %>%  pander(.)
```


Os achados concluem que o efeito da escolaridade (F(2,1427) = 7.58, p = 0.001, ηp2 = 0.01, 90% CI [.00 .02]) e o efeito da faixa etária são significativos (F(4,1427) = 32.97, p < 0.001, ηp2 = 0.08, 90% CI [.06 .11]). Isso indica que ambas as variáveis tem efeito nos resultados obtidos na avaliação psicológica.  

::: {.warning}
**Atenção**: Jamais apresente p = 0.00. Apresente até 3 casas decimais no valor de P ou, quando necessário, apresente p < 0.001.
:::


Note que a tabela já reúne a métrica do <u>tamanho do efeito</u>, que é dada pelo `eta quadrado parcial`. Uma vez que agora a ANOVA apresenta dois fatores, o valor do $\eta_p^2$ é diferente do $\eta^2$, mas a interpretação é a mesma da apresentada na ANOVA de 1 via.

::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::

Da mesma forma que apresentado na ANOVA de 1 via, a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. 


<mark>Normalidade</mark>: O QQ plot abaixo apresenta os valores teóricos e empíricos. Caso ambas as linhas estejam sobrepostas, isso apoia que o pressuposto da normalidade foi atendido. Neste caso, isso não parece ocorrer.

```{r }
olsrr::ols_plot_resid_qq(mod_escolaridade_faixa_etaria)
```
   
O Shapiro-wilk, Anderson-Darling e Jarque Bera também podem ser utilizado neste caso. A hipótese nula desses testes assumem que os resíduos são normalmente distribuídos.

```{r}
shapiro.test(residuals(mod_escolaridade_faixa_etaria))
```
Os resultados de ambas as técnicas foram similares, indicando a violação da normalidade dos resíduos.

<mark>Homocedasticidade</mark>: Este pressuposto pode ser testado por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico.

```{r}
olsrr::ols_plot_resid_fit(mod_escolaridade_faixa_etaria)
```

O teste de Levene, de Bartlett ou de Breusch-Pagan podem também serem utilzados de maneira formal. Eles estipulam $H_0$ como homocedasticidade e, idealmente, não deve ser rejeitada.

```{r}
olsrr::ols_test_breusch_pagan(mod_escolaridade_faixa_etaria)
```
Os resultados indicaram que a homocedasticidade foi preservada.  

<mark>Independência</mark>:  Esse pressupostos frequentemente não é testado na ANOVA, apesar de ser uma exigência dos modelos lineares. De fato, uma vez que espera-se que os grupos sejam mutuamente excludentes, teria pouco sentido acreditar que os resíduos não fossem independentes. 


## Execução no JASP

Para executar a ANOVA de 2 vias no JASP, será necessário baixar a base [CSV file - MEMORE Cognitive measurement.csv](https://osf.io/4hdc2/). Após carregar os dados no programa, a seção `Descriptives` apresentará o gráfico inicial dos resultados.


![](./img/cap_anova_two_way_descriptives.png)


Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/cap_anova_two_way_descriptives2.png)

Em seguida, ao clicar na opção `Plots`, será possível selecionar o `Boxplot` e `Boxplot element`. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados da avaliação psicológica em função dos níveis de <u>escolaridade</u>. Uma visualização preliminar indica que pessoas com escolaridade mais elevada (níveis 2 e 3) apresentam resultados maiores do que pessoas com o primeiro nível de escolaridade.


![](./img/cap_anova_two_way_plot.png)

Para modificar as variáveis de interesse, será necessário subdstituir <u>escolaridade</u> por <u>faixa_etária</u> na seção `Split`. Os resultados serão novamente calculados. A visualização sugere que pessoas mais velhas apresentam menor desempenho.  

![](./img/cap_anova_two_way_plot1.png)


Por padrão, o JASP não permite integrar os gráficos nesta seção. Isso será realizado posteriormente. Para executar a ANOVA, será necessário clicar na opção `ANOVA`, `Classical` e `ANOVA`. Essa etapa é similar a que foi feita na ANOVA de 1 via. Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir.

![](./img/cap_anova_two_way_interface.png)


O espaço de `Fixed factors` é o local onde as duas VIs deverão ser inseridas. O espaço `Dependent Variable` é o local onde a VD contínua irá ser inserida. Para realizar a ANOVA de duas vias, as variáveis <u>escolaridade</u> e <u>faixa_etaria</u> deverão ser arrastadas para `Fixed factors`. A variável <u>memore_total</u> deverá ser colocada em `Dependent Variable`.

O JASP automaticamente irá realizar as contas e apresentar os resultados. No entanto, estes resultados <u>não são estritamente de uma ANOVA de 2 vias aditiva</u>. Repare que, diferente do modelo que planejamos, existe um outro preditor `escolaridade x faixa_etaria`. Isso ocorre pois, por padrão, o JASP realiza uma <u>ANOVA fatorial</u>, que será discutida a seguir. 


![](./img/cap_anova_two_way_execucao.png)


Para ajustar a modelagem, será necessário clicar em `Model`, na parte inferior esquerda do programa. 


![](./img/cap_anova_two_way_model_interface.png)
Nesta tela, basta clicar em `escolaridade x faixa_etaria` e transferir do lado direito para o lado esquerdo clicando na seta destacada na imagem.

![](./img/cap_anova_two_way_model2.png)
Ao fazer isso, o JASP automaticamente irá refazer as contas e apresentar os resultados.   

Pragmaticamente, o valor de P é o indicador costumeiramente utilizado para tomar decisões inferenciais. Os valores são exatamente os mesmos obtidos anteriormente na modelagem pelo R, indicando que <u>ambas as variáveis</u> são significativas. Repare que esta tabela inicial não apresenta o <u>tamanho do efeito</u> que deverá ser calculado em seguida. Além disso, estes resultados ainda nào indicam se os pressupostos do modelo foram respeitados ou violados, o que também deverá ser testado.  


![](./img/cap_anova_two_way_resultados.png)

::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::

Para verificar se os pressupostos de <mark>normalidade</mark> e <mark>homocedasticidade</mark> foram respeitados, é necessário clicar em `Assumption checks`. 

![](./img/cap_anova_two_way_pressupostos.png)
As opções `Homogeneity tests` e `Q-Q plot of residuals` deverão ser marcadas. Pela impressão visual, a normalidade dos resíduos foi violada. Isso é mais fácil de perceber nos resultados extremos. Além disso, a homocedasticidade foi também violada. É importante notar que os resultados do JASP foram divergentes dos resultados do R. Isso se dá pelo teste de homocedasticidade utilizado. No R, o teste foi o `breusch Pagan`, enquanto no JASP foi o de `Levene`.  


![](./img/cap_anova_two_way_pressupostos2.png)


Existem algumas saídas que podem ser implementadas quando os pressupostos são violados. Muitas opções são possíveis e elas vão desde modificar a modelagem até não corrigir explicitamente tais condições desde que se justifique metodologicamente esta escolha. No ambiente JASP, ambas as correções propostas para violação da homocedasticidade não são possíveis para uma ANOVA de 2 vias. Assim, mesmo com os pressupostos não alcançados, o modelo utilizado não será corrigido.  
  
Antes de voltar à interpretação da ANOVA, é necessário inserir o tamanho do efeito. Para isso, basta clicar em `Estimatives of effect size` e, em seguida, no `eta quadrado parcial` ($η_p^2$). Diferente de uma ANOVA de 1 via, os resultados do $η_p^2$ serão diferentes do $η^2$. Uma vez que a ANOVA de 2 vias apresenta dois preditores, o $η_p^2$ informa a variância explicada por cada uma das variáveis após excluir a variância explicada pelas outras.



![](./img/cap_anova_two_way_tamanho_do_efeito.png)


A este momento, a interpretação pode ser feita integralmente. O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença, com interpretação disposta na tabela previamente exposta neste capítulo.

![](./img/cap_anova_two_way_resultados_finais.png)


## Escrita dos resultados


Após a execução de uma ANOVA de duas vias, foi possível concluir que ambas as variáveis foram significativas aos resultados da avaliação psicológica. Abaixo uma sugestão de escrita baseado nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA de duas vias para investigar o efeito da escolaridade e faixa etária nos resultados. Os achados permitiram concluir que tanto a escolaridade (F(2, 1427) = 7.58, p = 0.001, n2p = 0.01), como a faixa etária (F(4, 1427) = 32.972, p < 0.001, n2p = 0.08) tiveram efeito significativo nos resultados.

```


De forma análoga ao que aconteceu na ANOVA de 1 via, os resultados não indicam os níveis em que as diferenças podem existir. Testes post hoc são, novamente, necessários para responder à esta pergunta.

## Post hoc  

Na ANOVA de duas vias, o post hoc será realizado para cada um dos níveis ou fatores do modelo. Neste caso, <u>escolaridade</u> e <u>faixa_etaria</u>. 


## Execução no R 

O pacote `emmeans` será utilizado para, inicialmente, verificar cada uma das comparações entre os níveis de <u>escolaridade</u>. É bom notar que os resultados são ajustados pelas outras variáveis que integram o modelo. O vetor `post_hoc_twoway_escolaridade` reunirá os resultados.

```{r}
post_hoc_twoway_escolaridade <- emmeans(mod_escolaridade_faixa_etaria, "escolaridade_grupo") %>% 
  pairs(.,adj = "bonferroni")
```


A apresentação formal ocorre por tabelas, tal como a exposta a seguir. A última coluna `p.value` apresenta o valor de P corrigido pela técnica de Bonferroni.


```{r}
post_hoc_twoway_escolaridade %>% data.frame() %>% pander()
```


O gráfico a seguir apresenta um resultado mais fácil de interpretar em relação às comparações e também foi realizado também na ANOVA de 1 via. O eixo horizontal tem destaque ao valor `0` e o eixo vertical apresenta todas as comparações. Caso alguma das comparações passe pelo valor 0, isso indica que ela não é significativa.  

```{r}
CI <- confint(post_hoc_twoway_escolaridade)
ggplot(mapping = aes(contrast, estimate)) +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) +
  geom_point(data = summary(post_hoc_twoway_escolaridade)) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_size(trans = "reverse") + 
  coord_flip()
```


É possível concluir que pessoas com nível fundamental, quando comparadas às pessoas de nível médio (Δ = 3.23) e superior (Δ = 2.84), apresentam performance significativamente menor. Pessoas com ensino médio e ensino superior não tem resultados significativamente diferentes. 


Para comparar os resultados em função de todos os níveis de <u>faixa_etaria</u>, basta customizar um pouco a função.  


```{r}
post_hoc_twoway_faixaetaria <- emmeans(mod_escolaridade_faixa_etaria, "faixa_etaria") %>% 
  pairs(.,adj = "bonferroni")
```

Agora, a tabela apresenta os resultados das comparações etárias de maneira detalhada.

```{r}
post_hoc_twoway_faixaetaria %>% data.frame() %>% pander()
```

Conforme previamente descrito, O gráfico é um recurso útil à visualização dos resultados, permitindo que as conclusões tornem-se mais fáceis de serem obtidas.    

```{r}
CI <- confint(post_hoc_twoway_faixaetaria)
ggplot(mapping = aes(contrast, estimate)) +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) +
  geom_point(data = summary(post_hoc_twoway_faixaetaria)) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_size(trans = "reverse") + 
  coord_flip()
```
  

As conclusões indicam que pessoas mais novas (`Entre 14 e 24`) tem resultados mais elevados do que pessoas `Entre 35 e 44` , `Entre 45 e 54` e `Entre 55 e 64`. Participantes `Entre 25 e 34` também apresentam resultados maiores do que `Entre 35 e 44`, `Entre 45 e 54` e `Entre 55 e 64`. Não houve diferença significativa `Entre 14 e 24` e `Entre 25 e 34`, bem como `Entre 35 e 44` e `Entre 45 e 54` e `Entre 55 e 64`. Finalmente, participantes `Entre 45 e 54` e `Entre 55 e 64` também não tiveram resultados significativamente diferentes.

## Execução no JASP

Para executar o post hoc no JASP, é necessário clicar em `Post Hoc tests` na parte esquerda inferior do programa.

![](./img/cap_anova_two_way_posthoc.png)

Em seguida, selecionar ambas as variáveis e clicar na seta para deslocá-las para o lado direito.  

![](./img/cap_anova_two_way_posthoc_interface.png)



O JASP apresentará todas as comparações feitas em <u>escolaridade</u> e <u>faixa_etaria</u>, ajustando os resultados por todas as variáveis no modelo e corrigindo o valor de P. Por padrão, a correção de P é feita pelo método de `Tukey`, que pode ser alterada na seção `Correction`. 

![](./img/cap_anova_two_way_posthoc2.png)
Mesmo sem implementar a correção de Bonferroni, os achados são virtualmente idênticos aos obtidos anteriormente pelo R. É importante ter em mente que as comparações e os sinais podem ser invertidos para que os resultados tornem-se mais facilmente interpretáveis. Essa modificação não impacta em nada a interpretação dos achados. 


![](./img/cap_anova_two_way_posthoc_interpretacao.png)
Gráficos são recursos úteis para descrição destes resultados. Eles podem ser feitos clicando em `Descriptives Plots` e, em seguida, arrastando a <u>faixa_etaria</u> para `Horizontal axis` e a <u>escolaridade</u> para `Separated lines`. Para colocar o erro padrão, é necessário clicar em `Display error bars` e `Standard error`.

![](./img/cap_anova_two_way_descriptives_final.png)


Infelizmente, o JASP não realiza um gráfico completo dessa maneira na seção `Descriptives`, tal como apresentado. Por vezes, será necessário primeiro rodar integralmente a ANOVA para depois gerar esta apresentação. Quase sempre, o eixo X recebe a variável com maior quantidade de níveis.  


## Escrita dos resultados  


Os resultados obtidos agora indicam que tanto a escolaridade como a faixa etária são significativamente relacionadas aos resultados obtidos na avaliação psicológica. Esses achados são convergentes ao que vem sendo demonstrado na literatura. Os resultados devem trazer os achados principais da ANOVA e as comparações pareadas de ambos os fatores, destacando os valores de P corrigidos. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA de duas vias que investigou o efeito da escolaridade e da faixa etária nos resultados. Os achados permitiram concluir que tanto a escolaridade (F(2, 1427) = 7.58, p = 0.001, n2p = 0.01), como a faixa etária (F(4, 1427) = 32.972, p < 0.001, n2p = 0.08) tiveram efeito significativo nos resultados. Comparações pareadas foram realizadas e os valores de P foram corrigidos pela técnica de Bonferroni. Em relação à escolaridade, pessoas com nível fundamental, quando comparadas às pessoas de nível médio (Δ = -3.23, p < 0.001) e superior (Δ = -2.84, p < 0.001) apresentam performance significativamente menor. Não houve diferença entre participantes com ensino médio e ensino superior. Em relação à faixa etária, participantes entre 14 e 24 anos apresentam performance significativamente mais elevada do que participantes entre 35 e 44 (Δ = 4.21, p < 0.001), entre 45 e e 54 (Δ = 5.50, p < 0.001) e entre 55 e 64 anos (Δ = 5.50, p < 0.001).  Participantes entre 25 e 34 anos também apresentam performance significativamente superior do que participantes entre 35 e 44 anos (Δ = 4.03, p < 0.001), entre 45 e 54 (Δ = 5.32, p < 0.001) e entre 55 e 64 anos (Δ = 5.32, p < 0.001). Não houve diferença significativa na performance do grupo entre 14 e 24 anos do grupo entre 25 e 34, bem como entre o grupo entre 35 e 44 e 55 e 64. Também não houve diferença significativa entre os participantes com idades entre 45 e 54 daqueles com idade entre 55 e 64.

```  


## Resumo
::: {.explore}
1. A ANOVA de duas vias pode ser modelada por um modelo aditivo ou não-aditivo
2. O modelo aditivo não define interação entre os fatores, enquanto o não-aditivo sim    
3. Gráficos podem ser feitos antes das análises para auxiliar na interpretação dos resultados  
4. A interpretação dos resultados de um fator é ajustada pelo outro  
5. Os post hocs devem ser feitos individualmente para cada fator  
:::


---

## ANOVA Fatorial


A ANOVA Fatorial é uma ANOVA de 2 (ou mais) vias, em que se estipulam interações entre os fatores. O conceito de interação se aplica em condições em que o modelo apresenta dois ou mais fatores e o efeito de um fator no desfecho depende do nível dos outros fatores. É possível perceber que este tipo de modelagem estatística costuma vir mais por perguntas específicas e teóricas do que por análises puramente exploratórias.   

Na prática, na maior parte do tempo que um pesquisador pensa em uma ANOVA de 2 vias, o interesse justamente é o de testar se os fatores apresentam (ou não) uma interação. Talvez seja por isso que a maioria dos programas comerciais realizam, por padrão, uma ANOVA Fatorial quando se solicita uma ANOVA de 2 vias.


Conceitualmente, na ANOVA Fatorial, temos:

\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + b_3(X{_1}_i * X{_2}_i) + \epsilon_{i}\]

$y_i$ representa a variável dependente      
$b_0$ é o intercepto (coeficiente linear)   
$b_1$ é a inclinação da primeira VI   
$X_1$ é a primeira variável independente     
$b_2$ é a inclinação da segunda VI   
$X_2$ é a segunda variável independente    
$b_3$ é a inclinação da interação     
$\epsilon_{i}$ é o erro/resíduo  


Graficamente, a interação é tipicamente vista pelo cruzamento das linhas. O gráfico a seguir reproduz os resultados da pesquisa intitulada "Context-dependent memory in two natural environments: on land and underwater", de Godden e Baddeley. Os pesquisadores pediram que participantes memorizassem um conjunto de palavras ou embaixo d'agua ou na terra. Após algum tempo, eles solicitaram que os participantes recordassem as palavras em um ambiente convergente ou divergente daquele inicial. Assim, era possível que os participantes aprendessem as palavras embaixo d'agua e depois tivessem de recordá-las em terra, por exemplo. Os resultados indicaram um efeito de interação.


```{r, eval = FALSE}
set.seed(1)
data.frame(atribuicao = rnorm(200,10,0.5), 
           auto_estima = c("Embaixo d'agua","Em terra"),
           resultado = c(rep("Embaixo d'agua", 100), rep("Em terra", 100))) %>%
  mutate(atribuicao = case_when(
    auto_estima == "Embaixo d'agua" & resultado == "Embaixo d'agua" ~ atribuicao*1.2,
    auto_estima == "Em terra" & resultado == "Embaixo d'agua" ~ atribuicao*0.9,
    auto_estima == "Embaixo d'agua" & resultado == "Em terra" ~ atribuicao*0.9,
     auto_estima == "Em terra" & resultado == "Em terra" ~ atribuicao*1.2)) %>% 
  ggplot(., aes(x = resultado, y = atribuicao, color = auto_estima, group = auto_estima)) + 
  geom_point(size = 2,alpha=0.2) +
  geom_line(size=1.2) +
  ylim(c(7,14)) +
  labs(x = "Ambiente de aprendizagem", y = "Palavras lembradas", color = "Ambiente da recordação") +
  theme_bw()
```


## Execução no R  

No R, será necessário alterar os `contrastes` para assegurar que os valores obtidos serão os mesmos dos programas comerciais e, consequentemente, irão ter a mesma interpretação. Para isso, basta rodar a linha de código a seguir:

```{r}
options(contrasts = c("contr.helmert", "contr.poly"))
```


Após esta etapa, todo o restante segue o mesmo padrão da feita anteriormente, iniciando pela codificação dos dados. É importante frisar que erros nesta etapa podem distorcer totalmente os resultados. Na variável <u>faixa etária</u> há  rótulos para cada intervalo, tornando a interpretação bastante fácil e intuitiva. Na variável <u>escolaridade</u>, se utilizou valores de 1 a 3 para identificar o ensino fundamental, médio e superior.

```{r}
ds <- ds %>% 
  mutate(escolaridade_grupo = factor(escolaridade_grupo),
         faixa_etaria = factor(faixa_etaria))
```

Os dados apresentam casos ausentes na variável <u>faxa etária</u> e <u>escolaridade</u>. Muitas ações podem ser feitas para lidar com esta condição. No entanto, apenas para finalidade pedagógica, esses valores não serão utilizados nestas análises de agora.

```{r}
ds <- ds %>% 
  filter(!is.na(faixa_etaria) & !is.na(escolaridade_grupo))
```

A apresentação de tabelas e gráficos que possibilitem uma primeira descrição dos dados é importante e deve ser realizado.  Na tabela a seguir, as linhas irão reunir a <u>faixa etária</u>, enquanto as colunas reunirão a <u>escolaridade</u>.

```{r}
ds %>% 
  group_by(escolaridade_grupo, faixa_etaria) %>% 
  summarise_at(vars(memore_total), lst(n=~n(), mean, sd)) %>%  
  pivot_wider(names_from = escolaridade_grupo, #indexador unico
              names_sep = "_",  #pode ser removido
              values_from = c(n:sd)) %>%  #organizar valores
  pander(., split.table = Inf)
```


Diferente do proposto na ANOVA de 2 vias aditiva, o gráfico agora deve ser o mais completo o possível, indicando as três variáveis que estão sendo trabalhadas: <u>escolaridade</u>, <u>faixa etária</u> e <u>memore_total</u>. Tipicamente, no eixo X se coloca a VI com mais níveis, enquanto no agrupador (ou cluster), se coloca a VI com menos.


```{r}
ggplot(ds, aes(x = faixa_etaria, y = memore_total, color = escolaridade_grupo, group = escolaridade_grupo)) +
  stat_summary(geom = "line", fun = mean, size=1.5) +
  labs(x = "Faixa etária", y = "Resultados", color = "Escolaridade")
  
```
   
O gráfico parece indicar que a performance no teste varia tanto em função da idade, como em função da escolaridade do participante. Por exemplo, pessoas <u>entre 14 e 24</u> anos, bem como <u>entre 25 e 34</u> anos com <u>ensino médio</u> apresentam o desempenho mais elevado quando comparadas com os outros participantes. No entanto, isso começa a se alterar aos 35 anos. Para estes participantes e aqueles mais velhos, o <u>ensino superior</u> parece ser o principal determinante.


Agora, formalmente a modelagem estatística será feita. Os passos devem ser exatamente os mesmos executados anteriormente, incluindo a verificação de pressupostos e interpretação dos resultados. Para realizar a ANOVA Fatorial, é possível contar com a função `lm` ou `aov`. Aqui, a escolha da `lm` foi apenas por conveniência e o vetor `mod_escolaridade_faixa_etaria_fatorial` irá armazenar os resultados.


```{r}
mod_escolaridade_faixa_etaria_fatorial <- lm(memore_total ~ escolaridade_grupo * faixa_etaria, ds)
```

Repare que <u>não</u> é preciso descrever integralmente a equação na linha de código. Ao usar o símbolo `*`, o R já faz o restante.  


A tabela padronizada da ANOVA Fatorial, disponível na maioria dos pacotes comerciais, é a seguinte:

  | Fonte de variação | Soma dos Quadrados| Graus de liberdade |  Quadrado médio                   | Estat. F        | 
  | :-----------      | :-----------      | :-----------       |  :-----------                     | :-----------    |  
  | Fator (A)         | Entre (SS(A))     | K(A)-1             |  MS(A) = SS(A)/K-1                | F = MS(A)/MSW   | 
  | Fator (B)         | Entre (SS(B))     | K(B)-1             |  MS(B) = SS(B)/K-1                | F = MS(B)/MSW   | 
  | Interação (AB)    | Entre (SS(AB))    | (K(A)-1)*(K(B)-1)  |  MS(AB) = SS(AB)/(K(A)-1)*(K(B)-1)| F = MS(AB)/MSW  |  
  | Resíduo           | Dentro (SSW)      | N-(K(A)*K(B))      |  MSW = SSW/N-(K(A)*K(B))           |                |


Posto isso, os resultados obtidos são:  

```{r}
apaTables::apa.aov.table(mod_escolaridade_faixa_etaria_fatorial) %>% 
  pander(., split.table = Inf)
```


A interpretação de uma ANOVA Fatorial tem algumas heurísticas:

1. Sempre se começa pela interação (ou seja, de baixo para cima)  
2. Caso a interação seja significativa, não se interpreta os efeitos principais  
3. Caso a interação não seja significativa, a interpretação é a mesma da ANOVA de 1 ou 2 vias, anteriormente descritas  

No caso de agora, os achados indicam que o efeito da interação entre escolaridade e faixa etária é significativo (F(8, 1419) = 2.49, p = 0.011, n2p = 0.1, 90% CI [.00 .02]), bem como são também significativos os efeitos da escolaridade (F(2, 1419) = 4.87, p = 0.008, n2p = 01, 90% CI [.00 .01]) e da faixa etária (F(4, 1419) = 6.89, p < 0.001, n2p = 02, 90% CI [.01 .03]). Como a interação foi significativa, deve-se evitar a interpretação dos efeitos principais, uma vez que os níveis de um fator podem impactar na interpretação de outro.  

Note que a métrica do <u>tamanho do efeito</u> é o $\eta_p^2$ e já está na tabela. Sua interpretação é a mesma dos modelos mostrados anteriormente neste capítulo. 


Da mesma forma que apresentado no decorrer deste capítulo, a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. 


<mark>Normalidade</mark>: O QQ plot abaixo apresenta os valores teóricos e empíricos. Caso ambas as linhas estejam sobrepostas, isso apoia que o pressuposto da normalidade foi atendido. Neste caso, isso não parece ocorrer.

```{r }
olsrr::ols_plot_resid_qq(mod_escolaridade_faixa_etaria_fatorial)
```
   
O Shapiro-wilk, Anderson-Darling e Jarque Bera também podem ser utilizado neste caso. A hipótese nula desses testes assumem que os resíduos são normalmente distribuídos.

```{r}
shapiro.test(residuals(mod_escolaridade_faixa_etaria_fatorial))
```
Os resultados de ambas as técnicas foram similares, indicando a violação da normalidade dos resíduos.

<mark>Homocedasticidade</mark>: Este pressuposto pode ser testado por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico.

```{r}
olsrr::ols_plot_resid_fit(mod_escolaridade_faixa_etaria_fatorial)
```

O teste de Levene, de Bartlett ou de Breusch-Pagan podem também serem utilzados de maneira formal. Eles estipulam $H_0$ como homocedasticidade e, idealmente, não deve ser rejeitada.

```{r}
olsrr::ols_test_breusch_pagan(mod_escolaridade_faixa_etaria_fatorial)
```
Os resultados obtidos pelo teste de ` Breusch Pagan Test` indicaram que a homocedasticidade foi preservada.  

<mark>Independência</mark>:  Esse pressupostos frequentemente não é testado na ANOVA, apesar de ser uma exigência dos modelos lineares. De fato, uma vez que espera-se que os grupos sejam mutuamente excludentes, teria pouco sentido acreditar que os resíduos não fossem independentes. 


## Execução no JASP

Para executar a ANOVA Fatorial no JASP, será necessário baixar a base [CSV file - MEMORE Cognitive measurement.csv](https://osf.io/4hdc2/). Após carregar os dados no programa, a seção `Descriptives` apresentará o gráfico inicial dos resultados.


![](./img/cap_anova_two_way_descriptives.png)


Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/cap_anova_two_way_descriptives2.png)

Em seguida, ao clicar na opção Plots, será possível selecionar o `Boxplot` e `Boxplot element`. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados da avaliação psicológica em função dos níveis de <u>escolaridade</u>. Uma visualização preliminar indica que pessoas com escolaridade mais elevada (níveis 2 e 3) apresentam resultados maiores do que pessoas com o primeiro nível de escolaridade.


![](./img/cap_anova_two_way_plot.png)

Para alterar esta descrição, basta modificar as variáveis de interesse, colocando a  <u>faixa_etária</u>, por exemplo. A visualização sugere um padrão, em que pessoas mais velhas apresentam menor desempenho.  

![](./img/cap_anova_two_way_plot1.png)


Por padrão, o JASP não permite integrar os gráficos nesta seção. Isso será realizado posteriormente. Para executar a ANOVA, será necessário clicar na opção `ANOVA`, `Classical` e `ANOVA`. 

![](./img/cap_anova_interface3.png)

Essa etapa é similar a que foi feita na ANOVA de 1 via. Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir.

![](./img/cap_anova_two_way_interface.png)


O espaço de `Fixed factors` é o local onde as duas VIs deverão ser inseridas. O espaço `Dependent Variable` é o local onde a VD contínua irá ser inserida. Para realizar a ANOVA de duas vias, as variáveis <u>escolaridade</u> e <u>faixa_etaria</u> deverão ser arrastadas para `Fixed factors`. A variável <u>memore_total</u> deverá ser colocada em `Dependent Variable`.

![](./img/cap_anova_two_way_execucao.png)

O JASP automaticamente irá realizar as contas e apresentar os resultados da ANOVA Fatorial. Repare que, diferente do modelo visto anteriormente, agora a ANOVA reúne os resultados de `escolaridade`, `faixa etária` e `escolaridade x faixa etaria`. 

![](./img/cap_anova_fatorial_resultados1.png)


Pragmaticamente, o valor de P é o indicador costumeiramente utilizado para tomar decisões inferenciais. Os valores são exatamente os mesmos obtidos anteriormente na modelagem pelo R, indicando que o efeito da interação entre escolaridade e faixa etária é significativo (F(8, 1419) = 2.49, p = 0.011), bem como são também significativos os efeitos da escolaridade (F(2, 1419) = 4.87, p = 0.008) e da faixa etária (F(4, 1419) = 6.89, p < 0.001). Como a interação foi significativa, deve-se evitar a interpretação dos efeitos principais, uma vez que os níveis de um fator podem impactar na interpretação de outro.  


![](./img/cap_anova_fatorial_resultados2.png)

Esta tabela inicial não apresenta o tamanho do efeito e também não indica se o modelo respeitou ou violou os pressupostos. Para verificar se os pressupostos de <mark>normalidade</mark> e <mark>homocedasticidade</mark> foram respeitados, é necessário clicar em `Assumption checks`.

![](./img/cap_anova_fatorial_pressupostos.png)


As opções `Homogeneity tests` e `Q-Q plot of residuals` deverão ser marcadas. Repare que pela impressão visual, a normalidade não foi mantida. Além disso, a homocedasticidade foi também violada. É importante ter uma atenção que os resultados do JASP foram divergentes dos resultados do R. Isso se dá pelo teste de homocedasticidade utilizado. No R, o teste foi o `breusch Pagan`, enquanto no JASP foi o de `Levene`.  


![](./img/cap_anova_two_way_pressupostos2.png)


Existem algumas saídas para isso, que vão desde modificar a modelagem até não corrigir tais condições e justificar metodologicamente esta escolha. No ambiente JASP, ambas as correções propostas para violação da homocedasticidade não são possíveis para uma ANOVA de 2 vias (incluindo a Fatorial). Assim, mesmo com ambas as violações, o modelo utilizado não apresentará nenhum ajuste.

Antes de voltar à interpretação da ANOVA, é necessário inserir o tamanho do efeito. Para isso, basta clicar em `Estimatives of effect size` e, em seguida, no `eta quadrado parcial` ($η_p^2$). Diferente de uma ANOVA de 1 via, os resultados do $η_p^2$ serão diferentes do ($η^2$). Uma vez que a ANOVA Fatorial apresenta dois preditores, o $η_p^2$ informa a variância explicada por cada uma das variáveis após excluir a variância explicada pelas outras.


![](./img/cap_anova_fatorial_tamanho_do_efeito.png)


Agora, a interpretação agora pode ser feita integralmente. O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença, com interpretação disposta na tabela precedente neste capítulo.

![](./img/cap_anova_fatorial_resultados3.png)


Gráficos específicos são recursos úteis para descrição destes resultados. Eles podem ser feitos clicando em `Descriptives Plots`, arrastando a <u>faixa_etaria</u> para `Horizontal axis` e a <u>escolaridade</u> para `Separated lines`. Para colocar o erro padrão, é necessário clicar em `Display error bars` e `Standard error`.

![](./img/cap_anova_fatorial_descriptives_final.png)


Infelizmente, o JASP não realiza um gráfico completo dessa maneira na seção `Descriptives`, tal como apresentado. Por vezes, será necessário primeiro rodar integralmente a ANOVA para depois gerar esta apresentação. Quase sempre, o eixo X recebe a variável com maior quantidade de níveis.  


## Escrita dos resultados  


Os resultados serão escritos apresentado os achados principais da ANOVA, destacando se o efeito da interação foi significativo ou não. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA Fatorial para investigar o efeito da escolaridade, faixa etária, e de uma interação entre esses dois fatores nos resultados. Os resultados concluíram que a interação entre os fatores foi significativa (F(8, 1419) = 2.486, p = 0.011, n2p = 0.014), bem como a escolaridade (F(2, 1419) = 4.865, p = 0.008, n2p = 0.007) e a faixa etária (F(4, 1419) = 2.6.894, p < 0.001, n2p = 0.019).
```  

## Resumo
::: {.explore}
1. A ANOVA Fatorial é um modelo feito para testar se os fatores apresentam ou não uma interação   
2. A interpretação do modelo deve começar pela interação. Caso significativa, não se interpreta os efeitos principais    
3. Os gráficos costumam ser ótimos recursos para entender o padrão dos resultados de maneira rápida     
:::

De forma análoga ao que aconteceu nos outros exemplos, os resultados até aqui obtidos não indicam quais níveis em que as diferenças podem existir. Testes post hoc são necessários para responder à esta pergunta


## Post hoc

As comparações Post hoc de uma ANOVA Fatorial <mark>podem ser feitas de duas maneiras</mark>, a depender do interesse do pesquisador. É possível comparar todos os níveis presentes em ambas as variáveis ou comparar todos os níveis de uma variável específica, enquanto outra é mantida constante. No primeiro caso, um exemplo seria a comparação de <u>pessoas com ensino fundamental entre 14 e 24 anos</u> contra <u>pessoas com ensino superior entre 35 e 44 anos</u>. No segundo caso, a comparação ocorreria entre todas as faixas de escolaridade em pessoas entre 14 e 24 anos <u>ou</u> pessoas entre 25 e 34 anos, etc.


Normalmente, os post hocs são feitos após o pesquisador olhar os gráficos e os resultados obtidos podem confir ou não uma expectativa prévia. Os programas estatísticos comerciais tendem a realizar o segundo formato de análise, em que todas as interações intra-níveis são feitas após manter um nível de outro fator constante. Uma hipótese é que essa escolha ocorre para prevenir o erro do <u>tipo 2</u>. Uma vez que as correções para valor de P implementadas dependem da quantidade de comparações feitas, ao se comparar todos os níveis de um fator contra todos os níveis de outro fator, seria pouco provável ter resultados significativos. 

Neste caso, o post hoc será feito para todos os níveis de `escolaridade` com pessoas na faixa etária `Entre 14 e 24`. Em seguida, novamente todos os níveis de `escolaridade` serão comparados com pessoas na faixa etária `Entre 25 e 34` e assim por diante. Essa escolha reflete o que foi apresentado no gráfico introdutório desta seção. O vetor `post_hoc_fatorial` será computado e armazenará os resultados.    

```{r}
post_hoc_fatorial <- emmeans(mod_escolaridade_faixa_etaria_fatorial, pairwise ~ escolaridade_grupo | faixa_etaria, adj = "bonferroni") 
post_hoc_fatorial$contrasts %>% data.frame %>% pander()
```
O gráfico dessa vez será feito pela função `emmip` do pacote `emmeans`, que deve apresentar os mesmos resultados obtidos na tabela.  

```{r}
emmip(mod_escolaridade_faixa_etaria_fatorial, escolaridade_grupo ~ faixa_etaria, CIs = TRUE)
```
  
Entre as conclusões possíveis, se constata, de maneira contraintuitiva, que pessoas entre 14 e 24 anos com ensino médio apresentam performance maior do que pessoas com ensino superior (Δ = 1.145). Por sua vez, não há diferença na performance entre pessoas entre 25 e 34 anos que possuem o ensino médio ou ensino superior. No entanto, pessoas que tem essa idade, mas apresentam o ensino fundamental possuem performance significativamente menor do que seus pares com ensino médio (Δ = -6.317) ou superior (Δ = -5.46). Pessoas entre 35 e 44 anos com ensino superior apresentam performance mais elevada do que seus pares com ensino médio (Δ = 2.365) ou fundamental (Δ = 3.477).  




## Execução no JASP

Para executar o post hoc no JASP, é necessário clicar em Post Hoc tests na parte esquerda inferior do programa.

![](./img/cap_anova_fatorial_posthoc.png)

Em seguida, selecionar todas as variáveis e clicar na seta para deslocá-las para o lado direito. 



![](./img/cap_anova_fatorial_posthoc2.png)

O JASP apresentará todas as comparações feitas em <u>escolaridade</u>, <u>faixa_etaria</u> e <u>escolaridade x faixa etária</u>, ajustando os resultados por todas as variáveis no modelo e corrigindo o valor de P. Por padrão, a correção de P é feita pelo método de Tukey, que pode ser alterada na seção `Correction`. 


A interpretação principal é para interação <u>escolaridade x faixa etária</u>. No entanto, diferente do R, nesta versão do JASP <u>não</u> é possível reproduzir a análise feita em que a comparação entre todos os níveis de um fator é realizada enquanto se mantém o outro constante. Essa condição pode impactar um pouco na interpretação dos resultados, uma vez que os valores de P serão mais altos do que os previamente encontrados.    


![](./img/cap_anova_fatorial_posthoc3.png)
  
O gráfico feito anteriormente é um forte candidato a também ser inserido para auxiliar a visualização dos achados. A interpretação dos resultados pode ser feita considerando o valor de P, o tamanho do efeito e as comparações pareadas.


![](./img/cap_anova_fatorial_posthoc4.png)

## Escrita dos resultados


Os resultados serão escritos apresentado os achados principais da ANOVA, destacando se o efeito da interação foi significativo ou não e as comparações pareadas. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA). Como os resultados do R e do JASP foram um pouco diferente nas comparações pareadas, o R será utilizado como principal.  


```{block, type="writing"}
**Como escrever os resultados**  

Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA Fatorial para investigar o efeito da escolaridade, faixa etária, e de uma interação entre esses dois fatores nos resultados. Os resultados concluíram que a interação entre os fatores foi significativa (F(8, 1419) = 2.486, p = 0.011, n2p = 0.014), bem como a escolaridade (F(2, 1419) = 4.865, p = 0.008, n2p = 0.007) e a faixa etária (F(4, 1419) = 2.6.894, p < 0.001, n2p = 0.019). Em situações em que a interação é significativa os efeitos principais não são interpretados, já que os resultados podem depender de níveis específicos de cada uma das variáveis. As comparações pareadas foram feitas entre todos os níveis de escolaridade se mantendo a faixa etária constante e ajustando o valor de P pela técnica de Bonferroni. Pessoas entre 14 e 24 anos com ensino médio apresentam performance superior que seus pares com ensino superior (Δ = 1.145, p = 0.003). Pessoas ebtre 25 e 34 anos, com nível fundamental, têm performance significativamente mais baixa do que seus pares com ensino médio (Δ = -6.317, p < 0.001) e superior  (Δ = -5.46, p < 0.001). Finalmente, pessoas entre 35 e 44 anos com ensino superior tem performance significativamente maior do que aquelas com ensino fundamental  (Δ = 3.447, p < 0.001) e médio  (Δ = 2.365, p < 0.001). 

```  


É importante ter em mente que as comparações e os sinais podem ser invertidos para que os resultados tornem-se mais facilmente interpretáveis.


<!--chapter:end:06-anova.Rmd-->

# ANOVA de medidas repetidas

```{r, include = FALSE }
library(tidyverse)
library(pander)
library(knitr) #tables and graphs
library(kableExtra) #tables with different styles

load(file = "~/anovabr/mqt/bases/R - Base Lidia Carprofeno.RData") 
```


```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar a ANOVA de Medidas Repetidas    
2. Realizar passo-a-passo a modelagem analítica    
3. Verificar os pressupostos e implementar as correções sugeridas  
4. Escrever os resultados  
```

A ANOVA de medidas repetidas é um teste estatístico para a análise de dados longitudinais pareados. Isto significa que o mesmo conjunto de participantes foi acompanhado e avaliado no decorrer do tempo. Esta técnica pode ser entendida como uma expansão da ANOVA ou um caso especial do Modelo Linear de Efeitos Mistos (LMM). Os pressupostos deste teste são próximos aos discutidos em outros testes inferenciais:

*(i)* Os dados são aleatórios e representativos da população  
*(ii)* a variável dependente é contínua  
*(iii)* Os resíduos do modelo são normalmente distribuídos  
*(iv)* há esfericidade dos grupos  

## Pesquisa

<div class="alert alert-warning">
  <strong>Base: </strong> R - Base Lidia Carprofeno
</div>  


A esse momento, vamos ter como referência de análise a pesquisa intitulada ["Avaliação psicométrica em português do indicador de dor crônica de Helsinki em cães com sinais crônicos de osteoartrite"](https://www.scielo.br/scielo.php?script=sci_arttext&pid=S0102-09352019000100109), que tem como primeira autora Lídia Matsubara e eu sou coautor. Essa pesquisa foi publicada no "Arquivo Brasileiro de Medicina Veterinária e Zootecnia" em 2019 e objetivou tanto verificar o efeito do medicamento Carprofeno em sintomas relacionados à dor crônica, como apresentar estudos psicométricos de uma nova medida clínica.   

Nessa pesquisa, utilizamos um <mark>delineamento experimental</mark>. No início, todos os participantes foram avaliados em relação a características clínicas da dor crônica e, em seguida, alocados em dois grupos independentes e de maneira aleatória. Os grupos foram chamados de "grupo experimental" e "grupo controle". Os participantes do grupo experimental receberam o medicamento específico, enquanto os participantes do grupo controle receberam um placebo, que é uma substância que não possui o princípio ativo do medicamento. Nem os participantes, nem os profissionais sabiam quem estava em cada grupo.   

A cada duas semanas, durante o tempo de 6 semanas, todos os participantes foram acompanhados e diferentes medições ocorriam para verificar o efeito do medicamento na dor. Para verificar o impacto da retirada do medicamentos, na quarta semana, tanto o medicamento como o placebo foram retirados dos participantes, que foram novamente medidos ao fim da pesquisa, na sexta semana. A imagem a seguir apresenta este processo:

![](./img/delineamento_experimental.png)

Repare que esse tipo de delineamento contou com três elementos importantes em pesquisas experimentais, que são grupos <u>aleatórios</u>, com a presença de uma condição <u>placebo</u> e <u>duplo-cego</u>.

## Execução no R  

A primeira etapa nesta análise será a consolidação da base de dados. No vetor `dados`, há todas as variáveis utilizadas na pesquisa em formato largo (wide). Apesar de ser possível trabalhar dessa maneira no R, o formato longo é o mais tipicamente encontrado para análises longitudinais e, por isso, será implementado a seguir. Um novo vetor será chamado de `tratamento` e irá armazenar os mesmos dados originais, só que agrupados neste novo formato.

```{r}
tratamento <- dados %>% 
  mutate(id = row_number()) %>% 
  select(id, grupo_dummy,starts_with("total_")) %>% 
  pivot_longer(-c(id,grupo_dummy),
                names_to = "tempo",
               values_to= "resultado") %>% 
  rename(grupo = grupo_dummy) %>% 
  filter(grupo < 3) %>% 
  mutate(grupo = factor(if_else(grupo == 1, "Experimental", "Placebo"))) %>% 
  mutate(tempo = factor(case_when(
    tempo == "total_w4" ~ "antes",
    tempo == "total_w0" ~ "no_dia",
    tempo == "total_s2" ~ "semana_2",
    tempo == "total_s4" ~ "semana_4",
    tempo == "total_s6" ~ "semana_6",
  )))
```

As variávies neste conjunto de dados são:

```{r }
tratamento %>% names() %>% pander()
```

`id` refere-se a uma identificação única de cada participante.  
`gupo` refere-se ao grupo em que o participante foi alocado, tal como previamente apresentado (controle ou experimental).  
`tempo` diz respeito aos 5 pontos de medida e     
`resultado` é uma variável aleatória contínua do valor obtido na escala utilizada.  


É importante saber se os grupos foram balanceados e se houve perda experimental no decorrer do tempo. A tabela a seguir apresenta tais informações.

```{r }
tratamento %>% 
  group_by(grupo, tempo) %>% 
  count() %>% 
  pander()
```
Nota-se que apesar de não ter havido perda amostral, os grupos não tiveram a mesma quantidade de participantes. Quando isso ocorre, chama-se de desbalanceamento amostral.  

A modelagem estatística envolve definir claramente que o `resultado` é uma função do `tempo`, do `grupo` e da interação `tempo x grupo`. Conforme exposto no decorrer do livro, a primeira etapa analítica consiste na apresentação de tabelas e gráficos. Essas técnicas descritivas são muito informativas e permitem uma rápida compreensão dos resultados.

Dessa maneira, a tabela abaixo apresenta os valores da média e do desvio-padrão para todas as condições:

```{r results="asis" }
arsenal::tableby(tempo ~ resultado + grupo, test   = FALSE,tratamento) %>% summary() 
```


O gráfico abaixo também apresenta as mesmas informações, mas insere uma barra com o erro padrão da média. Isso é útil para interpretação inferencial.

```{r,fig.align='center'}
ggplot(tratamento, aes(x=tempo, y=resultado, group=grupo, color=grupo)) + #variaveis
  stat_summary(fun = mean, geom = "line", size=1.0, aes(linetype = grupo)) + #linha
  stat_summary(fun="mean", geom="point", size=2, aes(shape = grupo)) + #pontos
  stat_summary(fun.data = mean_se, geom = "errorbar",size=1) #barra de erro
```

É possível notar que as barras de erro estão superpostas, isto é, uma está contida na outra. Isso ocorre quando não há diferença significativa entre as condições. No entanto, o teste formal estatístico deve ser realizado. 


Para realizar a ANOVA de Medidas Repetidas, o pacote `ez` pode ser utilizado:

```{r }
library(ez)
```

Sua sintaxe envolve as seguintes características:

`data` refere-se à base de dados (no formato longo)   
`dv` refere-se à variável dependente (contínua)  
`wid` refere-se à variável com a identificação única de cada participante  
`within` refere-se à variável independente com efeito <u>dentro</u> do tratamento, ou seja, a variável que se repete. Nesse caso, cada uma das semanas  
`between` refere-se à variável independente com efeito <u>entre</u> os tratamentos, ou seja, cada um dos grupos  
`type` refere-se à forma pela qual a soma dos quadrado será calculada. O tipo 3 emula os resultados dos programas típicos e quase sempre é a melhor opção para finalidade de comparação entre resultados  
`detailed` refere-se à apresentação detalhada dos resultados  
`return_aov` refere-se à criação de um objeto no formato `aov` que tem utilidade para análises comparadas posteriores  

Para deixar o ambiente de programação mais organizado o objeto `ez_outcome` será criado e irá para armazenar os resultados.

```{r }
ez_outcome <- ezANOVA(
  data = tratamento,
  dv = resultado,
  wid = id,
  within = tempo,
  between = grupo,
  type = 3,
  detailed = TRUE,
  return_aov = TRUE)
```

A mensagem de aviso informa que os grupos estão desbalenceados em relação à quantidade de participantes, o que foi previamente descrito. 

Abaixo esta o `ez_outcome`, que é dividido em 4 blocos diferentes: `ANOVA`, `Mauchly's Test for Sphericity`, `Sphericity Corrections` e `aov`. O tamanho do efeito é calculado pelo eta quadrado generalizado ($\eta^2_G$) e está na última coluna da primeira tabela.

```{r }
ez_outcome %>% pander::pander()
```


A tabela gerada é bastante extensa e para interpretá-la adequadamente, será necessário testar os pressupostos do modelo a partir de testes estatísticos específicos. Estes testes irão tanto indicar <u>quais são os resultados que deverão ser verificados</u>, como se há segurança na interpretação dos achados Na ANOVA de Medidas Repetidas, é necessário verificar a <mark>normalidade</mark> e a <mark>esfericidade</mark>. 


<mark>Normalidade</mark>: A ANOVA de tem como um dos pressupostos a normalidade da distribuição dos resíduos. Isso pode ser feito de diferentes maneiras e abaixo há um QQ plot. Caso ambas as linhas estejam sobrepostas, isso gera evidências que o pressuposto foi atendido. Neste caso, isso não ocorre.

```{r }
tratamento %>% 
  mutate(residuos = proj(ez_outcome$aov)[[3]][, "Residuals"]) %>% 
  ggplot(aes(sample=residuos)) + 
  stat_qq() + 
  stat_qq_line()
```
   
Apesar do gráfico ter sido bastante claro, testes como o Shapiro-wilk, Anderson-Darling e Jarque Bera também podem ser utilizado neste caso. A hipótese nula desses testes assumem que os resíduos são normalmente distribuídos.

```{r}
shapiro.test(proj(ez_outcome$aov)[[3]][, "Residuals"])
```

Este último resultado foi convergente ao já visualizado na apresentação gráfica. Como o valor de p foi inferior ao alfa tipicamente estabelecido (0.05), não seria possível manter o pressuposto da normalidade. Quando isso acontece, é possível implementar ajustes nos dados, substituir o modelo analítico ou seguir a análise após justificar explicitamente essa violação. 


<mark>Esfericidade</mark>: A esfericidade na ANOVA de Medidas Repetidas tem um conceito próximo à Homocedasticidade nas ANOVAs vistas anteriormente. Neste delineamento pareado, a esfericidade siginfica que a variância de todas as diferenças entre cada nível de fator é constante. Esse pressuposto é bastante difícil de ser assumido e existem ajustes possíveis em casos em que isso ocorre.

Na tabela da ANOVA, o `Mauchly's Test for Sphericity` é o local que deve ser visualizado para verificar se a esfericidade foi violada ou não. A hipótese nula é definida como presença da esfericidade e idealmente não deve ser rejeitada. Abaixo, a reprodução desta parte da tabela.

```{r}
ez_outcome$`Mauchly's Test for Sphericity` %>% pander()
```
É possível concluir que a esfericidade foi violada mas há algumas saídas para isso. As correções Greenhouse-Geisser (p[GG]) e de Huynh-Feldt tentam corrigir essa violação a partir de ajustes nos graus de liberdade da ANOVA. Os resultados das duas correções costumam ser próximos e, frequentemenet, a correção de Greenhouse-Geisser é utilizada para interpretar os resultados.


Com ambas as verificações feitas, é possível interpretar os resultados, que começam <u>sempre</u> pela interação. A interação `grupo x tempo` não foi significativa: F(4, 152) = 0.696, p = 0.59, p ajustado = 0.52). O efeito do `grupo` em que o participante foi alocado também não significativo: F(1, 38) = 0.706, p = 0.406). Por sua vez, o passar do `tempo` foi signicativo: F(4, 152) = 3.304, p = 0.012, p ajustado = 0.035).

Frequentemente, os resultados corrigidos e os não-corrigidos concluem na mesma direção. Isso é verdadeiro nesse caso. Repare que os resultados não corrigidos alcancariam as mesmas conclusões:

```{r }
summary(ez_outcome$aov) %>% pander::pander()
```

O valor de P do efeito do `tempo` saiu de 0.01 (sem correção) para 0.03 (com correção). Já a interação `grupo x semana` saiu de 0.598 (sem correção) para 0.529 (com correção).

Nota: Essa pesquisa não teve resultados significativos e, em função disso, testes post hoc não foram realizados. Entretanto, frequentemente os resultados são significativos e a mecânica das comparações pareadas é próxima ao que foi demonstrado no capítulo de ANOVA Fatorial.

## Tamanho do efeito  


Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde.

Na ANOVA de medidas repetidas o <u>eta quadrado parcial</u> ($\eta_p^2$) e o <u>eta quadrado generalizado</u> ($\eta^2_G$) podem ser calculados. A interpretação do $\eta_p^2$ é a mesma já apresentada no capítulo sobre ANOVA, enquanto o $\eta^2_G$ pode ser interpretado segundo a tabela disposta a seguir:


  | eta quadrado generalizado | Interpretação              
  | :-----------           | :-----------      
  | $\eta^2_G$ < 0.02      | Irrelevante    
  | $\eta^2_G$ $\geq$ 0.13 | Pequeno     
  | $\eta^2_G$ $\geq$ 0.06 | Moderado      
  | $\eta^2_G$ $\geq$ 0.26 | Grande     


O tamanho do efeito foi calculado e apresentado na tabela da ANOVA de Medidas Repetidas.


## Execução no JASP  

A base utilizada será a [csv Lidia Carprofeno largo](https://www.dropbox.com/s/xyh6ndzjbj0s0p8/csv%20Lidia%20Carprofeno%20largo.csv?dl=0). Essa base reúne todas os dados da pesquisa, incluindo os grupos e as medidas de dor. Após carregar a base no JASP, será necessário apresentar tabelas e gráficos descritivos. Para fazer isso, é necessário clicar em `Descriptives`.

![](./img/cap_anovarm_descriptives.png)
  
Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal.

![](./img/cap_anovarm_descriptives2.png)


Será necessário arrastar a variável <u>grupo</u> para a VI e as variáveis relacionadas à dor para a VD. Estas últimas são <u>total_w4</u>, <u>total_w0</u>, <u>total_s2</u>, <u>total_s4</u> e <u>total_s6</u>. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização.

![](./img/cap_anovarm_descriptives3.png)

Em seguida, ao clicar na opção `Plots`, será possível selecionar o `Boxplot` e `Boxplot element`. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados das variáveis da <u>dor</u> em função dos níveis do <u>grupo</u>.


![](./img/cap_anovarm_plots1.png)


Por padrão, o JASP não permite integrar os gráficos nesta seção. Isso será realizado posteriormente. Para executar a ANOVA, será necessário clicar na opção `ANOVA`, `Classical` e `Repeated Measures ANOVA`. 

![](./img/cap_anovarm_interface0.png)
Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir.


![](./img/cap_anovarm_interface.png)


O espaço `Repeated Measures Factors` é o local onde os <mark>nomes</mark> devem ser inseridos para representar quantas repetições foram feitas.  É possível mudar o nome do argumento para ficar mais fácil. Por exemplo, substituir `RM Factor 1` para `Tempo`. Nesta pesquisa, 5 medições foram feitas e, por isso, sugiro preencher os espaços que começam por `level` com `antes`, `no dia`, `semana 2`, `semana 4` e `semana 6`. Repare que ao fazer isso, o `Repeated Measures Cells` também apresentará os nomes escolhidos.. 


![](./img/cap_anovarm_interface2.png)


Agora, será necessário levar as variáveis relacionadas à dor para cada lugar disponível em `Repeated Measures Cells`. Para isso, será necessário selecionar as variáveis e, em seguida, clicar na seta superior à direita, tal como abaixo:


![](./img/cap_anovarm_within.png)
Ao fazer isso, o JASP está sendo informado da variação <u>dentro</u>, ou seja, do efeito do tempo em todos os participantes, independentemente dos grupos em que eles foram alocados.

No entanto, nesta pesquisa há também um efeito <u>entre os grupos</u> e isso precisa ser estipulado no programa. Para fazer isso, basta arrastar a variável <u>grupo</u> para `Between Subjects Factor`. A tela será próxima à apresentada abaixo:  

![](./img/cap_anovarm_resultados.png)

Depois que isso tiver sido feito, o JASP automaticamente irá realizar as contas e apresentar os resultados do modelo linear misto a partir de alguns critérios padronizados do programa. 

![](./img/cap_anovarm_resultados2.png)

No entanto, por padrão, o JASP assume que tanto o intercepto como a inclinação são efeitos aleatórios, o que é diferente da hipótese da pesquisa. Para ajustar o modelo de acordo com o previamente definido, deve-se clicar em `Model`


![](./img/cap_lmm_model.png)
Nesta tela, será necessário deixar todas as opções desmarcadas.

![](./img/cap_lmm_model2.png)


Ao fazer isso, o JASP irá modificar as notas embaixo da tabela inicial de resultados, que agora podem ser interpretados.

A interpretação dOs resultados deve começar pela interação. Caso este termo seja significativo, os outros resultados não devem ser interpretados diretamente. 


![](./img/cap_lmm_resultados.png)


É possível ficar nesta tela e interpretar os resultados, começando <u>sempre</u> pela interação. A interação `Tempo x grupo` não foi significativa (F(4, 152) = 0.696, p = 0.596) e o `Grupo` também não (F(1, 38) = 0.706, p = 0.406). De maneira diferente, o efeito do `Tempo` foi significativo (F(4, 152) = 3.304, p = 0.013).  

Entretanto, para qu e a validade dessa interpretação seja assegurada, é necessário testar se os pressupostos do modelo foram respeitados ou rejeitados. Além disso, o cálculo do tamanho do efeito deve ser realizado para otimizar a interpretação dos achados.

Os dois principais pressupostos da ANOVA de Medidas Repetidas são a <mark>normalidade</mark> e a <mark>esfericidade</mark>. Para verificá-los, é necessário clicar em `Assumtpions checks`. 


![](./img/cap_anovarm_pressupostos.png)


As opções `Sphericity tests` deverá ser assinaladas. Repare que o JASP não realiza a verificação da normalidade dos resíduos aqui, bem como deixa a opção de homogeneidade, que não precisa ser acessada agora, já que a esfericidade tende a indicar algo similar.  

![](./img/cap_anovarm_esfericidade.png)

Os resultados do Teste de Mauchly indicaram que o pressuposto da esfericidade foi violado. Dessa maneira, será necessário implementar alguma correção antes de interpretar os resultados. O JASP oferece a correção de `Greenhouse-Geisser` e a `Huynh-Feldt`. Ambos os resultados são próximos e, pragmaticamente, vamos optar pela correção de `Greenhouse-Geisser`, clicando nela.

![](./img/cap_anovarm_esfericidade2.png)

Repare que ao fazer isso, o JASP irá refazer as contas e apresentar os resultados originais e os resultados corrigidos. Antes de fazer a interpretação, será necessário inserir o tamanho do efeito. Para isso, basta clicar em `Estimates of effect size`, na parte superior do programa. Há quatro opções disponíveis, que são o `eta quadrado`($\eta^2$), o `eta quadrado parcial` ($\eta^2_p$), o `eta quadrado generalizado` ($\eta^2_G$) e o `omega quadrado` ($\omega^2$). Para garantir os mesmos resultados obtidos anteriormente com o R, será necessário selecionar o $\eta^2_G$.

![](./img/cap_anovarm_tamanho_do_efeito.png)


Agora, a interpretação agora pode ser feita integralmente. O valor de P <u>corrigido</u> irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença, com interpretação disposta na tabela precedente neste capítulo.


![](./img/cap_anovarm_interpretacao.png)

Gráficos específicos são recursos úteis para descrição destes resultados. Eles podem ser feitos clicando em `Descriptives Plots`, arrastando o <u>tempo</u> para `Horizontal axis` e a <u>grupo</u> para `Separated lines`. Para colocar o erro padrão, é necessário clicar em `Display error bars` e `Standard error`. Esse gráfico é muito informativo, mas a impressão visual que ele traz é de que há diferença entre os grupos, o que não foi encontrado no teste de hipóteses modelado anteriormente.

![](./img/cap_anovarm_grafico.png)
Notas: Infelizmente, o JASP não realiza um gráfico completo dessa maneira na seção `Descriptives`, tal como apresentado. Por vezes, será necessário primeiro rodar integralmente a ANOVA para depois gerar esta apresentação. Quase sempre, o eixo X recebe a variável com maior quantidade de níveis. Essa pesquisa não teve resultados significativos e, em função disso, testes post hoc não foram realizados. Entretanto, frequentemente os resultados são significativos e a mecânica das comparações pareadas é próxima ao que foi demonstrado no capítulo de ANOVA Fatorial.

## Escrita dos resultados


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados a partir de uma ANOVA de medidas repetidas investigando o efeito fixo do grupo e do tempo, bem como a interação entre ambos. O teste de Mauchly indicou a violação da esfericidade (w = 0.26, p < 0.01) e, portanto, os resultados foram ajustados pelo método de Greenhouse-geisser. Não houve interação significativa entre o grupo e o tempo (F(4, 152) = 0.69, p ajusatdo = 0.520), nem efeito do grupo (F(1, 38) = 0.061, p = 0.406). O passar de tempo foi significativo no resultado, apesar de apresentar um efeito pequeno (F(4, 152) = 3.30, p ajustado = 0.0351, ng2 = 0.01). 
```




## Resumo  

1. A ANOVA de medidas repetidas é um teste bastante utilizado quando participantes de mesmos grupos são avaliados longitudinalmente  
2. Este modelo pode ser entendido como uma expansão de uma ANOVA ou um caso particular de uma regressão linear de efeitos mistos  
3. A execução deste teste no R solicita que a base seja transformada para o formato longo  
4. A interpretação dos resultados é, inicialmente, complicada e precisa ser feita de maneira cautelosa  
5. Os pacotes estatísticos oferecem correções automáticas para violação de alguns pressupostos  
6. Gráficos são muito informativos para uma análise inicial dos dados  
 


<!--chapter:end:07-anova_mr.Rmd-->

# Modelo linear misto

```{r base e ajustes, include = FALSE }
load("~/anovabr/mqt/bases/R - Base Lidia Carprofeno.RData") 
```

```{r, include = FALSE }
library(tidyverse)
```


```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar a ANOVA de Medidas Repetidas.    
2. Realizar passo-a-passo a modelagem analítica.    
3. Verificar os pressupostos e implementar as correções sugeridas.  
4. Escrever os resultados.  

```



O modelo linear misto (LMM) é um modelo linear, frequentemente utilizado para trabalhar dados longitudinais ou de medidas repetidas, que possibilita definir tanto parâmetros populacionais (efeitos fixos), como coeficientes individuais (efeitos aleatórios), além do erro experimental. Pragmaticamente, este modelo oferece mais flexibildiade à ANOVA de medidas repetidas e sua utilização vem ganhando mais espaço em Psicologia e áreas da saúde [@Gueorguieva2004]. 

Os efeitos fixos são compatilhados por todos os indivíduos, enquanto os aleatórios são especificos de cada um dos participantes. Com isso, a trajetória de cada indivíduo pode ser modelada, permitindo que um subconjunto dos parâmetros de regressão sejam definidos como aleatórios.

Tanto O LMM, como a ANOVa de Medidas Repetidas costumam ser utilizados em dados longitudinais. A tabela a seguir apresenta algumas das principais características de ambas as análises.   

  | Característica                             | ANOVA (MR)     |   Modelo Linear Misto  |  
  | :-----------                               | :-----------   | :-----------           |        
  | Sujeitos medidos em vários momentos        | Sim            | Sim                    |   
  | Dados completos em todos os segmentos      | Sim            | Não                    |   
  | Estimativas de tendências individuais      | Não            | Sim                    |
  | Covariáveis tempo-depenentes               | Não            | Sim                    |
  | Complexidade computacional                 | Baixa          | Alta                   |



## Pesquisa

<div class="alert alert-warning">
  <strong>Base: </strong> R - Base Lidia Carprofeno
</div>

A esse momento, vamos ter como referência de análise a pesquisa intitulada ["Avaliação psicométrica em português do indicador de dor crônica de Helsinki em cães com sinais crônicos de osteoartrite"](https://www.scielo.br/scielo.php?script=sci_arttext&pid=S0102-09352019000100109), que tem como primeira autora Lídia Matsubara e eu sou coautor. Os dados dessa pesquisa foram previamente utilizados no capítulo de ANOVA de medidas repetidas.  

Nessa pesquisa, temos um <u>grupo controle</u> e um <u>grupo experimental</u> e todos os participantes foram avaliados em 5 momentos diferentes do tempo: 1 semana antes do início do tratamento (W2), imediatamente antes do início do tratamento (W0), duas semanas e quatro semanas após o tratamento ter iniciado (S2 e s4) e após uma semana da retirada do tratamento (s6). Trata-se de um delineamento 2x5, considerando os 2 grupos e as 5 medições ao longo do tempo.

## execução no R

A base `dados` reúne as varáveis da pesquisa. No entanto, ela está em formato largo (wide). Na maioria das vezes, o formato longo é o mais tipicamente encontrado para análises longitudinais e, por isso, será imeplementado pela função `pivot_longer` do `tidyverse`. 

```{r}
tratamento <- dados %>% 
  mutate(id = row_number()) %>% 
  select(id, grupo_dummy,starts_with("total_")) %>% 
  pivot_longer(-c(id,grupo_dummy),
                names_to = "tempo",
               values_to= "resultado") %>% 
  rename(grupo = grupo_dummy) %>% 
  filter(grupo < 3) %>% 
  mutate(grupo = factor(if_else(grupo == 1, "Placebo", "Experimental"))) %>% 
  mutate(tempo = factor(case_when(
    tempo == "total_w4" ~ "antes",
    tempo == "total_w0" ~ "no_dia",
    tempo == "total_s2" ~ "semana_2",
    tempo == "total_s4" ~ "semana_4",
    tempo == "total_s6" ~ "semana_6",
  )))
```

As variávies neste conjunto de dados são as seguintes:

```{r }
tratamento %>% names()
```

Dessa forma:  

`id` Identificação única de cada participante.       
`grupo` Indica o grupo em que o participante foi alocado, tal como previamente apresentado (controle ou experimental).      
`tempo` Indica cada um dos 5 pontos de medida.   
`resultado` Apresenta os valores obtido pela escala utilizada. Quão maior o resultado, mais intenso são os sintomas.   


Como uma primeira etapa, é importante criar tabelas e gráficos. Esses dois recursos apresentam as principais características dos grupos, bem como seus resultados.

```{r results="asis" }
arsenal::tableby(tempo ~ resultado + grupo, test   = FALSE,tratamento) %>% summary() 
```

O gráfico de linhas tende a ser utilizado para medidas longitudinais e encontra-se a seguir.  

```{r}
ggplot(tratamento, aes(x=tempo, y=resultado, group=grupo, color=grupo)) + #variaveis
  stat_summary(fun = mean, geom = "line", size=1.0, aes(linetype = grupo)) + #linha
  stat_summary(fun="mean", geom="point", size=2, aes(shape = grupo)) + #pontos
  stat_summary(fun.data = mean_se, geom = "errorbar",size=1) #barra de erro
```
   
Os resultados já deixam a impressão de que ambos os grupos tiveram desfechos próximos durante toda a pesquisa. Entretanto, testes formais precisam ser feitos para se chegar a esta conclusão. O R oferece alguns pacotes específicos para modelos mistos. Os pacotes `lme4` e `lmerTest` serão utilizados aqui.  

```{r }
library(lme4)
library(lmerTest)
```

A estrutura computacional da sintaxe do `lme4` é bastante similar aos modelos tradicionais de regressão que utilizam a função `lm`. No entanto, agora é possível incluir tanto efeitos fixos como aleatórios. Quando os termos são definidos como correlacionados, se utiliza uma barra verticail (|). Quando são definidos como descorrelacionados, duas barras verticais (||) são utilizadas.  

Nesta pesquisa, se assumiu que cada participante apresentava seu próprio intercepto, ou seja, seu próprio valor de início. A sintaxe a seguir cria o modelo e o armazena os resultados no vertor `mod_lme`.  

```{r}
mod_lme <- lmer(resultado ~ tempo*grupo + (1|id) , data = tratamento)
```

Repare que esse modelo é composto pelo se seguintes componentes:  
1. Os resultados são definidos na variável `resultado`  
2. efeito fixo do `tempo`  
3. efeito fixo do `grupo`,   
4. efeito fixo da interação `tempo x grupo`  
5. efeito aleatório do `id`, indicando um intercepto aleatório e específico por participante  


Uma vez que o modelo já foi criado, agora é necessário recuperar seus resultados. É importante notar que O pressuposto da normalidade é necessário e ele já foi acessado (e aceito) anteriormente. Conforme dito ao início do capítulo, O LMM relaxa o pressuposto esfericidadde e, por consequência, também o da homogeneidade [@Quen2004].

Inicialmente, a `anova` permite uma visualização de todos os coeficientes do modelo. Isso é importante para verificar cada um dos preditores estipulados e sua significância. A interpretação dos resultados é similar à realizada em modelos de regressão e totalmente convergente ao resultado obtido na ANOVA. Novamente, a leitura da tabela deve começar pela interação. 

```{r}
anova(mod_lme) %>% pander::pander()
```

Verifique que a tabela apresenta três os resultados: `tempo x grupo`, `grupo` e `tempo`. A técnica de Satterthwaite's method é utilizada para corrigir os valores do grau de liberdade e, consequentemente, os valores de p. Os resultados são virtualmente identicos aos obtidos pela ANOVA, com a diferença que os graus de liberdade do numerador de do denominador não foram corrigidos.  

Para obter as informações completas do modelo, é necessário solicitar o `summary`. Essa função retorna 4 informações calculadas: `Scaled residuals`, `Random effects`, `Fixed effects` e `Correlation of Fixed Effect` e serve para aprofundar a interpretação dos resultados. Uma particular diferença entre esse relatório e o da ANOVA de Medidas Repetidas é o np2, que não faz parte do LMM.

```{r}
summary(mod_lme) 
```
## Execução no JASP  


A base utilizada será a [csv Lidia Carprofeno longo](https://www.dropbox.com/s/9q5f047b8o2jqoo/csv%20Lidia%20Carprofeno%20longo.csv?dl=0). Essa base tem o formato longo. Isso significa que os resultados obtidos no decorrer do tempo serão apresentados em cada uma das linhas do conjunto de dados. Modelos Lineares Mistos tendem a solicitar que os dados sejam organizadaos desta maneira.  

Após carregar a base no JASP, será necessário assegurar que a escala de medida de todas as variáveis são corretas. A variável <u>id</u> deverá ser definido como nominal e para fazer isso, clique no símbolo da régua ao lado dela.

![](./img/cap_lmm_nivel_medida.png)

Uma lista de opções irá aparecer. Será necessário selecionar a opção nominal.


![](./img/cap_lmm_nivel_medida2.png)

De maneira próxima ao que foi realizado no R, é importante apresentar tabelas e gráficos descritivos. Estes elementos auxiliam em uma primeira visualização do padrão das respostas. Para fazer isso, será necessário apresentar tabelas e gráficos descritivos. Para fazer isso, é necessário clicar em `Descriptives`.

![](./img/cap_lmm_descriptives.png)
Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal.

![](./img/cap_lmm_descriptives2.png)


O JASP permite fazer gráficos com apenas 1 agrupador. É possível, então, apresentar inicialmente os <u>resultados</u> pelo <u>tempo</u> e, em seguida, pelo <u>grupo</u>. Para isso, será necessário arrastar a variável <u>tempo</u> para o local de `Split` e a variável <u>resultado</u> para o local `Variables`. Ao fazer isso, o JASP irá preencher a tabela com várias informações descritivas.

É importante se lembrar que o JASP <u>não</u> está considerando o <u>grupo</u> que o participante foi alocado.

![](./img/cap_lmm_descriptives3.png)

Gráficos permitem um entendimento mais facilitado dos resultados. Para fazer isso, será necessário clicar na opção `Plots`.

![](./img/cap_lmm_plots.png)

Em seguida, será possível selecionar o `Boxplot` e `Boxplot element`. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados das variáveis em função do momenot da pesquisa.

![](./img/cap_lmm_boxplots1.png)


Para gerar as estatísticas descritivas e a apresentação gráfica sobre a relação entre os <u>resultados</u> e os respectvos <u>grupos</u>, será necessário, substituir a variável <u>tempo</u> por <u>grupo</u> no espaço `Split`.

![](./img/cap_lmm_boxplots2.png)


Apesar dessas análises serem informativas, esta versão do JASP não integra todas as três variáveis desejadas nas tabelas e gráficos produzidos. Isso será feito posteriormente.


Para realizar um Modelos Linear Misto, será necessário clicar em `Mixed Models` e `Linear Mixed Models`.

![](./img/cap_lmm_interface.png)

Após fazer isso, a interface do programa será próxima à apresentada abaixo. 
![](./img/cap_lmm_interface2.png)
O local `Dependent Variable` irá reunir a VD e a variável <u>resultado</u> deverá ser arrastada até este espaço. `Fixed effects` é o local que irá reúnir as variáveis entre participantes e as variáveis <u>tempo</u> e <u>grupo</u> devem ser inseridas neste local. O `Random effects grouping factors` irá reunir a o efeito aleatório e <u>id</u> deverá ser arrastado para lá.


Ao fazer isso, o JASP irá realizar a análise e apresentar, automaticamente, os resultados.  


![](./img/cap_lmm_interface3.png)

Esses resultados são baseados na configuração padrão do JASP, que define tanto o intercepto como a inclinação como efeitos aleatórios. No entanto, nesta pesquisa, apenas o intercepto foi definido como aleatório. Para alterar essa configuração, será necessário clicar na opção `Model`, na parte esquerda do programa.

![](./img/cap_lmm_model.png)

Todas as caixas de seleção na seção `Random effects` devem ser desmarcarcadas. 

![](./img/cap_lmm_model2.png)

Após isso feito, o JASP irá refazer as análises e apresentar os resultados, mudando também as mensagens de aviso. 

A interpretação dos resultados agora pode ser feita, sempre começando pela interação. A interação `Grupo x Tempo` não foi significativa (F(4, 152) = 0.696, p = 0.596). O efeito do `Grupo` também não foi significativo (F(3, 38) = 0.706, p = 0.406). De maneira distinta, o `Tempo` foi um preditor significativo (F(4, 152) = 3.304, p = 0.013).

![](./img/cap_lmm_resultados.png)


Esta versão do JASP não oferece nenhum recurso para avaliar os pressupostos do modelo. Dessa maneira, isso não será realizado. 

Apresentações gráficas são extremamente importantes e para fazer isso, é necessário clicar em `Plots`

![](./img/cap_lmm_resultados_plots.png) 

A variável `Tempo` deve ser inserida no eixo horizontal (`Horizontal axis`) e a variável `gruop` em `Separated lines`. As outras opções nào precisam ser alterada. O gráfico será gerado automaticamente e servirá como um recurso extra para entender os resultados.  


![](./img/cap_lmm_resultados_plots2.png)
Notas: Infelizmente, o JASP não realiza um gráfico completo dessa maneira na seção `Descriptives`, tal como apresentado. Por vezes, será necessário primeiro rodar integralmente o Modelo Linear misto para depois gerar esta apresentação. Quase sempre, o eixo X recebe a variável com maior quantidade de níveis. Essa pesquisa não teve resultados significativos e, em função disso, testes post hoc não foram realizados. Entretanto, frequentemente os resultados são significativos e a mecânica das comparações pareadas é próxima ao que foi demonstrado no capítulo de ANOVA Fatorial.


## Escrita dos resultados


um dos principais objetivos em delineamentos que contem com termos de interação é verificar se o efeito de uma variável depende dos níveis de outra. Nesta pesquisa, isso ocorreria caso os resultados obtidos dependessem da relação entre o tempo decorrido do tratamento e do grupo em que o participante tivesse sido alocado. No entanto, os resultados da interação não foram significativos, indicando que isso não parece ter ocorrido. Uma vez que o efeito principal do tempo foi significativo, é possível concluir que o tempo é um preditor significativo nos resultados, independente do grupo em que o participante se encontra.  

Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados** 

Os dados foram analisados através de um Modelo Linear de Efeitos Mistos, que verificou o efeito do tempo, do grupo, a interação entre esses dois preditores. Neste modelo, um intercepto aleatório foi definido para cada participante em com isso, essa análise levou em consideração tanto efeitos fixos quanto aleatórios. Os resultados permitiram concluir que Não há interação significativa tempo x grupo (F(4, 152 = 0.696), p = 0.596), bem como não há efeito significativo do grupo (F(1, 38 = 0.706), p = 0.406). Em outra direção, o efeito o tempo teve efeito significativo nos resultados (F(4, 152 = 3.304), p = 0.013).

```


## Resumo  

1. O Modelo Linear de Efeitos Mistos (LMM) oferece maior versatilidade à ANOVA de medidas repetidas    
2. A ANOVA tem como pressuposto Normalidade e Esfericidade, enquanto o LMM apenas Normalidade dos resíduos
3. Os resultados frequentemente encontrados em ambos os modelos vão na mesma direção  
4. A implementação computacional é mais trabalhosa  
5. A escrita apresenta algumas particularidades relacionadas à cada modelo.    



## Pesquisas adicionais  

1. Effects of Aerobic Training versus Breathing Exercises on Asthma Control: A Randomized Trial (DOI: 10.1016/j.jaip.2020.06.042)
Nesta pesquisa, 54 pacientes com asma foram aleatoriamente selecionados para receberem ou um tratamento baseado em exercícios aeróbicos ou um tratamento baseado em técnicas de respiração. Os pesquisadores acompanharam os participantes por 3 meses e concluíram que, em alguns aspectos, o grupo de exercícios aeróbicos teve uma melhora significativamente maior do que o grupo de técnicas respiratórias.  

<!--chapter:end:08-linear_misto.Rmd-->

# Correlação


```{r, include = FALSE }
load("~/anovabr/mqt/bases/Base R - imagem corporal.RData")

library(tidyverse)
library(pander)

library(kableExtra) #tables with different styles
library(olsrr) #regression diagnostics
library(gridExtra) #plot together
```

A correlação é um procedimento estatístico utilizado para verificar a relação entre duas variáveis. Há diferentes técnicas correlacionais e a maioria busca medir a <u>força</u> e a <u>direção</u> da <u>associação linear</u> desse relacionamento.

O nível de medida das variáveis indica qual técnica correlacional deve ser empregada. A tabela a seguir apresenta uma síntese:


  | Nível de medida                     | Correlação / Coeficiente               |  
  | :-----------                        | :-----------                           |        
  | Amas as variáveis são intervalares  | Correlação Produto momento de Pearson  |  
  | Amas as variáveis são ordinais      | Correlação de Spearman                 |  
  | Amas as variáveis são nominais      | Coeficiente Phi                        |  


O Coeficiente de Correlação de Pearson é um dos mais frequentemente calculados em Psicologia e outras áreas empíricas e será demonstrado neste capítulo. É importante, no entanto, ter em mente que algumas áreas específicas outros coeficientes tendem a ser utilizados. Como exemplo, é bem típico em Psicometria trabalhar com variáveis categóricas e, com isso, calcular correlações tetracóricas ou policóricas, que não serão abordadas aqui. 

A correlação de Pearson é apresentada por $\rho$ ou `r`, e é formada por um <u>valor numérico</u> e um <u>sinal</u>. Enquanto o valor numérico indica a força do relacionamento bivariado, o sinal indica a natureza proporcional ou inversamente proporcional desse relacionamento. A tabela abaixo descreve as possíveis interpretações [@Cohen1988].  

  | Valor         | Sinal Positivo (+)    | Sinal Negativo (-) | 
  | :-----------  | :-----------          | :-----------       |
  | 0.1           | Fraca positiva        | Fraca negativa     |
  | 0.3           | Moderada positiva     | Moderada negativa  |
  | 0.5           | Forte positiva        | Forte negativa     |

O gráfico de dispersão é uma excelente forma de ilustrar o relacionamento bivariado e as imagens abaixo demonstram tais conceitos.  

```{r, echo=FALSE }
grid.arrange(
  ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .1, .1, 1), nrow=2), empirical=TRUE)), 
         aes(x = X1, y = X2)) + geom_jitter() + labs(x= "", y = "Y (corr. positiva)") +
    geom_text(aes(label=paste("r=+0.1 - fraca")),  x=-Inf, y=Inf, hjust=-0.2, vjust=1.2),
  ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .3, .3, 1), nrow=2), empirical=TRUE)), 
         aes(x = X1, y = X2)) + geom_jitter() + labs(x= "X", y = "") +
    geom_text(aes(label=paste("r=+0.3 - moderada")),  x=-Inf, y=Inf, hjust=-0.2, vjust=1.2),
  ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .5, .5, 1), nrow=2), empirical=TRUE)), 
         aes(x = X1, y = X2)) + geom_jitter() + labs(x= "", y = "") +
    geom_text(aes(label=paste("r=+0.5 - forte")),  x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), 
  
  ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.1, -.1, 1), nrow=2), empirical=TRUE)), 
         aes(x = X1, y = X2)) + geom_jitter() + labs(x= "", y = "Y (corr. negativa)") +
    geom_text(aes(label=paste("r=-0.1 - fraca")),  x=-Inf, y=Inf, hjust=-0.2, vjust=1.2),
  ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.3, -.3, 1), nrow=2), empirical=TRUE)), 
         aes(x = X1, y = X2)) + geom_jitter() + labs(x= "X", y = "") +
    geom_text(aes(label=paste("r=-0.3 - moderada")),  x=-Inf, y=Inf, hjust=-0.2, vjust=1.2),
  ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.5, -.5, 1), nrow=2), empirical=TRUE)), 
         aes(x = X1, y = X2)) + geom_jitter() + labs(x= "", y = "") +
    geom_text(aes(label=paste("r=-0.5 - forte")),  x=-Inf, y=Inf, hjust=-0.2, vjust=1.2),
  
  nrow = 2)
```

Para realização da Correlação de Pearson, é necessário que ambas as variáveis sejam contínuas e apresentem relacionamento linear. O Coeficiente tem as seguintes propriedades:     

1. É limitado entre -1 e +1, com 0 indicando ausência de correlação    
2. O sinal indica a natureza, enquanto o número a força  
3. A correlação de uma variável com ela própria é igual a 1  
4. É simétrico, ou seja, `r(x,y) = r(y,x)`  
5. É adimensional e invariante em transformações lineares  
6. Sensível aos outliers  
7. Não indica causalidade  




## Pesquisa  

<div class="alert alert-warning">
  <strong>Base: </strong> Livro - Dados - Eating disorders
</div>  


Vamos utilizar a pesquisa intitulada ["Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students"](https://www.researchgate.net/publication/323729370_Aspects_Related_to_Body_Image_and_Eating_Behaviors_in_Healthy_Brazilian_Undergraduate_Students), publicada em 2018 no Global Journal of Educational Studies, que sou coautor.

Um dos objetivos dessa pesquisa foi verificar a relação entre percepção da imagem corporal e transtornos alimentares. Esse artigo contou com a utilização de escalas aplicadas em 219 participantes no Brasil. Para acessar características relacionados aos Transtornos alimentares, a escala EAT-26 foi aplicada. Já para aspectos da imagem corporal, a escala BSQ-34 foi aplicada. Em ambas as escalas, quão maior o valor, mais frequentes ou intensos são os sintomas relacionados a distorções na percepção da imagem corporal e em disfunções no comportamento alimentar.    

## Execução no R  


A primeira etapa da análise consite na apresentação de tabelas e gráficos que possam auxiliar na interpretação dos resultados. Abaixo há uma tabela inicial com os resultados das escalas.  

```{r, results = "asis" }
arsenal::tableby(~eat_soma + bsq_soma, test = FALSE, dados_brasil) %>% summary() 
```


Após isso realizado, a realização do gráfico de dispersão é fundamental para melhor entendimento do relacionamento entre as variáveis, especialmente para verificar se ele linear ou não. Apesar de técnicas correlacionais não elegerem, formalmente, uma VI e uma VD, com muita frequência, se usa o eixo X para colocar a variável que se assume como independente e Y para apresentar os resultados da variável assumida como dependente.    

```{r}
ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) +
  labs(x = "Imagem corporal (BSQ)", Y = "Disfunção alimentar (EAT)")
  geom_jitter()
```
  
O gráfico indica que as duas variáveis são relacionadas. Apesar do padrão deste relacionamento não ser estritamente linear, é possível testar formalmente a correlação entre ambas as variáveis,

Isso pode ser feito pela função `cor.test`, que é nativa do R.  

```{r}
cor.test(dados_brasil$eat_soma, dados_brasil$bsq_soma) %>% pander()
```

Os resultados permitem concluir que a correlação é positiva e forte (r = 0.675), além de significativa (p < 0.001). Isso indica que ambas as variáveis covariam de maneira proporcional, em que valores altos em uma tendem a acompanhar valores altos em outra. É importante atentar que esse relacionamento não indica causalidade e, dessa forma, essa covariação pode ser explicada por diferentes fatores não analisados ou controlados neste método, tal como previamente apresentado nas características de delineamentos observacionais.    

A correlação de Pearson não depende estritamente da normalidade das variáveis, apesar desse tema ser bastante discutido. Dessa forma, não há pressupostos para se checar além dos já discutidos no decorrer deste capítulo. 


## Execução no JASP  

Para executar as rotinas, será necessário carregar a base [csv eat bsq brasil](https://www.dropbox.com/s/l8xkxi5z5fntrd9/csv%20eat%20bsq%20brasil.csv?dl=0). Após fazer isso, para realizar tabelas e gráficos descritivos, deve-se clicar em `Descriptives` , na parte superior do programa.

![](./img/cap_correlacao_descritivo.png)
Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Apesar de na correlação os conceitos de VI e VD não serem formalmente empregados, a lista `Variables` costuma reunir as variáveis dependentes, enquanto a seção `Split` costuma receber a variável independente. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 


![](./img/cap_correlacao_descritivo2.png)
Será necessário arrastar tanto <u>eat_soma</u> como <u>bsq_soma</u> para o espaço de `Variables`. Apenas para melhor apresentação dos resultados, é importante que a primeira variável da lista seja <u>bsq_soma</u>. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização. .


![](./img/cap_correlacao_descritivo3.png)

Em seguida, para apresentar graficamente este relacionamento, será necessário clicar na opção `Plots`. 


![](./img/cap_correlacao_plot.png)


Dentro das opções, será possível selecionar `Scatter Plots`. O gráfico aparecerá na parte inferior do lado direito e trará diferentes informações estatísticas da relação entre aspectos da percepção da imagem corporal e possíveis disfunções alimentares dos participantes.  

![](./img/cap_correlacao_grafico_dispersao.png)

Por padrão, o JASP irá adicionar vários elementos extras no gráfico. Entretanto, para fins pedagógicos, o importante é conseguir notar o relacionamento que ambas as variáveis apresentam. Para realizar um gráfico mais simples, será necessário <u>desmarcar</u> (ou clicar em `none`) as opções `Graph above scatter plot`, `Graph righ of scatter plot` e `Add regression line`. 

![](./img/cap_correlacao_grafico_dispersao2.png)

Para execução da correlação, será necessário clicar em `Regression` e `Correlation`.

![](./img/cap_correlacao_interface.png)
Ao realizar isso, a tela a ser exibida será próxima à imgaem abaixo. Por padrão, em `Sample Correlation`, o JASP já deixa marcada a opção `Pearson's r`. Além disso, em `Additional Options`, a opção  `Report significance` também estará previamente ativada`.

![](./img/cap_correlacao_interface2.png)

O espaço `Variables` é o local onde todas as variáveis serão colocadas e o espaço `Condition on` não será utilizado no momento. Ao inserir o <u>eat_soma</u> e o <u>bsq_soma</u>, o JASP automaticamente irá realizar as contas e apresentar os resultados. 

O coeficiente de correlação e o valor de p serão apresentados em uma lista. No entanto, algumas condições são imoprtantes neste resultado e devem ser explicadas:

1. As variáveis serão alocadas tanto nas linhas, como nas colunas  
2. Todas as correlação de uma variável com ela própria será igual a 1 e o JASP não apresentará    
3. A ordem das correlações não interfere no resultado e o JASP somente apresentará uma correlação   

A interpretação dos resultados deve ser feita com base no coeficiente de correlação e no valor de P. Há um grande debate na literatura sobre a necessidade de normalidade na Correlação de Pearson, com grande parte dos argumentos apontam que ela <u>não</u> depende estritamente da normalidade das variáveis. Dessa maneira, não há a necessidade de avaliar outros pressupostos além dos já discutidos no decorrer deste capítulo. 


![](./img/cap_correlacao_resultados.png)

## Escrita dos resultados


Os resultados serão escritos apresentado os três principais ingredientes da correlação, que são o resultado e o sinal do coeficiente de correlação de Pearson, além do valor de p. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA). Como os resultados do R e do JASP foram um pouco diferente nas comparações pareadas, o R será utilizado como principal.  



```{block, type="writing"}
**Como escrever os resultados**  

A correlação entre o comportamento alimentar (EAT-26) e a percepção corporal (BSQ-34) foi calculada pelo Coeficiente Produto-Momento de Pearson. Os resultados concluíram que existe uma correlação positiva, forte e significativa entre ambas as variáveis (r = 0.675, p < 0.001), indicando que as duas variáveis covariam de maneira proporcional.
```


## Resumo  

1. O termo correlação diz respeito a um conjunto de métodos que visa verificar a direção e a força do relacionamento entre duas variáveis   
2. A correlação de Pearson assume que ambas as variáveis são linearmente correlacionadas   
3. O coeficiente sempre indicará a direção (por um sinal) e a força (por um número entre -1 e +1) do relacionamento bivariado  
4. Correlação não indica causalidade  


## Pesquisas adicionais  

1. Perception of an ambiguous figure is affected by own-age social biases (DOI: 10.1038/s41598-018-31129-7)    
Nesse estudo, 393 participantes de idades variadas foram recrutados e viram uma imagem ambígua em que é possível identificar tanto uma moça jovem, como uma senhora de idade. Os participantes deveriam olhar a imagem e indicar a idade a pessoa. Com estes resultados, os pesquisadores calcularam a correlação entre a idade do participante e a idade que as pessoas deram à pessoa.




<!--chapter:end:09-correlacao.Rmd-->

# Regressão linear simples


```{r, include = FALSE }
load("~/anovabr/mqt/bases/Base R - imagem corporal.RData")

library(tidyverse)
library(olsrr) #regression diagnostics
library(pander)
```

De forma geral, modelos de regressão são modelos estatísticos que visam predizer o comportamento de uma variável dependente (Y) como uma função de uma ou mais variáveis independentes (X). Em larga escala, eles substituem os outros testes paramétricos vistos até agora. Dessa maneira, quase tudo o que foi visto durante os capítulos anteriores são casos especiais de modelos de regressão [@Chartier2008]. 

Existem diferentes nomenclaturas utilizadas para classificar tais modelos e a tabela abaixo apresenta uma classificação funcional.

  | VI e VD      | VD Discreta    |  VD Contínua                 |  
  | :----------- | :-----------   | :-----------                 |        
  | VI Discreta  | Reg. logística |  Reg. linear (Teste T/ANOVA) |   
  | VI Contínua  | Reg. logística |  Reg. linear                 | 
  

Algumas conclusões são possíveis:  

1. A variável dependente irá definir se a regressão será linear ou logística. Quando a VD é continua (ex: peso, tempo de resposta, inteligência) trata-se de uma regressão linear. Quando a VD é discreta ou categórica (ex: acidente - sim ou não; orientação política - direita ou esquerda) trata-se de uma regressão logística.    
2.  Caso haja uma única VI, a regressão é chamada de simples. Com duas ou mais VIs, ela é chamada de múltipla.  
3.  Se houver mais de uma VD, o modelo será chamado de multivariado (em inglês, path analysis.  
4.  Teste T e ANOVA são casos de regressão linear simples.     
5.  ANCOVA, ANOVA de k vias e ANOVA fatorial são casos de regressão múltipla.  
6.  O qui-quadrado pode ser aproximado pela regressão logística simples e vice-versa.  


Isso posto, a Regressão linear é uma técnica estatística que permite estimar o quanto os valores de uma variável dependente (Y) variam em função de uma ou mais variáveis independentes (X). Isso é feito através de uma equação específica e há, ao menos, duas utilidades diretas em uma pesquisa, que são:  

(i) <mark>Predizer</marK> os valores da variável dependente (Y) em função dos valores da variável dependente (X);  
(ii) <mark>Explicar</marK> a variabilidade da variável dependente (Y) em função da variável independente (X). 

Abas as utilidades são virtualmente iguais e como a Regressão linear simples pode ser vista a partir de um incremento ou avanço dos modelos de correlação, os aspectos correlacionais devem (e podem) ser inicialmente investigados.  


Pela abrangência dos modelos de regressão, é possível tanto encontrar cursos completos e detahados sobre seus detalhes, como abordagens mais pragmáticas e operacionais voltadas a implementação deles em pesquisas. Nesse capítulo, o foco será dado na capacidade operacional.

Conceitualmente, a regressão linear simples é apresentada como:

\[y_i = b_0 + b_1X{_1}_i + \epsilon_{i}\]

$y_i$ representa a variável dependente  
$b_0$ é o intercepto (coeficiente linear)   
$b_1$ é a inclinação (coeficiente angular)  
$\epsilon_{i}$ é o erro/resíduo   


A interpretação dos resultados obtidos depende dos seguintes pressupostos:  
 
(i) A relação entre as variáveis é linear
(ii) Os resíduos são independentes  
(ii) Os resíduos são normalmente distribuídos (com média)    
(iii) A variância dos resíduos é constante  

O mnemônico <u>LINE</u> talvez ajude a lembrar destes pressupostos. Ele se refere à <u>linearity</u>, <u>independence</u>, <u>normality</u> e <u>equal variance </u>.  


## Glossário        
 
Diferentes termos são empregados em modelos de regressão. Alguns deles são apresentados a seguir para auxiliar no entendimento e também aproximar o leitor a este tipo de modelagem.    

```{block, type="writing"}
**GLOSSÁRIO**

**intercepto** ($b_0$): Valor previsto (médio) de Y quando X = 0  
**Inclinação** ($b_i$): Diferença média em unidades da variável dependente quando se altera uma unidade de X   
**SSR**: Soma dos Quadrados da Regressão   
**SSE**: Soma dos Quadrados dos Erros  
**SST**: Soma dos Quadrados Total  
**Coeficiente de Determinação** ($R^2$): Porcentagem de variação da variável dependente (Y) que pode ser atribuída à variabilida da(s) variável (is) independente(s) (X)  
**Coeficiente de Determinação ajustado** ($R^2_{adj}$): Coeficiente que pondera o $R^2$ pelo número de variáveis explicativas e pelo número de observações da amostra. É particularmente útil quando deseja-se comparar modelos de regressão múltipla para mesma variável dependente, pois penaliza aquele modelo com maior número de variáveis independentes   
```


## Breve explicação conceitual


Conforme descrito, modelos de regressão conseguem substituir a maior parte dos testes estatísticos realizados para testar hipóteses. Neste sentido, a maior parte dos livros tenta fazer uma introdução a estes modelos de forma que tanto aspectos conceituais, como algumas características analíticas possam ser melhor entendidas. Nesta seção, essa apresentação será feita de uma forma mais intuitiva. Caso você queira pular esta seção e ir direto à [pesquisa](##pesquisa), não há problema. 

Inicialmente, se pensarmos que as variáveis da pesquisa podem ser representadas por conjuntos, é possível imaginar que tanto Y como X são independentes. Neste sentido, a realização de Y não dependente da realização de X e vice-versa. 

![](./img/cap_reg_xy.png)


No entanto, isso não é o que costuma ocorrer. Na verdade, com muita frequência, existe algum grau de relacionamento entre as variáveis, tal como exposto abaixo.  

![](./img/cap_reg_x_y2.png)


Caso se assuma que X é um fator de causalidade à realização de Y, isso significa que uma parte da realização de Y, necessariamente, depende de X. Tecnicamente, é isso que faz com que X seja chamada de variável independente e Y variável dependente. A área de intersecção destacada representa a parte de Y que pode ser atribuída ou explicada por X.  

Analiticamente, essa área passará por algumas transformações algébricas e receberá o nome de `Soma dos Quadrados da Regressão` (SSR, em inglês).  

![](./img/cap_reg_xy_SSR.png)

No entanto, nem toda a variabilidade de Y pode ser atribuída à X. Essa região de Y que está fora da intersecção também sofrerá transformações algébricas e será chamada de `Soma dos Quadrados dos Erros` (SSE, em inglês).  

Essa área representa a variabilidade de Y que não pode ser atribuída ou explicada por X.   

![](./img/cap_reg_x_y_SSE.png)


Agora, tecnicamente Y existe independentemente de X e possui uma variabilidade ou dispersão interna. Essa variabilidade é bastante próxima do conceito de variância visto em estatística descritiva e pode ser obtida pelo somatório da área explicada pela regressão (SSR) com a área não explicada (SSE). 

Essa região total também passará por transformações algébricas e será chamada de `Soma dos Quadrados Total` (SST, em inglês).


![](./img/cap_reg_xy_SST.png)


Vendo todas as partições de uma única vez, temos o seguinte:


![](./img/cap_reg_x_y_SSE_SSR_SST.png)


A porcentagem de variação de Y que pode ser atribuída à variabilidade de X é uma razão entre a Soma dos Quadrados da Regressão (SSR) e a Soma dos Quadrados Total (SST). O coeficiente obtido por essa razão recebe o nome de <u>Coeficiente de Determinação</u> ou $R^2$, e indica a porcentagem de variação de Y que pode ser atribuída à variabilida de X.

![](./img/cap_regr2.png) 

Isso é equivalente a subtração do espaço máximo de variabilidade (1 ou 100%) pela razão entre a Soma dos Quadrados dos Erros (SSE) e Soma dos Quadrados Total (SST):


![](./img/cap_reg_r21.png)


Evidentemente, essa explicação conceitual conta apenas uma parte da estória. É igualmente possível entender os modelos de regressão a partir da ampliação de uma análise de correlação. Por exemplo, se duas variáveis aleatórias contínuas são correlacionadas de maneira linear e positiva, tal como demonstrado abaixo:


```{r, echo=FALSE }
ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) +
  geom_jitter() +
  labs(x = "X", y = "Y") 
```
  
É possível verificar quanto os valores de Y podem ser atribuídos à X a partir de um modelo estatístico. Este modelo irá computar uma função para ajustar uma reta bem próxima aos pontos reais. Tecnicamente, quão mais próximo essa reta estiver dos pontos, melhor ajustada ela estará e, consequentemente, menor os erros serão. No entanto, muitas retas podem ser traçadas, tal como demonstrado a seguir.  

```{r, echo=FALSE}
set.seed(123)
ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) +
  geom_jitter() +
  labs(x = "X", y = "Y") +
  xlim(10,200) +
  geom_abline(slope = c(rnorm(10,0.4,0.5), rnorm(10,0.2,0.15)),color = 1:20)
```

De maneira geral, todas as retas traçadas acertam alguns pontos e erram outros. Há aquelas que se saem melhores e outras que tem um desempenho muito ruim. O que isso demonstra é que encontrar o <u>melhor</u> modelo estatístico para este caso é um problema de otimização. Isso pode ser feito justamente resgatando um pouco o conceito de função de primeiro grau, aprendido no ensino médio:

$$y = a + bX$$


Nesta equação, $y$ depende de duas constantes e uma variável. As constante são $a$, que também é chamada de intercepto ou coeficiente linear e $b$, que é chamada de inclinação ou coeficiente angular. A variável da equação é apresentada por $X$. Por uma questão de simbologia, três alterações são feitas com a equação:    

(i) Os símbolos são alterados. Agora $a = b_0$ e $b = b_1$. A alteração de simbologia não altera em nada os cálculos.  

(ii) Como se sabe que função vai <u>estimar</u> os valores reais de $Y$, letras minúsculas ou um chapéu sobre as letras será utilizado em vez das letras maiúsculas ou gregas.  

(iii) Para que cada valor estimado seja associado a um participante a letra $i$ será adicionada abaixo do $y$ e do $b_1$.   

Assim, temos que os valores estimados de y, agora $\hat{y}$, são obtidos pelo $b_0$ e $b_1$:

$$\hat{y}_i = b_0 + b_1X{_1}_i$$



Acredito que fique claro que essa equação possibilitará construir uma reta que minimize os erros e não que os anule totalmente. Ou seja, entre o valor real de y (os pontos que estão no gráfico) e os valores estinados pela equação $\hat{y}$, haverá <u>sempre</u> uma certa quantidade de erro de estimativa. O erro é simbolizado por $e_i$, é aleatório e abrange todas as influências no comportamento de Y que não podem ser explicadas linearmente pelo comportamento de X. Além disso, alguns pressupostos estatísticos são impostos a este termo para que as mudanças em X tenham efeito (ceteris paribus) em Y.  

É possível agora reescrever a equação anterior, considerando que qualquer que seja o valor estimado, sempre haverá uma quantidade de erro. 

$$y_i = a + b_1X{_1}_i+\underbrace{e_i}_\text{aleatório}$$

A melhor reta a ser construída será a que melhor minimize o erro. Por sua vez, os erros se formam pela diferença entre os valores obtidos e previstos.

$$e_i = y_i - \hat{y_i}$$
O que é análogo à:

$$e_i = y_i - (b_0 + b_1X{_1}_i) \\ =  y_i - b_0 - b_1X{_1}_i$$

O método de Mínimos Quadrados Ordinários (em inglês, Ordinary Least Squares -- OLS) é o mais frequentemente utilizado para estimar os valores de $b_0$ e $b_1$ que possam minimizar o erro quadrático, chamado de $SSE$. A intuição de calcular o erro quadrático em vez do absoluto é a de punir mais severamente os desvios grandes. 

$$SSE = \sum_{i=1}^n e_i^2 = \sum_{i=1}^n (y_i - b_0 - b_1 X_i)^2$$


Para encontrar o mínimo, é necessário derivar $SSE$ em relação à $b_0$ e e $b_1$ e, em seguida, igualar à 0:

$$\frac{\partial e^2}{\partial b_0}  = 0,\\ \frac{\partial e^2}{\partial b_1} = 0$$

Rearrumando um pouco os resultados, eles permitem concluir que a inclinação da reta (slope) é dada por:
$$b_1=\frac{\sum\limits_{i=1}^{n} (x_i-\overline{x}) (y_i-\overline{y})}{\sum\limits_{i=1}^{n} (x_i-\overline{x})^2} = \frac{COV(x,y)}{VAR(X)}$$

Enquanto o intercepto é dado por:

$$b_0 = \overline{y} - b_1 \overline{x}$$

Pela forma como são calculados, o $b_0$ e o $b_1$ são chamados de estimadores de mínimos quadrados ordinários. O $b_1$ representa o quanto a média de Y varia para um aumento de uma unidade da variável X. O $b_0$ indica o ponto onde a reta corta o eixo das ordenadas e pode ser
interpretável ou não, tal como descrito no [glossário](#glossario).  

Implementando as fórmulas, agora é possível traçar a <u>melhor</u> reta para descrever o relacionamento entre as variáveis, tal como abaixo:

```{r, echo = FALSE }
b1 <- cov(dados_brasil$bsq_soma, dados_brasil$eat_soma)/var(dados_brasil$bsq_soma)
b0 <- mean(dados_brasil$eat_soma)-(b1*mean(dados_brasil$bsq_soma))
```

```{r, echo = FALSE }
ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) +
  geom_jitter() +
  labs(x = "", y = "") +
  geom_abline(intercept = b0, slope = b1)

```

Essa reta passará necessariamente pela média de ambas as variáveis.

```{r, echo = FALSE }
ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) +
  geom_jitter() +
  labs(x = "X", y = "Y") +
  geom_abline(intercept = b0, slope = b1) +
  geom_vline(xintercept = mean(dados_brasil$bsq_soma), size=1.5, color = "red", linetype = "dashed") +
  geom_hline(yintercept = mean(dados_brasil$eat_soma), size=1.5, color = "red", linetype = "dashed")
```


Aproveitando o gráfico, agora é possível apresentar os dados reais, a linha de regressão e as distâncias entre ela e os pontos reais,

```{r, echo = FALSE, message=FALSE }
eat_soma_2 <- transform(dados_brasil, Fitted = fitted(mod_linear_simples))
gridExtra::grid.arrange(
  ggplot(dados_brasil, aes(bsq_soma, eat_soma)) +
    geom_jitter(color ="darkgray"),
  
  ggplot(dados_brasil, aes(bsq_soma, eat_soma)) +
    geom_jitter(color ="darkgray") +
    geom_smooth(method="lm", se = FALSE),
  
  ggplot(eat_soma_2, aes(bsq_soma, eat_soma)) +
    geom_jitter(color ="darkgray") +
    geom_smooth(method="lm", se = FALSE) +
    geom_segment(aes(x = bsq_soma, y = eat_soma,
                     xend = bsq_soma, yend = Fitted), color = "lightgrey"),
  ncol=3
)
```

Com esse sistema de equações, é possível verificar que a variabilidade total de Y pode ser descrita por uma parte explicada pelo modelo de regressão e uma parte não explicada. Existem muitas siglas para expressar estes conceitos e aqui vou utilizar a versão em inglês. SST (total sum of squares) se refere à Soma Total dos Quadrados, SSR (regression sum of squares) se refere à Soma dos Quadrados da Regressão e SSE (error sum of squares) se refere à Soma dos Quadrados dos Erros, que é a parte não explicada pelo modelo.  

Conceitualmente, isso é descrito da seguinte manteira:  


$$\underbrace{\sum\limits_{i=1}^{n} (y_i-\overline{y})^2}_\text{SST} = \underbrace{\sum\limits_{i=1}^{n} (\widehat{y_i}-\overline{y})^2}_\text{SSR} + \underbrace{\sum\limits_{i=1}^{n} (y_1-\widehat{y_i})^2}_\text{SSE}$$


Adicionando as equações ao gráfico, tem-se o seguinte:  

![](./img/cap_reg_equacoes.png)

A avaliação deste modelo pode ser feita de maneira análoga ao apresentado anteriormente, em que SSR e SST são divididos e geram um coeficiente de determinação, representado por $R^2$. 

$$R^2=\frac{\sum\limits_{i=1}^{n} (\widehat{y_i}-\overline{y})^2}{\sum\limits_{i=1}^{n} (y_i-\overline{y})^2} = \frac{SSR}{SST}$$
Rearrumando a equação, o $R^2$ também pode ser obtido por:

$$R^2 = 1- \frac{SSE}{SST}$$  


Este coeficiente varia entre 0 até 1 e indica a proporção da variação total da variável dependente que pode ser atribuída à variável independente. Ele pode ser utilizado como uma medida da qualidade do ajustamento da reta de regressão aos dados e um indicador da confiança das previsões geradas pelo modelo de regressão.


Isso feito, o sumário de algumas fórmulas fechadas pode auxiliar no entendimento desta modelagem àqueles com este interesse específico.  

```{block, type="writing"}
Soma dos Quadrados da Regressão: $SSR =  \sum\limits_{i=1}^{n} (\widehat{y_i}-\overline{y})^2$  

Soma dos Quadrados dos Erros: $SSE =  \sum\limits_{i=1}^{n} (y_1-\widehat{y_i})^2$  

Soma dos Quadrados Total: $SST =  \sum\limits_{i=1}^{n} (y_i-\overline{y})^2$  

Variabilidade total: $SST = SSR + SSE$  

$R^2= \frac{\sum\limits_{i=1}^{n} (\widehat{y_i}-\overline{y})^2}{\sum\limits_{i=1}^{n} (y_i-\overline{y})^2} = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$  


$R^2_{adj}$: $1-\frac{SSE/N-K}{SST/N-1}$  

```



É importante destacar que esta introdução é inicial e serve apenas para introduzir as principais ideia da modelagem de regressão de uma maneira intuitiva. Existem excelente obras mais detalhadas e com aplicações à Psicologia, entre elas:  

Data Analysis: A Model Comparison Approach To Regression, ANOVA, and Beyond, de Charles M. Judd,  Gary H. McClelland e Carey S. Ryan;   
Regression, ANOVA, and the General Linear Model": A Statistics Primer, de Paul Vik;   
Regression: Linear Models in Statistics e N.H. Bingham e J.M. Fry, e   
Regression and Other Stories, de Andrew Gelman   

## Pesquisa  

<div class="alert alert-warning">
  <strong>Base: </strong> Livro - Dados - Eating disorders
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada ["Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students"](https://www.researchgate.net/publication/323729370_Aspects_Related_to_Body_Image_and_Eating_Behaviors_in_Healthy_Brazilian_Undergraduate_Students), publicada em 2018 no Global Journal of Educational Studies, que sou coautor.

O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e na percepção da imagem corporal. Os primeiros aspectos foram avaliados pela escala EAT-26, enquanto o segundo foi avaliado pela escala BSQ-34.  

Uma das principais hipóteses era que alterações na percepção da imagem corporal seriam preditores para possíveis transtornos alimentares. Operacionalmente, a hipótese era de que os valores da BSQ-34 poderiam predizer os valores da EAT-26 e que quão maior fossem os primeiros, maior seriam os efeitos na maximização dos segundos.    

Em modelos de regressão, as hipóteses costumam ser feitas em cascata. Quase sempre, se compara o modelo de desenvolvido com um modelo mais simples. Em seguida, verifica-se cada preditor de forma individual e assim sucessivamente. Uma vez que a definição de cada hipótese ocuparia um espaço grande aqui, elas serão suprimidas.  



## Execução no R  


A primeira etapa da análise é realizada pelo desenvolvimento de tabelas e gráficos que possam auxiliar na interpretação dos resultados. De maneira similar à feita em outros capítulos, abaixo há uma tabela descritiva . 

```{r results="asis" }
arsenal::tableby(~eat_soma + bsq_soma, dados_brasil) %>% summary() 
```



O cálculo da correlação entre ambas as variáveis também é importante, apesar de tecnicamente não ser necessário neste capítulo. Em linhas gerais, o coeficiente de correlação expressa a força e a direção do relacionamento entre as variáveis. A força pode ser interpretada como `fraca` (0.1), `moderada` (0.3) ou `forte` (0.5) [@Cohen1988] e a direção pode ser positiva ou negativa, a depender do sinal. A correlação entre as variáveis foi 0.675 e significativa (p < 0.001).

```{r}
cor.test(dados_brasil$eat_soma, dados_brasil$bsq_soma) %>% pander()
```
   
O gráfico de dispersão apresenta esse relacionamento. No eixo X deve-se inserir a VI (neste caso, os resultados da BSQ-34), enquanto a VD é inserida em Y.

```{r}
ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) +
  geom_jitter()
```

Tanto a tabela como o gráfico deixam claro que existe um padrão (aproximadamente linear) entre ambas as variáveis que ocorre de maneira forte e significativa. Com isso, é natural que o interesse seja verificar o quanto os resultados do <u>EAT-26</u> variam em função do <u>BSQ-34</u>.   

Para executar esse procedimento, o R conta com a função nativa `lm`. Por sua vez, o pacote `olsrr` oferece excelentes complementos para interpretar os achados.  O vetor `mod_linear_simples` será criado e armazenará os resultados. Lembre-se que, no R, é importante <u>sempre</u> atentar para o nível de medida das variáveis para que os resultados sejam adequados.  


```{r}
mod_linear_simples <- lm(eat_soma ~ bsq_soma, data = dados_brasil)
```


Na maioria dos programas comerciais, os resultados do modelo de regressão são apresentados em uma tabela padronizada. Essa tabela é virtualmente identica à que foi exposta no capítulo sobre a ANOVA de uma via e encontra-se abaixo descrita:    

  | Fonte de variação | SS               | df  | MS     | F-Value        | P-Value  |  
  | :-----            | :-----           | :-- | :----- | :-----         | :-----   |   
  | Regressão         | SSR (Regressão)  | K-1 | MSR    | SSR/K-1        | MSR/MSE  |   
  | Erro              | SSE (Erro)       | N-K | MSE    | SSE/N-K        | --       |     
  | Total             | SST (Total)      | N-1 | --     |  --            | --       |       
  | R2 = SSR/SST                                                                    |   
  
Nota: Nessa tabela, K considera dois preditores na regressão, que são o intercepto e a inclinação. É possível também encontrar `N-K-1` em alguns livros que não explicitam o intercepto na tabela.  

Isto explicado, a função `ols_regress` do pacote `olsrr` dispoõe os resultados neste padrão:  


```{r }
ols_regress(mod_linear_simples)
```

É fácil notar que os resultados apresentados são muitos e se recomenda uma ordem específica para interpretá-los.   

Em <u>primeiro momento</u>, é necessário verificar o ajuste do modelo na seção `ANOVA`. Este teste compara o modelo em questão contra um modelo em que apenas o intercepto é utilizado para prever todos os valores. Tecnicamente, o modelo analisado é chamado de <u>irrestrito</u> (ou aumentado) e o modelo que tem apenas o intercepto é chamado de <u>restrito</u> ou nulo. Valores significativos são necessários nesta etapa.  Nesta análise, o resultado foi F(1, 218) = 182.883, p < 0.0001, indicando que os outros resultados podem ser interpretados.  

O <u>segundo momento</u> é a interpretação do $R^2$. Como exposto no início do capítulo, essa indicador mensura a parte da variação da variável dependente (Y) que pode ser atribuída às variáveis independentes do modelo (X). Repare que ele é computado pela razão entre o SSR e o SST e indica que cerca de 46% dos resultados da variabilidade do EAT-26 podem ser explicados pelo modelo.     


O <u>terceiro momento</u> é a análise do $R^2 ajustado$. Em modelos de regressão, modelos com mais parâmetros/preditores sempre vão ter $R^2$ maior do que modelos mais compactos, independente da signficância destes outros parâmetros. O $R^2 ajustado$ é uma medida que considera a complexidade do modelo e pune a entrada de novas variáveis. Neste caso, como há apenas dois preditores (intercepto e bsq_soma), o $R^2 ajustado$ e o $R^2$ são quase idênticos.  

Finalmente, o <u>quarto momento</u> é análise dos preditores, que é feito na seção `Parameter Estimates`. Para isso, deve-se identificar os preditores um a um, seus valores de `Beta` e de P (`Sig`). O `Beta` indica a diferença média em unidades da <u>variável dependente</u> quando se altera uma unidade de X. Por exemplo, mais 1 ponto no BSQ-34, mais `0.178` pontos, em média, no EAT-26. Esse resultado é significativo, tal como é indicado na coluna `Sig`.  



O intercepto é chamado de `constante` na maior parte dos programas e indica o valor médio (esperado) de Y quando `X=0`. Nesse caso, se alguém tivesse tirado o valor `0` na escala BSQ-34, o valor previsto para os resultados da Escala EAT-26 seria de 1.46. No entanto, o `Sig` indica que esse valor não é significativo, ou seja, não é diferente de `0`. O indicador de beta padronizado `Std. Beta` traz as mesmas informações, mas trabalha em unidades de desvios-padrão em todas as variáveis presentes no modelo. Eventualmente, o `Std. Beta` pode ser entendido como uma medida perliminar de tamanho do efeito [@fox2016].

É importante notar que frequentemente o intercepto não tem interpretação lógica e, por isso, costuma ser desconsiderado. Para que ele tenha melhor capacidade de interpretação, algumas estratégias são possíveis, tal como centralizar os valores do preditor $(x_i-\bar{x})$. Caso isso seja feito, o intercepto irá ser o valor médio da variável dependente.  

Estes resultados obtidos são muito auxiliados pela apresentação de gráficos de dispersão, tal como feito no início do capítulo. Entretanto, agora estes gráficos ganham dois elementos a mais: (1) uma reta de regressão, obtida pela Função de Regressão Amostral (FRA), que irá indicar o intercepto, a inclinação e o intervalo de confiança das estimativas e (2) uma indicação textual com as equações características do modelo e seus respectivos resultados. Essas adições gráficas são feitas pelo pacote `ggpubr`. 

```{r}
ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) +
  geom_jitter() + geom_smooth(method = "lm") + 
  ggpubr::stat_regline_equation(label.x = 3, label.y = 40) +
  ggpubr::stat_cor(method = "pearson", label.x = 3, label.y = 44)
```


Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.

<mark> Normalidade</mark>: O pressuposto da Normalidade é atendido se os <u>resíduos</u> do modelo de regressão seguirem uma distribuição normal. Isso pode ser avaliado graficamente por QQ plots e também por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera.

O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis contra os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade.  Caso os pontos e a reta diagonal estejam superpostos, se considera que este pressuposto foi atendido. 

```{r}
ols_plot_resid_qq(mod_linear_simples)
```

Testes estatísticos formais também podem ser utilizados, tal como abaixo:  

```{r}
ols_test_normality(mod_linear_simples)
```
Apesar dos resultados obtidos por tais testes serem algo discordantes, os achados sugerem violação deste pressuposto.  


<mark>Homocedasticidade</mark>: Este pressuposto de variâncias constantes pode ser analisada em um gráfico de dispersão dos resíduos (residual) contra os valores previstos (fitted).  

```{r}
ols_plot_resid_fit(mod_linear_simples)
```

Caso haja padrões neste gráfico, isso sugere que este pressuposto foi violado. O gráfico não sugere padrões específicos. No entanto, testes formais são recomendados para que a decisão tomada tenha maior apoio. Existem diferentes testes para isso e, entre eles, o teste de Bartlett, Levene e Breusch-Pagan. Os resultados dependem das propriedades de cada um dos modelos e, em função da praticidade computacional, o teste de Breusch-Pagan será utilizado. Em todos estes testes, a hipótese nula assume homocedasticidade. Portanto, a estatística de teste não deveria ser significativa para que a homocedasticidade fosse apoiada.


```{r}
ols_test_breusch_pagan(mod_linear_simples)
```
Os resultados indicaram que a homocedasticidade foi violada. Isso vai na direção oposta da percepção gráfica, o que pode ocorrer sem nenhum problema.  

<mark>Independência</mark>: A independência dos resíduos depende bastante do delineamento utilizado ser transversal ou longitudinal. O teste de Durbin Watson pode ser utilizado e a hipótees nula é de que os resíduos não são correlacionados. Este pressuposto foi atendido, o que já era esperado.  

```{r}
car::durbinWatsonTest(mod_linear_simples)
```


Isso posto, os diagnósticos executados indicaram que o modelo violou a normalidade e a homocedasticidade e preservou a linearidade e a independência dos resíduos. Apesar desse tipo de resultado ser frequente em Psicologia, a interpretação dos resultados é limitada e deve ser feita de forma apenas preliminar. 


## Execução no JASP  

Para executar as rotinas necessárias, será necessário carregar a base de dados para o ambiente JASP. A base chama-se [csv eat bsq brasil](https://www.dropbox.com/s/l8xkxi5z5fntrd9/csv%20eat%20bsq%20brasil.csv?dl=0). Após fazer isso, para realizar tabelas e gráficos descritivos, deve-se clicar em `Descriptives` , na parte superior do programa.

![](./img/cap_correlacao_descritivo.png)

Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Neste caso, será necessário colocar o <u>bsq_soma</u> e o <u>eat_soma</u> na seção `Variables`. É importante manter essa ordem para as apresentações gráficas futuras.

![](./img/cap_reg_descritivo.png)

Ao fazer isso, automaticamente o JASP apresentará as médias e desvios-padrão de cada uma das variáveis, além de valores mínimos e máximos. Para realizar um gráfico que descreva o relacionamento entre ambas as variáveis, é necessário clicar em `Plots`.

![](./img/cap_reg_plot.png)


Há diversas opções, mas a `Scatter Plots` é a mais completa. Ao selecioná-la, o JASP já irá apresentar o gráfico, bem com adicionar elementos que possam maximizar o entendimento do relacionamento entre elas. A este momento, o interesse é fazer uma primeira avaliação sobre o perfil linear no relacionamento entre os dados, o que parece ocorrer.

![](./img/cap_reg_plot2.png)
É possível calcular a correlação entre ambas as variáveis, tal como foi realizado no R. Entretanto, essa etapa reproduziria o que foi feito no capítulo anterior e, por isso, não será apresentada. 

Para execução da regressão linear, será necessário clicar em `Regression` e `Linear Regression`. 

![](./img/cap_reg_multipla_interface.png)

A tela do JASP irá apresentar algumas opções. É importante notar que a `Covariates` é o local onde as VIs serão colocadas e `Dependent Variable` é onde a VD deverá ser inserida. Enquanto é possível inserir muitas variáveis independentes (fazendo um modelo múltiplo), apenas uma VD poderá ser inserida. O JASP apenas aceitará variáveis contínuas ou definidas como contínuas nos espaços apresentados.  

![](./img/cap_reg_interface.png)


Para realizar o modelo, será necessário levar a <u>bsq_soma</u> para seção `Covariates` e a <u>eat_soma</u> para `Dependent variable`. Ao fazer isso, o JASP irá fazer todas as principais análises e apresentar os resultados em uma tabela específica, ao lado direito da tela. É fácil notar que os resultados apresentados são muitos e se recomenda uma ordem específica para interpretá-los.   


Em <u>primeiro momento</u>, é necessário verificar o ajuste do modelo na seção `ANOVA`, bem ao centro dos resultados. Este teste compara o modelo em questão contra um modelo em que apenas o intercepto é utilizado para prever todos os valores. No JASP, esses modelos são descritos por `H1` e `H0` nas principais tabelas. Tecnicamente, o modelo analisado é chamado de <u>irrestrito</u> (ou aumentado, `H1`) e o modelo que tem apenas o intercepto é chamado de <u>restrito</u> ou nulo, `H0`. Valores significativos são necessários nesta etapa. Nesta análise, o resultado foi F(1, 218) = 182.883, p < 0.0001, indicando que os outros resultados podem ser interpretados. Quando isso acontece, deve-se desconsiderar todas as linhas que o JASP apresentar resultados para o modelo nulo, simbolizado por`H0`, e apenas interpretar os resultados do modelo testado, que é apresentado sempre por `H1`.   

![](./img/cap_reg_resultados1.png)

O <u>segundo momento</u> é a interpretação do $R^2$, que está localizado na parte superior, em `Model summary`. Como exposto no início do capítulo, essa indicador mensura a parte da variação da variável dependente (Y) que pode ser atribuída às variáveis independentes do modelo (X). Repare que ele é computado pela razão entre o SSR e o SST e indica que cerca de 46% dos resultados da variabilidade do EAT-26 podem ser explicados pelo modelo.     

![](./img/cap_reg_resultados2.png)

O <u>terceiro momento</u> é a análise do $R^2 ajustado$, que também está localizado na parte superior, em `Model summary`. Em modelos de regressão, modelos com mais parâmetros/preditores sempre vão ter $R^2$ maior do que modelos mais compactos, independente da signficância destes outros parâmetros. O $R^2 ajustado$ é uma medida que considera a complexidade do modelo e pune a entrada de novas variáveis. Neste caso, como há apenas dois preditores (intercepto e bsq_soma), o $R^2 ajustado$ e o $R^2$ são quase idênticos.  

![](./img/cap_reg_resultados3.png)

Finalmente, o <u>quarto momento</u> é análise dos preditores, que é feito na seção `Coefficients`. Para isso, deve-se identificar os preditores um a um, seus valores `Unstandardized` e de `P`. O `Unstandardized` indica a diferença média em unidades da <u>variável dependente</u> quando se altera uma unidade de X. Por exemplo, mais 1 ponto no BSQ-34, mais `0.178` pontos, em média, no EAT-26. Esse resultado é significativo, tal como é indicado na coluna `Sig`.  

O intercepto é chamado de `constante` na maior parte dos programas e indica o valor médio (esperado) de Y quando `X=0`. Nesse caso, se alguém tivesse tirado o valor `0` na escala BSQ-34, o valor previsto para os resultados da Escala EAT-26 seria de 1.46. No entanto, o `Sig` indica que esse valor não é significativo, ou seja, não é diferente de `0`. O indicador de beta padronizado `Standardized` traz as mesmas informações, mas trabalha em unidades de desvios-padrão em todas as variáveis presentes no modelo. Eventualmente, o `Standardized` pode ser entendido como uma medida perliminar de tamanho do efeito [@fox2016].

É importante notar que frequentemente o intercepto não tem interpretação lógica e, por isso, costuma ser desconsiderado. Para que ele tenha melhor capacidade de interpretação, algumas estratégias são possíveis, tal como centralizar os valores do preditor $(x_i-\bar{x})$. Caso isso seja feito, o intercepto irá ser o valor médio da variável dependente. 

![](./img/cap_reg_resultados4.png)

Em síntese, cada uma das etapas deve ser feita de maneira sequencial. A imagem a seguir apresenta um sumário com todos os passos expostos.

![](./img/cap_reg_resultados_juntos.png)

Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.  

Para verificar os pressupostos, será necessário utilizar as opções dispostas na parte inferior à esquerda do programa. 

A <mark>normalidade</mark> é testada ao clicar em `Plots` e `Q-Q plot standardized results`. O JASP irá apresentar um QQ plot com duas informações principais: uma diagonal e um conjunto de pontos/círculos. Caso os círculos estejam sobrepostos à linha, isso apoia que os resíduos se distrubem normalmente. No caso abaixo, isso não foi alcançado.

![](./img/cap_reg_normalidade.png)

Diferente do R, esta versão do JASP não permite testar formalmente a hipótese de normalidade residual. Dessa forma, será necessário contar apenas com a perceção do gráfica para checar se o pressuposto foi respeitado ou violado.  

A <mark>homocedasticidade</mark> é também verificada graficamente. Ao clicar no `Residuals vs. Predicted`, o plano irá apresentar os valores dos resíduos em Y e os valores previstos em X. Nesse gráfico, é importânte não detectar nenhum padrão nos elementos apresentados. A disposição do gráfico indica que este pressuposto foi alcançado.  

![](./img/cap_reg_homocedasticidade_jasp.png) 


A <mark>Independência</mark> dos resíduos é bastante dependente do tipo de delineamento utilizado. No entanto, o JASP permite que esse pressuposto seja formalmente testado pelo teste de Durbin Watson. Isso é feito ao clicar em `Statistics`, `Residuals` e `Durbin-Watson`

![](./img/cap_reg_independencia_jasp.png) 


Os resultados irão ser apresentados na parte superior do programa. Caso a hipótese nula não seja rejeitada, isso apoia que os resíduos são independentes. Nesse caso, o valor de p foi 0.242, indicando que isso ocorreu.  


![](./img/cap_reg_independencia2_jasp.png) 

Uma vez que nem todos os pressupostos foram atendidos, é possível proceder a algumas alterações na modelagem estatística ou, realizar a interpretação cautelosa dos resultados. Neste capítulo, a interpretação será feita.

## Escrita dos resultados


De uma forma geral, o principal achado do modelo de regressão é que a percepção da imagem corporal é um preditor significativo ao comportamento alimentar. Neste sentido, ao saber informações sobre como uma pessoa percebe o próprio corpo, pode-se estimar condições eventualmente disfuncionar de seu comportamento alimentar. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).



```{block, type="writing"}
**Como escrever os resultados**  

Um modelo de regressão foi calculado para verificar os resultados dos comportamentos alimentares (EAT-26) em função da percepção de imagem corporal (BSQ-34). Os resultados indicaram que cerca de 46% da variância do EAT-26 pode ser atribuída ao BSQ-34 (R2 = 0.456, F(1,218) = 182.88, p < 0.001). Cada ponto a mais no BSQ-34 impacta, em média, em 0.178 no EAT-26 (b = 0.178, p < 0.001). 

```  



## Resumo  

1. Existem diferentes modelos de regressão e eles sempre visam prever/explicar um resultado a partir de uma ou um conjunto de variáveis  
2. O tipo de modelagem depedente tanto da natureza e quantidade das VIs e VDs e é possível entender grande parte dos testes estatísticos estudados como casos particulares dos modelos de regressão   
3. Os principais indicadores de um modelo de regressão são sua significância geral, o $R^2$,o o $R^2_{adj}$, bem como o coeficiente e a significância dos preditores   
4. o diagnóstico é uma parte essencial desta modelagem e o mnemônico LINE pode ajudar na lembrança dos pressupostos   


## Pesquisas adicionais  

1. Influence of Age and Education on the Performance of Elderly in the Brazilian Version of the Montreal Cognitive Assessment Battery (DOI: 10.1159/000489774)
Nesta pesquisa, 110 participantes foram recrutados para que os pesquisadores pudessem produzir tabelas estatísticas para um novo exame neuropsicológico. Uma das análises feitas verificou o impacto dos anos de estudo no desempenho neste exame neuropsicológico, concluindo pelo seu efeito protetivo. 

<!--chapter:end:10-regressao_linear_simples.Rmd-->

# Regressão linear múltipla


```{r, include = FALSE }
load("~/anovabr/mqt/bases/Base R - imagem corporal.RData")

library(tidyverse)
library(knitr) #tables and graphs
library(kableExtra) #tables with different styles
library(olsrr) #regression diagnostics
library(gridExtra) #plot together
library(stargazer) #presenting results
```

Os modelos de regressão linear múltipla são desenvolvidos para predizer os valores médios de uma variável resposta (Y) em função de duas ou mais variáveis independentes (X). Estes modelos tendem a ampliar a acurácia obtida por uma regressão linear simples, apesar de também aumentarem a complexidade de sua realização e interpretação. Nestes modelos, a VD deve ser contínua e as VIs podem ser tanto contínuas como categóricas. Tecnicamente, a família da ANOVA vista anteriormente são casos particulares de modelos de regressão múltipla.


Conceitualmente, neste modelo, se adicionam outros preditores à equação vista no capítulo de regressão linear simples. Assim:

\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + ... + b_pX{_p}_i+ \epsilon_{i}\]

$y_i$ representa a variável dependente  
$b_0$ é o intercepto (coeficiente linear)   
$b_p$ indica a inclinação de cada um dos preditores      
$\epsilon_{i}$ é o erro/resíduo   


A interpretação dos resultados obtidos depende dos seguintes pressupostos:  
 
(i) A relação entre as variáveis é linear
(ii) Os resíduos são independentes  
(ii) Os resíduos são normalmente distribuídos (com média)    
(iii) A variância dos resíduos é constante  

O mnemônico <u>LINE</u> (linearity, independence, normality, equal variance) talvez ajude a lembrar destes pressupostos.



## Pesquisa  

<div class="alert alert-warning">
  <strong>Base: </strong> Livro - Dados - Eating disorders
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada ["Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students"](https://www.researchgate.net/publication/323729370_Aspects_Related_to_Body_Image_and_Eating_Behaviors_in_Healthy_Brazilian_Undergraduate_Students), publicada em 2018 no Global Journal of Educational Studies, que sou coautor.

O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e na percepção da imagem corporal. Os primeiros aspectos foram avaliados pela escala EAT-26, enquanto o segundo foi avaliado pela escala BSQ-34.  

Uma das principais hipóteses era possíveis alterações na percepção da imagem corporal, bem como o índice de massa corporal (IMC) poderiam ser  preditores no desenvolvimento de transtornos alimentares. Neste sentido, pessoas com uma distorção na percepção de imagem corporal (dadas por resultados altos do BSQ), além de alto IMC tenderiam a fazer uma restrição alimentar mais intensa (obtidas pelos valores do EAT) 

Da mesma forma que apresentado no capítulo de regressão linear simples, a definição estatística das hipóteses em modelos de regressão costumam ser feitas em cascata. Quase sempre, se compara o modelo de desenvolvido com um modelo mais simples. Em seguida, verifica-se cada preditor de forma individual e assim sucessivamente. Uma vez que a definição de cada hipótese ocuparia um espaço grande aqui, elas serão suprimidas.  


## Execução no R  

A primeira etapa da análise é realizada pelo desenvolvimento de tabelas e gráficos que possam auxiliar na interpretação dos resultados. De maneira similar à feita em outros capítulos, abaixo há uma tabela descritiva. 

```{r results="asis" }
arsenal::tableby(~eat_soma + bsq_soma + imc, dados_brasil) %>% summary() 
```



É também possível, inicialmente, implementar um modelo de correlação ou correlação parcial visando produzir maior suporte à regressão linear múltipla. O modelo de correlação estima a força e a direção da correlação bivariada e o modelo de correlação parcial é feita para estimar o quanto uma variável se correlaciona com outra após controlar essa relação por uma terceira variável. No entanto, ambas as análise apenas trariam suporte indireto à regressão linear múltipla e por isso não serão feitas.

Para criar o modelo de regressão linear múltipla no R, será necessário resgatar o modelo visto em regressão linear simples para introduzir nova variável à equação.   

Neste caso, o vetor `mod_linear_multiplo` será armazenado para verificar o efeito da <u>percepção de imagem corporal</u> e do <u>IMC</u> no <u>EAT-26</u>, que se refere ao comportamento alimentar. É importante notar que, por padrão, o R não usa linhas com dados ausentes e isso pode reduzir o poder do teste. Neste base, há 215 linhas completas.


```{r}
mod_linear_multiplo <- lm(eat_soma ~ bsq_soma + imc, data = dados_brasil)
```

A apresentação dos resultados pode ser feita pelo pacote `olsrr`. Ela segue o mesmo formato da realizada no capítulo específico de regressão linear simples, apenas com a diferença da inclusão de um novo preditor.

```{r }
ols_regress(mod_linear_multiplo)
```
  
Da mesma forma que exposto anteriormente, os resultados devem ser analisados aos poucos e de maneira cautelosa. 

<u>Inicialmente</u>, deve-se olhar a seçao `ANOVA` e verificar se o modelo testado é significativo ou não. Neste caso, é possível concluir que o modelo foi globalmente significativo (F(2, 212) = 99.976, p < 0.001).   

Em <u>segundo momento</u>, verifica-se o $R^2$, que indicou que carca de 48.5% da variabilidade dos resultados do EAT-26 podem ser atribuídos aos preditores do modelo (BSQ-34 e IMC).   

Em <u>terceiro momento</u>, o $R^2 ajustado$ deve ser interpretado Esse indicador pune a entrada de preditores e oferece uma métrica que protege o superajuste e que ajuda a comparar modelos com diferentes números de preditores, quando necessário. Neste caso, o valor foi muito similar ao obtido previamente, mantendo a conclusão feita anteriormente.

O <u>quarto momento</u> consiste na interpretação dos resultados de cada um dos preditores do modelo. Em relação ao BSQ-34, cada unidade a mais em seu resultado impacta, em média, 0.19 pontos a mais no EAT-26, controlando pelo IMC do participante (p < 0.001). Além disso, cada 1 unidade a mais no IMC do participante impacta em -0.447 (p < 0.001), em média, nos resultados do EAT-26, controlando pelos valores do BSQ-34. O intercepto não tem interpretação lógica, uma vez que valores 0 no IMC não existem.  

A ideia de estimar o efeito de uma variável controlando por outra faz com que esses coeficientes sejam chamados de <u>coeficientes parciais</u>. A forma pela qual isso é feito tem características particulares.   

Assumindo duas pessoas que <u>tem o mesmo IMC</u> (por exemplo, o IMC médio), cada ponto extra no BSQ gera, em média, 0.19 pontos a mais no EAT-26. A função `predict` do R permite essa demonstração.  

O valor estimado no <u>EAT-26</u> de Um participante que teve 45 pontos no <u>BSQ</u> e tem <u>IMC</u> de 23.2 (o IMC médio) é de 9.06. 

```{r}
imc_medio <- mean(dados_brasil$imc, na.rm=T)
predict(mod_linear_multiplo, data.frame(bsq_soma=c(45), imc=imc_medio))
```

Já o valor estimado no <u>EAT-26</u> de um outro participante com 46 pontos no <u>BSQ</u> (ou seja, 1 ponto a mais) e mesmo <u>IMC</u> do primeiro participante (23.2) é de 9.25. 

```{r}
predict(mod_linear_multiplo, data.frame(bsq_soma=c(46), imc=imc_medio))
```
A diferença entre esses dois valores é exatamente igual ao coeficiente calculado na regressão (b = 0.19). Abaixo há duas linhas de código apresentando esses resultados.

```{r}
round(predict(mod_linear_multiplo, data.frame(bsq_soma=c(46), imc=imc_medio)) - predict(mod_linear_multiplo, data.frame(bsq_soma=c(45), imc=imc_medio)),2)
```
Esse formato analítico é similar para o resultado do <u>IMC</u>. Caso duas pessoas tenham o mesmo resultado do <u>BSQ</u>, uma unidade a mais no IMC impactará em uma redução de 0.447, em média, no <u>EAT-26</u>. 

Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.

<mark> Normalidade</mark>: O pressuposto da Normalidade é atendido se os <u>resíduos</u> do modelo de regressão seguirem uma distribuição normal. Isso pode ser avaliado graficamente por QQ plots e também por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera.

O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis contra os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade.  Caso os pontos e a reta diagonal estejam superpostos, se considera que este pressuposto foi atendido


```{r}
ols_plot_resid_qq(mod_linear_multiplo)
```

Testes estatísticos formais também podem ser utilizados, tal como abaixo:  

```{r}
ols_test_normality(mod_linear_multiplo)
```

Tanto a visualização do QQ plot, como a maior parte dos testes estatísticos específicos convergiram, indicando que a normalidade foi violada. 

<mark>Homocedasticidade</mark>: Este pressuposto de variâncias constantes pode ser analisada em um gráfico de dispersão dos resíduos (residual) contra os valores previstos (fitted).  

```{r}
ols_plot_resid_fit(mod_linear_multiplo)
```

Caso haja padrões neste gráfico, isso sugere que este pressuposto foi violado. Pelo gráfico, parece não haver padrões específicos. No entanto, testes formais são recomendados para que a decisão tomada tenha maior apoio. Existem diferentes testes para isso e, entre eles, o teste de Bartlett, Levene e Breusch-Pagan. Os resultados dependem das propriedades de cada um dos modelos e, em função da praticidade computacional, o teste de Breusch-Pagan será utilizado. Em todos estes testes, a hipótese nula assume homocedasticidade. Portanto, a estatística de teste não deveria ser significativa para que a homocedasticidade fosse apoiada.


```{r}
ols_test_breusch_pagan(mod_linear_multiplo)
```
Os resultados indicaram que a homocedasticidade foi violada (assumingo alfa = 0.05). Isso vai em direção distinta à percepção gráfica, o que pode ocorrer sem nenhum problema.  

<mark>Independência</mark>: A independência dos resíduos depende bastante do delineamento utilizado ser transversal ou longitudinal. O teste de Durbin Watson pode ser utilizado e a hipótees nula é de que os resíduos não são correlacionados. Este pressuposto foi atendido, o que já era esperado.  

```{r}
car::durbinWatsonTest(mod_linear_multiplo)
```
<mark>Multicolinearidade</mark>: Diferente da regressão linear simples,  a regressão múltipla reúne diversas variáveis independentes. É possível que essas variáveis sejam muito correlacionadas entre si, impactando na interpretação dos resultados. Uma maneira de verificar isso é pela análise chamada Variance Inflaction Factor (VIF).   

Valores de VIF superiores a 4 indicam que as variáveis indepenentes são fortemente correlacionadas e suas estimativas podem ser distorcidas. Neste caso, isso não aconteceu.

```{r}
ols_coll_diag(mod_linear_multiplo)
```

Com isso realizado, os diagnósticos indicaram que a normalidade e a homocedasticidade foram violadas, novamente sugerindo uma interpretação cautelosa dos resultados. Abaixo uma orientação de como escrever os resultados.



## Execução no JASP

Para executar as rotinas necessárias, será necessário carregar a base de dados para o ambiente JASP. A base chama-se [csv eat bsq brasil](https://www.dropbox.com/s/l8xkxi5z5fntrd9/csv%20eat%20bsq%20brasil.csv?dl=0). Após fazer isso, para realizar tabelas e gráficos descritivos, deve-se clicar em `Descriptives`, na parte superior do programa.

![](./img/cap_correlacao_descritivo.png)

Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Neste caso, será necessário colocar o <u>bsq_soma</u>, <u>eat_soma</u> e o <u>imc</u> na seção `Variables`. Essa ordem ajuda em apresentações gráficas futuras.


![](./img/cap_reg_multipla_descriptives.png)

Apesar de não ser uma etapa fundamental, é possível gerar os gráficos de dispersão entre as variáveis para ter uma primeira análise do relacionamento entre elas. Para fazer isso, será necessário clicar em `Plots`.

![](./img/cap_reg_multipla_plots.png)

Muitas opções são possíveis, mas a `Scatter Plots` é a mais completa e é necessário clicar neste local. Ao fazer isso, o JASP irá apresentar três gráficos diferentes.

![](./img/cap_reg_multipla_plots2.png)

O JASP insere alguns Esses gráficos são úteis para verificar o perfil de relacionamento entre as variáveis, bem como algumas outras características. Seria possível, formalmente, calcular a correlação e a correlação parcial entre as variáveis. Apesar de alguma utilidade deste procedimento, isso acabaria repetindo algo do que foi demonstrado no capítulo sobre regressão e, por isso, não será refeito.

Para execução da regressão linear, será necessário clicar em `Regression` e `Linear Regression`. 

![](./img/cap_reg_multipla_interface.png)

A tela do JASP irá apresentar algumas opções. É importante notar que a `Covariates` é o local onde as VIs serão colocadas e `Dependent Variable` é onde a VD deverá ser inserida. Enquanto é possível inserir muitas variáveis independentes (fazendo um modelo múltiplo), apenas uma VD poderá ser inserida. O JASP apenas aceitará variáveis contínuas ou definidas como contínuas nos espaços apresentados.  

![](./img/cap_reg_interface.png)


Para realizar o modelo, será necessário levar a <u>bsq_soma</u> e <u>imc</u> para seção `Covariates` e a <u>eat_soma</u> para `Dependent variable`. Ao fazer isso, o JASP irá fazer todas as principais análises e apresentar os resultados em uma tabela específica, ao lado direito da tela. É fácil notar que os resultados apresentados são muitos e se recomenda uma ordem específica para interpretá-los.   


Em <u>primeiro momento</u>, é necessário verificar o ajuste do modelo na seção `ANOVA`, bem ao centro dos resultados. Este teste compara o modelo em questão contra um modelo em que apenas o intercepto é utilizado para prever todos os valores. No JASP, esses modelos são descritos por `H1` e `H0` nas principais tabelas. Tecnicamente, o modelo analisado é chamado de <u>irrestrito</u> (ou aumentado, `H1`) e o modelo que tem apenas o intercepto é chamado de <u>restrito</u> ou nulo, `H0`. Valores significativos são necessários nesta etapa. Nesta análise, o resultado foi F(2, 212) = 99.976, p < 0.0001, indicando que os outros resultados podem ser interpretados. Quando isso acontece, deve-se desconsiderar todas as linhas que o JASP apresentar resultados para o modelo nulo, simbolizado por`H0`, e apenas interpretar os resultados do modelo testado, que é apresentado sempre por `H1`. 

![](./img/cap_reg_multipla_resultado_1.png)


O <u>segundo momento</u> consiste na interpretação do $R^2$, que está localizado na parte superior, em `Model summary`. Como exposto no início do capítulo, essa indicador mensura a parte da variação da variável dependente (Y) que pode ser atribuída às variáveis independentes do modelo (X). Repare que ele é computado pela razão entre o SSR e o SST e indica que cerca de 48% dos resultados da variabilidade do EAT-26 podem ser explicados pelo modelo.  

![](./img/cap_reg_multipla_resultado_2.png)

O <u>terceiro momento</u> é a análise do $R^2 ajustado$, que também está localizado na parte superior, em `Model summary`. Em modelos de regressão, modelos com mais parâmetros/preditores sempre vão ter $R^2$ maior do que modelos mais compactos, independente da signficância destes outros parâmetros. O $R^2 ajustado$ é uma medida que considera a complexidade do modelo e pune a entrada de novas variáveis.  

![](./img/cap_reg_multipla_resultado_3.png)

Finalmente, o <u>quarto momento</u> é análise dos preditores, que é feito na seção `Coefficients`. Para isso, deve-se identificar os preditores um a um, seus valores `Unstandardized` e de `P`. O `Unstandardized` indica a diferença média em unidades da <u>variável dependente</u> quando se altera uma unidade de X. 



Por exemplo, mais 1 ponto no BSQ-34, mais `0.190` pontos, em média, no EAT-26, controlando pelos resultados do IMC. Esse resultado é significativo, tal como é indicado na coluna `Sig`.  

O intercepto é chamado de `constante` na maior parte dos programas e indica o valor médio (esperado) de Y quando `X=0`. Nesse caso, se alguém tivesse tirado o valor `0` na escala BSQ-34, o valor previsto para os resultados da Escala EAT-26 seria de 1.46. No entanto, o `Sig` indica que esse valor não é significativo, ou seja, não é diferente de `0`. O indicador de beta padronizado `Standardized` traz as mesmas informações, mas trabalha em unidades de desvios-padrão em todas as variáveis presentes no modelo. Eventualmente, o `Standardized` pode ser entendido como uma medida perliminar de tamanho do efeito [@fox2016].

É importante notar que frequentemente o intercepto não tem interpretação lógica e, por isso, costuma ser desconsiderado. Para que ele tenha melhor capacidade de interpretação, algumas estratégias são possíveis, tal como centralizar os valores do preditor $(x_i-\bar{x})$. Caso isso seja feito, o intercepto irá ser o valor médio da variável dependente. 


![](./img/cap_reg_multipla_resultado_4.png)

Em síntese, cada uma das etapas deve ser feita de maneira sequencial. A imagem a seguir apresenta um sumário com todos os passos expostos.

![](./img/cap_reg_multipla_resultado_5.png)

Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.  

Para verificar os pressupostos, será necessário utilizar as opções dispostas na parte inferior à esquerda do programa. 

A <mark>normalidade</mark> é testada ao clicar em `Plots` e `Q-Q plot standardized results`. O JASP irá apresentar um QQ plot com duas informações principais: uma diagonal e um conjunto de pontos/círculos. Caso os círculos estejam sobrepostos à linha, isso apoia que os resíduos se distrubem normalmente. No caso abaixo, isso não foi alcançado.  

![](./img/cap_reg_multipla_normalidade.png)
Diferente do R, esta versão do JASP não permite testar formalmente a hipótese de normalidade residual. Dessa forma, será necessário contar apenas com a perceção do gráfica para checar se o pressuposto foi respeitado ou violado.  

A <mark>homocedasticidade</mark> é também verificada graficamente. Ao clicar no `Residuals vs. Predicted`, o plano irá apresentar os valores dos resíduos em Y e os valores previstos em X. Nesse gráfico, é importânte não detectar nenhum padrão nos elementos apresentados. Os resultados parecem indicar uma violação deste pressuposto foi alcançado.  

![](./img/cap_reg_multipla_homocedasticidade.png)

A <mark>Independência</mark> dos resíduos é bastante dependente do tipo de delineamento utilizado. No entanto, o JASP permite que esse pressuposto seja formalmente testado pelo teste de Durbin Watson. Isso é feito ao clicar em `Statistics`, `Residuals` e `Durbin-Watson`

![](./img/cap_reg_multipla_ind_residuos.png) 


Os resultados irão ser apresentados na parte superior do programa. Caso a hipótese nula não seja rejeitada, isso apoia que os resíduos são independentes. Nesse caso, o valor de p foi 0.769, indicando que isso ocorreu.  

![](./img/cap_reg_multipla_ind_residuos2.png) 

A <mark>Multicolinearidade</mark> é uma condição que, diferente da regressão linear simples, deve ser testada na regressão múltipla. Isso ocorre pois este tipo de modelo estatístico reúne diversas variáveis independentes e é possível que elas sejam muito correlacionadas entre si. Uma maneira de testar essa condição é pela análise chamada Variance Inflaction Factor (VIF).   

No JASP, será necessário clicar, dentro da seção `Statistics`, a opção `Colinearity diagnosis`.

![](./img/cap_reg_multipla_colinearidade_jasp.png) 

O JASP irá fazer os cálculo e irá apresentar os resultados na seção `Coefficients`, nas últimas colunas ao lado direito da tabela. Cada um dos coeficientes apresentará um valor e o ideal é que o VIF seja inferior a 4. Valores acima disso indicam que as variáveis independentes são fortemente correlacionadas e suas estimativas podem ser distorcidas. Neste caso, isso não aconteceu. 

![](./img/cap_reg_multipla_colinearidade2_jasp.png)


Com isso realizado, os diagnósticos indicaram que a normalidade e a homocedasticidade foram violadas, novamente sugerindo uma interpretação cautelosa dos resultados. 


## Escrita dos resultados  

De uma forma geral, o principal achado do modelo de regressão é que a percepção da imagem corporal e o IMC são preditores significativos ao comportamento alimentar. Possíveis superestimativas da imagem do próprio corpo impactam em alterações no comportamento alimentar. Quanto maior a distorção na percepção corporal, mais intensos e frequentes são algumas características disfuncionais do comportamento alimentar. Além disso, pessoas com maior IMC tendem a apresentar uma redução no comportamento alimentar. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).

```{block, type="writing"}
**Como escrever os resultados**  

Um modelo de regressão múltipla foi calculado para verificar os resultados dos comportamentos alimentares (EAT-26) em função da percepção de imagem corporal (BSQ-34) e do peso do participante. Os resultados indicaram que cerca de 48% da variância do EAT-26 pode ser atribuída aos preditores (R2 = 0.486, F(2,213) = 100.675, p < 0.001). Cada ponto a mais no BSQ-34 impacta, em média, em 0.180 no EAT-26 (p < 0.001), controlando pelo peso do participante. 

```  


## Técnicas automáticas de seleção de variáveis  

Entre os principais debates realizados na construção de modelos estatísticos, os critérios sobre quantas, quais e como eleger as variáveis independentes é um dos mais intensos.   

Neste sentido, a seleção das VIs visa otimizar a acurácia do modelo, mas sem perder sua parcimônia, ou seja, simplicidade [@Unger1973; @Gaudio2001]. É possível inserir as variáveis por uma justificativa teórica alinhada com a área principal em que o pesquisador se insere, como também é possível implementar seleção automática a partir de algorítimos específicos. 

Apesar do detalhamento das técnicas automáticas estar fora do escopo dete capítulo, a seguir são listadas algumas delas:  

1. Backward selection  
2. Forward selection  
3. Stepwise selecion  
4. Lasso selection  


## Resumo  
::: {.explore}
1. O termo regressão múltipla se refere a um modelo de regressão com duas ou mais variáveis independentes   
2. As VIs podem ser de qualquer natureza, o que significa que toda família da ANOVA pode ser entendida como casos particulares de regressão
3. As estimativas geradas pela regressão múltipla para uma variável são controlam por todas as variáveis do modelo   
4. Os diagnósticos são os mesmos dos modelos simples, mas agora é necessário também testar a multicolinearidade do modelo  
5. Existem diferentes métodos para adicionar preditores e maneiras manuais e automáticas são disponíveis    
::: 

## Pesquisas adicionais  

1. Influence of Age and Education on the Performance of Elderly in the Brazilian Version of the Montreal Cognitive Assessment Battery (DOI: 10.1159/000489774)
Nesta pesquisa, 110 participantes foram recrutados para que os pesquisadores pudessem produzir tabelas estatísticas para um novo exame neuropsicológico. Uma das análises feitas verificou o impacto dos anos de estudo no desempenho neste exame neuropsicológico, concluindo pelo seu efeito protetivo.   


## Questões  

<div class="question">

1. (ENADE, Economia - 2019) Com o objetivo de entender o impacto das internações causadas pela falta de saneamento básico, um pesquisador estimou o modelo apresentado na tabela a seguir, usando a quantidade de dias de internação de uma amostra de 7 260 pacientes do Sistema Único de Saúde como variável explicada. As variáveis explicativas são: (i) gênero do paciente, binária em que é 1 é utilizado para identificar as mulheres e 0 para identificar os homens; (ii) idade do paciente em anos de vida; e (iii) motivo da internação, também binária, em que recebe o valor 1 para identificar internações que são causadas por problemas de saneamento básico e o valor 0 para as demais internações<br>![](./img/exercicio_regressao.png)<br>a) O coeficiente R-quadrado encontra-se abaixo de 30%, o que significa que o modelo deve ser descartado.<br>b) As internações causadas pela deficiência de saneamento básico tendem a gerar um aumento de 1,96% nos gastos de saúde.<br>c) A média de dias de internação para mulheres é estatisticamente maior que a de internação para homens.<br> d) A variável idade não é estatisticamente significativa para explicar o número de dias de internação.<br> e) O teste F mostra que as variáveis explicativas conjuntamente são estatisticamente significativas para explicar o número de dias de internação.   
</div>   
<div class="mirror">&#9986; Gabarito: 1e</div>    




<!--chapter:end:11-regressao_linear_multipla.Rmd-->

# Regressão logística binária


```{r, include = FALSE }
load("~/anovabr/mqt/bases/Base R - Headache anonymous.RData")
library(tidyverse)
library(pander)
```




```{block, type="writing"}
**GLOSSÁRIO**

**Modelo Linear Generalizado**: Classe de modelos compostos por uma função de ligação, preditores lineares e uma distribuição de probabilidades. São ampliações de modelos lineares.    
**Função de ligação**: Termo que associa os valores esperados da resposta aos preditores lineares no modelo.  
**Logit**: Uma função de ligação que transforma probabilidades em chances.    
**Risco**: Probabilidade ou proporção.    
**Chance ou Odds**: Caso particular de uma razão em que o numerador não está contido no denominador. Tradução para Odds.  
**Razão de Chances ou Odds Ratio**: Medida de tamanho de efeito que indica a chance de ocorrência de um desfecho em um grupo quando comparado a outro. Seus valores variam entre 0 e infinito.  


```


A regressão logística é um modelo estatístico que permite estimar a chance da ocorrência de um determinado desfecho categórico (Y) em função de um ou mais preditores (X), que podem ser contínuos ou categóricos. Quando a variável dependente apresenta apenas dois níveis ou classes, a regressão é chamada de binária. Quando há mais níveis ou classes, é chamada de multinomial. 

Assim, é possível entender a regressão logística como um complemento da regressão linear aplicada a variáveis categóricas a partir de uma função de ligação ou, de maneira geral, um caso particular da famiília dos modelos lineares generalizados (GLM), que implementa uma ligação logit. 

Conceitualmente, neste modelo há os seguintes termos:

\[\underbrace{ln\left ( \frac{P}{1-P} \right)}_\text{logit} = b_0+b_1X_1+ \dots + b_iX_i\]

Onde:   
$P$ representa a probabilidade de um desfecho ocorrer     
$1-P$ representa a probabilidade de um desfecho não ocorrer  
$ln\left ( \frac{P}{1-P} \right)$ representa uma transformação logit variável dependente  
$b_0$ é o intercepto    
$b_i$ indica os preditores 

Os seguintes pressupostos devem ser investigados:  

*(i)* Os dados são aleatórios e representativos da população  
*(ii)* A variável dependente é dicotômica/binária   
*(iii)* Os preditores não apresentam alta correlação  
*(iv)* Há uma relação linear entre preditores contínuos e o logit do desfecho 


Há muitas aplicações de modelos logísticos. Em áreas de saúde, eles tendem a ser os modelos de primeira escolha para verificar possíveis condições clínicas e de agravo à saúde. Em Psicologia, por exemplo, ele é util para descrever e investigar os possíveis preditores de condições diagnósticas bem definidas, tal como TDAH e outros transtornos psiquiátricos. Em epidemiologia, eles são fundamentais em estudos do tipo caso-controle. 

Algumas condições são importantes:   
(1) A variável dependente nesta equação é um transformação logit da probabilidade da presença de um determinado desfecho. Ela não é, por definição, uma probabilidade, mas sim uma função.   
(2) Não há a definção de um termo de erro (tal como nos modelos de regressão linear) e   
(3) o desfecho é assumido seguir uma distribuição binomial. 

Como exposto, os resultados da regressão logística informam sobre <u>chances</u> (*Odds*) e <u>Razão de chances</u> (*Odds Ratio*) e não sobre probabilidades, diretamente. Existem muitas formas de demonstrar esta diferença. Entretanto, julgo que a forma mais simples é ilustrá-la matematicamente. 

Uma probabilidade é uma razão entre uma parte contra o todo (*Tudo o que tenho sobre tudo o que posso quero*, em jargão pedagógico). A chance é uma razão em que o numerador é uma probabilidade e o denominador é seu complemento. A figura a seguir ilustra essa diferença.   
![](./img/cap_reg_log_odds.png)

É legítimo ter dificuldade na interpretação do conceito, além de questionar o motivo pelo qual ele é tão utilizado nestas áreas. No entanto, uma ajuda interpretativa é lembrar que a probabilidade, maior também serão as chances de um determinado evento. A relação entre ambos tem o seguinte formato. 


```{r, echo = FALSE }
cbind(seq(0,1, by = 0.05), seq(0,1, by = 0.05)/(1-seq(0,1, by = 0.05))) %>% 
  data.frame() %>% 
  ggplot(., aes(x = X1, y = X2, group = 1)) +
  xlim(0,1) + ylim(0,25) +
  geom_line(size = 1.5) +
  labs(x = "Probabilidade", y = "Chance (Odds)") +
  geom_hline(yintercept = 1) + geom_vline(xintercept = 0.5) +
  theme_bw()
```

A métrica Razão de chances (Odds Ratio ou OR) é utilizada como uma medida de tamanho de efeito que se dá pela comparação entre dois grupos. 

Como em áreas de saúde, tradicionalmente, o interesse é verificar situações clínicas, quanto maior for o OR, maior será a chance da ocorrência de um desfecho negativo em um determinado grupo em comparação à outra e, consequentemente, maior o risco. 

Neste sentido:

Chance | Probabilidade| Interpretação
:-----|:------------ | :---
< 1    |< 50% | Fator de risco
= 1    | 50% | Fator neutro  
> 1    | > 50% | Fator de proteção  



## Pesquisa  

<div class="base">
  A base desta pesquisa está disponível em formato **R (Rdata)** e em **CSV**, que é lido pelo JASP. Clique na opção desejada.     
      
  <strong>R Base: </strong> [Base R - Headache anonymous](https://github.com/anovabr/mqt/raw/master/bases/Base%20R%20-%20Headache%20anonymous.RData)   
  <strong>Base JASP : </strong> [Base CSV - headache (no names)](https://github.com/anovabr/mqt/raw/master/bases/bases_csv_jasp.zip)
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada ["Resilience and vulnerability in adolescents with primary headaches: a cross-sectional population-based study"](https://www.researchgate.net/publication/323729370_Aspects_Related_to_Body_Image_and_Eating_Behaviors_in_Healthy_Brazilian_Undergraduate_Students), publicada em 2021 no Headache, que sou coautor.

Essa é uma pesquisa censitária, que contou com todos os 339 estudantes de uma cidade pequena no interior do Brasil. O estudo visou mapear as possíveis condições de baixos recursos psicológicos e alta vulnerabilidade em adolescentes portadores de enxaqueca de diferentes tipos e intensidades. Na literatura médica internacional, são raros os estudos com finalidade epidemiológica descritiva sobre enxaqueca. No Brasil, por sua vez, este nosso estudo foi o primeiro. Esse fato marcou o caráter inovador da pesquisa e também permitiu impactar positivamente o trabalho de clínicos que, em seu dia a dia, lidam com jovens com tais características.        

Para definir o tipo e a frequência da dor de cabeça, os participantes responderam a diferentes questionários médicos. Por sua vez, para verificar um possível risco de participantes enxaquecocos apresentarem baixos recursos psicológicos e alta vulnerabilidade, eles foram submetidos à escala *Resiliency Scales for Children and Adolescents*, que foi desenvolvida justamente para medir tais condições.

Uma dos objetivos que tivemos na execução das análises foi verificar quais eram os preditores significativos que poderiam impactar na probabilidade de um adolescente estar no grupo de risco de vulnerabilidade psicológica. Os preditores de interesse foram a idade da criança (age), sua etnia (race), sexo (sex), classe sócioeconômica (ses), problemas de sono (sleeping), prematuridade (premature), fumo durante a gestão (smoking), uso de álcool durante a gestação (alcohol) e possível TDAH (sdq_risk).


Para isso, modelos de regressão logística binária foram utilizados.  



## Execução no R  

A primeira etapa da análise é realizada pelo desenvolvimento de tabelas e gráficos que possam auxiliar na interpretação dos resultados. De maneira similar à feita em outros capítulos, abaixo há uma tabela descritiva. 


```{r results="asis" }
arsenal::tableby(risk_cefaleia_resources ~ 
                   age + race +  sex + ses + sleeping + premature + smoking + alcohol + sdq_risk, 
                 base_uso) %>% summary() 
```

Essa tabela oferece uma primeira informação sobre os dados e poderia ser utilizada também para computar vários testes Qui-quadrado. Entretanto, o qui-quadrado serviria para verificar relacionamentos bivariados, mas não controlaria os resultados pelas outras variáveis de interesse. Apesar de ser possível fazer alguns ajustes particulares ou utilizar o teste de Cochran–Mantel–Haenszel, a regressão logística é a modelagem mais adaptada para lidar com esta situação.

Para executar esse tipo de regressão no R, será necessário usar a função nativa `glm` e deixar claro que a família é a `binomial`. Isso indicará que o desfecho é binário e que a função logit deverá ser implementada na equação. 

O vetor `mod_risco` será criado e reunirá os resultados do modelo de regressão logística. 

```{r}
mod_risco <- glm(risk_cefaleia_resources ~
                       age + race +  sex + ses + sleeping + premature + smoking + alcohol + sdq_risk, 
                    family = "binomial", data = base_uso)
```

Há muitas formas de apresentar os resultados e o pacote `sjPlot` tem ótimas funções para isso. A tabela produzida gera o Odds Ratio de cada preditor, seu intervalo de confiança, a estatística de teste e o valor de P. Ao fim  da tabela, a quantidade de observações utilizada e uma medida de ajuste ($R^2$) é apresentada.   


```{r}
sjPlot::tab_model(mod_risco,show.stat = TRUE, 
          digits = 2)
```

Essa apresentação não verifica se o modelo testado é mais informativo do que um modelo nulo, mas apenas assume esta condição. Testá-la é particularmente importante em modelos com menos variáveis e isso pode ser feito pela função nativa `Summary`.


```{r, eval = FALSE }
#deviance do modelo nulo
base_uso %>% 
  filter(across(c(age,race,sex,ses,sleeping,premature,smoking,alcohol,sdq_risk), ~!is.na(.x))) %>% 
  glm(risk_cefaleia_resources ~ 1, family = "binomial", data = .) %>% summary()

#deviance do modelo testado
mod_risco %>% summary()
```


Nesta tabela, a primeira interpretação a ser feita é relacionada ao $R^2$, que está localizado na parte inferior. Existem diferentes maneiras de calculá-lo e sua interpretação não é igual à feita na regressão linear. Enquanto na regressão linear, o $R^2$ se refere à proporção da variância explicada, em modelos logísticos, no geral, o $R^2$ indica o quanto o modelo testado é próximo de um modelo com ajuste perfeito aos dados (saturado) [@portugues2020]. 

O $R^2 \, de \, Tjur$ é a medida utilizada nesta apresentação e seus valores variam entre 0 e 1. Ele é feito verificando a diferença entre os dados e os valores previstos pelo modelo testado. Quão maior o valor, mais discriminativo é o modelo testado. Neste caso, o o $R^2 \, de \, Tjur$ foi de 0.10.

A segunda interpretação é baseada nos Odds Ratio (OR) e sugere alguma com atenção: o OR indica a <u>chance</u> de ocorrência de um desfecho caso o preditor analisado tenha ocorrido, em comparação com sua não ocorrência. Ele não indica diretamente sobre a probabilidade, apesar disso ser possível de ser feito. 

Os preditores <u>sex[female]</u> e <u>sqd_risk</u> foram significativos. A interpretação pode ser feita da seguinte maneira:

* A chance do participante vir a apresentar baixo recurso psicológico é 3.07 maior em meninas do que em meninos. 
* A chance do participante vir a apresentar baixo recursos psicológico é 7.53 maior em participantes com TDAH do que em participantes sem TDAH..  


Eventualmente, variáveis contínuas também podem ser significativas. Caso a variável <u>age</u> tivesse sido significativa, sua interpretação poderia ser:  

* O aumento de 1 ano de idade impacta a chance de vir a apresentar baixos recursos psicológicos em 0.82, indicando uma característica protetiva. 


A apresentação desses resultados é muito beneficada por gráficos e o *Forest plot* pode ser utilizado. Neste gráfico, o eixo horizontal apresenta os valores possíveis de OR ($0-\infty$) e o eixo vertical todos os preditores analisados. A interpretação é feita em contraste ao valor 1, que está ao centro e indica que os resultados não são distintos entre os grupos ou níveis da variáveis. Valores de OR acima de 1 se situam à direita e indicam um possível fator de risco. Valores de OR abaixo de 1 se situam à esquerda e indicam um possível fator protetivo. 


```{r}
sjPlot::plot_model(mod_risco,
            grid = FALSE, 
            show.values = TRUE, value.offset = .3, 
            colors = "bw",
            vline.color = "darkgray") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme_bw() +
  theme(legend.position = "top")
```

Caso haja interesse, é também possível computar as probabilidades e adicioná-las à tabela aplicando $Odds/(1+Odds)$. Ao fazer isso, uma nova informação será apresentada e poderá ter alguma utilidade para interpretar preditores variáveis categóricas. Tradicionalmente, isso não é feito. 

::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::


Um aspecto importante é que a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.

<mark>Multicolinearidade</mark>. A multicolinearidade pode ser investigada pela análise chamada Variance Inflaction Factor (VIF). Essa análise verifica o quão correlacionados são os preditores e gera um resultado numérico. Valores abaixo de 4 são tipicamente utilizados para indicar que os preditores <u>não</u> são fortemente correlacioandos e, consequentemente, considerar este pressuposto atendido.


```{r}
car::vif(mod_risco) %>% pander()
```

<mark>Relação linear entre preditores contínuos e o logit</mark>. O pacote `sjplot` também pode ser utilizado para testar este pressuposto. Não há um teste formal específico para este pressuposto e, com isso, a decisão é baseada na visualização do relacionamento.  

```{r}
sjPlot::plot_model(mod_risco, type = "pred", terms =  "age")
```


O gráfico não sugere desvio da linearidade. Com isso, esse pressuposto é considerado mantido.

Após essas análises, é possível interpretar os resultados.  


## Execução no JASP

Inicialmente, é necessário carregar a base intitulada "Base CSV - headache (no names)" para o ambiente JASP. Essa base apresenta as variáveis que foram pesquisadas, bem como um conjunto de variáveis auxiliares que serviram para responder a outras perguntas.

Inicialmente, a apresentação de tabelas e gráficos é sempre muito importante e pode ser feito ao clicar na opção `Descriptives`.

![](./img/cap_logistica_base.png)

Ao clicar nesta opção, a interface do JASP ser próxima à exposta a seguir. É possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. 


![](./img/cap_logistica_descriptives.png)


Neste caso, o interesse é agrupar os resultados pelo risco do participante apresentar baixo recurso. Neste sentido, a variável <u>risk_cefaleia_resources</u> deve ser inserido na parte `Split` e as variáveis <u>age</u>, <u>race</u>, <u>sex</u>, <u>ses</u>, <u>sleeping</u>, <u>premature</u>, <u>smoking</u>, <u>alcohol</u> e <u>sdq_risk</u> deverão ser inseridas em `Variables`. 

Para a apresentação ficar adequada à escala de medida, é necessário marcar a opção `Frequency tables (nominal and ordinal variables)`.


![](./img/cap_logistica_descriptives2.png)


A tabela apresentada será bastante informativa e pode ser utilizada também para uma apreensão inicial dos dados. Variáveis contínuas serão resumidas por suas médias e desvios-padrão e variáveis categórias serão apresentadas por contagens e proporções.   

Gráficos tendem a ser úteis também para verificar o formato da distribuição dos dados. o JASP permite realizá-los clicando em `Plots`.

![](./img/cap_logistica_plots.png)

Como há variáveis contínuas (<u>age</u>) e variáveis categóricas (<u>sex</u>, etc) o ideal é apresentar tanto boxplots como gráficos de barras. Ao clicar na opção `Boxplot` e `Distribution plots`, o JASP irá realizar todos os gráficos e apresentar ao lado direito.   

![](./img/cap_logistica_plots2.png)

A análise conjunta da tabela previamente realizada e os gráficos pode ser feitas. Apesar deste procedimento inicial não ser uma etapa fundamental, ele tem sua aplicação em aspectos descritivos da estatística. Com isto feito, é possível fazer a regressão logística.  

Para execução da regressão logística, será necessário clicar em `Regression` e `Logistic Regression`. 

![](./img/cap_logistica_regression.png)

A tela do JASP irá apresentar algumas opções. O local `Dependent variables` é onde a VD será inserida. Repare que o JASP somente permitirá variáveis nominas ou ordinais neste espaço. `Covariates` é o local onde as VIs contínuas serão colocadas e `Factors` é onde as VIs categóricas serão colocadas.   

![](./img/cap_logistica_interface.png)


Para realizar o modelo, será necessário levar a <u>risk_cefaleia_resources</u> para `Dependent Variable`. Em seguida, <u>age</u> para seção `Covariates` e <u>race</u>, <u>sex</u>, <u>ses</u>, <u>sleeping</u>, <u>premature</u>, <u>smoking</u>, <u>alcohol</u> e <u>sdq_risk</u> para `Factors`. Ao fazer isso, o JASP irá fazer as principais análises e apresentar os resultados em uma tabela específica, ao lado direito da tela.


![](./img/cap_logistica_resultado_0.png)


É fácil notar que os resultados apresentados são muitos. É recomendado uma ordem específica para interpretá-los.   


Em <u>primeiro momento</u>, é importante verificar o ajuste do modelo na seção `Model summary`, na parte superior dos resultados. O JASP compara o modelo ajustado `H1` contra um modelo nulo `H0` em uma métrica de desvio (*Deviance*) e pelos critérios de informação de Akaike (AIC) e Bayesiano (BIC). De maneira similar à regressão linear, `H0` indica o modelo mais simples possível (sem preditores) e `H1` indica o modelo com os preditores que estão sendo testados. Valores de p são usados como critérios de decisão. Os critérios AIC e BIC são medidas de comparação entre modelos que visam balencear a acurácia do modelo e sua parcimônia. O melhor modelo tende a ser o que apresenta o menor valor. 

A síntese desses resultados indica que o modelo testado é mais informativo que o modelo nulo, uma vez que o valor de p foi de 0.008 e o AIC do modelo testado foi inferior, apesar do BIC ter sido superior.     

![](./img/cap_logistica_resultado_1.png)



O <u>segundo momento</u> consiste na interpretação de uma métrica análoga ao $R^2$ em modelos de regressão. Na seção `Model summary`, o JASP apresenta algumas opções de uso. Existem debates na literatura sobre qual resultado é o mais indicado e, cada vez mais, o $R^2 \, de \, Tjur$ tem sido escolhido. Essa é uma métrica entre 0 e 1 que é computada verificando as diferenças médias dos resultados obtidos pelo modelos nulo e pelo modelo testado. Independentemente do $R^2$ escolhido, é importante ter claro que os valores do $R^2 {Cox\,\& \,Snell}$ não estão contido no intervalo 0-1, o que gera dificuldade em sua interpretação. No modelo testado, o $R^2 \, de \, Tjur$ foi de 0.101

![](./img/cap_logistica_resultado_2.png)

O <u>terceiro momento</u> é a análise das estimativas obtidas em cada um dos preditores, que aparece na seção `Coefficients`. No entanto, os valores que o JASP apresentam são o log(odds) dos resultados, cuja interpretação é pouco intuitiva. Antes de interpretar, é necessário adicionar o Odds Ratio à tabela. Para fazer isso, ao lado esquerdo da interface, é necessário clicar em `Statistics` e, em seguida `Odds Ratio`.

![](./img/cap_logistica_resultado_3.png)

O Odds Ratio será adicionado à tabela. Agora, cada um dos preditores poderá ser analisado individualmente, com interpretação levando em consideração o Odds Ratio e os valores de P.

![](./img/cap_logistica_resultado_4.png)


A interpretação do Odds Ratio (OR) precisa ser feita com atenção: ele indica a <u>chance</u> de ocorrência de um desfecho caso o preditor analisado tenha ocorrido, em comparação com sua não ocorrência. Eles não indicam diretamente sobre a probabilidade, apesar disso ser possível de ser feito. 

Os preditores <u>sex[1 - Mulheres]</u> e <u>sqd_risk</u> foram significativos. A interpretação pode ser feita da seguinte maneira:

* A chance do participante vir a apresentar baixo recurso psicológico é 3.07 maior em meninas do que em meninos. 
* A chance do participante vir a apresentar baixo recursos psicológico é 7.53 maior em participantes com TDAH do que em participantes sem TDAH..  


Eventualmente, variáveis contínuas também podem ser significativas. Caso a variável <u>age</u> tivesse sido significativa, sua interpretação poderia ser:  

* O aumento de 1 ano de idade impacta a chance de vir a apresentar baixos recursos psicológicos em 0.82, indicando uma característica protetiva. 


::: {.warning}
**Atenção**: A validade das inferências dos resultados depende da adequação ou não dos pressupostos dos testes estatísticos. A avaliação destas condições é parte de um procedimento diagnóstico que deve ser sempre feito.  
:::


Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.  


## Escrita dos resultados


De uma forma geral, o principal achado do modelo de regressão é que a percepção da imagem corporal é um preditor significativo ao comportamento alimentar. Neste sentido, ao saber informações sobre como uma pessoa percebe o próprio corpo, pode-se estimar condições eventualmente disfuncionar de seu comportamento alimentar. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).



```{block, type="writing"}
**Como escrever os resultados**  

Um modelo de regressão foi calculado para verificar os resultados dos comportamentos alimentares (EAT-26) em função da percepção de imagem corporal (BSQ-34). Os resultados indicaram que cerca de 46% da variância do EAT-26 pode ser atribuída ao BSQ-34 (R2 = 0.456, F(1,218) = 182.88, p < 0.001). Cada ponto a mais no BSQ-34 impacta, em média, em 0.178 no EAT-26 (b = 0.178, p < 0.001). 

```  


## Regressão logística e Qui-quadrado

Em uma regressão logística binária em que há apenas um preditor categórico com dois grupos, a analise é baseada em tabelas de contingência. A tabela a seguir apresenta a relação entre o sexo do participante e ele(a) estar incluído ou não na categoria de baixos recursos psicológicos.


```{r}
library(janitor)
base_uso %>%
  tabyl(sex, risk_cefaleia_resources) %>%
  adorn_totals(c("row", "col")) %>%
  adorn_percentages("row") %>% 
  adorn_pct_formatting(rounding = "half up", digits = 0) %>%
  adorn_ns() %>%
  pander()
```

```{r}
(19/162)/(8/150)
```


Caso o Qui-quadrado de independência fosse calculado, seu valor de P indicara que os grupos não são associados, com estatística de teste = 2.697 e valor de P = 0.206.

```{r}
base_uso %>% 
  mutate(risk = if_else(risk_cefaleia_resources == "0",0,1)) %>% 
  {chisq.test(.$sex, .$risk)}
```

```{r}
base_uso %>% 
  mutate(risk = if_else(risk_cefaleia_resources == "0",0,1)) %>% #nuneric for poisson 
  glm(risk ~ sex, family = poisson, data = .) %>% 
  car::Anova(., test.statistic="Wald", type = 2)
```



```{r }
glm(risk_cefaleia_resources ~ sex, family = binomial, data = base_uso) %>% 
  car::Anova(., test = "Wald")
```

```{r}
base_uso %>% 
janitor::tabyl(sex, risk_cefaleia_resources) %>% janitor::adorn_totals(where = c("row","col"))
(exp(-2.9311937)*exp(0.7880364))/(1+(exp(-2.9311937)*exp(0.7880364)))

0.05333333*2.19907406/(1+0.05333333*2.19907406)
```
```{r}
#odds to probability
#predict(mod_1, newdata=data.frame(sex="Female"), type="response")
```


```{r}
(19*150)/(162*8)#odds of females have risk (compared to males)
19/181 #proportion of females with risk
8/158 #proportion of males with risk
```



## Resumo  
::: {.explore}
1. O termo regressão múltipla se refere a um modelo de regressão com duas ou mais variáveis independentes   
2. As VIs podem ser de qualquer natureza, o que significa que toda família da ANOVA pode ser entendida como casos particulares de regressão
3. As estimativas geradas pela regressão múltipla para uma variável são controlam por todas as variáveis do modelo   
4. Os diagnósticos são os mesmos dos modelos simples, mas agora é necessário também testar a multicolinearidade do modelo  
5. Existem diferentes métodos para adicionar preditores e maneiras manuais e automáticas são disponíveis    
::: 

## Pesquisas adicionais  

1. Influence of Age and Education on the Performance of Elderly in the Brazilian Version of the Montreal Cognitive Assessment Battery (DOI: 10.1159/000489774)
Nesta pesquisa, 110 participantes foram recrutados para que os pesquisadores pudessem produzir tabelas estatísticas para um novo exame neuropsicológico. Uma das análises feitas verificou o impacto dos anos de estudo no desempenho neste exame neuropsicológico, concluindo pelo seu efeito protetivo.   


## Questões  

<div class="question">

1. (Retirado de Andy Field - Dicovering statistics) A regressão logística assume entre seus pressupostos<br>a) Relacionmento linear entre os preditores contínuos e a variável resposta.<br>b) Relacionmento linear entre os preditores contínuos e o logit da variável resposta.<br>c) Relacionamento linear entre os preditores contínuos.<br>d) Relacionamento linear entre todas as observações. <br>e) Todas as opções são incorretas.



 
</div>
<div class="mirror">Gabarito: 1-b;</div>

<!--chapter:end:12-regressao_logistica_binaria.Rmd-->

