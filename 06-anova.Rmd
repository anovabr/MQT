---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# ANOVA


```{r, include = FALSE }
load("~/anovabr/mqt/bases/Livro - R - TEG.RData")
library(tidyverse)
library(emmeans) #posthoc
library(knitr) #tables and graphs
library(kableExtra) #tables with different styles
```

```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar a ANOVA  
2. Discutir os pressupostos de execução da ANOVA  
3. Realizar gráficos relacionados à comparação de médias  
4. Apresentar e interpretar métricas de tamanho do efeito  
5. Dar exemplos relacionados à escrita dos resultados  
6. Discutir os testes post-hoc  
7. Apresentar o teste Kruskal-Wallis    
```


A ANOVA é um teste estatístico desenvolvimento para verificar <u>diferenças médias entre diversos grupos</u>. Pragmaticamente, é possível entender ANOVA como um super Teste T ou também um caso particular de um modelo de regressão. Assim, de maneira similar ao Teste T, a ANOVA e todas as suas extensões (e.g., ANCOVA e MANOVA) são casos especiais de um modelo de regressão que lidam com variáveis independentes categóricas.   

Alguns autores indicam que a ANOVA é a técnica inferencial mais utilizada em Psicologia [@Chartier2008; @Howell2011]. Se por um aspecto, isso é extremamente vantajoso uma vez que estreita a relação entre Psicologia e Estatística, por outro, isso parece ter contribuído para criação e manutenção de diferentes conceitos equivocados sobre a ANOVA. 

Conceitualmente, a ANOVA é um modelo linear, tal que:

\[y_i = b_0 + b_1X{_1}_i + \epsilon_{i}\]

$y_i$ representa a variável dependente      
$b_0$ é o intercepto (coeficiente linear)   
$b_1$ é a inclinação (coeficiente angular)  
$X_1$ é a variável independente em questão  
$\epsilon_{i}$ é o erro/resíduo   

Os seguintes pressupostos dos modelos linares são mantidos, que são:

*(i)* a variável dependente é contínua  
*(ii)* Os resíduos são independentes  
*(iii)* Os resíduos são normalmente distribuídos  
*(iv)* A variância dos resíduos é constante  

A linearidade dos resíduos não é formalmente um pressuposto, já que a VI é categórica em vez de conínua. Operacionalmente, o erro representa <u>todos os fatores de pesquisa</u> e problemas de medição que afetam o resultado, além das variáveis independentes consideradas na modelagem.


Da mesma forma que feito em outros capítulos, a tabela abaixo concatena os testes estatísticos relacionados quando os pressupostos são violados. Para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida "ordinal".  

  | Versão do teste | Um ou mais fatores |  Momentos repetidos             |  
  | :-----------    | :-----------       | :-----------                    |        
  | Paramétrica     | Anova de k via(s)  |  Anova de medidas repetidas     |   
  | Não-paramétrica | Kruskal-Wallis     |  Teste de Friedman ou Page Test |   

A ANOVA tem diversas características de modelagem que serão descritas na seção a seguir,

## Legenda

Diferentes termos são empregados em uma ANOVA e em modelos próximos. A legenda a seguir visa auxiliar no entendimento de cada um deles e aproximar o leitor a conceitos amplos utilizados em modelos lineares:

```{block, type="writing"}
**Via**: Variável independente, variável fonte, variável preditora, tratamento  
**Fator**: Sinônimo de via    
**Desfecho**: Variável dependente, variável critério    
**Níveis**: Grupos, classes, condições, categorias da variável independente  
**Efeito principal**: Efeito da variável independente em questão (controlanddo pelas outras no modelo)    
**Efeito de interação**: Efeito do termo de interação entre duas ou mais variáveis independentes. Quando significativo, não se interpreta os efeitos principais.   
**Efeito simples**: Efeito de uma variável independente em um nível (específico) de outra variável independente.  
**ANCOVA**: Análise de covariância, onde se controla os resultados por uma variável contínua 
**MANOVA**: Análise multivariada de variância, onde se extende a ANOVA para incluir duas variáveis dependentes. É um modelo multivariado.    
```


Por heurística, se escreve os delinementos estudados por uma ANOVA com $\eta$. Por exemplo, se o interesse for verificar o efeito do sexo (masculino ou feminino) e da escolaridade (fundamental, médio e superior), a representação será $\eta =  2 \times 3$. Isso significa que a ANOVA tem dois fatores (sexo e escolaridade) e o primeiro fator tem dois níveis e o segundo tem 3 níveis. 



A tabela a seguir resume as denominações encontradas na literatura:


  | VD / VI     | Uma VI                    |  2 ou mais VIs (sem interação)       | 2 ou mais VIs (com interação)  
  | :-----------| :-----------              | :-----------                         | :-----------          
  | Uma VD      | Anova de 1 via (one way)  |  Anova 2 (ou mais)  vias (multi way) |   Anova fatorial
  | > uma VD    | MANOVA     

## Pesquisa
  
<div class="alert alert-info" role="alert">
  <strong>Base: </strong> Livro - R - TEG
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada ["A relação entre o nível de Empreendedorismo (TEG) e os aspectos sociodemográficos dos Taxistas cooperados da cidade de Santo André/São Paulo, Brasil"](https://www.metodista.br/revistas/revistas-metodista/index.php/REGS/article/view/6453), publicada em 2016 na Revista Eletrônica de Gestão e Serviços, em que sou co-autor. O objetivo dessa pesquisa foi identificar o nível de empreendedorismo em 147 taxistas de Santo André/SP, bem como averiguá-lo em associação aos aspectos sociodemográficos. A base contém 14 variáveis, sendo 6 variáveis da escala utilizada para avaliação do empreendedorismo e 8 variáveis gerais, incluindo aqui os aspectos sociodemográficos, como sexo e escolaridade. Essa base será utilizada para realizar uma ANOVA de 1 via, 2 vias e uma ANOVA fatorial.


## ANOVA de 1 via

A pergunta que temos agora é sobre o possível efeito da `escolaridade` na Tendência Empreendedora Geral (`teg`). Trata-se de uma ANOVA de 1 via, dado que existe apenas uma VI, com mais de 2 níveis.  


As hipóteses precisam ser formalmente descritas:

$$H_0: \mu_{escolaridade_i} - \mu_{escolaridae_j} = 0 \\ H_a: c.c \\ \alpha = 0.05$$
Aqui, o subscrito $i$ e $j$ foi utilizado de maneira liberal para apresentar a diferença entre todas as combinações lineares possíveis.

### Execução no R

Ao trabalhar no R, é <u>fundamental</u> se certificar que os tipos das variáveis estão corretamente definidos em função da escala de medida utilizada. Erros nessa etapa podem gerar resultados absolutamente incorretos. A escolaridade é uma variável categórica (ordinal, tratada como discreta) e é necessário definir claramente isso ao R antes da análise propriamente dita. 

Isso pode ser feito pela função `case_when` e `levels`. O `case_when` irá usar os valores originalmente presentes nessa variável na criação de uma variável categórica e o `levels` deixará claro a ordem de cada categoria, o que é útil para que os gráficos sejam feitos corretamente.



Uma vez que os itens de um instrumento sociodemográfico devem levar em consideração o contexto das pessoas avaliadas as categorias de escolaridade foram definidas como da seguinte maneira: Primário significa escolaridade até o 5º ano, ginásio significa escolaridade até o 9º ano e colegial é equivalente ao ensino médio.



```{r }
dados_teg <- dados_teg %>% 
  mutate(escolaridade_fct = factor(case_when(
      escolaridade == 1 ~ "primario",
      escolaridade == 2 ~ "ginasio",
      escolaridade == 3 ~ "Colegial",
      escolaridade == 4 ~ "superior"), 
      levels=c("primario","ginasio","Colegial","superior")))
```

Os resultados descritivos devem ser calculados. A média irá apresentar a concentração dos dados, enquanto o desvio-padrão o afastamento dos valores em torno da respectiva média. 

```{r}
dados_teg %>% 
  group_by(escolaridade_fct) %>% 
  summarise_at(vars(teg), lst(n=~n(),mean,sd)) %>% 
  kable(digits = 2) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```
    
Tal como ilustrado no decorrer dos outros capítulos, gráficos são fundamentais para entendimento do relacionamento entre as variáveis. Uma vez que a escolaridade (VI) é tratada como discreta e a TEG (VD) é contínua, um gráfico de barras é adequado. A inclusão das barras de erro permite uma compreensão inferencial inicial.

```{r, message=FALSE}
ggplot(dados_teg, aes(x=escolaridade_fct, y = teg, fill = escolaridade_fct)) +
  geom_bar(stat = "summary", fun = mean) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  theme(legend.position = "none")
```


A visualização dos resultados já permite identificar algumas caracteríticas gerais. Primeiro, quão maior a escolaridade, maior o o valor obtido na escala. Segundo, algumas barras de erros estão superpostas e outras não, o que nos leva à conclusão preliminar de que resultados significativos estarão presentes na próxima etapa, que é a modelagem formal dessa hipótese. 

Para realizar a ANOVA, é possível contar com a função `lm` ou `aov`. Aqui, a escolha da `lm` foi apenas por conveniência e o vetor `mod_escolaridade` irá armazenar os resultados.

```{r}
mod_escolaridade <- lm(teg ~ escolaridade_fct, dados_teg)
```


Para apresentação, a função `apa.aov.table` do pacote `apatables` pode ser utilizada. Este pacote gera uma tabela parecida com a dos principais pacotes estatísticos comerciais e apresenta os principais elementos interpretáveis de uma ANOVA. A tabela a seguir sintetiza tais características.  



  | Preditor          | Soma dos Quadrados| Graus de liberdade  |  Quadrado médio | Estat. F      | 
  | :-----------      | :-----------      | :-----------        |  :-----------   | :-----------  |  
  | Fator             | Entre (SSB)       | K-1                 |  MSB = SSB/K-1 | F = MSB/MSW    | 
  | Resíduo           | Dentro (SSW)      | N-K                 |  MSW = SSW/N-K |                |
  | Total             | Total (SQT)       | N-1                 |  


Aqui, K significa quantidade de categorias dentro de um fator e N significa a quantidade de observações consideradas. As siglas em inglês são são utilizadas para apresentar a "Soma dos quadrados entre os grupos" (SSB), "Soma dos quadrados dentro dos grupos" (SSW), "Quadrado médio entre grupos" (MSB) e "Quadrado médio dentro dos grupos" (MSW). Repare também que,a este momento, os aspectos são apenas apresentados conceitualmente e não matematicamente. Em outro momento, aspectos da decomposição da variância serão também descritos.

```{r}
apaTables::apa.aov.table(mod_escolaridade) %>% pander::pander(., split.table = Inf)
```


A leitura desse resultado quase sempre irá pontuar as principais estatísticas obtidas da seguinte maneira: F(3,143) = 8.23, p < 0.01, ηp2 = 0.15, 90% CI [.06, .22].  

Um aspecto importante é que a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.


<u> Normalidade</u>: A ANOVA tem como um dos pressupostos a normalidade da distribuição dos resíduos. Isso pode ser feito de diferentes maneiras e abaixo há um QQ plot. Caso ambas as linhas estejam sobrepostas, isso gera evidências que o pressuposto foi atendido. Neste caso, isso parece ocorrer.

```{r }
olsrr::ols_plot_resid_qq(mod_escolaridade)
```
   
Apesar do gráfico ter sido bastante claro, o teste shapiro-wilk costuma ser utilizado neste caso. A hipótese nula desse teste assume que os resíduos são normalmente distribuídos.

```{r}
shapiro.test(residuals(mod_escolaridade))
```
De maneira diferente à conclusão gráfica, o teste concluiu pela rejeção da normalidade.


<u>Homocedasticidade</u>: Este pressuposto pode ser testado por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico, tal como o gráfico a seguir.

```{r}
olsrr::ols_plot_resid_fit(mod_escolaridade)
```

O teste de Bartlett ou Levene podem também ser utilzados de maneira formal. Ambos estipulam $H_0$ como homocedasticidade e, idealmente, não deve ser rejeitada.

```{r}
car::leveneTest(mod_escolaridade)
```


<u>Independência</u>:  Esse pressupostos frequentemente não é testado na ANOVA, apesar de ser uma exigência dos modelos lineares. De fato, uma vez que espera-se que os grupos sejam mutuamente excludentes, teria pouco sentido acreditar que os resíduos não fossem independentes. 


## Tamanho do efeito  


Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde.

No ambiente da ANOVA, 3 medidas costumem ser utilizadas para tamanho do efeito, que são o <u>eta quadrado</u> ($\eta^2$), o <u>eta quadrado parcial</u> ($\eta_p^2$) e o <u>ômega quadrado</u> ($\omega^2$). Em uma ANOVA de uma via, como é o caso aqui, o $\eta^2$ e o $\eta_p^2$ possuem o mesmo valor. A ideia de ambas as medidas é verificar a variância explicada que o modelo testado apresenta quando comparado com um modelo simples, que contou apenas com a média. Esse conceito será melhor descrito no capítulo de regressão linear. No caso de agora, o $\eta^2$ e o $\eta_p^2$ indicam a proporção da variabilidade dos resultados do TEG que pode ser atribuídos à escolaridade. A interpretação pode ser feita da seguinte maneira:

  | ηp2             | Interpretação              
  | :-----------    | :-----------      
  | ηp2 < 0.01      | Irrelevante    
  | ηp2 $\geq$ 0.01 | Pequeno     
  | ηp2 $\geq$ 0.06 | Moderado      
  | ηp2 $\geq$ 0.14 | Grande     


<aqui>

De fato, quando isso ocorre, a busca por possíveis diferenças entre <u>todas as comparações possíveis</u> costuma ser feita por testes post hocs.

Entretanto, é importante mencionar que que se uma ANOVA é significativa, isso não significa necessariamente que haverá alguma diferença <u>entre as médias dos grupos</u>. Tecnicamente, a diferença pode ocorrer em qualquer comparação possível, como grupo 1 contra grupos 2 + grupo 3 ou grupo 2 contra grupo 1+3. Dessa forma, o resultado geral da ANOVA e testes post hoc respondem questões diferentes e é possível realizar qualquer comparação múltipla sem sequer realizar a ANOVA, desde que os resultados sejam devidamente corrigidos caso se assuma alguns pressupostos sobre os constrastes.  


Uma vez que realizar uma ANOVA não é tecnicamente necessário para realização de comparações pareadas, é possível que alguém se pergunte qual é, então, a necessidade da realização deste primeiro teste. De fato, hoje em dia, a realização da ANOVA ocorre mais para que o pesquisador (i) consiga realizar computacionalmente todas as comparações pareadas entre as categorias da variável e, em seguida, (ii) corrigir adequadamente o valor de P obtido em cada computação.

Isso dito, uma vez que a <u>escolaridade</u> foi significativa, as principais comparações serão testadas dois a dois.Sempre que múltiplas que comparações são realizadas, é esperado que haja uma inflação do erro do tipo 1 e, por isso, é necessário ajustar o valor de P. Repare que a quantidade de comparações pode ser calculada da seguinte forma:

 \[ J*(\frac{J-1}2) \] 

$J$ é a quantidade de níveis da variável

Nesse caso:  

\[ 4*(\frac{3}2) = 6 \]. 

Para a comparação pareada, o pacote `emmeans` será utilizado.

### Post hoc

A mecanica do por detrás do post hoc é a comparação pareada de todos os níveis presentes no fator, seguido pelo ajuste do valor de P. Existem muitas técnicas para tal ajuste e elas costumam ser agrupadas em função da sua robustez à violação da homocedasticidade. Para fins práticos, vamos utilizar uma técnica considerada bastante conservadora, chamada de Bonferroni, que multiplica o valor de p encontrado pela quantidade de comparações.

O resultado das comparações dois a dois será armazenado em um objeto específico, nomeado como `post_hoc_escolaridade`. Isso será útil para apresentar sumários e gráficos.


```{r}
post_hoc_escolaridade <- emmeans(mod_escolaridade, "escolaridade_fct") %>% 
  pairs(., reverse = TRUE, adjust = "bonferroni")
```

Tal como feito até agora, o gráfico inicial das comparações será realizado. A adição das barras de erro gera interpretação mais rápida e simples para todas as comparações.

```{r}
CI <- confint(post_hoc_escolaridade)
ggplot(mapping = aes(contrast, estimate)) +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) +
  geom_point(data = summary(post_hoc_escolaridade)) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_size(trans = "reverse") + 
  coord_flip()
```


A apresentação tabular é fundamental e apresenta as estatísticas inferenciais de interesse:

```{r}
post_hoc_escolaridade %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Os resultados são significativos na comparação `Superior - Primário`, `Superior - Ginásio` e `Superior - Colegial`. Em todos, os resultados do TEG foi mais elevado naqueles participantes que haviam concluído o ensino superior.  

## Execução no JASP

A base utilizada será a [base_csv_teg_processed](https://osf.io/gxbdc/). Para deixar os níveis de <u>Escolaridade<u> adequados às tabelas e gráficos, será necessário clicar no centro da variável <u>escolaridade_fct<u>, selecionar o grupo desejado (no caso, <u>primário</u>) e clicar na seta para que ele seja o primeiro grupos.

![](./img/cap_anova_ordem_variaveis.png)
A ordem dos níveis deve ser a utilizada durante a pesquisa: primário, ginásio, colegial e superior. É importante relembrar que esses termos foram utilizados em função do público que foi avaliado nessa pesquisa. Para fechar esta parte superior, basta clicar no `X` embaixo das setas.

![](./img/cap_anova_ordem_variaveis2.png)


Após feito isso, da mesma forma que foi feita no R, a apresentação de gráficos auxiliam o pesquisador a verificar padrões diferentes nos dados.  Para fazer os gráficos, é necessário clicar em `Descriptives`.

![](./img/jasp_descriptives.png)


Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/jasp_descriptives2.png)


Agora é necessário arrastar as variáveis de interesse aos seus respectivos locais. Neste caso, o <u>teg</u> para parte das VDs, enquanto <u>escolaridade_fct</u> para a VI. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização.   


![](./img/cap_anova_descritivo.png)
Em seguida, ao clicar na opção `Plots`, será possível selecionar o <u>Boxplot</u>. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da <u>distribuição dos resultados</u> de empreendedorismo em função dos <u>níveis de escolaridade</u>.


![](./img/cap_anova_descritivo2.png)

Para execução da ANOVA, deve-se clicar em `ANOVA` e, em seguida, `Classical` e `ANOVA`.  

![](./img/cap_anova_interface.png)

Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir:

![](./img/cap_anova_interface2.png)


O espaço de `Fixed factors` é o local onde a VI deverá ser colocada, enquanto o `Dependent Variable` é o local onde a VD irá ser inserida. Para realizar a ANOVA de uma via, é necessário inserir a <u>escolaridade_fct</u> e o <u>teg</u>, respectivamente, em `Fixed factors` e `Dependent Variable`.

O JASP automaticamente irá realizar as contas e apresentar os resultados. Pragmaticamente, o valor de P é o indicador costumeiramente utilizado para tomar decisões inferenciais. Neste caso, <u>como o valor de p foi menor do que o nível de significância escolhido, rejeita-se a hipótese nula</u>.

![](./img/cap_anova_resultados_iniciais.png)
Entretanto, da mesma forma como apresentado antes, a interpretação deste resultado <u>não pode ser feita de uma forma automática</u>. É necessário saber se os pressupostos foram ou não atendidos, bem como calcular o tamanho do efeito. Estas opções estão dispostas na parte inferior à esquerda do programa.

![](./img/cap_anova_assumptions.png)

A <u>normalidade</u> é feita por um QQ-plot, enquanto o Teste de Levene testa a homocedasticidade. Idealmente, as linhas devem estar sobrepostas no QQ-plot para assumir a normalidade da distribuição dos resíduos. Além disso, o valor de p <u>deve ser superior</u> ao nível de significância eleito (quase sempre, 0.05) para considerar homogeneidade das variâncias. Neste caso, há a impressão visual de que a normalidade está mantida, da mesma forma que a homogeneidade. [Nota: O JASP não oferece um teste formal para testar a normalidade dos reíduos de uma ANOVA, tal como feito no R na seção anterior].


![](./img/cap_anova_assumptions2.png)


Após testar estes pressupostos, é importante avaliar o quanto a interpretação originalmente deve ser mantida. Existem diferentes recomendações sobre o que fazer quando os pressupostos são violados. Entre eles, transformar a distribuição da variável de interesse, usar versões robustas da ANOVA, usar testes não-paramétricos com objetivos próximos à ANOVA ou eleger algum modelo estatístico mais adequado à distribuição empírica obtida pelos dados. No JASP, as técnicas `Brown-Forsythe` e `Welch` são disponíveis para corrigir a violação do pressuposto de homocedasticidade.


Finalmente, para inserir o tamanho do efeito é necessário clicar em `Estimatives of effect size` e, em seguida, no `eta quadrado` ($\eta^2$). O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença.


![](./img/cap_anova_resultados.png)

A esse momento, a escrita é fundamental:


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados a partir de uma ANOVA de uma via investigando o efeito da escolaridade no empreendedorismo, medido por um escala específica. Foi possível concluir que a escolaridade é significativa (F(3, 143) = 8.23, p < 0.01, ηp2 = 0.15, 90% CI [.06, .22]). As comparações pareadas foram ajustadas pela técnica de Bonferroni e mostraram que os participantes com ensino superior apresentam pontuação mais alta do que àqueles com o primário (Δ = 7.16, p < 0.01), ginásio (Δ = 5.07, p < 0.01) e colegial (Δ = 2.96, p < 0.05).  
```


## ANOVA de 2 vias

Frequentemente, o interesse do pesquisador está em investigar como múltiplos fatores afetam a variável de interesse. Ao aumentar o número de variáveis independentes no modelo, se aumenta a quantidade de vias que a ANOVA possui. Se, por exemplo, a investigação visasse testar o efeito da <u>escolaridade</u> e do <u>sexo</u> no <u>empreendedorismo</u>, teríamos, por definição, uma ANOVA de duas vias. É fundamental atentar que essa modelagem inicialmente considera apenas os efeitos principais dos fatores e não assume ou modela uma possível interação entre os preditores.

### Execução no R

Após a escrita adequada da hipótese, a modelagem segue o mesmo padrão da feita anteriormente, iniciando pela definição correta do tipo de variável em relação à sua escala de medida.

```{r }
dados_teg <- dados_teg %>% 
  mutate(sexo_fct = factor(case_when(
      sexo == 1 ~ "masculino",
      sexo == 2 ~ "feminino"), levels=c("masculino","feminino")))
```


Tabelas e gráficos também devem ser apresentadas.

```{r}
dados_teg %>% 
  group_by(escolaridade_fct, sexo_fct) %>% 
  mutate(rn = row_number()) %>% 
  summarise_at(vars(teg), lst(n=~n(), mean, sd)) %>% 
  pivot_wider(names_from = sexo_fct, #indexador unico
              names_sep = "_",  #pode ser removido
              values_from = c(n:sd)) %>%  #organizar valores
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Repare que não há desvio-padrão para mulheres com o ensino superior. Isso ocorre pela quantidade de participantes que satisfazem essas condições. Tecnicamente, isso ou impossibilitaria essa análise ou tornaria a interpretação altamente viesada. No entanto, por condição pedagógica, vamos seguir com o procedimento.

Como o objetivo é verificar duas variáveis isoladamente, os gráficos também podem ser isolados. 

```{r, message=FALSE}
gridExtra::grid.arrange(
  ggplot(dados_teg, aes(x=escolaridade_fct, y = teg, fill = escolaridade_fct)) +
  geom_bar(stat = "summary") +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  theme(legend.position = "none"),
  
  ggplot(dados_teg, aes(x = sexo_fct, y = teg, fill = sexo_fct)) +
  geom_bar(stat = "summary") +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  theme(legend.position = "none"))

```

Agora, formalmente a modelagem será feita. Os passos devem ser exatamente os mesmos, incluindo a verificação de pressupostos e interpretação dos resultados. A esse momento, a tabela padronizada da ANOVA é a seguinte:


  | Preditor      | Soma dos Quadrados| Graus de liberdade |  Quadrado médio             | Estat. F       | 
  | :-----------  | :-----------      | :-----------       |  :-----------               | :-----------   |  
  | Fator (A)     | Entre (SS(A))     | K(A)-1             |  MS(A) = SS(A)/K-1          | F = MS(A)/MSW  | 
  | Fator (B)     | Entre (SS(B))     | K(B)-1             |  MS(B) = SS(B)/K-1          | F = MS(B)/MSW  | 
  | Resíduo       | Dentro (SSW)      | N-1-(df(A)+df(B))  |  MSW = SSW/N-1-(df(A)+df(B))|                |



Posto isso, os resultados obtidos são:

```{r}
mod_escolaridade_sexo <- lm(teg ~ escolaridade_fct + sexo_fct, dados_teg)
apaTables::apa.aov.table(mod_escolaridade_sexo)
```


Os resultados continuam constantando o efeito da escolaridade (F(3,142) = 8.24, p < 0.01, ηp2 = 0.15, 90% CI [.06, .22]) no empreendedorismo, mas também concluiu que o efeito do sexo não é significativo (F(1, 142) = 0.816, p = 0.36, ηp2 = 0.01, 90% CI [.00, .04]). É importante ter atenção à forma de reportar os resultados, uma vez que delineamentos de dois fatores quase sempre produz coeficientes são diferentes do delineamento anterior. A análise post hoc que seria feita agora seria a mesma feita anteriormente e, em função disso, será suprimida.


Uma sugestão de escrita desses resultados é a seguinte:



```{r, eval = FALSE, include=FALSE  }
#Apesar de não ter uma interpretação direta, o valor apresentado ao intercepto é o valor médio dos homens com escolaridade primária. Isso ocorre pois como há duas variáveis categóricas sendo analisadas, o valor utilizado para referência (ou seja, 0) do sexo foi para homens e este valor para escolaridade foi para aqueles com ensino primário.
dados_teg %>% filter(sexo_fct == "masculino" & escolaridade_fct == "primario") %>% summarise(mean(teg))
summary(lm(teg ~ escolaridade_fct + sexo_fct, dados_teg))$coefficients[1,1]
```


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados a partir de uma ANOVA de duas vias investigando o efeito da escolaridade e do sexo no empreendedorismo. Foi possível concluir que a escolaridade é um fator significativo aos resultados (F(3, 142) = 8.24, p < 0.01, ηp2 = 0.15, 90% CI [.06, .22]), mas que o sexo não é significativo nessa relação (F(1, 142) = 0.81, p = 0.36, ηp2 = 0.01, 90% CI [.00, .04]).   
```

## ANOVA Fatorial

A ideia da ANOVA fatorial é provavelmente uma das mais frequentes em perguntas de pesquisas, que consistem em tentar saber se os fatores tem alguma interação entre si. Nesse sentido, a modelagem envolve o cálculo de um terceiro parâmetro para investigar essa relação. Dessa maneira:


\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + b_3(X{_1}_i * X{_2}_i) + \epsilon_{i}\]

Os coeficientes $b_1$ e $b_2$ estimam os efeitos principais, enquanto o $b_3$ estima o efeito da interação. 

Dessa vez, é importante ressaltar alguns aspectos:  

1. Apesar de efeitos de interação poderem ser exploratórios, a ideia de adicioná-lo é fortemente relacionada à teoria. Ou seja, a modelagem é frequentemente confirmatória;  

2. A análise gráfica que é especialmente útil a todas as análises é ainda mais necessária nessa técnica;    

3. A interpretação dos resultados <u>sempre</u> começa pela interação. Caso ela seja significativa, não se interpreta os efeitos principais.    

Nessa pesquisa, tivemos o interesse em saber se o nível de empreendedorismo varia em função de uma interação entre `sexo` e  `estado civil` (solteiro ou casado) dos participantes e, mais especificamente, se o estado civil impactaria o empreendedorismo de maneira diferente em homens e mulheres. Em áreas comportamentais, a interação entre o efeito estado civil e do sexo em características sociais é bastante estudado.  

### Execução no R

Como mencionado, é fundamental ajustar todas as características da base para que os resultados não sejam distorcidos em função de definições computacionais. Como nessa pesquisa, também permitimos que pessoas divorciadas e viuvas, uma opção para deixar as análises totalmente pareadas com a pergunta da pesquisa é criar uma base contendo apenas solteiros (originalmente codificados com 1) e casados (originalmente codificados como 2).

```{r}
base_interacao <- dados_teg %>% filter(civil == 1 | civil == 2)
base_interacao <- base_interacao %>% 
  mutate(estado_civil_fct = factor(case_when(
      civil == 1 ~ "solteiro",
      civil == 2 ~ "casado"), levels=c("solteiro","casado")))
```

Agora o gráfico apresentado deve combinar as duas variáveis independentes, uma no eixo de X e outro no agrupamento. A escolha de como apresentar estas variáveis não deve ser aleatória, mas ser atrelada à forma da pergunta de pesquisa. Se o interesse for responder "Quanto o estado civil depende do sexo para gerar os resultados do TEG" sugere que em X coloque-se a variável "estado civíl" e no agrupamento a variáel "sexo.

```{r, message=FALSE}
ggplot(base_interacao, aes(x = estado_civil_fct, y = teg, group = sexo_fct, col = sexo_fct)) +
  geom_line(stat = "summary", fun = mean, size=1) + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width=0.1, size=1)
```

O gráfico sugere que existe um efeito de interação, uma vez que as linhas se cruzam. No entanto, o teste formal deve ser feito. Da mesma forma do realizado anteriormente, a modelagem omitirá a verificação dos pressupostos, que foi apresentada em etapa inicial. 

```{r}
mod_int_sexo_civil <- lm(teg ~ sexo_fct * estado_civil_fct, base_interacao)
apaTables::apa.aov.table(mod_int_sexo_civil)
```


A leitura da tabela começa de cima para baixo, ou seja, pela interação. Neses caso, ela é significativa (F(1,129) = 4.24, p = 0.042, ηp2 = 0.03, 90% CI [.00, .10]). Quando isso acontece, não se deve interpretar os efeitos principais, mesmo que eles sejam significativos. 


### Post hoc


No caso, à pergunta "o sexo tem efeito no empreendedorismo", a resposta adequada seria "depende", uma vez que ele varia em função do estado civil do participante. O post hoc vez será também feito pelo pacote `emmeans`, que já foi carregado anteriormente. Para deixar a rotina clara, vamos armazenar os resultados no objeto `post_hoc_int` e, em seguida, explorar os coeficientes.Repare que dessa vez, os valores de p ajustados ou não são os mesmos, dado que há apenas duas categorias em cada grupo.

```{r}
post_hoc_int <- emmeans(mod_int_sexo_civil, pairwise ~ sexo_fct * estado_civil_fct)
```

O resultado deve ser acessado via contrastes.

```{r}
post_hoc_int$contrasts %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


Repare que as informações repetem aquilo já visualizado no gráfico anterior, mas com as correções para evitar a inflação do erro do tipo 1. Neste momento, a interpretação torna-se menos visual e mais detalhada. Os resultados indicam que o empreededorismo depende tanto do estado civil como do sexo do participante. Quando solteiros, há uma tendência das mulheres empreenderem mais do que os homens (Δ = -5.048, p = 0.09). Entretanto, essa diferença não ocorre quando os participantes são casados, já que homens e mulheres casadas tem, em media, o mesmo nível de empreendedorismo (Δ = 0.482, p = 1). No entanto, especialmente nas mulheres casadas, o nível de empreendedorismo é significativamente menor do que nas solteiras (Δ = -6.222, p = 0.07). Em linhas gerais, parece que o empreendedorismo diminui em pessoas casadas e isso é especialmente válido às mulheres.  
É importante também atentar que a correção do valor de P deve ser feita para proteger falsos positivos (erro do tipo 1), mas que, idealmente, não devem também gerar falsos negativos (erro do tipo 2), o que talvez pudesse ser sugerido se aqui não tivéssemos interpretado os valores entre 0.05 e 0.1 dos resultados.  

```{r}
write.csv(dados_teg, "base_csv_teg_processed.csv", row.names = F)
write.csv(base_interacao, "base_csv_teg_interacao_processed.csv", row.names = F)

```


## Resumo  

1. A ANOVA pode tanto ser entendida como um super Teste T, como um caso particular de um modelo de regressão  
2. Testes post hoc e resultados globais da ANOVA não respondem às mesmas perguntas  
3. As comparações pareadas devem proteger a inflação do erro do tipo 1, sem gerar o erro do tipo 2 

