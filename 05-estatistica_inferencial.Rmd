---
output: html_document
editor_options: 
  chunk_output_type: inline
---

# Estatística Inferencial



```{block, type="objectives"}
**Objetivos do capítulo**  
1. Introduzir alguns conceitos de estatística inferencial  
2. Apresentar os procedimentos feitos durante o Teste de Significância de Hipótese Nula (NHST)   
3. Discutir condições particulares sobre valores de P      
4. Oferecer leituras complementares sobre os tópicos  
```

Um dos principais objetivos ao se fazer uma pesquisa é conseguir generalizar as descobertas feitas no estudo para toda a população de onde os participantes pertencem Essa tarefa faz parte dos objetivos da estatística inferencial, que se ocupa majoritariamente com desenvolver estimativas sobre os parâmetros populacionais e testar hipóteses. 


Como apresentado em outros capítulos, a população pode ser formada por indivíduos, famílias, etc e é comumeiramente classificada em "população-alvo" e "população externa". A população-alvo é formada por aqueles indivíduos não amostrados, mas que o estudo pode generalizar os resultados. A população externa é formada por todos aqueles em que há a intenção de generalizar os resultados, mesmo que apresente características algo distintas dos indivíduos amostrados.

Em uma pesquisa de nosso grupo [@AfonsoJunior2020], nós contamos com uma amostra aleatória de estudantes universitários de uma universidade do Rio de Janeiro e estudamos algumas de suas características epidemiológicas. Neste caso, a população-alvo poderia ser entendida como todos os estudantes universitários da cidade do Rio de Janeiro, enquanto a população externa poderia ser formada por todos os estudantes universitários do Brasil. 


![](./img/cap_inferencia_amostra_populacao.png)


O processo para estimar parâmetros envolve algumas etapas e, apesar de importantes, são quase sempre secundários em Psicologia e muitas áreas científicas. Na grande maioria dos casos, Psicólogos e outros profissionais de áreas científicas fazem uma pesquisa visando testar hipóteses sobre seu objeto de investigação. Dessa forma, como testes de hipóteses figuram como os principais protagonistas da estatística inferencial, eles terão também destaque neste  capítulo.  



## NHST (Teste de Significância de Hipótese Nula)


```{block, type="glossario"}
<U>**GLOSSÁRIO**</U>   
**Parâmetro**: Valor que descreve uma característica da população. Esse valor é fixo e desconhecido. Sua representação é feita por letras gregas.  
**Estatística**: Valor que descreve uma característica da amostra. Esse valor é aleatório e calculado através dos dados coletados.  É apresentado por letras romanas.  
**Inferência**: Processo pelo qual, através de modelos estatísticos, se tiram-se conclusões sobre características da população a partir dos dados amostrais e permite fazer generalizações e previsões a respeito da população. Técnicas inferenciais permitem a estimativa dos parâmetros populacionais e testar hipóteses.  
**Modelo estatístico**:  Sistema de equações que descreve ou representa o possível processo gerador de dados do conjunto de dados em análise.    
**NHST**: Sigla que representa Teste de Significância de Hipótese Nula (em Inglês, Null Hypothesis Significance Testing)
```


::: {.warning}
**Atenção**: É extramamente difícil conseguir falar sobre este conceito em uma linguagem simples para todos, mas ao mesmo tempo sem inconsistências estatísticas. Algumas notas são deixadas durante a seção visando atingir este objetivo.     
:::


A sigla NHST se refere ao Teste de Significância de Hipótese Nula, que é o procedimento mais utilizado quando pesquisadores desejam testar hipóteses de pesquisa utilizando recursos da estatística. Subjacente a todo o processo, esta o pressuposto de que é possível transformar perguntas científicas em modelos probabilísticos e, com isso, utilizar a linguagem estatística para lidar com tais questões.

![](./img/cap_inferencia_modelos_estatisticos.png)



Existem diferentes maneiras de introduzir o tema e as subseções a seguir o apresentará descrevendo cada um dos termos que compõem a sigla por uma forma pragmática. Com algumas sutis diferenças, esses procedimentos e suas interpretações são similares em todas as áreas da teoria de decisão, tal como Teoria de Detecção de Sinal e diagnóstico médico, o que foi discutido por um trabalho meu recente.  

Algo colateral ao aspecto pragmatico, a forma pela qual os testes de hipóteses são feitos hoje é uma mistura entre a forma pela qual Ronald Fisher pensava ser a correta e a maneira pela qual Jerzy Neyman e Egon Pearson defendia ser a adequada.  

### A primeira etapa: a hipótese  

Na maioria das vezes, quando uma pesquisa é feita, ela visa testar uma hipótese. Por sua vez, uma hipótese é uma conjectura, uma suposição sobre o estado das coisas feita pelo pesquisador e usualmente pensada no presente do indicativo (ex: há) ou no futuro do pretérito (ex: haveria). Em ingles, há o habito de tratar uma hipótese de pesquisa como *Educated Guess*, tendo em vista que ela costuma ser feita de maneira cuidadosa e após alguma reflexão sobre o tema de interesse. As hipóteses podem ser classificadas como substantivas ou estatísticas.   

Uma hipótese substantiva é uma formulação textual e semântica sobre determinado fenômeno. Ou seja, é uma frase, tal como "haveria uma relação entre nível de atividade física e bem-estar psicológico", ou "o tratamento psicofarmacológico melhora quadros de depressão" ou ainda que "o tipo de colégio - público ou privado - influencia nos resultados de alunos em provas nacionais". A hipótese estatística, por sua vez, visa operacionalizar a hipótese substantiva e, com isso, é uma afirmação conjectural, em termos quantitativos, das relações estatísticas da hipótese substantiva (p. 46), o que será apresentado em seguida. 

![](./img/cap_inferencia_tipos_hipoteses.png)

Ao se fazer uma pesquisa, as hipóteses estatísticas podem ser divididas em Hipótese nula, representada por $H_0$ e Hipótese alternativa, representada por $H_1$ ou $H_a$.

Muitas pesquisas podem ser feitas e, consequentemente, muitas hipóteses construídas. Em Psicologia, quase sempre as hipóteses de interesse verificam diferenças entre grupos ou relacionamento entre variáveis e, por sua frequência na literatura, serão apresentadas aqui.  

Em pesquisas com esta finalidade, a hipótese nula é a mais conservadora sobre determinado fenômeno. Ela advoga que pela ausência de padrões, pela inexistência de um relacionamento de causa e efeito, de associação entre variáveis ou de diferença entre grupos. Em termo gerais, a hipótese nula define que qualquer condição observada na população/natureza pode ser melhor explicada pelo acaso.   

Por contraste, a hipótese alternativa apoia relação de causalidade entre variáveis, ou que determinado fator apresenta relacionamento com outro ou que existe diferenças entre grupos, etc. Em linhas gerais, a hipótese nula costuma ser definida como aquilo que o pesquisador não acredita (em ingles, chama-se de *Straw person Principle*) e a hipótese alternativa tende a ser a hipótese que o pesquisador previamente assumiu para motivar sua coleta de dados. 

Em estatística frequentista, por um apoio epistemológico, a hipótese nula é assumida como verdadeira antes mesmo de qualquer procedimento de coleta e análise de dados. Note que ao assumi-la como verdadeira, isso não significa afirmar que ela seja, de fato, verdadeira. Essa suposição tem origem em discussões clássicas em estatística e, pragmaticamente, a hipótese nula é o que pesquisadores desejam falsear ou refutar na maioria das vezes em suas investigações [@Lecoutre2014]. 

Apesar da definição textual da hipótese ser de fácil entendimento para todos, ele não tem utilidade para etapa de coleta de dados. Dessa forma, esse formato textual é substuído pelo formato estatístico. Por exemplo, se uma determinada pesquisa é feita sob hipótese de que "um determinado antidepressivo auxilia na melhora de pacientes deprimidos", isso tende a gerar a hipótese alternativa que pode ser lida como: "em média, pessoas deprimidas do grupo que usou o medicamento tem resultados mais baixos em uma escala de depressão quando constrastado com o grupo que não usou o medicamento". Conceitualmente:

$$\underbrace{O \,grupo \,que \,tomou \,antidepressivo \,terá \,menos \,depressão}_\text{Hipótese  substantiva}$$

$$H_0: \mu_{grupo (1)} = \mu_{grupo (2)} \\ \underbrace{H_a: \mu_{grupo (1)} < \mu_{grupo (2)}}_\text{Hipóteses estatísticas}$$

Neste tipo de formulação estatística, a hipótese nula necessariamente será formada pelo sinal de igual ($=$), enquanto a hipótese alternativa poderá ser diferente ($\neq$), maior ($>$) ou menor ($<$). Tecnicamente, isso costuma alterar levemente etapas analíticas, que são descritas em outros capítulos.  

É importante introjetar duas condições. A primeira é que o pesquisador não testa diretamente a hipótese substantiva, mas sim a hipótese estatística, que tenta operacionalizar a primeira. A segunda característica é que, em estatística frequentista, por mais importante que seja a hipótese alternatviva -- afinal, foi ela que motivou a pesquisa -- ela não é testada diratamente. De fato, se assume que a hipótese nula seja verdadeira por princípio e, em seguida, compara-se o quão compatível os resultados obtidos são à tal hipótese.


::: {.warning}
**Atenção**: O pesquisador tende a fazer uma pesquisa para verificar a adequação de sua hipótese ($H_a$). Entretanto, o mecânica da estatística frequentista testa o quão os resultados são compatíveis ou não com a hipótese nula.     
:::

Com tais explicações feitas, a primeira parte da sigla "NH" (de Null Hypothesis Significance Testing) foi apresentada.


## Nível de significância   

Toda pesquisa tem erros. Como visto anteriormente, em estatística frequentista, a hipótese nula é definida como verdadeira inicialmente. Dessa maneira, o nível de significância (denotado pela letra $\alpha$) é definido como o máximo erro tolerável [@Greenland2019] da probabilidade de se rejeitar a hipótese nula quando ela é, de fato, verdadeira. Ele deve ser estipulado <u>antes</u> da coleta e análise de dados e, por ser uma probabilidade, compreende valores entre 0 e 1. 

Apesar deste nível ser uma escolha do pesquisador, quanto maior ele for, mais facilmente a hipótese nula será rejeitada. No extremo, se o nível de significância for 1, todos os resultados irão concluir pela rejeição da hipótese nula. Por oposição, se o nível de significância for igual a 0, a hipótese nula jamais seria rejeitada, mesmo quando falsa.  

Em estatística frequentista, é convencional estipular o nível de significância em 5% (0.05) ou 1% (0.01). Em algumas ocasiões, 10% (0.1) como nível de significância é aceito, mesmo que isso possa gerar uma maior dificuldade na publicação. Apesar desses números não serem mágicos, a origem dos 5% remonta a Ronald Fisher, que no trabalho "*Statistical Methods for Research Workers*" (1925), deixou uma tabela com indicando quais seriam os resultados esperados tendo como critério este nível.

O nível de significância é importante pois ele é associado com o conceito de erros. Quando se rejeita uma hipótese nula verdadeira, da-se o nome de erro do tipo I. Em pesquisas médicas, esse é erro é chamado de "falso positivo" e, em psicofísica, de "falso alarme". 

Entende-se também que é possível que a hipótese nula não seja rejeitada mesmo quando ela é falsa. Esse é o erro do tipo II (2), que também é chamado de "falso negativo" em pesquisas médicas ou "perda" em psicofísica. Note que o erro do tipo 2 e alguns conceitos derivados não se conectam tão diretamente com o conceito de nível de significância. Isso ocorre pois esse conceito não é bem uma defesa de Ronald Fisher, mas foi introjetado posteriormente por Jerzy Neyman e Egon Pearson [@cohen2013explaining]. 

A tabela de tomada de decisão a seguir é a mais tradicionalmente apresentada para apresentar esse conceito. 


![](./img/cap_inferencia_tabela_decisao.png)
*Nota: Ronald Fisher tinha bastante resistência à ideia do erro do tipo II ou também aos intervalos de confiança. Essa tabela é uma junção pragmática de sua forma de entender testes de hipóteses e da forma de Jerzy Neyman e  Egan Pearson. A hipótese nula é assumida como verdeira e não <u>provada</u> ou <u>refutada</u> como tal.*


Existe um *trade-off*, ou relação de perde-ganha, entre o erro do tipo I e o erro do tipo II. Aumentar o erro do tipo I leva à diminuição do erro do tipo II. Desta forma, o pesquisador deverá pesar as consequências do erro do tipo I (falsos positivos) e também as consequências do erro do tipo II (falsos negativos) durante a testagem de hipótese.  

Ao fim desta seção, outro exemplo será dado para tornar esta tabela mais palatável. Com isto posto, a terceira parte da sigla "S" é considerada apresentada.



## O teste estatístico  

A testagem estatística pode ser entendida como uma maneira formal de modelar os dados e verificar a probabilidade de se obter determinados resultados assumindo a hipótese nula como verdadeira. De maneira mais direta, é uma ferramenta de auxílio para contrastar hipóteses, permitindo rejeitar ou não a hipótese nula, a partir de um nível de significância fixo previamente definido [@Lecoutre2014]. Com isso, ao se implementar testes estatísticos, se possibilita ter inferências sobre aspectos populacionais a partir dos resultados amostrais.  

Pragmaticamente, após a definição da hipótese nula e alternativa, bem como o nível de significância, testes estatísticos são calculados com base nos dados e seus resultados auxiliam a rejeitar ou falhar em rejeitar a hipótese nula. A estatística dispõe de um exército de testes estatísticos (ex: Teste T, Teste de Kruskal-Walis, etc), que tendem a ser classificados por muitos critérios, como o tipo de distribuição de algumas variáveis ou a natureza da VI/VD, etc. 

Apesar dessa estratégia ser comumeiramente feita não apenas em Psicologia, ela pode levar à falsa percepção de que os testes estatísticos são mutuamente exclusivos e que há uma fórmula de bolo padronizada em que cada situação de pesquisa necessita de um teste específico e não outro.

Neste livro, mesmo nos capítulos em que testes estatísticos são descritos, essas condições serão um pouco desafiadas. O que é fundamental ter conhecimento é que: 

(1) Todo teste estatístico assume alguns pressupostos, que devem ser sempre testados;   
(2) Os testes produzirão um valor numérico, que é um sumário estatístico chamado de estatística de teste, representado por letras como T ou $\chi^2$;    
(3) Esta estatística de teste é uma variável aleatória com algumas propriedades específicas;  
(4) Apesar da importância destes resultados, eles são sempre transformados em um valor de P. Por sua vez,       
(5) O valor de P é usado como critério de tomada de decisão.



## O valor de P

Após definir da hipótese nula e alternativa, bem como o nível de significância e execução do teste estatístico, um valor de P será apresentado. Ele é o critério mais comumente empregado para tomada de decisão em estatística frequentista e apresenta as seguintes condições:

(1) Seu valor é uma probabilidade e, portanto, compreende valores entre 0 e 1;   
(2) Seu valor é obtido por um modelo estatístico que é assumido como adequado e bem específicado;   
(3) Seu valor indica a probabilidade de se obter uma estatística de teste igual ou ainda mais extrema que observada assumindo a hipótese nula como verdadeira;    
(3) Seu valor indica a compatibilidade dos resultados obtidos e os esperados assumindo a hipótese nula verdadeira;     
(4) Quando o valor de P é baixo, isso possibilita que o pesquisador conclua pela rejeição da hipótese nula;     
(5) Quando o valor de P é alto, isso impede que a hipótese nula seja rejeitada.     

Como valores baixos ou altos são relativos, em estatística frequentista, se considera que a rejeição da hipótese nula ocorre apenas quando o valor de p é menor do que o valor previamente estipulado no nível de significância. Neste sentido, a tomada de decisão segue uma regra discreta, que é:

$$P<\alpha \Rightarrow \ Rejeitar \, H_0 \\P 	\geq \alpha \Rightarrow \ Falhar \,em \,Rejeitar $$



É importante notar que rejeitar $H_0$ não significa aceitar $H_a$. Esse erro é frequente e é chamado de *Modus Tolens* [@Trafimow2019]. Repare que neste procedimento sequer há a necessidade de $H_a$. Além disso, os valores de P se referem às estatisticas de teste obtidas durante etapas analíticas. Eles não se referem à teoria científica que motivou a pesquisa e, desta forma, rejeitar $H_0$ também não significa falar que uma teoria foi provada.   

Finalmente, falhar em rejeitar $H_0$ não prova que ela é verdadeira. É possível apenas concluir que ainda não existem evidências sólidas para rejeitá-la. Aceitá-la significa cair num erro chamado de *Argumentum ad Ignorantiam*, em que as pessoas tendem a achar que algo que não foi provado como falso é, consequentemente, algo verdadeiro. 


Com isso, a última letra "T" de NHST, foi descrita.


## O tamanho do efeito  

Os valores de P são importantes como uma medida de força de evidência contra a hipótese nula, bem como permitem que os parâmetros (populacionais) sejam estimados pelos resultados amostrais. Por estas características, eles são importantes em testes de hipóteses e devem sempre ser relatados. No entanto, pragmaticamente, seus resultados são discretos (sim ou não) e <u>não</u> respondem diretamente as questões ou hipóteses que motivaram a execução da pesquisa, apesar de auxiliarem na tomada de decisão [@Goodman1999]. 


Medidas chamadas de Tamanho do efeito foram mais recentemente desenvolvidas tentando ofercer um indicador <u>contínuo</u> que visam responder a magnitude, relevância ou importância dos resultados, especialmente, quando se investiga diferenças entre dois grupos. 


Em todas as pesquisas amostrais, apenas uma parte da população foi acessada. Neste sentido, como parte da população não foi investigada, qualquer processo de generalização dos resultados pode incorrer em erros inferenciais. Uma vez que a estatística assume que a hipótese nula é, a priori, verdadeira, o erro que primeiro pode aparecer no processo de inferência ocorre quando o pesquisador rejeita a hipótese nula de maneira incorreta. Como a hipótese nula tende a apoiar, por exemplo, que não há diferença entre grupos, ao rejeitar incorretamente

 

## Um exemplo intuitivo   



## O que não te contaram sobre inferência estatística na graduação e pós-graduação  
 
Conforme previamente exposto, introduzir o conceito de teste de significância de hipótese nula em uma linguagem que seja estatisticamente correta e, ao mesmo tempo, facilmente capturável por todos é uma tarefa que parece já nascer fracassada. Há farta literatura indicando isso, como X, X e X. Sem precisar de grande esforço, algumas inconsistências ou atalhos também podem ser identificados neste texto. 

Em Psicologia e muitas áreas de pesquisa, tais entraves parecem parecem universais e já bastante enraizados na docência de estatística e outros métodos quantitativos. Tendo essa condição como base, a listagem de tópicos a seguir visa, ao menos, reduzir que algumas inconsistências sobre testes de hipóteses sejam mantidas ou reforçadas.    


(1) A ideia de uma tabela de tomada de decisão é uma mistura entre as formas de entender os testes de significância de Ronald Fisher e o Teste de Hipóteses de Neyman e Pearson. Há um excelente capítulo intitulado *The Fisher, Neyman–Pearson and Jeffreys Views of Statistical Tests* indicando passagens históricas sobre a relação agressiva e conturbada entre eles [@Lecoutre2014].   

(2) O valor de P não pressupõe hipótese alternativa. Ele é uma medida de quão compatível os dados são assumindo a hipótese nula como verdadeira.   
1) A maioria dos testes inferenciais nada mais são do que modelos de regressão. As chamadas variações ou alternativas não-paramétricas tendem a ser modelos de regressão em dados ordenados.  


(3) Como o valor de P depende exclusivamente da hipótese nula, ele pode ser representado tanto em sentido possibilístico ou, com restrições, como uma probabilidade condicional. 

(4) A grande maioria dos testes estatísticos são versões reduzidas de modelos lineares. Assim, testar a normalidade da variável dependente não é um pressuposto de Teste T ou ANOVA. A normalidade desses modelos estatísticos são assumidas aos resíduos.  

(5) A violação dOs modelos estatísticos costuma ocorrer com relativa frequência em Psicologia. Há uma intensa discussão sobre as consequências disso, incluindo posicionamentos que sugerem que a crise de replicação é em função disso e posicionamentos que julgam que a violação dos pressupostos tem pouco ou nenhum impacto na maioria das vezes. 

(6) O Teorema Central do Limite e a Lei dos Grandes Números são fundamentais na teoria da inferência, mesmo que não tenham sido abordado diretamente aqui.   

() De acordo com a teoria Poperiana, uma teoria ou hipótese jamais podem ser provadas. Só é possível gerar evidências que a corroborem provisoriamente ou a rejeitem. Como diz Einstein “No amount of experimentation can ever prove me right, but a single experiment can prove me wrong”.
Uma teoria gera um conjunto de hipóteses que, por sua vez, podem produzir dados. 


O valor de P  

## Questões  

<div class="question">

1. (Retirado de Business Statistics) Qual ads sentenças é verdadeira<br>a) A hipótese nula não é testada. A hipótese alternativa é testada.<br>b) A hipótese nula é testada. A hipótese alternativa não é testada.<br>c) Ambas as hipóteses (nula e alternativa) são testadas.<br>d) Ambas as hipóteses (nula e alternativa) não são testadas<br>e) Todas as opções.
 
</div>
<div class="mirror">Gabarito: 1b</div>



## Pesquisas adicionais  

Como este capítulo apresentou tanto aspectos pragmáticos, como alguns eventos históricos sobre inferência estatística e testes de hipótese, seria possível listar inúmeras referências de qualidade como recursos adicionais. Entretanto, vou optar por apenas algumas obras que eu costumo acessar várias vezes para reler.

1. On some assumptions of the null hypothesis statistical testing (DOI: 10.1177/0013164416667979)
Este é um trabalho de Alexandre Patriota que, em minha opinião, é uma autoridade tanto na aplicação como na docência em estatística.
