# ANOVA de medidas repetidas

```{r, include = FALSE }
library(tidyverse)
library(knitr) #tables and graphs
library(kableExtra) #tables with different styles

load(file = "~/anovabr/mqt/bases/R - Base Lidia Carprofeno.RData") 
```


```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar a ANOVA de Medidas Repetidas.    
2. Realizar passo-a-passo a modelagem analítica.    
3. Verificar os pressupostos e implementar as correções sugeridas.  
4. Escrever os resultados.  
```

A ANOVA de medidas repetidas é oferece uma moelagem analítica para a análise de dados longitudinais pareados, isto é, relacionados. Esta técnica pode ser entendida como uma expansão da ANOVA ou um caso especial do <u>Modelo Linear de Efeitos Mistos (LMM)</u> [@howell_2013], que é realizada quando se deseja verificar se os resultados de vários grupos variam significativamente com o tempo. Os pressupostos são similares aos discutidos em outros testes inferenciais:

*(i)* Os dados são aleatórios e representativos da população  
*(ii)* a variável dependente é contínua  
*(iii)* Os resíduos do modelo são normalmente distribuídos
*(iv)* há esfericidade dos grupos  

## Pesquisa


A esse momento, vamos ter como referência de análise a pesquisa intitulada ["Avaliação psicométrica em português do indicador de dor crônica de Helsinki em cães com sinais crônicos de osteoartrite"](https://www.scielo.br/scielo.php?script=sci_arttext&pid=S0102-09352019000100109), que tem como primeira autora Lídia Matsubara e eu sou co-autor. Essa pesquisa foi publicada no "Arquivo Brasileiro de Medicina Veterinária e Zootecnia" em 2019.

Nessa pesquisa, temos um **grupo controle** e um **grupo experimental** e todos os participantes foram avaliados em 5 momentos diferentes do tempo: 1 semana antes do início do tratamento (W2), imediatamente antes (W0), duas semanas e quatro semanas após o tratamento ter iniciado (S2 e s4) e após uma semana da retirada do tratamento (s6). Dessa forma, trata-se de um delineamento 2x5, considerando os 2 grupos e as 5 medições ao longo do tempo. A base `dados` reúne as varáveis da pesquisa em formato largo (wide) Entretanto, o formato longo é o mais tipicamente encontrado para análises longitudinais e, por isso, será imeplementado a seguir.

```{r}
tratamento <- dados %>% 
  mutate(id = row_number()) %>% 
  select(id, grupo_dummy,starts_with("total_")) %>% 
  pivot_longer(-c(id,grupo_dummy),
                names_to = "tempo",
               values_to= "resultado") %>% 
  rename(grupo = grupo_dummy) %>% 
  filter(grupo < 3) %>% 
  mutate(grupo = factor(if_else(grupo == 1, "Placebo", "Experimental"))) %>% 
  mutate(tempo = factor(case_when(
    tempo == "total_w4" ~ "antes",
    tempo == "total_w0" ~ "no_dia",
    tempo == "total_s2" ~ "semana_2",
    tempo == "total_s4" ~ "semana_4",
    tempo == "total_s6" ~ "semana_6",
  )))
```

As variávies neste conjunto de dados são:

```{r }
tratamento %>% names()
```

Dessa forma:  

**id** refere-se a uma identificação única de cada participante.  
**grupo** refere-se ao grupo em que o participante foi alocado, tal como previamente apresentado (controle ou experimental).  
**tempo** diz respeito aos 5 pontos de medida e     
**resultado** é uma variável aleatória contínua do valor obtido na escala utilizada.  

## Execução no R   

A modelagem estatística envolve definir claramente que o `resultado` é uma função do `tempo`, do `grupo` e da interação `tempo x grupo`. Conforme exposto, a primeira etapa consiste na apresentação de tabelas e gráficos. Essas técnicas descritivas são muito informativas e permitem uma rápida compreensão dos resultados.

A tabela a seguir apresenta a quantidade de participantes nas condições com o passar do tempo.

```{r }
tratamento %>% 
  group_by(grupo, tempo) %>% 
  count() %>% 
  pivot_wider(names_from=grupo, values_from = n) %>% 
  kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```
Nota-se que apesar de não ter havido perda amostral, os grupos não tiveram a mesma quantidade de participantes, gerando o que é classicamente entendido como desbalanceamento amostral. Em seguida, a tabela abaixo apresenta os valores da média e do desvio-padrão para todas as condições:

```{r }
tratamento %>%  #base de dados
  group_by(grupo,tempo) %>% #agrupar
  summarise_at(vars(resultado),lst(mean, sd)) %>% #tirar estatisticas 
  pivot_longer(-c(grupo, tempo), names_to = "medida") %>% 
  mutate(key = paste0(medida,"=", value)) %>%  #criar um unico inexador
  select(grupo, tempo, key) %>%  #selecionar apenas as 3 variaveis importantes
  separate(key, into=c("medida","resultado"),sep = "=", convert = TRUE) %>%  #dividir media e desvio
  pivot_wider(names_from = tempo, values_from = resultado) %>%  #alargar
  kable(., digits=2) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

O gráfico abaixo também apresenta as mesmas informações, mas insere uma barra com o erro padrão da média. Isso é útil para interpretação inferencial.

```{r,fig.align='center'}
ggplot(tratamento, aes(x=tempo, y=resultado, group=grupo, color=grupo)) + #variaveis
  stat_summary(fun = mean, geom = "line", size=1.5, aes(linetype = grupo)) + #linha
  stat_summary(fun="mean", geom="point", size=5, aes(shape = grupo)) + #pontos
  stat_summary(fun.data = mean_se, geom = "errorbar",size=1) #barra de erro
```

É possível ver que as barras de erro estão superpostas, isto é, uma dentro da outra. Isso ocorre quando não há diferença significativa entre as condições. No entanto, o teste formal estatístico deve ser realizado. Isso pode ser feito por algumas funções do pacote `ez`, descritas abaixo:


```{r }
library(ez)
```

Sua sintaxe envolve as seguintes características:

**data** refere-se à base de dados (lembre-se que ela deve estar no formato longo)   
**dv** refere-se à variável dependente (contínua)  
**wid** refere-se à variável com a identificação única de cada aprticipante  
**within** refere-se à variável independente com *efeito dentro do tratamento*, ou seja, a variável que se repete. Nesse caso, cada uma das semanas  
**between** refere-se à variável independente com *efeito entre os tratamentos*, ou seja, cada um dos grupos  
**type** refere-se à forma pela qual a soma dos quadrado será calculada. O tipo 3 emula os resultados dos programas típicos e quase sempre é a melhor opção para finalidade de comparação entre resultados  
**detailed** refere-se à apresentação detalhada dos resultados  
**return_aov** refere-se à criação de um objeto no formato `aov` que tem utilidade para análises comparadas posteriores  

Visando facilitar a comunicação, criaremos um objeto (`ez_outcome`) para armazenar os resultados e, em seguida, iremos acionar a função `summary` para apresenta-los.

```{r }
ez_outcome <- ezANOVA(
  data = tratamento,
  dv = resultado,
  wid = id,
  within = tempo,
  between = grupo,
  type = 3,
  detailed = TRUE,
  return_aov = TRUE)
```

A mensagem de aviso informa que os grupos estão desbalenceados em relação à quantidade de participantes, o que foi mencionado acima. Antes de interpretar os resultados, é necessário verificar os pressupostos já que a validade dessa interpretação é atrelada à manutenção (ou sua ausência) dos pressupostos que a técnica solicita.  

No caso da ANOVA de Medidas Repetidas, é necessário verificar a <u>normalidade</u> e a <u>esfericidade</u>. A normalidade pode ser feita via gráficos e testes estatísticos formais. A esfericidade é verificada resgatando o objeto anteriormente definido (`ez_outcome`) e o examinando passo a passo. A principal novidade dos pressupostos está na esfericidade, que guarda um princípio similar à homogeneidade e pode ser entendida como sua extensão. A esfericidade se refere às variâncias das diferenças entre todos os pares de medidas serem similares e a homogeneidade se refere à constância das variâncias entre os grupos [@Quen2004].

A normalidade dos resíduos é vista pelo gráfico a seguir. Repare que a função `mutate` foi utilizada para adicionar uma coluna com os resíduos do modelo à base de dados antes de plotá-los. 

```{r, message=FALSE}
tratamento %>% 
  mutate(residuos = proj(ez_outcome$aov)[[3]][, "Residuals"]) %>% 
  ggplot(aes(x=residuos)) +
      geom_histogram(colour="black", fill="grey") +
      geom_density(aes(y= ..count..))
```

É possível argumentar que a normalidade dos resíduos foi relativamente mantida. Caso o interesse fosse um teste formal, ele seria feito pelo `Shapiro Wilk`, que assume $H_0$ de normalidade. 

```{r}
shapiro.test(proj(ez_outcome$aov)[[3]][, "Residuals"])
```

Por esse último resultado, como o valor de p foi inferior ao alfa tipicamente estabelecido (0.05), não seria possível manter o pressuposto da normalidade e algo deveria ser feito, como transformação dos dados ou implementação de outra técnica analítica. No entanto, desde a década de 1960 é sabido que o valor de p é inversamente associado ao tamanho da amostra [@Lin2013; @Nunnally1960]. Nessa análise, há 200 observações (40 participantes em cada um dos 5 pontos de medida), o que influencia na redução do valor de p [@Lin2013]. Dessa maneira, o resultado exposto previamente no gráfico é considerado nessa análise.

Já a esfericidade é testada pelo **teste de Mauchly**. Esse teste define a hipótese nula como presença da esfericidade e idealmente a não rejeição da $H_0$ é desejada. No entanto, quando o pressuposto da esfericidade é rejeitado, é necessário aplicar algum ajuste, como a <u>correção de Greenhouse-Geisser</u> ou a de <u>Huynh-Feldt</u>. Ambas as técnicas ajustam os graus de liberdade a partir de um coeficiente particular. 

Abaixo esta o `ez_outcome`, que é dividido em 4 blocos diferentes: `$ANOVA`, `$Mauchly's Test for Sphericity`, `$Sphericity Corrections` e `$aov`. Como são muitas informações, os resultados serão especificamente comentados.

```{r }
ez_outcome %>% pander::pander()
```
A primeira parte que se olha é o **Mauchly's Test for Sphericity**. Caso haja rejeição da hipótese nula, deve-se olhar inicialmente todos os resultados dispostos no **Sphericity Corrections** para depois olhar a parte **ANOVA**.    

Caso não haja rejeição da hipótese nula, basta os resultados já na parte **ANOVA**, que fica ao início do output.   

Nessa pesquisa, se rejeitou a esfericidade para o efeito principal do `tempo` (w = `r round(ez_outcome$"Mauchly's Test for Sphericity"[1,2],2) `, p < 0.05) e da interação `tempo x grupo` (w = `r round(ez_outcome$"Mauchly's Test for Sphericity"[2,2],2) `, p < 0.05). Dessa forma, as correções devem ser implementadas nos graus de liberdade de ambos os coeficientes. Duas correções são possíveis, a Greenhouse-Geisser (p[GG]) e a de Huynh-Feldt e existe uma regra prática (*rule of thumb*) para isso:  

1) Quando o valor de Greenhouse-Geisser (ϵ ou GGe) é inferior a 0.75, os valores dos graus de liberdade do numerador e do denominador são ajustados pela correção de Greenhouse-Geisser  
2) quando é superior a 0.75, o ajuste é feito pela de Huynh-Feldt. 

Nessa pesquisa, o ajuste será feito via Greenhouse-Geisser.  

Antes de iniciar a interpretação dos resultados, lembre-se que toda interpretação deve ser <u>sempre</u> iniciada pela interação. Caso ela seja significativa, <u>não se deve interpretar</u> os efeitos principais.

Repare que a parte **Sphericity Corrections** tem informações sobre a interação `tempo x grupo` e da `semana`. Esses efeitos devem ser interpretados aqui nessa seção, em vez da seção **ANOVA**. A interação `tempo x grupo` não é significativa. O valor de p é de 0.52. Manualmente, esse valor pode ser obtido computando a região crítica da cauda à direita da densidade da distribuição F. Para isso, é necessário plugar o valor de F obtido (`r round(ez_outcome$ANOVA[4,6],3) `), encontrado na primeira parte do output (**ANOVA**), e ajustar o numerador para 2.29 (DFn = `4 x 0.5739 =  2.29`) e o denominador para 87.24 (DFd=`152 x 0.5739 = 87.24`). Assim:

```{r}
1-pf(0.69, 4 * 0.57, 152 * 0.57)
```
  
O efeito principal do `tempo` é significativo, com valor de p = 0.03.

```{r}
1-pf(3.30, 4 * 0.57, 152 * 0.57)
```

O efeito principal do `grupo` deve ser visto diretamente na parte `ANOVA` e não é significativo. O valor de p é de 0.40, que pode ser manualmente computado assim:
```{r}
1-pf(0.71, 1, 38)
```

Assim, é possível concluir que o passar do tempo gerou uma diferença significativa no resultado da dor dos animais (VD), mas que isso não é relacionado a nenhum grupo específico. Em outras palavras, esse efeito não depende do grupo em que o animal se encontra. 

Frequentemente, os resultados corrigidos e os não-corrigidos concluem na mesma direção. Isso é verdadeiro nesse caso. Repare que os resultados não corrigidos:

```{r }
summary(ez_outcome$aov) %>% pander::pander()
```
Chegariam as mesmas conclusões dos corrigidos:  

```{r}
ez_outcome$`Sphericity Corrections`%>% pander::pander()
```


O valor de P do efeito do `tempo` saiu de 0.01 (sem correção) para 0.03 (com correção). Já a interação `grupo x semana` saiu de 0.59 (sem correção) para 0.52 (com correção).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados a partir de uma ANOVA de medidas repetidas investigando o efeito fixo do grupo e do tempo, bem como a interação entre ambos. O teste de Mauchly indicou a violação da esfericidade (w = 0.26, p < 0.01) e, portanto, os graus de liberdade foram corrigidos pelo ajuste de Greenhouse-geisser (ϵ = 0.57). Não houve interação significativa entre o grupo e o tempo (F(2.29, 87.24) = 0.69), nem efeito do grupo (F(1, 38) = 0.71, p < 0.40). O passar de tempo foi significativo no resultado, apesar de apresentar um efeito pequeno (F(2,29, 87.24) = 3.30, p = 0.035, np2 = 0.01). 
```




## Resumo  

1. A ANOVA de medidas repetidas é um teste bastante utilizado quando participantes de mesmos grupos são avaliados longitudinalmente  
2. Este modelo pode ser entendido como uma expansão de uma ANOVA ou um caso particular de uma regressão linear de efeitos mistos  
3. A execução deste teste no R solicita que a base seja transformada para o formato longo  
4. A interpretação dos resultados é, inicialmente, complicada e precisa ser feita de maneira cautelosa  
 

