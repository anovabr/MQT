# Teste T

```{r base e pacotes Teste T, include = FALSE }
load(file="~/anovabr/mqt/bases/Livro - R - ASQ SE 12 e 18.RData")

library(tidyverse)
library(knitr) #tables and graphs
library(kableExtra) #tables with different styles


```

```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar o Teste T  
2. Discutir os pressupostos de execução do Teste T  
3. Realizar gráficos relacionados à comparação de médias  
4. Apresentar e interpretar métricas de tamanho do efeito  
5. Dar exemplos relacionados à escrita dos resultados 
6. Apresentar versões não paramétricas do Teste T (Wilcoxon-Mann-Whitney)
```

O Teste T é um teste estatístico frequentemente utilizado para testar hipóteses sobre <u>diferenças entre médias</u>. Por utilizar dados amostrais para estimar um parâmetro ($\mu$), ele é um teste parâmetrico. Apenas por um preâmbulo histórico, a origem do Teste T remonta o artigo publicado em 1908 por William Gosset. Na época, em função de seu trabalho na cervejaria Guiness, ele não assinou o artigo, mas apenas usou seu pseudônimo *Student*, motivo pelo qual o Teste T também é chamado de Teste T de Student.   

É importante notar que estudantes de Psicologia e profissionais que trabalham com avaliação psicológica costumam ser deparados com uma métrica chamada "T score" (Escore T, as vezes), desenvolvido em 1939 por um professor de Psicologia (William Anderson McCall). Tenha em mente que essa métrica não tem relação com os procedimentos inferenciais relacionados ao Teste T a não ser uma similaridade de nome [@Krus1977]. 

É possível usar o Teste T para comparar a média de uma amostra com a média populacional (*one sample t test*), para comparar duas médias amostrais (*two sample t test*) ou para  comparar duas médias de uma mesma amostra que foi investigada em dois momentos do tempo (*paired ou matched t test*). 

Se assume os seguintes pressupostos funcionais à execução de um Teste T:  

*(i)* Os dados são aleatórios e representativos da população  
*(ii)* a variável dependente é contínua  
*(iii)* A distribuição dos resultados populacionais é assumida como normal    

Quando há o interesse de utilizar o Teste T para comparar os resultados de dois grupos, é também necessário que: 

*(iv)* As variâncias dos grupos seja homogênea (princípio da homocedasticidade)  
*(v)* ambos os grupos sejam independentes  

Quando se utiliza o Teste T pareado, se viola o princípio da independência, mas é necessário que:  

*(vi)* o tamanho amostral seja o mesmo  


Eventualmente, quando os pressupostos são violados, testes não-paramétricas com propostas parecidas podem ser implementadas. A tabela abaixo concatena os testes estatísticos relacionados e, para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida "ordinal".


  | Versão do teste | Um grupo           | Dois grupos independentes |  Grupos pareados    
  | :-----------    | :-----------       | :-----------              |  :-----------      
  | Paramétrica     | One-sample  t test | Two-samples t test        |  Paired t test
  | Não-paramétrica | Signed rank test   | Mann-whitney              |  Wilcoxon


Nota: Existe um intenso debate sobre a utilização de testes paramétricos e não-paramétricos em Psicologia. Algo pouco comentado, apesar de ser o aspecto mais importante em minha opinião, é que a hipótese testada em um teste paramétrico é diferente da testeda em um não-paramétrico. Ou seja, a substituição de um teste estatístico por outro, necessariamente, muda a hipótese de pesquisa investigada.  


## Pesquisa
  
<div class="alert alert-info" role="alert">
  <strong>Base: </strong> Livro - R - ASQ SE 12 e 18  
</div>  


Neste capítulo, vamos utilizar a pesquisa intitulada [“Confirmatory analysis and normative tables for the Brazilian Ages and Stages Questionnaires: Social–Emotional”](https://onlinelibrary.wiley.com/doi/abs/10.1111/cch.12649), publicada em 2019 na Child Care Health Development. Esse trabalho teve dois objetivos. O primeiro visou confirmar a estrutura fatorial de um instrumento utilizado para avaliar possíveis atrasos no desenvolvimento de competências sociais e emocionais (ASQ:SE) e o segundo visou desenvolver tabelas normativas para comparar meninos e meninas. Essa é uma pesquisa muito importante, visto que conta com uma base de dados robusta (mais de 50 mil participantes) e faz interface entre psicometria, avaliação psicológica e políticas públicas.



Neste capítulo, nosso o interesse será é o de comparar os resultados médios obtidos por meninos e meninas aos 12 e 18 meses. Assim, é necessário a escrita adequada das hipóteses e o nível de significância adotado na análise. Dessa maneira:

$$H_0: \mu_{meninos} - \mu_{meninas} = 0 \\ H_a: \mu_{meninos} - \mu_{meninas} \neq 0 \\ \alpha = 0.05$$


## Execução no R  


A primeira etapa importante é assegurar que a base de dados tenha o resultado relacionado às competências sociais e emocionais das crianças. Esse valor será computado pela soma de todos os itens da escala. No dplyr, isso é feito pela integração da função `mutate` com a `select` e será executado às crianças com 12 (asq_12months) e 18 meses (asq_18months). 

```{r}
asq_12months <- asq_12months %>% 
  mutate(total_12 = rowSums(select(., starts_with("q_")), na.rm = TRUE))

asq_18months <- asq_18months %>% 
  mutate(total_18 = rowSums(select(., starts_with("q_")), na.rm = TRUE))

```

Em seguida, iremos começar <u>pelos 12 meses</u>. O processo de testagem da hipótese é feito preliminarmente de maneira gráfica e, em seguida, pela implementação do teste específico e seus pressupostos. Apesar do gráfico não ser decisivo na tomada de decisão, ele auxilia a visualilzação da distribuição da variável que temos interesse, bem como oferece um entendimento inicial dos resultados.

Posto que a VI é tratada como discreta e a VD é continua, tanto o gráfico de colunas/barras como o de densidade são úteis. O gráfico de barras tem uma vantagem de ser possível adicionar barras de erros, que já apresentam uma primeira evidência inferencial.


```{r}
gridExtra::grid.arrange(
  #plot 1 
  ggplot(asq_12months, aes(x = sex, y = total_12, fill = sex)) +
    geom_bar(stat = "summary", fun = mean) +
    stat_summary(fun.data = mean_se, geom = "errorbar", width = .2),
  #plot 2
    ggplot(asq_12months, aes(x = total_12, fill = sex)) + 
    geom_density(color = NA, alpha=.6)
)
```

Feito isso, o próximo passo é a testagem formal da hipótese, que encontra-se abaixo:

```{r}
t_test_12m <- t.test(total_12 ~ sex, var.equal = T, data = asq_12months)
t_test_12m %>% pander::pander(., split.table = Inf)
```

Os resultados trazem a média de ambos os grupos (`r round(t_test_12m$estimate[1],2)` e `r round(t_test_12m$estimate[2],2)`), a estatística do teste (`r round(t_test_12m$statistic,2)`, as vezes chamada de T calculado), os graus de liberdade (`r t_test_12m$parameter`) e o valor de p `r round(t_test_12m$p.value,2)`. 

Repare que como <u>o valor de p é superior ao valor estipulado do nível de significância (0.05), falha-se em rejeitar a hipótese nula</u>, indicando que, apesar de numericamente distintos, os resultados não são estatisticamente significativos (na população).

Um aspecto importante é que a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer [@Lix1996; @Barker2015; @Ernst2017]. Corriqueiramente, testar os pressupostos é uma etapa <u>anterior</u> à própria realização do teste inferencial. Entretanto, <u>pedagogicamente</u> a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir.

<u> Normalidade</u>: O Teste T de duas amostras independentes assume que os resultados da variável de interesse se distribuam normalmente. É importante relembrar que o Teste T é um caso especial de um modelo de regressão, o que significa que a normalidade se refere aos <u>resíduos</u> do modelo. Neste caso pode, isso pode ser aproximado testando a distribuição marginal dos resultados de ambos os grupos.  


A normalidade pode ser avaliada graficamente por QQ-plots e por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera.

O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis conta os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade.

```{r}
ggplot(asq_12months, aes(sample = total_12)) + 
  stat_qq() + 
  stat_qq_line() +
  facet_wrap(~sex)
```

Apesar do gráfico já ter sido bastante claro e sugerir fortemente desvio da normalidade em ambos os grupos, o teste formal é importante. O Shapiro-wilk costuma ser utilizado neste caso, uma vez que ele reúne diferentes características positivas no balanço entre erro do tipo 1 e 2 [@Yap2011]. A hipótese nula desse teste assume que a variável de interesse tem distribuiÇào (aproximadamente) normal. Assim, rejeitar a hipótese nula sugere que esse princípio foi violado e, com isso, o Teste T pode ter resultados distorcidos.

```{r}
asq_12months %>% 
  group_by(sex) %>% 
  summarise(shapiro = shapiro.test(total_12)$p.value) %>% pander::pander()
```

De maneira convergente ao gráfico, o Shapiro-wilk também apontou que o princípio da normalidade foi violado.  


<u>Homocedasticidade</u>: A homogeneidade ou igualdade das variâncias pode ser testada visualmente, pelo teste de Levene ou teste de Bartlett. De maneira análoga ao Shapiro-wilk, estes últimos assumem como hipótese nula a homogeneidade das variâncias. Consequemente, a rejeição desse pressuposto pode também trazer resultados distorcidos ao resultado do Teste T. Diferentemente do pressuposto da normalidade, o pressuposto da homocedasticidade foi preservado, tal como apresentado abaixo:  



```{r}
car::leveneTest(total_12 ~ sex, data = asq_12months) %>% pander::pander()
```
  
Após testar estes pressupostos, é importante avaliar o quanto a interpretação originalmente deve ser mantida. Existem diferentes recomendações sobre o que fazer quando os pressupostos são violados. Entre eles, transformar a distribuição da variável de interesse, usar versões robustas do Teste T, usar testes não-paramétricos com objetivos próximos ao Teste T ou eleger algum modelo estatístico mais adequado à distribuição empírica obtida pelos dados. Parte dessas recomendações serão demonstradas a seguir.

---

Com isto concluído, é também possível verificar se existem diferenças em idades mais avançadas, <u>tal como 18 meses</u>. A sintaxe é customizável e torna-se fácil testar a hipótese da diferença apenas modificando a hipótese e a sintaxe. O gráfico a seguir é a primeira parte a ser feita e apresenta o padrão dos resultados aos 18 meses.  


```{r}
gridExtra::grid.arrange(
  ggplot(asq_18months, aes(x = sex, y = total_18, fill = sex)) +
  geom_bar(stat = "summary", fun=mean) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .2),

  ggplot(asq_18months, aes(x = total_18, fill = sex)) + 
  geom_density(color = NA, alpha=.6))
```

Tal como feito anteriormente, a realização do Teste T e a verificação de seus pressupostos devem ser realizadas. Em relação aos resultados do Teste T, eles indicaram que ambos os grupos tem resultados médios significativamente diferentes. Meninos apresentam resultados mais elevados (M = 24.92) do que meninas (M = 24.44).  

```{r}
t_test_18m <- t.test(total_18 ~ sex, var.equal = T,data = asq_18months)
t_test_18m %>% pander::pander(., split.table = Inf)
```

Diferentemente do anterior, agora o resultado foi significativo (p < 0.01), trazendo evidências que permitem concluir pela rejeição da hipótese nula. Desta vez, tantoa  normalidade como a homocedasticidade foram violados, fazendo que com as interpretações tornem-se frágeis, apesar de possíveis.  

Isso posto, é importante ter uma atenção especial ao conceito subjacente à significância estatística. <u>De forma alguma</u>, um resultado que rejeita a hipótese nula deve ser entendido como "aceitação da hipótese alternativa", tampouco como evidência de causalidade. É fundamental lembrar que o valor de P se refere à probabilidade de encontrar a estatística de teste calculada, ou uma ainda mais exterma, assumindo que a hipótese nula é verdadeira [@Wasserstein2016]. Apesar de algo contra-intuitivo (e talvez desanimador), é assim que a estatística frequentista funciona.

## Tamanho do efeito  

Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da <u>relevância clínica</u> dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde.

Existem duas famílias principais no ambiente do tamanho do efeito, que são a família "d" e a família "r". Tecnicamente, quando comparamos médias, usamos o d de Cohen para calcular a distância entre as médias das distribuições normais sobrepostas.

A interpretação é a seguinte:

  | Cohen's d      | Interpretação         
  | :-----         | :-----     
  | d < 0.2        | Irrelevante
  | d $\geq$ 0.2   | Pequeno
  | d $\geq$ 0.5   | Moderado      
  | d $\geq$ 0.8   | Grande 
  
Com esse conjunto de dados, o tamanho do efeito foi irrelevante, indicando que a diferença dos resultados não apresenta uma relevância clínica importante.   

```{r}
effsize::cohen.d(total_18 ~ sex, data = asq_18months)
```

## Execução no JASP

Da mesma forma que foi feita no R, a apresentação de gráficos auxiliam o pesquisador a verificar padrões diferentes nos dados. Nesta parte, apenas a base de crianças com [18 meses](https://osf.io/xr2sq/) será utilizada. Após carregar tal base, a seção `Descriptives` apresentará o gráfico inicial dos resultados.


![](./img/jasp_descriptives.png)

Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista `Variables` irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção `Split`. É importante atentar à opção `Frequency tables (nominal and ordinal)`, que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. 

![](./img/jasp_descriptives2.png)

Isto posto, será necessário arrastar as variáveis de interesse aos seus respectivos locais. Neste caso, o <u>total_18</u> para parte das VDs, enquanto <u>sexo</u> para a VI. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização.   


![](./img/cap_testet_tabela_descritiva.png)

Em seguida, ao clicar na opção `Plots`, será possível selecionar o <u>Boxplot</u>. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da <u>distribuição dos resultados</u> das crianças de 18 meses em função do <u>sexo</u>.


![](./img/cap_testet_tabela.png)

Para execução do Teste T, deve-se clicar em `T-Test` e, em seguida, `Independent samples T-test`. 

![](./img/cap_testet_interface1.png)

Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir:


![](./img/cap_testet_interface.png)

Repare que a `Grouping variable` é o local onde a VI deverá ser colocada, enquanto a `Variables` é o local onde a VD irá ser inserida. É possível ter apenas uma VI, enquanto diferentes VDs podem ser inseridas na seção `Variables` para serem analisadas independentemente.  Neste caso de agora, a VI é <u>sexo</u> e a VD é <u>total_18</u>. Ao fazer isso, o JASP automaticamente irá fazer o Teste T e apresentar os resultados. Pragmaticamente, o valor de P costuma ser utilizado para decisões estatísticas e ele está marcado pelo quadrado roxo. 


![](./img/cap_testet_resultados_iniciais.png)

Entretanto, da mesma forma como apresentado antes, a interpretação deste resultado <u>não pode ser feita de uma forma automática</u>. É necessário saber se os pressupostos foram ou não atendidos, bem como calcular o tamanho do efeito. Estas opções estão dispostas na parte inferior à esquerda do programa.


![](./img/cap_testet_pressupostos.png)

É necessário marcar ambas as opções para que os testes sejam realizados. Os resultados são os mesmos já obtidos pelo R e indicam que Ambos os pressupostos foram violados, sugerindo uma interpretação bastante cautelosa dos achados.

![](./img/cap_testet_pressupostos_resultados.png)

Finalmente, o resultado do tamanho do efeito foi inserido ao lado do Teste T e podem ser analisados em conjunto. O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença. 

![](./img/cap_testet_resultados.png)

Os resultados obtidos pelo JASP são identicos aos do R. Eventualmente, a diferença em relação ao sinal (+ ou -) é devida à codificação feita pelos programas e nada interfere na interpretação dos resultados.



## Escrita dos resultados


O primeiro achado foi que meninos e meninas não apresentaram diferenças em seus resultados médios quando tinham 12 meses. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA).


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 12 meses de idade. Os resultados mostraram que os valores médios de meninos e meninas não são significativamente diferentes (t(1039) = 0.37, p = 0.71). Dessa maneira, as diferenças encontradas podem ser mais bem explicadas por outras fontes de variações. 
```

Em seguida, verificamos que essa diferença é significativa aos 18 meses e abaixo uma outra sugestão de escrita.  

```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 2 anos de idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, DP = 21.8) e meninas (M = 24.9, DP = 20.3) são significativamente diferentes (t(5725) = 4.62, p < 0.01), apesar do tamanho do efeito ser irrelevante (d = 0.12). 
```  

## Versão robusta do Teste T

Em muitas situações, os pressupostos do Teste T são violados. Parte da literatura argumenta que o Teste T é robusto o suficiente para lidar com isso [@Lumley2002], enquanto outra parte sugere que é melhor optar por versões com médias aparadas, técnicas não-paramétricas [@Field2017] ou outros modelos estatísticos. O Welch test é considerado uma versão robusta do Teste T, uma vez que <u>não</u> assume homocedasticidade, ou seja, lida bem com grupos com variâncias distintas.  


O tamanho do efeito do Welch test é também o d de Cohen e, por isso, não será novamente calculado nesta seção.  

Um aspecto importante e que  não costuma ser discutido com tanta frequência é que a modificação do teste estatístico utilizado pode modificar a hipótese da pesquisa. Nesse sentido, a decisão de alterar ou não o teste inferencial deve ser feita com justificativa teórica por parte do pesquisador.



### Execução no R


Para executar o O Welch-test no R, deve-se alterar a sintaxe, estipulando `var.equal = F` na sintaxe previamente exposta. Como por padrão, o R executa o Welch test quando faz o Teste T, caso se remova este argumento por completo, este teste será calculado. Existem outras soluções disponíveis no pacote `WRS` , que não serão implementadas neste livro. 


O Welch-test será calculado considerando as crianças com <u>18 meses</u>

```{r}
t.test(total_18 ~ sex,data = asq_18months) %>% pander::pander(., split.table = Inf)
```


Repare que a estatística de teste, como os graus de liberdade apresentam são diferentes. No entanto, apesar disso, os resultados são virtualmente os mesmos obtidos anteriormente, indicando que os grupos apresentam valores distintos. 


### Execução no JASP  

No JASP, é possível acessar a versão robusta clicando em `Welch`, embaixo do `Student`, que já é previamente marcado.

![](./img/cap_testet_welch.png)



## Mann-whitney

O teste de Wilcoxon-Mann-Whitney costuma ser chamado de versão não-paramétrica do Teste T. Na verdade, isso não é totalmente verdadeiro, já que eles testam hipóteses diferentes. Enquanto o Teste T compara médias, o Mann-whitney compara os valores ranqueados (postos). Nota-se que ele não é um teste para comparar medianas e que isso só ocorre em condições restritas.

No entanto, quando os pressupostos do Teste T são violados, o Mann-Whitney é um forte candidato para sua substituição. O pesquisador tem de sempre ter em mente que, se de um lado esse teste supera tais pressupostos, por outro ele responde a uma hipótese diferente daquela que o Teste T trabalha. 


### Execução No R

A sintaxe a seguir apresenta os resultados. Repare que as conclusões estatística são virtualmente identicas às obtidas previamente, em que foi possível rejeitar a hipótese nula.


```{r}
mann_whiyney_18m <- wilcox.test(total_18 ~ sex, data = asq_18months)
mann_whiyney_18m %>% pander::pander()
```


### Tamanho do efeito

O tamanho do efeito também pode ser calculado por $Z/\sqrt{(n)}$. O output padrão do R não oferece a informação de `Z`, mas o pacote `coin` dispõe dessa métrica.

```{r}
coin::statistic(coin::wilcox_test(total_18 ~ sex, data = asq_18months))
```
Assim, implementando a fórmula, o tamanho do efeito seria aproximadamete `0.06`.


### Execução no JASP

No JASP, é necessário marcar a opção `Mann-Whitney` no lugar da opção `Student`, já previamente definida. O JASP utiliza a Correlação rank-bisserial como método padrão para relatar o tamanho do efeito para o teste de Mann-Whitney.

![](./img/cap_testet_mw.png)


### Escrita dos resultados  

A literatura <u>não</u> é muito concordante em como escrever os resultados do Mann-Whitney e abaixo há uma sugestão.  

```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados pelo teste Wilcoxon-Mann-Whitney para investigar as diferenças nos resultados do desenvolvimento entre meninos (Mdn = 25, IQR = 30, M = 27.53, DP = 21.61) e meninas (Mdn = 20, IQR = 25, M = 24.95, DP = 20.34) com 18 meses de idade. Os resultados indicaram que os resultados foram significativos (W = 4368187, p < 0.01), mas com efeito negligenciável (0.12). 
```  



## Teste T e regressão

Conforme alertado, o Teste T é um caso particular de um modelo de regressão que assume que a variável independente é uma dummy. Isso significa que ao realizar um Teste T, o pesquisador está fazendo um modelo de regressão, mesmo que isso não lhe seja intuitivo em primeiro momento. Neste modelo, $b_0$ (intercepto) é o grupo que recebeu o valor 0 e $b_1$ (inclinação) é o grupo que recebeu o valor 1. Caso isso não tenha sido definido inicialmente, ao se usar o R, basta estipular que a variável é um <u>fator</u>.


```{r}
lm(total_18 ~ sex, data = asq_18months) %>% 
  olsrr::ols_regress()
```


Em função da ordem alfabética, o R atribuiu os meninos (`male`) como intercepto. Assim, o valor de $b_0$ será o valor médio obtido pelos dos meninos, que foi de `27.53`. A inclinação $b_1$ é justamente a diferença entre os valores dos meninos e das meninas (`24.95-27.53`) e, nesse caso, -2.58. A estatística F é equivalente a $t^2$ do Teste T em sua versão tradicional, que assume variâncias iguais entre grupos.

Agora torna-se mais intuitivo mostrar que a <u>normalidade no Teste T se refere à normalidade dos resíduos deste modelo de regressão</u>. Isso pode ser visualmente pela análise de um QQ plot, tal como a seguir.

```{r}
olsrr::ols_plot_resid_qq(lm(total_18 ~ sex, data = asq_18months))
```
  
Há também testes estatísticos formais, como o Shapiro-Wilk ou o Anderson-Darling. Nestes, a hipótese nula é de que os resíduos são normalmente distribuídos e idealmente não se deve rejeitá-la.

```{r}
nortest::ad.test(lm(total_18 ~ sex, data = asq_18months)$residuals)
```

Os resultados foram convergentes ao alcançados durante o capítulo, indicando pela violação da normalidade.  

A homocedasticidade pode ser investigada também por um gráfico, em que os resíduos são plotados contra os valores ajustados, tal como abaixo.

```{r}
olsrr::ols_plot_resid_fit(lm(total_18 ~ sex, data = asq_18months))
```

O teste de Levene, de Bartlett ou de Breusch-Pagan também oferecem recursos para tal análise. Todos estes indicam pela hipótese nula a homocedasticidade. 

```{r}
olsrr::ols_test_breusch_pagan(lm(total_18 ~ sex, data = asq_18months))
```

Os achados também concluem pela rejeição da homocedasticidade, tal como foi previamente apresentado. 

Mais detalhes sobre modelos de regressão são apresentados em capítulos específicos.  

## Resumo  

1. O Teste T é um teste paramétrico e alguns pressupostos devem ser checados antes da interpretação dos resultados
2. Com frequência, os pressupostos são violados e o pesquisador deverá tomar decisões sobre a manutenção, modificação ou substituição deste teste por outro
3. O Teste T é um caso particular de um modelo de regressão
4. O tamanho do efeito é uma métrica importante e deve ser apresentada


## Pesquisas adicionais  

1. Are Women Really More Talkative Than Men? (DOI: 10.1126/science.1139940)    
Nesta pesquisa, 96 participantes (210 mulheres and 186 homens) foram investigados entre 1998 e 2004. Os pesquisadores deram para todos um tipo de gravador de voz que eles deveriam utilizar diariamente. Ao fim, a média de palavras produzidas por homens e mulheres foram comparadas. 
