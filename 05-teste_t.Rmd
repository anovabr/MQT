# Teste T

```{r base e pacotes teste t, include = FALSE }

load(file="C:/Users/luisf/OneDrive/Documentos/anovabr/MQT/bases/Livro - R - ASQ SE all age intervals.RData")

library(tidyverse)
library(knitr) #tables and graphs
library(kableExtra) #tables with different styles


```

```{block, type="objectives"}
**Objetivos do capítulo**  
1. Apresentar o teste T  
2. Discutir os pressupostos de execução do teste T  
3. Realizar gráficos relacionados à comparação de médias  
4. Apresentar e interpretar métricas de tamanho do efeito  
5. Dar exemplos relacionados à escrita dos resultados 
6. Apresentar versões não paramétricas
```

O Teste T é um teste estatístico frequentemente utilizado para testar hipóteses sobre <u>diferenças entre médias</u>. Por utilizar dados amostrais para estimar um parâmetro ($\mu$), ele é um teste parâmetrico. Apenas por um preâmbulo histórico, a origem do Teste T remonta o artigo publicado em 1908 por William Gosset. Na época, em função de seu trabalho na cervejaria Guiness, ele não assinou o artigo, mas apenas usou seu pseudônimo *Student*, motivo pelo qual o teste T também é chamado de Teste T de Student. Estudantes de Psicologia e profissionais que trabalham com avaliação psicológica costumam ser deparados com uma métrica chamada "T score", desenvolvido em 1939 por um professor de Psicologia (William Anderson McCall). É importante avisar que esta métrica não ter relação com os procedimentos inferenciais relacionados ao teste T [@McCall1939; @Krus1977]. 

É possível estipular que o Teste T pode ser utilizado para comparar a média de uma amostra com a média populacional (*one sample t test*), ou quando se deseja comparar duas médias amostrais (*two samples t test*) ou um quando se compara duas médias de uma mesma amostra que foi investigada em dois momentos do tempo (*paired ou matched t test*). 

Se assume os seguintes pressupostos funcionais à execução de um Teste T:  

*(i)* Os dados são aleatórios e representativos da população
*(ii)* a variável dependente é contínua
*(iii)* A distribuição dos resultados populacionais é assumida como normal  

Quando se utiliza o Teste T para comparar os resultados de dois grupos, é também necessário que 

*(iv)* As variâncias dos grupos seja homogênea (princípio da homocedasticidade)
*(v)* ambos os grupos sejam independentes

Quando se utiliza o Teste T pareado, se viola o princípio da independência, mas é necessário que:
*(vi)* o tamanho amostral seja o mesmo


Eventualmente, quando os pressupos são violados, versões não-paramétricas podem ser implementadas. A tabela abaixo concatena os testes estatísticos relacionados e, para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados tem nível de medida "ordinal".


  | Versão do teste | Um grupo           | Dois grupos independentes |  Grupos pareados    
  | :-----------    | :-----------       | :-----------              |  :-----------      
  | Paramétrica     | One-sample  t test | Two-samples t test        |  Paired t test
  | Não-paramétrica | Signed rank test   | Mann-whitney              |  Wilcoxon



## Pesquisa
  
<div class="alert alert-info" role="alert">
  <strong>Base</strong> Livro - R - ASQ SE all age intervals
</div>  


Neste capítulo,  vamos utilizar a pesquisa intitulada “Confirmatory analysis and normative tables for the Brazilian Ages and Stages Questionnaires: Social–Emotional”, publicada em 2019 no Child Care Health Development. O objetivo da pesquisa se quebrou em dois eixos. O primeiro visando confirmar a estrutura fatorial de um instrumento utilizado para avaliar competências sociais e emocionais relacionadas ao desenvolvimento infantil e o segundo para gerar tabelas normativas ao desempenho obtido pelos meninos e meninas avaliados. Essa é uma pesquisa muito importante, uma vez que conta com uma base de dados robusta (mais de 50 mil participantes) e costura psicometria, avaliação psicológica e políticas públicas

## Execução no R  


O teste T trabalha com variáveis contínuas e nessa base de dados, isso será feito pela soma de todos os itens da escala. No dplyr, isso é feito pela integração da função `mutate` com a `select`

```{r}
asq_12months <- asq_12months %>% 
  mutate(total_12 = rowSums(select(., starts_with("q_")), na.rm = TRUE))
```

Para comparar os resultados médios obtidos por meninos e meninas aos 12 meses, o teste T é uma opção frequente. Em relação à formalidade analítica, é necessário escrita adequada das hipóteses e o nível de significância adotado nesta análise. Dessa maneira:

$$H_0 = \mu_{meninos} - \mu_{meninas} = 0 \\ H_a = \mu_{meninos} - \mu_{meninas} \neq 0 \\ \alpha = 0.05$$

Em seguida, o processo de testagem da hipótese é feito preliminarmente de maneira gráfica e, em seguida, pela implementação do teste específico. Apesar do gráfico não ser decisivo na tomada de decisão, ele auxilia a visualilzação da distribuição da variável que temos interesse, bem como oferece já um entendimento inicial dos resultados.

Uma vez que a VI é discreta e a VD é continua (exposta no capítulo \@ref(01-estatistica_descritiva)) tanto o gráfico de colunas/barras como o de densidade são úteis.

```{r}
gridExtra::grid.arrange(
  #plot 1 
  ggplot(asq_12months, aes(x = sex, y = total_12, fill = sex)) +
    geom_bar(stat = "summary") +
    stat_summary(fun.data = mean_se, geom = "errorbar", width = .2),
  #plot 2
    ggplot(asq_12months, aes(x = total_12, fill = sex)) + 
    geom_density(color = NA, alpha=.6)
)
  
```

Posto isso, o próximo passo é a testagem formal da hipótese. Como exposto, o teste T de duas amostras independentes assume que os resultados da variável de interesse se distribua normalmente e que variância entre os grupos seja homocedástica. Tecnicamente, como o teste T é um caso especial de um modelo de regressão, a normalidade da variável de interesse se refere aos resíduos do modelo e, neste caso pode ser testada pela distribuição marginal dos resultados de ambos os grupos.  

A normalidade pode ser avaliada graficamente por QQ-plots e por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera.

O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis conta os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade.

```{r}
ggplot(asq_12months, aes(sample = total_12)) + 
  stat_qq()  + stat_qq_line() +
  facet_wrap(~sex)
```

Apesar do gráfico já ter sido bastante claro e sugerir fortemente desvio da normalidade em ambos os grupos, o teste formal é necessário. O Shapiro-wilk costuma ser utilizado neste caso, uma vez que ele reúne diferentes características positivas no balanço entre erro do tipo 1 e 2.

```{r}
asq_12months %>% 
  group_by(sex) %>% 
  summarise(shapiro = shapiro.test(total_12)$p.value)
```



```{r}
t_test_12m <- t.test(total_12 ~ sex, data = asq_12months)
```

Como frequentemente o pressuposto da homogeneidade das variâncias é violado, o R já executa por padrão a versão robusta do teste T (Welch test). Nesse caso, o valor de P do teste T é de `r t_test_12m$p.value`, indicando pela não rejeição da hipótese nula. A apresentação abaixo traz o output do teste T.

```{r}
t_test_12m

```

```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados por um Teste T para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas. Os resultados mostraram que os valores médios de meninos e meninas não não são significativamente diferentes (t(1037.4) = 0.368, p = 0.71). **Dessa forma, as diferenças podem ser mais bem explicadas por outras fontes de variações.** 
```

No entanto, é também possível verificar se existem diferenças em idades mais avançadas. A sintaxe é customizável e torna-se fácil testar a hipótese da diferença, por exemplo, aos 2 anos. Nesse sentido, o teste de hipóteses deve ser normalmente escrito:


$$H_0 = \mu_{meninos} - \mu_{meninas} = 0 \\ H_a = \mu_{meninos} - \mu_{meninas} \neq 0 \\ \alpha = 0.05$$

O gráfico novamente deve ser realizado


```{r}
plot_3 <- ggplot(asq_18months, aes(x = sex, y = score, fill = sex)) +
  geom_bar(stat = "summary") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .2)
plot_4 <- ggplot(asq_18months, aes(x = score, fill = sex)) + 
  geom_density(color = NA, alpha=.6)

gridExtra::grid.arrange(plot_3, plot_4)
```

E o teste formal computado:

```{r}
t_test_18m <- t.test(score ~ sex, data = asq_18months)
t_test_18m
```

Diferentemente do anterior, agora o resultado foi significativo (p < 0.01) e deve ser reportado:


```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados por um Teste T para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 2 anos de idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, SD = 21.8) e meninas (M = 24.9, SD = 20.3) são significativamente diferentes (t(5724.3) = -4.63, p < 0.01). 
```

É importante ter uma atenção especial à significância estatística. De forma alguma, um resultado que rejeita a hipótese nula (como o de agora) deve ser entendido como "aceitação da hipótese alternativa", tampouco como evidência de causalidade. É fundamental lembrar que o valor de P se refere à probabilidade de encontrar a estatística de teste calculada, ou uma ainda mais exterma, assumindo que a hipótese nula é verdadeira. Apesar de algo contra-intuitivo (e talvez desanimador), é assim que a estatística frequentista funciona.

## Tamanho do efeito 
Resultados significativos não são nenhum pouco claros em relação ao tamanho do efeito. Essa métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística.

Existem duas famílias principais no framework do tamanho do efeito, que são a família `d`e a família `r`. Tecnicamente, quando comparamos médias, usamos o d de cohen para calcular a distância entre as médias das distribuições normais sobrepostas.

A interpretação é a seguinte:

  | Cohen's d | Interpretação         
  | :-----    | :-----     
  | d $\geq$ 0.8   | Alto 
  | d $\geq$ 0.5   | Medio      
  | d $\geq$ 0.2   | Pequeno
  | d < 0.2   | Irrelevante


```{r}
library(effsize)
cohen.d(score ~ sex, data = asq_18months)
```

Agora é possível agregar ambos os resultados e a escrita iria por esse caminho.

```{block, type="writing"}
**Como escrever os resultados**  

Os dados foram analisados por um Teste T para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 2 anos de idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, SD = 21.8) e meninas (M = 24.9, SD = 20.3) são significativamente diferentes (t(5724.3) = -4.63, p < 0.01), apesar do tamanho do efeito ser negligenciável (d = 0.12) 
```  

## Teste T e regressão

Conforme alertado, o Teste T nada mais é do que um modelo de regressão que assume que a variável independente é uma dummy. Assim, $b_0$ é o grupo que recebeu o valor 0 e  $b_1$ é o grupo que recebeu o valor 1. Caso isso não tenha sido definido inicialmente, basta estipular que a variável é um *fator*, mesmo que de maneira implícita, e o R cuidará de todo o resto.

Nesse caso, o R atribuiu os meninos como intercepto o valor médio dos meninos e a inclinação $b_1$ é justamente a diferença entre os valores (*24.95-27.53)*. Nesse caso, -2.58. A estatística F é equivalente a $t^2$ do teste t em sua versão tradicional (assumindo que as variâncias dos grupos são igual, adicionando `var.equal = T` ao argumento)

```{r}
lm(score ~ sex, data = asq_18months) %>% 
  stargazer::stargazer(., type = "text")
```

## Aspectos matemáticos
