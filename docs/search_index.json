[
["index.html", "Métodos quantitativos em Psicologia com R Capítulo 1 Introdução 1.1 Objetivo 1.2 Bases 1.3 Pacotes e sintaxes 1.4 Aspectos gerais", " Métodos quantitativos em Psicologia com R Luis Anunciação (PUC-Rio), PhD 2020-04-15 Capítulo 1 Introdução Aprender estatística e análise de dados é uma das tarefas mais importantes e desafiadoras que existe no meio acadêmico, especialmente às disciplinas agrupadas em ciências humanas, como Psicologia. Por consequência, ensinar ambas as matérias também impõe um desafio enorme, mas necessário. Por diversas razões, as pesquisas feitas em Psicologia apresentam muitas informações misturadas e sobrepostas e a utilização da estatística é fundamental para conseguir separar e filtrar àquelas informações que temos interesse (sinal) daquelas que apenas distorcem estas primeiras (ruído). 1.1 Objetivo Talvez uma das coisas mais importantes para se ter em mente neste livro é que ele foi, propositalmente, escrito de forma pouco linear. Apesar de toda metodologia estatística ser apresentada de forma estruturada, os capítulos podem também ser acessados apenas para responder questões específicas, particulares e pontuais. Assim, penso que o livro consegue atender tanto aqueles leitores com interesse em ler a obra por completo, como aqueles que buscam apenas informações mais específicas de uma das partes. Evidentemente, como muitos testes estatísticos podem ser entendidos como casos particulares de outros, alguns fragmentos que podem parecer destoantes em alguns capítulos tornam-se fáceis e acessíveis àqueles que se dispuserem a fazer uma releitura após ter terminado uma leitura integral do livro. Para ilustrar, o capítulo sobre o Teste T expõe uma pequena parte sobre modelos de regressão, conteúdo que somente é abordado posteriormente. Se em um primeiro momento isso pode gerar alguma (pequena) confusão, a releitura do capítulo após o término da sequência do livro frequentemente se traduz em um resultado mais positivo e uma melhor percepção da integração que existe entre diferentes modelos estatísticos. 1.2 Bases Todas as bases de dados utilizadas neste livro são frutos de pesquisas empíricas que apresentam artigos publicados. Uma vez que o objetivo de um livro é diferente do objetivo da publicação de um artigo, alguns ajustes foram feitos às bases para torná-las mais acessíveis. Nenhuma alteração foi realizada nos dados, mas apenas em mudanças em relação a nomes de variáveis e quantidade de vetores. 1.3 Pacotes e sintaxes Este livro utiliza majoritariamente o ambiente tidyverse para realização das análises. Entretanto, sempre que necessário, funções R-base e uso de outros pacotes serão utilizados. Toda sintaxe utilizada no livro está disponível gratuitamente neste (GitHub)[https://github.com/anovabr/mqt]. 1.4 Aspectos gerais Conforme já explicitado, a estatística pode ser dividida em duas áreas interligadas: estatística descritiva e estatística inferencial. O objetivo da estatística descritiva é apresentar sínteses e resumos dos resultados a partir de gráficos e tabelas. Não é intenção dessa área fazer generalizações ou extrapolar os resultados obtidos em uma pesquisa a pessoas não investigadas durante a coleta de dados. Por contraste, a estatística inferencial visa extrapolar os dados e fazer generalizações que toquem toda população de onde aquela mostra foi retirada e é representativa. Dessa maneira, o principal objetivo da estatística inferencial é, de fato, fazer inferências. Apesar de livros e aulas unirem ambas as áreas da estatística, alguns pontos merecem destaque, que são: A estatística descritiva surgiu antes que a inferencial. A etimologia da palavra talvez ajude a entender, uma vez que estatística vem da palavra estado e este sempre teve interesse em saber quantos eram os cidadãos de um determinado local para, entre outras atividades, taxá-los. Dessa maneira, aspectos descritivos antecedem os inferenciais. Por sua vez, a estatística inferencial guarda origem e proximidade com a teoria dos jogos e, consequentemente, isso ajuda a entender o motivo pelo qual a maioria dos exemplos inferenciais envolvem jogos de azar. A estatística tem duas “escolas” ou “formas de pensamento”. A estatística frequentista e a estatística bayesiana. Aspectos fundamentais que tocam à definição de probabilidade são diferentes, bem como a definição de dados e parâmetros também o são. Pela perspectiva histórica, a estatística bayesiana é mais antiga que a frequentista. No entanto, se for comparado a proporção de uso entre os pesquisadores, a estatística frequentista é ainda a mais frequente e justifica a ênfase deste livro nesta área. A relação entre estatística e Machine Learning (ML) é relativamente recente. Apesar de grande interface, e do fato que as análises realizadas em estatística e ML encontram resultados virtualmente idênticos, as áreas têm objetivos diferentes. Ainda sob perspectiva histórica, a estatística, como uma área do conhecimento, é anterior à ML e, também por isso, justifica a ênfase do livro. "],
["estatística-descritiva.html", "Capítulo 2 Estatística Descritiva 2.1 Pesquisa 2.2 Condições gerais 2.3 Verbos do dplyr 2.4 Tabelas 2.5 Gráficos 2.6 1 variável discreta 2.7 1 variável contínua 2.8 2 variáveis com VI discreta (e VD contínua) 2.9 2 variáveis com VI contínua (e VD contínua) 2.10 Outros gráficos e configurações 2.11 Resumo", " Capítulo 2 Estatística Descritiva Objetivos do capítulo 1. Apresentar tabelas e gráficos 2. Introduzir os verbos do dplyr e funções do ggplot. 3. Oferecer convenções ou regras gerais para criação de gráficos 2.1 Pesquisa Base: Dados - Brasil e espanha fusionados Neste capítulo (e em alguns outros), vamos utilizar a pesquisa intitulada “Sintomas de depressão e ansiedade em universitários espanhóis, portugueses e brasileiros”, com previsão de publicação pela Revista Psicologia: Teoria e Pesquisa em 2020. Nessa pesquisa, sou o coautor e o pesquisador responsável para correspondência. O objetivo da pesquisa foi explorar sintomas de ansiedade e depressão em universitários, bem como investigar possíveis relações entre tais traços latentes e fatores sociodemográficos. Um diferencial importante do trabalho foi a seleção amostral. Partiu-se de uma amostra estratificada (probabilística) dos estudantes de três universidades, PUC-Rio (Brasil), Universidade de Extremadura (Espanha) e Universidade de Coimbra (Portugal). Isso permitiu ter maior validade externa dos resultados. 2.2 Condições gerais Todo documento acadêmico e científico é composto de aspectos textuais, tabulares e gráficos que devem caminhar na mesma direção e serem sempre associados às perguntas e objetivos traçados na pesquisa. É fácil perceber, dessa maneira, que a parte principal de qualquer trabalho acadêmico não são necessariamente os aspectos estatísticos, mas sim os objetivos e as possíveis hipóteses investigadas pelos pesquisadores. A estatística, neste sentido, é uma valiosa ferramenta de trabalho (ou uma atividade de meio) para que as perguntas sejam respondidas de forma adequada e válida. Frequentemente, as primeiras análises descritivas começam pela apresentação de tabelas e gráficos. Da mesma forma que a construção de um prédio depende que andaimes sejam colocados, um relatório técnico depende dessas condições. Ainda neste sentido, da mesma maneira que a conclusão do prédio cursa com a retirada dos andaimes, é bem possível que as versões finais de artigos científicos ou relatórios aproveitem apenas parte dos gráficos e tabelas desenvolvidos. Dito isso, o R e seus pacotes oferecem excelentes ferramentas para aspectos descritivos. No entanto, algumas apresentações relativamente simples frequentemente trazem uma dificuldade computacional intensa, o que pode gerar alguma desvantagem na utilização do R para tais apresentações quando comparados com programas mais acessíveis, como o Excel. No entanto, apesar dessa condição, a relação entre dificuldade e complexidade favorece o R àquelas tarefas mais complicadas, como realizar análises inferenciais e psicométricas, como apresentado a seguir. 2.3 Verbos do dplyr O dplyr funciona de maneira muito intuitiva. O padrão original do R considera que as operações são realizadas a partir de uma lógica do tipo verbo(sujeito, complemento) enquanto o ambiente tidyverse opta por sujeito %&gt;% verbo(complemento), tornando-se o ato de programar mais natural e associado à maneira que organizamos as ideias. Os verbos principais do pacote estão listados na tabela a seguir e as sintaxes deixadas no decorrer deste capítulo (e do livro) permitem uma melhor apreensão das funcionalidades. É importante lembrar que, em alguns momentos, em função da praticidade computacional, algumas sintaxes vão contar com o formato base do R. Verbo Ação glimpse Inspeciona os dados count Conta os níveis de uma variável select seleciona uma variável específica filter Filtra os resultados por um nível específico de uma variável group_by Agrupa os resultados por níveis de uma variávei específica summarise Apresenta sumários (com medidas estatísticas) mutate Cria novas variáveis ou altera as existentes arrange Organiza a apresentação dos resultados left_join Junta bases ou colunas pivot_longer Transforma uma base larga em longa pivot_wider Transforma uma base longa em larga É também importante ficar atento às atualizações do dplyr e do sistema tidyverse como um todo. Eventualmente, mudanças podem ocorrer e impossibilitar (ou dificultar) a reprodução de rotinas antigas. O site é o local ideal para acompanhar as atualizações. 2.4 Tabelas Tabelas apresentam os sumários informacionais de uma pesquisa de maneira reunida e objetiva. Como os verbos do dplyr possibilitam que os mesmos resultados sejam encontrados por vias diferentes, os códigos a seguir tentarão manter uma uniformidade lógica. Em alguns momentos, para ampliar as possibilidades de codificação, sintaxes extras serão oferecidas. A tabela a seguir apresenta a quantidade de participantes em cada país. Dataset %&gt;% group_by(country) %&gt;% summarise(n=n()) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country n Espanha 1216 Portugal 426 Brasil 315 É também possível adicionar proporções relativas à tabela, o que é uma escolha adequada para apresentação dos resultados. Dataset %&gt;% group_by(country) %&gt;% summarise(n=n(), Prop = n/nrow(.)) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country n Prop Espanha 1216 0.62 Portugal 426 0.22 Brasil 315 0.16 O pacote janitor oferece complementos úteis à família tidyverse e um deles justamente adiciona os totais, de maneira mais rápida e, em função disso, os exemplos também irão acessar as funções deste pacote. Dataset %&gt;% tabyl(country) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country n percent Espanha 1216 0.62 Portugal 426 0.22 Brasil 315 0.16 Total 1957 1.00 O mesmo que foi realizado com os países, pode também ser realizado com o sexo do participante. Dataset %&gt;% tabyl(sex) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) sex n percent valid_percent M 736 0.38 0.38 F 1214 0.62 0.62 NA 7 0.00 NA Total 1957 1.00 1.00 A adição do argumento para filtrar os participantes com dados ausentes sobre sexo auxilia a apresentar melhor os resultados. É importante atentar que essa análise tem finalidade descritiva e que omitir a apresentação de variáveis ausentes não significa excluir ou remover os participantes das análises que serão feitas posteriormente. Somente em possibilidades remotas se retira participantes das análises de maneira definitiva. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(sex) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) sex n percent M 736 0.38 F 1214 0.62 Total 1950 1.00 Para fazer uma tabela cruzada, em que seja possível apresentar a quantidade de homens e mulheres por país, épossível utilizar função pivot_wider: Dataset %&gt;% filter(!is.na(sex)) %&gt;% count(country,sex) %&gt;% pivot_wider(names_from = sex, values_from = n) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country M F Espanha 384 825 Portugal 203 223 Brasil 149 166 Da mesma maneira como continuar com o tabyl, mas agora adicionando uma variável. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(country, sex) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country M F Espanha 384 825 Portugal 203 223 Brasil 149 166 Total 736 1214 Finalmente, para apresentar a quantidade de participantes totais, bem como separar a quantidade e a porcentagem de homens e mulheres por país, a codificação torna-se mais densa. O código abaixo apresenta os comentários para auxiliar no entendimento da rotina. Dataset %&gt;% #get data #filter filter(!is.na(sex)) %&gt;% #agrupar group_by(country, add=TRUE) %&gt;% mutate(participantes = n()) %&gt;% #adicionar a relacao de quantidade de pais e sexo group_by(country, sex, participantes, add=TRUE) %&gt;% summarise( #cria a contagem de sexo sex_count = n(), #cria a porcentagem de sexo por pais sex_percentage = round(sex_count/first(participantes),2)) %&gt;% # cria uma variável agrupada mutate(n_percentage = paste0(sex_count,&quot; (&quot;,sex_percentage,&quot;)&quot;)) %&gt;% #seleciona apenas as variaveis de interesse select(country, sex, n_percentage, participantes) %&gt;% #Muda para formato largo de apresentação spread(sex, n_percentage, fill=&quot;-&quot;) %&gt;% #coloca os totais janitor::adorn_totals(&quot;row&quot;) %&gt;% kable(., digits = 2, booktabs = T) %&gt;% kable_styling(position = &quot;center&quot;, full_width = F, bootstrap_options = &quot;striped&quot;) country participantes M F Espanha 1209 384 (0.32) 825 (0.68) Portugal 426 203 (0.48) 223 (0.52) Brasil 315 149 (0.47) 166 (0.53) Total 1950 Ainda a partir da função tabyl, a realização desta tabela é simplificada. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(country, sex) %&gt;% adorn_totals(c(&quot;row&quot;, &quot;col&quot;)) %&gt;% adorn_percentages(&quot;row&quot;) %&gt;% adorn_pct_formatting(rounding = &quot;half up&quot;, digits = 0) %&gt;% adorn_ns() %&gt;% adorn_title(&quot;combined&quot;) %&gt;% kable(., digits = 2, booktabs = T) %&gt;% kable_styling(position = &quot;center&quot;, full_width = F, bootstrap_options = &quot;striped&quot;) country/sex M F Total Espanha 32% (384) 68% (825) 100% (1209) Portugal 48% (203) 52% (223) 100% (426) Brasil 47% (149) 53% (166) 100% (315) Total 38% (736) 62% (1214) 100% (1950) 2.5 Gráficos A máquina gráfica do tidyverse é o ggplot. Pelo menos 3 argumentos são necessários para criação de gráficos, que são: O banco dados (data = ), que pode ser omitido da sintaxe, O aspecto estético, que permite diferentes complementos aes(x = , y = , fill = , color = ), O aspecto geométrico, que varia em função do gráfico a ser apresentado geom_ É também possível adicionar outros argumentos, como: 4. Transformações estatísticas stat_summary 5. Facetas para dividir a visualização facet_ 6. Sistema de coordenadas coord_ 7. Temas específicos theme_ É importante notar que apesar dos argumentos utilizados na sintaxe serem similares aos utilizados em toda família tidyverse, a ligação %&gt;% é substituída pelo +. Quando bem feitos, os gráficos são extremamente úteis. Como aponta Morettin e Bussab (Morettin and Bussab 2010), eles possibilitam: (a) buscar padrões e relações; (b) confirmar (ou não) certas expectativas que se tinha sobre os dados; (c) descobrir novos fenômenos; (d) confirmar (ou não) suposições feitas sobre os procedimentos estatísticos usados; e (e) apresentar resultados de modo mais rápido e fácil. É sempre bom que o gráfico tenha um título e uma escala. A maioria dos gráficos são apresentados em um plano com um eixo horizontal (abcissas) e um vertical (ordenadas). Por sua vez, tais planos se referem, nessa ordem, ou aos níveis da variável que está sendo medida (eixo x) e as contagens ou proporções encontradas (eixo y) ou aos níveis da variável independente (eixo x) e os resultados médios da variável dependente (eixo y). Para eleger que gráfico será realizado, é necessário responder a duas perguntas que são atreladas às pesquisas em Psicologia e áreas congêneres: 1. Quantas variáveis serão apresentadas ? 2. Qual o nível de medida da variával independente ? O diagrama abaixo oferece uma árvore de decisão funcional. 2.6 1 variável discreta Quando há apenas uma variável discreta (incluindo aqui as categóricas), os gráficos são criados para apresentar as contagens e/ou suas proporções. Nesse caso, é recomendado utilização de um gráfico de barras ou gráfico de setor. Apesar de ser possível apresentar as frequências absolutas, esses resultados podem gerar distorção da informação e, portanto, é preferível sempre apresentar as proporções de ocorrência de uma determinada variável ou valor. Por definição, quando se trabalha com proporções, o valor máximo da soma das proporções é 100. O gráfico de barras abaixo apresenta a contagem absoluta dos participantes pesquisados em cada país. ggplot(Dataset, aes(x = country)) + geom_bar(stats = identity) + labs(x = &quot;País&quot;, title = &quot;Número de participantes nos países investigados&quot;) ## Warning: Ignoring unknown parameters: stats Já abaixo, as barras são utilizadas considerando os resultados proporcionais. Para isso, um recurso do pacote scales foi utilizado para adequar o eixo y e também para adicionar o valor às colunas. ggplot(Dataset, aes(x = country, y = ..prop.., group = 1)) + geom_bar(stat = &quot;count&quot;) + geom_text(aes(label=scales::percent(round(..prop..,2)), y=..prop..), stat= &quot;count&quot;, color = &quot;white&quot;, size = 3, position = position_stack(vjust = 0.5)) + scale_y_continuous(labels = scales::percent_format()) + labs(x = &quot;País&quot;, title = &quot;Proporção de participantes em cada país investigado&quot;) O gráfico de setor (as vezes chamado de pizza ou torta) pode também ser utilizado. O aspecto principal desse gráfico é apresentar os setores de maneira proporcional às frequências. ggplot(Dataset, aes(x=factor(1), fill=country))+ geom_bar(width = 1) + coord_polar(&quot;y&quot;) + labs(title = &quot;Proporção de participantes em cada país&quot;) 2.7 1 variável contínua Quando uma única variável é apresentada no gráfico e ela é continua, os gráficos adequados são o histograma, densidade e o boxplot. Abaixo um histograma da idade dos participantes: ggplot(Dataset, aes(x = age)) + geom_histogram(bins = 30, color = &quot;black&quot;, fill = &quot;lightgrey&quot;) + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_bin). Abaixo um gráfico de densidade da idade: ggplot(Dataset, aes(x = age)) + geom_density(fill = &quot;lightgray&quot;) + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_density). Por sua vez, abaixo o boxplot dessa mesma variável: ggplot(Dataset, aes(y = age, x = &quot;&quot;)) + geom_boxplot() + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_boxplot). O boxplot tem vantagens em comparação com os outros gráficos apresentados até agora. A caixa reúne 50% da distribuição (Q1, Mediana e Q3) e os bigodes são construídos com base em Q1 - 1.5*IQR e Q3 + 1.5*IQR. Apesar de algo difícil de visualizar ao início, a informação apresentada no boxplot e no gráfico de densidade são iguais. gridExtra::grid.arrange( #Grafico 1 ggplot(Dataset, aes(x = age)) + geom_density(fill = &quot;lightgray&quot;), #Grafico 2 ggplot(Dataset, aes(y = age, x = &quot;&quot;)) + geom_boxplot() + coord_flip(), top = &quot;Distribuição da idade dos participantes&quot; #título ) ## Warning: Removed 28 rows containing non-finite values (stat_density). ## Warning: Removed 28 rows containing non-finite values (stat_boxplot). 2.8 2 variáveis com VI discreta (e VD contínua) Gráficos de barras ou colunas (considerando aqui as barras de erro) e o boxplot são adequados para apresentar essa relação. Basicamente, esses gráficos permitem verificar a diferença entre os grupos. Como exemplo, o gráfico abaixo mostra os resultados do Inventário Beck de Ansiedade entre 3 países investigados. As barras de erro são importantes para verificar, inicialmente, as possíveis diferenças significativas entre os países. ggplot(Dataset, aes(x = country, y = bai_sum)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(geom = &quot;errorbar&quot;,fun.data = mean_se, width = .5) ## No summary function supplied, defaulting to `mean_se() O boxplot a seguir também é um gráfico indicado: ggplot(Dataset, aes(x = country, y = bai_sum)) + geom_boxplot() 2.9 2 variáveis com VI contínua (e VD contínua) Assumindo que a VI é contínua e a VD também, o gráfico de pontos e de dispersão são virtualmente identicos e indicados. Esses gráficos permitem verificar a associação entre as variáveis. No ggoplot, o argumento geom_point e geom_jitter são possíveis. Abaixo, utilizando os pontos. ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_point() ## Warning: Removed 28 rows containing missing values (geom_point). Abaixo, utilizando o jitter ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_jitter() ## Warning: Removed 28 rows containing missing values (geom_point). Tradicionalmente, de maneira análoga às barras de erros apresentadas em gráficos cujas VIs são discretas, adiciona-se uma reta de regressão amostral (fra) quando a VI é contínua, tal como apresentado a seguir. ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_smooth). ## Warning: Removed 28 rows containing missing values (geom_point). 2.10 Outros gráficos e configurações Evidentemente, é possível apresentar mais informações nos gráficos com mais de um variável apresentada, desde que elas sejam relacionadas ao problema de pesquisa estudado e não sobrecarreguem a visualização dos resultados. Frequentemente, as informações adicionais são feitas pela inclusão de clusters ou agrupamentos. Isso é tanto possível em gráficos cuja VI seja discreta quanto contínua. No exemplo abaixo, o gráfico dos resultados do Inventário Beck de Ansiedade entre os 3 países investigados (VI discreta) agora está agrupado pelo sexo do participante. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = country, y = bai_sum, fill = sex)) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;) + stat_summary(geom=&quot;errorbar&quot;, fun.data = mean_se, position = position_dodge(0.95), width = .5) ## No summary function supplied, defaulting to `mean_se() Já no exemplo abaixo, a relação entre idade e pontuação no Inventário Beck de Ansiedade está agora agrupada pelo sexo do participante. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## Warning: Removed 24 rows containing non-finite values (stat_smooth). ## Warning: Removed 24 rows containing missing values (geom_point). Em situações onde existe uma grande quantidade de informação para ser apresentada, os resultados começam a se tornar difíceis de serem entendidos. O gráfico abaixo, por exemplo, é excessivamente carregado de informação e, consequentemente, inadequado. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex, shape = country)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## Warning: Removed 24 rows containing non-finite values (stat_smooth). ## Warning: Removed 24 rows containing missing values (geom_point). Em outro sentido, o gráfico a seguir quebra a apresentação dos resultados por país e, com isso, potencializa que a informação seja melhor compreendida. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) + facet_wrap( ~ country) ## Warning: Removed 24 rows containing non-finite values (stat_smooth). ## Warning: Removed 24 rows containing missing values (geom_point). 2.11 Resumo Este capítulo apresentou os aspectos tabulares e gráficos corriqueiramente encontrados em pesquisas de Psicologia e áreas congêneres. Entre os pontos principais, a heurística típica de construção de gráficos é um conteúdo importante para ser sempre lembrado. References "],
["teste-t.html", "Capítulo 3 Teste T 3.1 Pesquisa 3.2 Execução no R 3.3 Tamanho do efeito 3.4 Versão robusta do teste T 3.5 Mann-whitney 3.6 Teste T e regressão 3.7 Aspectos matemáticos 3.8 Resumo", " Capítulo 3 Teste T Objetivos do capítulo 1. Apresentar o teste T 2. Discutir os pressupostos de execução do teste T 3. Realizar gráficos relacionados à comparação de médias 4. Apresentar e interpretar métricas de tamanho do efeito 5. Dar exemplos relacionados à escrita dos resultados 6. Apresentar versões não paramétricas do teste T (Wilcoxon-Mann-Whitney) O Teste T é um teste estatístico frequentemente utilizado para testar hipóteses sobre diferenças entre médias. Por utilizar dados amostrais para estimar um parâmetro (\\(\\mu\\)), ele é um teste parâmetrico. Apenas por um preâmbulo histórico, a origem do Teste T remonta o artigo publicado em 1908 por William Gosset. Na época, em função de seu trabalho na cervejaria Guiness, ele não assinou o artigo, mas apenas usou seu pseudônimo Student, motivo pelo qual o teste T também é chamado de Teste T de Student. É importante notar que estudantes de Psicologia e profissionais que trabalham com avaliação psicológica costumam ser deparados com uma métrica chamada “T score” (Escore T, as vezes), desenvolvido em 1939 por um professor de Psicologia (William Anderson McCall). Tenha em mente que essa métrica não ter relação com os procedimentos inferenciais relacionados ao teste T a não ser uma similaridade de nome (???; ???). É possível estipular que o Teste T pode ser utilizado para comparar a média de uma amostra com a média populacional (one sample t test), para comparar duas médias amostrais (two sample t test), ou para comparar duas médias de uma mesma amostra que foi investigada em dois momentos do tempo (paired ou matched t test). Se assume os seguintes pressupostos funcionais à execução de um Teste T: (i) Os dados são aleatórios e representativos da população (ii) a variável dependente é contínua (iii) A distribuição dos resultados populacionais é assumida como normal Quando há o interesse de utilizar o Teste T para comparar os resultados de dois grupos, é também necessário que: (iv) As variâncias dos grupos seja homogênea (princípio da homocedasticidade) (v) ambos os grupos sejam independentes Quando se utiliza o Teste T pareado, se viola o princípio da independência, mas é necessário que: (vi) o tamanho amostral seja o mesmo Eventualmente, quando os pressupostos são violados, versões não-paramétricas podem ser implementadas. A tabela abaixo concatena os testes estatísticos relacionados e, para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida “ordinal”. Versão do teste Um grupo Dois grupos independentes Grupos pareados Paramétrica One-sample t test Two-samples t test Paired t test Não-paramétrica Signed rank test Mann-whitney Wilcoxon 3.1 Pesquisa Base: Livro - R - ASQ SE all age intervals Neste capítulo, vamos utilizar a pesquisa intitulada “Confirmatory analysis and normative tables for the Brazilian Ages and Stages Questionnaires: Social–Emotional”, publicada em 2019 na Child Care Health Development. Esse trabalho teve dois objetivos. O primeiro visou confirmar a estrutura fatorial de um instrumento utilizado para avaliar competências sociais e emocionais relacionadas ao desenvolvimento infantil (ASQ:SE) e o segundo visou desenvolver tabelas normativas para comparar meninos e meninas. Essa é uma pesquisa muito importante, visto que conta com uma base de dados robusta (mais de 50 mil participantes) e costura psicometria, avaliação psicológica e políticas públicas 3.2 Execução no R Como exemplo, a variável dependente do teste T tem de ser contínua. Na base de dados específica às crianças de 12 meses (asq_12months), essa variável será computada pela soma de todos os itens da escala. No dplyr, isso é feito pela integração da função mutate com a select asq_12months &lt;- asq_12months %&gt;% mutate(total_12 = rowSums(select(., starts_with(&quot;q_&quot;)), na.rm = TRUE)) Uma vez que o interesse é o de comparar os resultados médios obtidos por meninos e meninas aos 12 meses, é necessário a escrita adequada das hipóteses e o nível de significância adotado na análise. Dessa maneira: \\[H_0 = \\mu_{meninos} - \\mu_{meninas} = 0 \\\\ H_a = \\mu_{meninos} - \\mu_{meninas} \\neq 0 \\\\ \\alpha = 0.05\\] Em seguida, o processo de testagem da hipótese é feito preliminarmente de maneira gráfica e, em seguida, pela implementação do teste específico. Apesar do gráfico não ser decisivo na tomada de decisão, ele auxilia a visualilzação da distribuição da variável que temos interesse, bem como oferece já um entendimento inicial dos resultados. Posto que a VI é discreta e a VD é continua (exposta no capítulo @ref(01-estatistica_descritiva)) tanto o gráfico de colunas/barras como o de densidade são úteis. O gráfico de barras tem uma vantagem de ser possível adicionar barras de erros, que serão melhores descritas futuramente. gridExtra::grid.arrange( #plot 1 ggplot(asq_12months, aes(x = sex, y = total_12, fill = sex)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width = .2), #plot 2 ggplot(asq_12months, aes(x = total_12, fill = sex)) + geom_density(color = NA, alpha=.6) ) ## No summary function supplied, defaulting to `mean_se() Feito isso, o próximo passo é a testagem formal da hipótese. Como exposto, o teste T de duas amostras independentes assume que os resultados da variável de interesse se distribua normalmente e que variância entre os grupos seja homocedástica. Tecnicamente, como o teste T é um caso especial de um modelo de regressão, a normalidade da variável de interesse se refere aos resíduos do modelo e, neste caso pode ser testada pela distribuição marginal dos resultados de ambos os grupos. A normalidade pode ser avaliada graficamente por QQ-plots e por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera. O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis conta os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade. ggplot(asq_12months, aes(sample = total_12)) + stat_qq() + stat_qq_line() + facet_wrap(~sex) Apesar do gráfico já ter sido bastante claro e sugerir fortemente desvio da normalidade em ambos os grupos, o teste formal é necessário. O Shapiro-wilk costuma ser utilizado neste caso, uma vez que ele reúne diferentes características positivas no balanço entre erro do tipo 1 e 2. a Hipótese nula desse teste assume que a variável de interesse tem distribuiÇào (aproximadamente) normal. Assim, rejeitar a hipótese nula sugere que esse princípio foi violado e, com isso, o teste T pode ter resultados distorcidos. asq_12months %&gt;% group_by(sex) %&gt;% summarise(shapiro = shapiro.test(total_12)$p.value) ## # A tibble: 2 x 2 ## sex shapiro ## &lt;fct&gt; &lt;dbl&gt; ## 1 M 1.98e-19 ## 2 F 4.80e-17 De maneira convergente ao gráfico, o Shapiro-wilk também apontou que o princípio da normalidade foi violado. Entretanto, por finalidades didáticas, as análises continuarão. A homogeneidade das variâncias pode ser testada visualmente e pelo teste de Bartlett ou Levene. De maneira análoga ao Shapiro-wilk, esses testes assumem como Hipótese nula a homogeneidade das variâncias. Consequemente, a rejeição desse pressuposto pode também trazer resultados distorcidos ao resultado do teste T. bartlett.test(total_12 ~ sex, data = asq_12months) ## ## Bartlett test of homogeneity of variances ## ## data: total_12 by sex ## Bartlett&#39;s K-squared = 1.1357, df = 1, p-value = 0.2866 Diferentemente do pressuposto da normalidade, o pressuposto da homocedasticidade foi preservado. Agora, finalmente, o teste T. (t_test_12m &lt;- t.test(total_12 ~ sex, var.equal = T, data = asq_12months)) ## ## Two Sample t-test ## ## data: total_12 by sex ## t = 0.36787, df = 1039, p-value = 0.713 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.077671 3.036424 ## sample estimates: ## mean in group M mean in group F ## 24.91713 24.43775 Os resultados trazem a média de ambos os grupos (24.9171271 e 24.437751), a estatística do teste (0.3678679, as vezes chamada de T calculado), os graus de liberdade (1039) e o valor de p 0.7130467. Repare que como o valor de p é superior ao valor estipulado do nível de significância (0.05), falha-se em rejeitar a Hipótese nula, indicando que, apesar de numericamente distintos, os resultados não são estatisticamente significativos. Como escrever os resultados Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas. Os resultados mostraram que os valores médios de meninos e meninas não não são significativamente diferentes (t(1039) = 0.37, p = 0.71). Dessa maneira, as diferenças encontradas podem ser mais bem explicadas por outras fontes de variações. Com isto concluído, é também possível verificar se existem diferenças em idades mais avançadas. A sintaxe é customizável e torna-se fácil testar a hipótese da diferença, por exemplo, aos 18 meses. Nesse sentido, o teste de hipóteses deve ser normalmente escrito: \\[H_0 = \\mu_{meninos} - \\mu_{meninas} = 0 \\\\ H_a = \\mu_{meninos} - \\mu_{meninas} \\neq 0 \\\\ \\alpha = 0.05\\] O gráfico novamente deve ser realizado gridExtra::grid.arrange( ggplot(asq_18months, aes(x = sex, y = score, fill = sex)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width = .2), ggplot(asq_18months, aes(x = score, fill = sex)) + geom_density(color = NA, alpha=.6)) ## No summary function supplied, defaulting to `mean_se() Bem como a verificação do pressuposto de normalidade e homocedasticidade, seguidos pelo teste formal. (t_test_18m &lt;- t.test(score ~ sex, var.equal = T,data = asq_18months)) ## ## Two Sample t-test ## ## data: score by sex ## t = 4.6185, df = 5725, p-value = 3.949e-06 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 1.484680 3.674581 ## sample estimates: ## mean in group M mean in group F ## 27.52685 24.94722 Diferentemente do anterior, agora o resultado foi significativo (p &lt; 0.01) e deve ser reportado: Como escrever os resultados Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 18 meses idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, SD = 21.8) e meninas (M = 24.9, SD = 20.3) são significativamente diferentes (t(5725) = 4.62, p &lt; 0.01). É importante ter uma atenção especial à significância estatística. De forma alguma, um resultado que rejeita a hipótese nula (como o de agora) deve ser entendido como “aceitação da hipótese alternativa”, tampouco como evidência de causalidade. É fundamental lembrar que o valor de P se refere à probabilidade de encontrar a estatística de teste calculada, ou uma ainda mais exterma, assumindo que a hipótese nula é verdadeira. Apesar de algo contra-intuitivo (e talvez desanimador), é assim que a estatística frequentista funciona. 3.3 Tamanho do efeito Resultados significativos não são nenhum pouco informativos em relação ao tamanho do efeito. Essa métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Assim, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos (em cenário biométrico, do tratamento ou condiçào). Existem duas famílias principais no framework do tamanho do efeito, que são a família “d” e a família “r”. Tecnicamente, quando comparamos médias, usamos o d de cohen para calcular a distância entre as médias das distribuições normais sobrepostas. A interpretação é a seguinte: Cohen’s d Interpretação d \\(\\geq\\) 0.8 Grande d \\(\\geq\\) 0.5 Moderado d \\(\\geq\\) 0.2 Pequeno d &lt; 0.2 Irrelevante library(effsize) cohen.d(score ~ sex, data = asq_18months) ## ## Cohen&#39;s d ## ## d estimate: 0.12216 (negligible) ## 95 percent confidence interval: ## lower upper ## 0.07025972 0.17406037 Agora é possível agregar ambos os resultados e a escrita iria por esse caminho. Como escrever os resultados Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 2 anos de idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, SD = 21.8) e meninas (M = 24.9, SD = 20.3) são significativamente diferentes (t(5725) = 4.62, p &lt; 0.01), apesar do tamanho do efeito ser negligenciável (d = 0.12). 3.4 Versão robusta do teste T Em muitas situações, os pressupostos do teste T são violados e parte da literatura argumenta que o teste T é robusto o suficiente para lidar com isso (Lumley et al. 2002), equanto outra parte sugere que é melhor optar por versões com médias aparadas ou não-paramétricas (Field and Wilcox 2017). No entanto, o que não costuma ser discutido com tanta frequência é que a modificação do teste estatístico utilizado, necessariamente, modifica a hipótese da pesquisa. Nesse sentido, a decisão de alterar o teste estatístico deve ser feito com justificativa teórica por parte do pesquisador. O pacote WRS apresenta versões robusta do Teste T. Ainda, o próprio R base oferece uma solução para condições em que a homogeneidade dos grupos não é aceita, que é o Welch-test. Esse teste é feito assumindo estipulando var.equal = F na sintaxe previamente exposta ou removendo este argumento por completo. 3.5 Mann-whitney A chamada versão não paramétrica do teste T é o teste de Wilcoxon-Mann-Whitney. Quando os pressupostos do teste T são violados, o Mann-Whitney é um forte candidato para sua substituição. Se de um lado esse teste supera tais pressupostos, por outro ele responde a uma hipótese diferente daquela que o teste T trabalha. Enquanto o teste T compara médias, o Mann-whitney compara os valores ranqueados (postos). Nota-se que ele não é um teste para comparar medianas e que isso só ocorre em condições restritas. (mann_whiyney_18m &lt;- wilcox.test(score ~ sex, data = asq_18months)) ## ## Wilcoxon rank sum test with continuity correction ## ## data: score by sex ## W = 4368187, p-value = 9.902e-06 ## alternative hypothesis: true location shift is not equal to 0 Os resultados foram convergentes ao previamente encontrado e, em outras palavras, tambem apoiam a rejeição da hipótese nula. O tamanho do efeito também pode ser calculado ao implementar \\(Z/\\sqrt{(n)}\\). O output padrão do R não oferece essa informação, mas o pacote coin dispõe dessa métrica. coin::statistic(coin::wilcox_test(score ~ sex, data = asq_18months)) ## [1] 4.41932 Assim, implementando a fórmula, o tamanho do efeito seria aproximadamete 0.06. Como escrever os resultados Os dados foram analisados pelo teste Wilcoxon-Mann-Whitney para investigar as diferenças nos resultados do desenvolvimento entre meninos (Mdn = 25, IQR = 30, M = 27.53, SD = 21.61) e meninas (Mdn = 20, IQR = 25, M = 24.95, SD = 20.34) com 18 meses de idade. Os resultados indicaram que os resultados foram significativos (W = 4368187, p &lt; 0.01), mas com efeito negligenciável (0.12). 3.6 Teste T e regressão Conforme alertado, o Teste T é um caso particular deum modelo de regressão que assume que a variável independente é uma dummy. Assim, \\(b_0\\) (intercepto) é o grupo que recebeu o valor 0 e \\(b_1\\) (inclinação) é o grupo que recebeu o valor 1. Caso isso não tenha sido definido inicialmente, basta estipular que a variável é um fator e o R cuidará de todo o resto. Nesse caso, o R atribuiu os meninos como intercepto o valor médio dos meninos e a inclinação \\(b_1\\) é justamente a diferença entre os valores (24.95-27.53). Nesse caso, -2.58. A estatística F é equivalente a \\(t^2\\) do teste t em sua versão tradicional (assumindo variâncias iguais entre grupos, adicionando var.equal = T à função). lm(score ~ sex, data = asq_18months) %&gt;% stargazer::stargazer(., type = &quot;text&quot;) ## ## =============================================== ## Dependent variable: ## --------------------------- ## score ## ----------------------------------------------- ## sexF -2.580*** ## (0.559) ## ## Constant 27.527*** ## (0.387) ## ## ----------------------------------------------- ## Observations 5,727 ## R2 0.004 ## Adjusted R2 0.004 ## Residual Std. Error 21.117 (df = 5725) ## F Statistic 21.331*** (df = 1; 5725) ## =============================================== ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 3.7 Aspectos matemáticos [Em desenvolvimento] 3.8 Resumo Este capítulo introdução à lógica por detrás do Teste T, ensinou sua execução, interpretaçào e escrita dos resultados. Frequentemente, os pressupostos que são exigidos à execução desse teste são violados e o teste de Wilcoxon-Mann-Whitney costuma ser implementado em substituição. Nesse sentido, este capítulo também apresentou os aspectos básicos deste teste. Finalmente, métricas relacionados ao tamanho do efeito foram calculadas e discutidas. É importante levar deste capítuloq que o Mann-Whitney e o teste T testam hipóteses diferentes e que significância estatística não é sinônimo de relevância clínica. References "],
["anova.html", "Capítulo 4 ANOVA 4.1 Legenda 4.2 Pesquisa 4.3 ANOVA de 1 via 4.4 ANOVA de 2 vias 4.5 ANOVA Fatorial", " Capítulo 4 ANOVA Objetivos do capítulo 1. Apresentar a ANOVA 2. Discutir os pressupostos de execução da ANOVA 3. Realizar gráficos relacionados à comparação de médias 4. Apresentar e interpretar métricas de tamanho do efeito 5. Dar exemplos relacionados à escrita dos resultados 6. Discutir os testes post-hoc 7. Apresentar versões não paramétricas da teste ANOVA (Kruskal-Wallis) A ANOVA é um teste estatístico desenvolvimento para verificar diferença entre diversos grupos. Pragmaticamente, é possível entender ANOVA como um super teste T, onde o que está em jogo não é somente o quanto as médias amostrais estão distantes, mas o quão distantes estão relativamente à variabilidade de observações individuais. Conceitualmente, similar ao teste T, a ANOVA é um caso especial de um modelo de regressão em que a variável independente é discreta/categórica. Em Psicologia, alguns autores indicam que a ANOVA é a técnica inferencial mais utilizada (Chartier and Faulkner 2008; Howell 2011). Se por um aspecto, isso é extremamente vantajoso por estreitar a relação entre Psicologia e Estatística, por outro, isso parece ter contribuído para criação e manutenção de diferentes conceitos equivocados sobre a ANOVA. Conceitualmente, a ANOVA é um modelo linear, tal que: \\[y_i = b_0 + b_1X{_1}_i + \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) é a inclinação (coeficiente angular) \\(\\epsilon_{i}\\) é o erro/resíduo Todos os pressupostos dos modelos linares são mantidos e o mnemônico LINE auxilia a resgatar todos eles. Assume-se que o erro é independente e identicamente distribuído (\\(iid\\)), distribuído normalmente com média 0 e variância constante \\(\\sigma^2\\), ou seja: \\[ \\epsilon\\stackrel{iid}{\\sim} \\mathcal{N}(\\mu,\\,\\sigma^{2})\\,\\] Além de homocedástico: \\[ VAR(\\epsilon |x_1,x_2,...,x_k)=\\sigma^2 \\]. iidainda signica erros descorrelatados \\[ COV(\\epsilon_1,\\epsilon_j)=0 \\]. É importante atentar que assumir média 0 \\(E(\\epsilon|x)=0\\), também implica que a correlação do erro com as variáveis é nula. Operacionalmente, o erro representa todos os fatores de pesquisa e problemas de medição que afetam o resultado além das variáveis independentes consideradas na modelagem. Da mesma forma que feito em outros capítulos, a tabela abaixo concatena os testes estatísticos relacionados quando os pressupostos são violados. Para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida “ordinal”. Versão do teste Um ou mais fatores Momentos repetidos Paramétrica Anova de k via(s) Anova de medidas repetidas Não-paramétrica Kruskal-Wallis Teste de Friedman ou Page Test A ANOVA tem diversas características de modelagem que serão descritas na seção a seguir, 4.1 Legenda Diferentes termos são empregados em uma ANOVA. A legenda a seguir visa auxiliar no entendimento de cada um deles e aproximar o leitor a conceitos amplos utilizados em modelos lineares: Fator: Variável independente, via, variável fonte, variável preditora, tratamento Desfecho: Variável dependente, variável critério Níveis: Grupos, condições, categorias da variável independente Efeito principal: Efeito da variável independente, sem considerar outras caracterísitcas do modelo Efeito de interação: Efeito do termo de interação entre duas ou mais variáveis independentes.Quando significativo, não se interpreta os efeitos principais. Efeito simples: Efeito de uma variável independente em um nível (específico) de outra variável independente. Por heurística, se escreve os delinementos estudados por uma ANOVA com \\(\\eta\\). Se, por exemplo, o interesse seja o de verificar o efeito do sexo (masculino ou feminino) e da escolaridade (fundamental, médio e superior), a representação será \\(\\eta = 2 \\times 3\\). Isso significa que a ANOVA tem dois fatores (sexo e escolaridade) e o primeiro fator tem dois níveis e o segundo tem 3 níveis. 4.2 Pesquisa Base: Livro - R - TEG Neste capítulo, vamos utilizar a pesquisa intitulada “A relação entre o nível de Empreendedorismo (TEG) e os aspectos sociodemográficos dos Taxistas cooperados da cidade de Santo André/São Paulo, Brasil”, publicada em 2016 na Revista Eletrônica de Gestão e Serviços, em que sou co-autor. O objetivo dessa pesquisa foi identificar o nível de empreendedorismo em 147 taxistas de Santo André/SP, bem como averiguá-lo em associação aos aspectos sociodemográficos. A base contém 14 variáveis, sendo 6 variáveis da escala utilizada para avaliação do empreendedorismo e 8 variáveis gerais, incluindo aqui os aspectos sociodemográficos, como sexo e escolaridade. Essa base será utilizada para realizar uma ANOVA de 1 via, 2 vias e uma ANOVA fatorial. 4.3 ANOVA de 1 via A pergunta que temos agora é sobre o possível efeito da escolaridade na Tendência Empreendedora Geral (teg). Trata-se de uma ANOVA de 1 via, dado que existe apenas uma VI, com mais de 2 níveis. 4.3.1 Execução no R Ao trabalhar no R, é fundamental se certificar que os tipos das variáveis estão corretamente definidos em função da escala de medida utilizada. Erros nessa etapa podem gerar resultados absolutamente incorretos. A escolaridade é uma variável categórica (ordinal, tratada como discreta) e é necessário definir claramente isso ao R antes da análise propriamente dita. Isso pode ser feito pela função case_when e levels. O case_when irá substituir os valores originalmente presentes nessa variável e o levels deixará claro a ordem de cada categoria, o que é útil para que os gráficos sejam feitos corretamente. dados_teg &lt;- dados_teg %&gt;% mutate_at(vars(escolaridade), ~factor(case_when( . == 1 ~ &quot;Primário&quot;, . == 2 ~ &quot;Ginásio&quot;, . == 3 ~ &quot;Colegial&quot;, . == 4 ~ &quot;Superior&quot;), levels=c(&quot;Primário&quot;,&quot;Ginásio&quot;,&quot;Colegial&quot;,&quot;Superior&quot;))) Uma vez que os itens de um instrumento sociodemográfico devem levar em consideração o contexto das pessoas avaliadas e, as categorias de escolaridade foram definidas como as apresentadas. Primário significa escolaridade até o 5º ano, ginásio significa escolaridade até o 9º ano e colegial é equivalente ao ensino médio. As hipóteses precisam ser descritas: \\[H_0 = \\mu_{escolaridade_i} - \\mu_{escolaridae_j} = 0 \\\\ H_a = c.c \\\\ \\alpha = 0.05\\] Aqui, o subscrito \\(i\\) e \\(j\\) foi utilizado de maneira liberal para apresentar a diferença entre todas as combinações lineares possíveis. Em seguida, a apresentação tabular das médias e desvios-padrão pode ser realizada. dados_teg %&gt;% group_by(escolaridade) %&gt;% summarise_at(vars(teg), lst(n=~n(),mean,sd)) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) escolaridade n mean sd Primário 6 24.67 4.63 Ginásio 33 26.76 3.86 Colegial 85 28.87 4.11 Superior 23 31.83 5.23 Tal como ilustrado no decorrer dos outros capítulos, gráficos são fundamentais para entendimento do relacionamento entre as variáveis. Uma vez que a escolaridade (VI) é tratada como discreta e a TEG (VD) é contínua, um gráfico de barras é adequado. A inclusão das barras de erro permite uma compreensão inferencial inicial. ggplot(dados_teg, aes(x=escolaridade, y = teg, fill = escolaridade)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;) + theme(legend.position = &quot;none&quot;) A visualização dos resultados já permite identificar algumas caracteríticas gerais. Primeiro, quão maior a escolaridade, maior o o valor obtido na escala. Segundo, algumas barras de erros estão superpostas e outras não, o que nos leva à conclusão preliminar de que resultados significativos estarão presentes na próxima etapa, que é a modelagem formal dessa hipótese. A modelagem formal irá contemplar n-1 níveis dos preditores e estipulará no intercepto o nível de referência. Dessa maneira: \\[y_{i} = b_{0} + b_1Esc_{ginasio_i} + b_2Esc_{colegial_i} + b_1Esc_{superior_i} + \\epsilon_{i}\\] \\(b_0\\) representa o intercepto, que aqui é o valor médio da Escolaridade primária \\(b_i\\) representa os outros preditores \\(\\epsilon_{it}\\) representa o erro A função lm será utilizada e o objeto mod_escolaridade será armazenado. É também possível utilizar a função aov e a escolha da lm foi apenas por conveniência. mod_escolaridade &lt;- lm(teg ~ escolaridade, dados_teg) Antes de checar os resultados, é necessário verificar se os pressupostos da ANOVA foram atendidos. Esses pedem que os resíduos sejam normalmente distribuídos e homocedásticos. Tal como previamente exposto no teste T, a investigação dessas condições é tanto feita por gráficos e testes formais e ambos são muito úteis. A análise da normalidade dos resíduos será inicialmente feita. O gráfico abaixo apresenta a distribuição dos resíduos: ggplot(fortify(mod_escolaridade), aes(.resid)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;grey&quot;) + geom_density(aes(y= ..count..)) O teste formal pode ser feito via shapiro-wilk. Tal como no teste T, a \\(H_0\\) desse teste assume normalidade e, idealmente, não deve ser rejeitada. shapiro.test(residuals(mod_escolaridade)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod_escolaridade) ## W = 0.97502, p-value = 0.008721 Uma vez que o valor foi menor do que o previamente estipulado ao \\(\\alpha\\), é possível concluir que o pressuposto da normalidade foi violado. situações como essa são muito frequentes. Na literatura, são presentes recomendações de ajuste dos dados por alguma função g(.) ou tornar mais severo o valor de p na interpretação dos resultados. Por exemplo, em vez de 0.05, usar 0.01. A homocedasticidade pode ser verificada por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico. ggplot(fortify(mod_escolaridade), aes(x=.fitted, y=.resid)) + geom_point() + geom_hline(yintercept = 0) Além do teste de Bartlett ou Levene, em que estipulam \\(H_0\\) como homocedasticidade e, idealmente, não deve ser rejeitada. car::leveneTest(mod_escolaridade) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 1.1372 0.3362 ## 143 A homocedasticidade foi assumida. Dessa maneira, mesmo com a violação da normalidade, o modelo será utilizado e seu sumário geral será apresentado pela função apa.aov do pacote apaTables. Isso é importante para garantir resultados programas tipicamente utilizados, como o SPSS e o STATA. Essa tabela é padronizada e muito similar na maioria dos programas estatísticos. Ela traz as seguintes informações principais: Preditor Soma dos Quadrados Graus de liberdade Quadrado médio Estat. F Fator Entre (SSB) K-1 MSB = SSB/ k-1 F = MSB/MSW Resíduo Dentro (SSW) N-k MSW = SSW/ N-K Total Total (SQT) N-1 Aqui, K significa quantidade de categorias dentro de um fator e N significa a quantidade de observações consideradas. As siglas em inglês são comumeiramente utilizadas falar falar da “Soma dos quadrados entre os grupos” (SSB), “Soma dos quadrados dentro dos grupos” (SSW), “Quadrado médio entre grupos” (MSB) e “Quadrado médio dentro dos grupos” (MSW). Repare também que,a este momento, os aspectos são apenas apresentados conceitualmente e não matematicamente. Em outro momento, aspectos da decomposição da variância serão também descritos. apaTables::apa.aov.table(mod_escolaridade) ## ## ## ANOVA results using teg as the dependent variable ## ## ## Predictor SS df MS F p partial_eta2 ## (Intercept) 3650.67 1 3650.67 200.61 .000 ## escolaridade 449.33 3 149.78 8.23 .000 .15 ## Error 2602.27 143 18.20 ## CI_90_partial_eta2 ## ## [.06, .22] ## ## ## Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared A leitura desse resultado é similar a de um modelo de regressão e a de outros modelos lineares e, em linhas gerais, em relatório ou publicações quase sempre apenas se diz que o modelo foi significativo, indicando as principais estatísticas obtidas da seguinte maneira: F(3,143) = 8.231, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]. No entanto, o que essa constatação está realmente dizendo é que houve uma comparação entre dois modelos, um que usou os resultados da variável “escolaridade” para prever os resultados obtidos pelo TEG (chamado de Modelo aumentado) e outro que usou apenas a média que o TEG (chamado de modelo compacto ou nulo neste caso). O resultado significativo indica que a inclusão da “escolaridade” no modelo testado foi significativamente capaz de reduzir o erro de previsão que o modelo nulo obteve (em ingles Proportional Reduction in Error ou PRE). Ainda nesse caso, o ηp2 (eta parcial quadrado) indica a proporção da variabilidade dos resultados do TEG que pode ser atribuídos à escolaridade e é uma métrica de tamanho do efeito, cuja interpretação se recomenda da seguinte maneira: ηp2 | Interpretação | :—– :—– | ηp2 \\(\\geq\\) 0.14 | Grande | ηp2 \\(\\geq\\) 0.06 | Moderado | ηp2 \\(\\geq\\) 0.01 | Pequeno | ηp2 &lt; 0.01 | Irrelevante De fato, quando isso ocorre, a busca por possíveis diferenças entre todas as comparações possíveis costuma ser feita por testes post hocs. Entretanto, é importante mencionar que que se uma ANOVA é significativa, isso não significa necessariamente que haverá alguma diferença entre as médias dos grupos. Tecnicamente, a diferença pode ocorrer em qualquer comparação possível, como grupo 1 contra grupos 2 + grupo 3 ou grupo 2 contra grupo 1+3. Dessa forma, o resultado geral da ANOVA e testes post hoc respondem questões diferentes e é possível realizar qualquer comparação múltipla sem sequer realizar a ANOVA, desde que os resultados sejam devidamente corrigidos caso se assuma alguns pressupostos sobre os constrastes. Uma vez que realizar uma ANOVA não é tecnicamente necessário para realização de comparações pareadas, é possível que alguém se pergunte qual é, então, a necessidade da realização deste primeiro teste. De fato, hoje em dia, a realização da ANOVA ocorre mais para que o pesquisador (i) consiga realizar computacionalmente todas as comparações pareadas entre as categorias da variável e, em seguida, (ii) corrigir adequadamente o valor de P obtido em cada computação. Isso dito, uma vez que a escolaridade foi significativa, as principais comparações serão testadas dois a dois.Sempre que múltiplas que comparações são realizadas, é esperado que haja uma inflação do erro do tipo 1 e, por isso, é necessário ajustar o valor de P. Repare que a quantidade de comparações pode ser calculada da seguinte forma: \\[ J*(\\frac{J-1}2) \\] , onde \\(J\\) é a quantidade de níveis da variável Nesse caso: \\[ 4*(\\frac{3}2) = 6 \\]. Para a comparação pareada, o pacote emmeans será utilizado. 4.3.2 Post hoc A mecanica do por detrás do post hoc é a comparação pareada de todos os níveis presentes no fator, seguido pelo ajuste do valor de P. Existem muitas técnicas para tal ajuste e elas costumam ser agrupadas em função da sua robustez à violação da homocedasticidade. Para fins práticos, vamos utilizar uma técnica considerada bastante conservadora, chamada de Bonferroni, que multiplica o valor bruto encontrado pela quantidade de comparações. O resultado das comparações dois a dois será armazenado em um objeto específico, nomeado como post_hoc_escolaridade. Isso será útil para apresentar sumários e gráficos. library(emmeans) ## Warning: package &#39;emmeans&#39; was built under R version 3.6.3 post_hoc_escolaridade &lt;- emmeans(mod_escolaridade, &quot;escolaridade&quot;) %&gt;% pairs(., reverse = TRUE, adjust = &quot;bonferroni&quot;) Tal como feito até agora, o gráfico inicial das comparações será realizado. A adição das barras de erro gera interpretação mais rápida e simples para todas as comparações. CI &lt;- confint(post_hoc_escolaridade) ggplot(mapping = aes(contrast, estimate)) + geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) + geom_point(data = summary(post_hoc_escolaridade)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_size(trans = &quot;reverse&quot;) + coord_flip() A apresentação tabular é fundamental e apresenta as estatísticas inferenciais de interesse: post_hoc_escolaridade %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) contrast estimate SE df t.ratio p.value Ginásio - Primário 2.09 1.89 143 1.10 1.00 Colegial - Primário 4.20 1.80 143 2.33 0.13 Colegial - Ginásio 2.11 0.87 143 2.42 0.10 Superior - Primário 7.16 1.96 143 3.66 0.00 Superior - Ginásio 5.07 1.16 143 4.37 0.00 Superior - Colegial 2.96 1.00 143 2.95 0.02 Os resultados são significativos na comparação Superior - Primário, Superior - Ginásio e Superior - Colegial. Em todos, os resultados do TEG foi mais elevado naqueles participantes que haviam concluído o ensino superior. A esse momento, a escrita é fundamental: Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de uma via investigando o efeito da escolaridade no empreendedorismo, medido por um escala específica. Foi possível concluir que a escolaridade é significativa (F(3, 143) = 8.23, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]) e as comparações pareadas, ajustadas pela técnica de Bonferroni, mostraram que os participantes com ensino superior apresentam pontuação mais alta do que àqueles com o primário (Δ = 7.16, p &lt; 0.01), ginásio (Δ = 5.07, p &lt; 0.01) e colegial (Δ = 2.96, p &lt; 0.05). 4.4 ANOVA de 2 vias Frequentemente, o interesse do pesquisador está em investigar como múltiplos fatores afetam a variável de interesse. Ao aumentar o número de variáveis independentes no modelo, se aumenta a quantidade de vias que a ANOVA possui. Se, por exemplo, a investigação visasse testar o efeito da escolaridade e do sexo no empreendedorismo, teríamos, por definição, uma ANOVA de duas vias. É fundamental atentar que essa modelage inicialmente considera apenas os efeitos principais dos fatores e não assume ou modela uma possível interação entre os preditores. 4.4.1 Execução no R Após a escrita adequada da hipótese, a modelagem segue o mesmo padrão da feita anteriormente, iniciando pela definição correta do tipo de variável em relação à sua escala de medida. dados_teg &lt;- dados_teg %&gt;% mutate_at(vars(sexo), funs( factor(case_when( . == 1 ~ &quot;Masculino&quot;, . == 2 ~ &quot;Feminino&quot;), levels=c(&quot;Masculino&quot;,&quot;Feminino&quot;)))) Tabelas e gráficos também devem ser apresentadas. dados_teg %&gt;% group_by(escolaridade, sexo) %&gt;% mutate(rn = row_number()) %&gt;% summarise_at(vars(teg), lst(n=~n(), mean, sd)) %&gt;% pivot_wider(names_from = sexo, #indexador unico names_sep = &quot;_&quot;, #pode ser removido values_from = c(n:sd)) %&gt;% #organizar valores kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) escolaridade n_Masculino n_Feminino mean_Masculino mean_Feminino sd_Masculino sd_Feminino Primário 6 NA 24.67 NA 4.63 NA Ginásio 30 3 27.03 24.00 3.91 2.00 Colegial 73 12 28.63 30.33 3.83 5.48 Superior 22 1 31.59 37.00 5.23 NaN Repare que não há desvio-padrão para mulheres com o ensino superior. Isso ocorre pela quantidade de participantes que satisfazem essas condições. Tecnicamente, isso ou impossibilitaria essa análise ou tornaria a interpretação altamente viesada. No entanto, por condição pedagógica, vamos seguir com o procedimento. Como o objetivo é verificar duas variáveis isoladamente, os gráficos também podem ser isolados. gridExtra::grid.arrange( ggplot(dados_teg, aes(x=escolaridade, y = teg, fill = escolaridade)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;), ggplot(dados_teg, aes(x = sexo, y = teg, fill = sexo)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;)) Agora, formalmente a modelagem será feita. Os passos devem ser exatamente os mesmos, incluindo a verificação de pressupostos e interpretação dos resultados. A esse momento, a tabela padronizada da ANOVA é a seguinte: Preditor Soma dos Quadrados Graus de liberdade Quadrado médio Estat. F Fator (A) Entre (SS(A)) K(A)-1 MS(A) = SS(A)/k-1 F = MS(A)/MSW Fator (B) Entre (SS(B)) K(B)-1 MS(B) = SS(B)/k-1 F = MS(B)/MSW Resíduo Dentro (SSW) N-1-(df(A)+df(B)) MSW = SSW/N-1-(df(A)+df(B)) Posto isso, os resultados obtidos são: mod_escolaridade_sexo &lt;- lm(teg ~ escolaridade + sexo, dados_teg) apaTables::apa.aov.table(mod_escolaridade_sexo) ## ## ## ANOVA results using teg as the dependent variable ## ## ## Predictor SS df MS F p partial_eta2 ## (Intercept) 3650.67 1 3650.67 200.36 .000 ## escolaridade 450.51 3 150.17 8.24 .000 .15 ## sexo 14.93 1 14.93 0.82 .367 .01 ## Error 2587.34 142 18.22 ## CI_90_partial_eta2 ## ## [.06, .22] ## [.00, .04] ## ## ## Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared Os resultados continuam constantando o efeito da escolaridade (F(3, 142) = 8.24, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]) no empreendedorismo, mas também concluiu que o efeito do sexo não é significativo (F(1, 142) = 0.816, p = 0.36, ηp2 = 0.01, 90% CI [.00, .04]). É importante ter atenção à forma de reportar os resultados, uma vez que delineamentos de dois fatores quase sempre produz coeficientes são diferentes do delineamento anterior. Assim, uma sugestão de escrita é a seguinte: #Apesar de não ter uma interpretação direta, o valor apresentado ao intercepto é o valor médio dos homens com escolaridade primária. Isso ocorre pois como há duas variáveis categóricas sendo analisadas, o valor utilizado para referência (ou seja, 0) do sexo foi para homens e este valor para escolaridade foi para aqueles com ensino primário. dados_teg %&gt;% filter(sexo == &quot;Masculino&quot; &amp; escolaridade == &quot;Primário&quot;) %&gt;% summarise(mean(teg)) summary(lm(teg ~ escolaridade + sexo, dados_teg))$coefficients[1,1] %&gt;% round(.,1) Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de duas vias investigando o efeito da escolaridade e do sexo no empreendedorismo. Foi possível concluir que a escolaridade é um fator significativo aos resultados (F(3, 142) = 8.24, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]), mas que o sexo não é significativo nessa relação (F(1, 142) = 0.81, p = 0.36, ηp2 = 0.01, 90% CI [.00, .04]). 4.5 ANOVA Fatorial A ideia da ANOVA fatorial é provavelmente uma das mais frequentes em perguntas de pesquisas, que consistem em tentar saber se os fatores tem alguma interação entre si. Nesse sentido, a modelagem envolve o cálculo de um terceiro parâmetro para investigar essa relação. Dessa maneira: \\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + b_3(X{_1}_i * X{_2}_i) + \\epsilon_{i}\\] Os coeficientes \\(b_1\\) e \\(b_2\\) estimam os efeitos principais, enquanto o \\(b_3\\) estima o efeito da interação. Dessa vez, é importante ressaltar alguns aspectos: Apesar de efeitos de interação poderem ser exploratórios, a ideia de adicioná-lo é fortemente relacionada à teoria. Ou seja, a modelagem é frequentemente confirmatória; A análise gráfica que é especialmente útil a todas as análises é ainda mais necessária nessa técnica; A interpretação dos resultados sempre começa pela interação. Caso ela seja significativa, não se interpreta os efeitos principais. Nessa pesquisa, tivemos o interesse em saber se o nível de empreendedorismo varia em função de uma interação entre sexo e estado civil (solteiro ou casado) dos participantes. Ou seja, se o nível de homens e mulheres variava em função deles(as) serem casados(as) ou não. Em áreas comportamentais, a interação entre o efeito estado civil e do sexo em características sociais é bastante estudado. 4.5.1 Execução no R Como mencionado, é fundamental ajustar todas as características da base para que os resultados não sejam distorcidos em função de definições computacionais. Como nessa pesquisa, também permitimos que pessoas divorciadas e viuvas, uma opção para deixar as análises totalmente pareadas com a pergunta da pesquisa é criar uma base contendo apenas solteiros (originalmente codificados com 1) e casados (originalmente codificados como 2). base_interacao &lt;- dados_teg %&gt;% filter(estado_civil == &quot;1&quot; | estado_civil == &quot;2&quot;) base_interacao &lt;- base_interacao %&gt;% mutate_at(vars(estado_civil), ~factor(case_when( . == 1 ~ &quot;solteiro&quot;, . == 2 ~ &quot;casado&quot;), levels=c(&quot;solteiro&quot;,&quot;casado&quot;))) Agora o gráfico apresentado deve combinar as duas variáveis independentes, uma no eixo de X e outro no agrupamento. A escolha de como apresentar estas variáveis não deve ser aleatória, mas ser atrelada à forma da pergunta de pesquisa. Se o interesse for responder “Quanto o estado civil depende do sexo para gerar os resultados do TEG” sugere que em X coloque-se a variável “estado civíl” e no agrupamento a variáel \"sexo. ggplot(base_interacao, aes(x = estado_civil, y = teg, group = sexo, col= sexo)) + geom_line(stat = &quot;summary&quot;, size=1) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width=0.1, size=1) O gráfico indica que existe um efeito de interação, uma vez que as linhas se cruzam. No entanto, o teste formal deve ser feito. Da mesma forma do realizado anteriormente, a modelagem omitirá a verificação dos pressupostos, que foi apresentada em etapa inicial. mod_int_sexo_civil &lt;- lm(teg ~ sexo * estado_civil, base_interacao) apaTables::apa.aov.table(mod_int_sexo_civil) ## ## ## ANOVA results using teg as the dependent variable ## ## ## Predictor SS df MS F p partial_eta2 ## (Intercept) 35206.10 1 35206.10 1696.99 .000 ## sexo 113.84 1 113.84 5.49 .021 .04 ## estado_civil 13.04 1 13.04 0.63 .429 .00 ## sexo x estado_civil 87.89 1 87.89 4.24 .042 .03 ## Error 2676.27 129 20.75 ## CI_90_partial_eta2 ## ## [.00, .11] ## [.00, .04] ## [.00, .10] ## ## ## Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared A leitura da tabela começa de cima para baixo, ou seja, pela interação. Neses caso, ela é significativa (F1, 129) = 4.23, p &lt; 0.05, ηp2 = 0.03, 90% CI [.00, .10]). Quando isso acontece, não se deve interpretar os efeitos principais, mesmo que eles sejam significativos. No caso, à pergunta “o sexo tem efeito no empreendedorismo”, a resposta adequada seria “depende”, uma vez que ele varia em função do estado civil do participante. O post hoc vez será também feito pelo pacote emmeans, que já foi carregado anteriormente. Para deixar a rotina clara, vamos armazenar os resultados no objeto post_hoc_int e, em seguida, explorar os coeficientes.Repare que dessa vez, os valores de p ajustados ou não são os mesmos, dado que há apenas duas categorias em cada grupo. post_hoc_int &lt;- emmeans(mod_int_sexo_civil, pairwise ~ sexo * estado_civil, adjust = &quot;bonferroni&quot;) O resultado deve ser acessado via contrastes. post_hoc_int$contrasts %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) contrast estimate SE df t.ratio p.value Masculino,solteiro - Feminino,solteiro -5.05 2.15 129 -2.34 0.12 Masculino,solteiro - Masculino,casado 0.69 0.87 129 0.79 1.00 Masculino,solteiro - Feminino,casado 1.17 1.67 129 0.70 1.00 Feminino,solteiro - Masculino,casado 5.74 2.10 129 2.73 0.04 Feminino,solteiro - Feminino,casado 6.22 2.54 129 2.45 0.09 Masculino,casado - Feminino,casado 0.48 1.60 129 0.30 1.00 Repare que as informações repetem aquilo já visualizado no gráfico anterior, mas com as correções, a interpretação torna-se menos visual. Os resultados indicam que as mulheres solteiras têm resultados mais elevados do que os homens casados (Δ = 5.74, p = 0.04) e que existe uma tendência das mulheres solteiras, quando comparadas às mulheres casadas, terem também mais empreendedorismo (Δ = 6.22, p = 0.09). Repare que a diferença visual entre homens e mulheres solteiras não é significativa. Em linhas gerais, parece que o empreendedorismo diminui em pessoas casadas e isso é especialmente válido às mulheres. "]
]
