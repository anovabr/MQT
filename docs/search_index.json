[
["index.html", "Métodos quantitativos em Psicologia com R Capítulo 1 Introdução 1.1 Objetivo 1.2 Público-alvo 1.3 Formato do livro 1.4 Bases 1.5 O R 1.6 Pacotes e sintaxes 1.7 Outros recursos", " Métodos quantitativos em Psicologia com R Luis Anunciação (PUC-Rio), PhD 2020-12-30 Capítulo 1 Introdução Aprender estatística e análise de dados é uma das tarefas mais importantes e desafiadoras que existe no meio acadêmico, especialmente às disciplinas agrupadas em ciências humanas, como Psicologia. Por consequência, ensinar ambas as matérias também impõe um desafio enorme, mas necessário. Frequentemente, pesquisas feitas em Psicologia apresentam um conjunto de resultados sobrepostos que, sem a utilização da estatística, torna-se impossível a separação e filtro daquelas informações que são válidas e despertam o interesse acadêmico (sinal) daquelas que apenas distorcem estas primeiras (ruído). 1.1 Objetivo Este livro tem como objetivo apresentar, discutir e operacionalizar conceitos relacionados à análise estatística de dados. A abordagem deste livro segue um padrão computacional e pragmático. Cada um dos capítulos irá usar uma publicação científica para articular uma determinada análise e seu conjunto de conceitos associados. Em menor nível, a modelagem matemática será apresentada e descrita. 1.2 Público-alvo Este livro foi desenvolvido com mais aderência a estudantes de pós-graduação em Psicologia, especialmente aos alunos do Departamento de Psicologia da PUC-Rio e de Psicometria da UFRJ. Apesar dos conceitos em estatística e análise de dados serem supradisciplinares, os exemplos tocam mais frontalmente perguntas feitas por psicólogos e neurociêntistas. 1.3 Formato do livro O livro foi pensando para ter uma estrutura linear formada por capítulos autossuficientes e desenvolvidos para responder questões específicas, particulares e pontuais. Dessa maneira, acredito que o livro atenda tanto aqueles leitores com interesse em ler a obra inteira, como aqueles que buscam apenas informações mais específicas de um tópico particular. Esse formato adotado tende a gerar uma percepção diferente entre aqueles que consultarem apenas um capítulo ou outro e aqueles que lerem o conteúdo por completo. Isso ocorre pois como muitos testes estatísticos são entendidos como casos particulares de outros, alguns fragmentos que podem parecer destoantes durante uma leitura inicial, tornam-se mais fáceis e articulados àqueles que lerem o trabalho inteiro e se dispuserem a fazer uma releitura de partes específicas. Para ilustrar, o capítulo sobre o Teste T expõe uma pequena parte sobre modelos de regressão, conteúdo que somente é abordado posteriormente. Se em um primeiro momento isso provavelmente pode gerar alguma (pequena) confusão, a releitura do capítulo após o término da sequência do livro poderá gerar, além de um conhecimento mais profundo por parte do leitor, a percepção da integração tanto da estrutura do livro, como da relação existente entre diferentes modelos estatísticos. 1.4 Bases Todas as bases de dados utilizadas neste livro são frutos de pesquisas empíricas que apresentam artigos publicados. Visando otimização, alguns ajustes foram feitos às bases para torná-las mais acessíveis. Nenhuma alteração foi realizada nos dados, mas apenas em mudanças em relação a nomes de variáveis e quantidade de vetores. Todo material pode ser acessado livre e gratuitamente em https://github.com/anovabr/mqt/tree/master/bases 1.5 O R O livro é feito integralmente no R, utilizando o Rmarkdown e funções nativas e do Tidyverse. Caso alguém apresente o interesse em reproduzir as análises, será necessário seguir todas as linhas de código disponíveis no decorrer dos capítulos. A parte textual e a parte de programação do texto se sobrepõem frequentemente e isso foi feito de maneira intencional, visando deixar todo o desenvolvimento deste livro o mais próximo o possível do cotidiano de pesquisadores e estatísticos. 1.6 Pacotes e sintaxes Este livro utiliza majoritariamente o ambiente tidyverse para realização das análises. Entretanto, sempre que necessário, funções R-base e uso de outros pacotes serão utilizados. Toda codificação utilizada no livro é exibida nos capítulos e integralmente disponível gratuitamente neste (GitHub)[https://github.com/anovabr/mqt] O tidyverse costuma ter atualizações frequentes e espero que as funções utilizadas durante o livro não sejam descontinuadas (deprecated) com o tempo. 1.7 Outros recursos Tão importante como saber como saber estatística e programação, é saber onde buscar ajuda (de qualidade) para as questões que, naturalmente, aparecem no decorrer das atividades. Eu recomendo fortemente a comunidade stackoverflow neste sentido. "],
["aspectos-gerais.html", "Capítulo 2 Aspectos gerais 2.1 Principais áreas da estatística 2.2 Considerações sobre escalas de medida e o processo de mensuração em Psicologia", " Capítulo 2 Aspectos gerais Os subtópicos a seguir ilustram um conjunto de conceitos importantes que tendem a ser apresentados antes mesmo de introduzir conceitos em Estatística. Como os conceitos são transversais, eles podem também ser úteis em métodos e técnicas de pesquisa em geral. 2.1 Principais áreas da estatística A estatística pode ser dividida em duas áreas interligadas: estatística descritiva e estatística inferencial. O objetivo da estatística descritiva é apresentar sínteses e resumos dos resultados de uma pesquisa pela utilização de gráficos e tabelas. Não é intenção dessa área fazer generalizações ou extrapolar os resultados obtidos a pessoas (ou objetos) não investigadas durante a coleta de dados. Por contraste, a estatística inferencial visa extrapolar os dados e fazer generalizações que toquem toda população de onde aquela mostra foi retirada e é representativa. Dessa maneira, o principal objetivo da estatística inferencial é, de fato, fazer inferências. Essa divisão é certamente mais didática do que pragmática e, com muita frequência, ambas as áreas estão presentes em uma pesquisa. No entanto, alguns pontos merecem destaque: A estatística descritiva surgiu antes que a inferencial. A etimologia da palavra talvez ajude a entender. Estatística vem da palavra estado e este sempre teve interesse em saber quantos eram os cidadãos de um determinado local para, entre outras atividades, taxá-los. Assim, aspectos descritivos antecedem os inferenciais. Por sua vez, a estatística inferencial guarda origem e proximidade com a teoria dos jogos e, consequentemente, isso ajuda a entender o motivo pelo qual a maioria dos exemplos inferenciais envolvem jogos de azar. A estatística tem duas “escolas” ou “formas de pensamento”. A estatística frequentista e a estatística bayesiana. Aspectos fundamentais que tocam à definição de probabilidade são diferentes, bem como a definição de dados e parâmetros também o são. Pela perspectiva histórica, a estatística bayesiana é mais antiga que a frequentista. No entanto, se for comparado a proporção de uso entre os pesquisadores, a estatística frequentista é ainda a mais frequente e justifica a ênfase deste livro nesta área. A relação entre estatística e Machine Learning (ML) e seus derivados é relativamente recente. Apesar de grande interface e do fato que as análises realizadas em estatística e ML encontram resultados virtualmente idênticos, há diferentes argumentos apontando que as áreas têm objetivos diferentes, o que eu não necessariamente concordo. Ainda sob perspectiva histórica, a estatística, como uma área do conhecimento, é anterior à ML, que não será abordada neste livro. 2.2 Considerações sobre escalas de medida e o processo de mensuração em Psicologia L. Anunciação &amp; J. Landeira-Fernandez A existência de um fenômeno é condicionada à uma determinada quantidade. Como atribuído à Thorndike (1914), “Se algo existe, ele tem de existir em uma certa quantidade e se uma determinada quantidade existe, ela pode ser mensurada”. Assim, tal como em outras ciências, o processo de mensuração é absolutamente vital à Psicologia. Isso pode ser demonstrado tanto pela implementação de técnicas estatísticas para modelar fenômenos psicológico, como pelas lentes de uma das áreas mais voltadas ao desenvolvimento de instrumentos, que é a Psicometria. Entretanto, nunca faltaram céticos de diferentes locais questionando se fenômenos psicológicos poderiam, de fato, ser medidos e uma das primeiras e mais estáveis respostas sobre esse questionamento ocorreu em 1946, com a publicação intitulada “On the theory of scales of measurement” do psicólogo e psicofísico Stanley Stevens. Este trabalho apresentou algumas conclusões que até hoje são importantes e que tocam, principalmente (1) à definição de medida, (2) o conceito de escalas (níveis) de medida e (3) à condição da mensuração de fenômenos psicológicos. Inicialmente, Stevens parafraseou N.R. Campbell ao entender que a “mensuração, em sentido mais amplo, é definida como a atribuição de números a objetos ou eventos de acordo com algumas regras” (Stevens, 1946, p. 677). Uma vez feito isso, ele concluiu que esses números são atribuídos (ou existem) em função da possibilidade de realização de operações estatísticas e matemáticas com eles. Duas regras gerais são subjacentes neste conceito: a primeira é que a as operações possíveis para cada escala são as que se mantêm invariantes para as transformações matemáticas que cada um dos níveis de mensuração aceita e a segunda é que é necessário que haja um isomorfismo (as vezes, apresentado como s(x)) entre os entre os objetos que estão sendo medidos e os números atribuídos a eles. Em função destas condições, Stevens descreve quatro escalas que se apresentam hierarquicamente como: (i) nominal, (ii) ordinal, (iii) intervalar e (iv) de razão. Desde o trabalho de Stevens, essa relação entre o valor numérico e o objeto para o qual este valor foi utilizado atraiu ao menos dois grupos de pesquisadores, que são aqueles que possuem um interesse mais voltado à análise de informação que este número ou esta escala traz e, neste sentido, tentam responder à pergunta “O que este número está informando” e os que possuem um maior interesse em desenvolver tratamentos estatísticos a tais números ou escalas e, analogamente, tentam responder à pergunta “Como que se trata estatisticamente tais números?”. Posto isso, este seção realiza uma síntese deste conceito, bem como apresenta as descrições de cada uma das escalas, especialmente a partir de uma orientação mais pragmática, suas condições de uso e uma breve contextualização atual. 2.2.1 Escala nominal Essa escala é a mais primitiva de todas e a única regra relacionada ao processo de mensuração é que o número atribuído a um determinado objeto ou evento deve ser exclusivo, não sendo possível atribuir um mesmo número a diferentes eventos ou objetos. É importante destacar que os números aqui são arbitrários e, além disso, não refletem grandezas ou magnitudes. Nessa escala, só é possível contagens e proporções. Em relação a aspectos estatísticos, é possível obter apenas a moda dos valores. Exemplos concretos são: o número da camisa dos jogadores de futebol, atribuir o valor 1 para homens e 2 para mulheres ou 1 para psicólogos, 2 para geógrafos e 3 para pedagogos. É importante notar existem livros e manuais que consideram que quando há apenas dois valores possíveis para o objeto ou evento, o ideal é chamar essa escala de “dicotômica”, “binária” ou “dummy”, mas isso varia bastante em função da área e o consenso não é fácil. Por exemplo, em estudos em ciências sociais, é possível encontrar autores chamando a classificação de sexo biológico (por exemplo, 1 para homens e 2 para mulheres) de variável binária; já em estudos epidemiológicos, é frequente à atribuição do valor “1” para um grupo de pessoas com uma determinada doença e “0” para um grupo de pessoas sem esta doença (apesar disso poder ser entendido como ordinal em alguns casos) e, finalmente, em estudos em economia, por vezes os pesquisadores utilizam o valor “1” para indicar algo de interesse (por exemplo, desempregado) e “0” para caso contrário. Tirando essas particularidades, é fundamental entender que os números atribuídos à essa escala são arbitrários e apenas identificam objetos ou eventos. 2.2.2 Escala ordinal Nessa escala, os números respeitam uma relação de ordem ranqueada e essa é a regra pela qual os números são atribuídos aos eventos ou objetos. É importante ter em perspectiva que essa escala pode ser utilizada pragmaticamente em uma pesquisa mesmo quando o fenômeno que está sendo estudado é facilmente compreendido dentro de uma escala superior, como será visto. Por exemplo, é plenamente possível que um psicólogo meça o tempo de reação de um grupo de pessoas e depois tenha criado categorias ordenadas, como “lento (1)”, “esperado (2)” e “rápido (3)”. Em função disso, alguns livros tentam dividir essa escala a partir de uma origem objeto ou evento que está sendo medido e utilizam de termos como “origem natural” e “origem não natural”, que não serão utilizados aqui (Pasquali, 1998). Nessa escala, além da contagem, proporções e moda, é também possível identificar mínimo, máximo e amplitude. Exemplos concretos são a Escala de dureza dos metais (Escala de Mohs), o nível de satisfação de uma empresa, onde 1 é baixo, 2 é moderadamente satisfeito e 3 é alto e a posição ao fim de uma corrida, podendo ser o primeiro lugar, segundo ou terceiro. 2.2.3 Escala intervalar Os números aqui assumem um aspecto propriamente quantitativo e, em outras palavras, quase sempre o número não segue nem uma relação arbitrária (por exemplo, 1 para homens e 2 para mulheres), nem tampouco uma convenção informal (por exemplo, 1 para ensino fundamental e 2 para ensino médio), mas é obtido a partir de um processo em que se contou com a utilização de instrumentos de medida. Nessa escala, as distâncias entre as categorias são iguais, apesar do valor zero ser uma conveniência. Dessa maneira, a diferença entre categorias será sempre relacional e jamais absoluta. Assim, nesse nível, é possível ter propriedades aditivas, mas não multiplicativas. Considerando unidades arbitrárias, é possível falar que a diferença entre 30 e 29 (1 unidade) é a mesma que entre 15 e 14 (1 unidade). No entanto, no que diz respeito à magnitude do que está sendo medido, nessa escala não é possível falar que 30 unidades é o dobro de 15 unidades. Nessa escala, além da contagem, proporções, moda, identificar mínimo, máximo e amplitude, é possível tirar diferenças e fazer adições, bem como calcular a média, a variância e o desvio-padrão dos resultados. Exemplos concretos são o calendário que utilizamos. Repare que utilizamos “AC” (antes de Cristo) e “DC” depois de Cristo, estipulando um zero arbitrário; a temperatura sendo medida por graus Célsius ou Fahrenheit, já que cada uma dessas medidas tem um ponto 0 arbitrário. Aproveitando o exemplo da temperatura para ilustrar mais detalhadamente o que significa “0” arbitrário, o valor “0o C” na escala célsius se refere à temperatura que a água congela, enquanto “100o C” se refere à temperatura em que a água entre em ebulição. Em Fahrenheit, esse valor é o “32 o F” e “212 o C”. Apesar de haver a possibilidade de conversão de uma escala para outra, repare que não é possível utilizar a propriedade multiplicativa. Por exemplo, enquanto numericamente 30 x 2 = 60, afirmar que 30º C x 2 = 60º C é incorreto. Na verdade, 30º C se refere a 86º F e 60º C se refere a 140º F. Assim, apesar de ser intuitivo pensar que se um ambiente tem 32 graus célsius, ele está o dobro de quente de um ambiente que está 16º celsius, isso não é correto. 2.2.4 Escala de razão Aqui há um 0 absoluto e todas as operações previamente podem ser feitas, bem como o produto das categorias. Escalas de razão são mais encontradas na física. Nessa escala, além das capacidades matemáticas previamente descritas, é possível implementar propriedades multiplicativas. Raramente, essa escala será utilizada em um processo de avaliação psicológica. Entretanto, algumas pesquisas costumam utilizar variáveis que pertencem à escala de razão, como pesquisas em psicofísica que medem o tempo de “tempo de reação” ou pesquisas em neuropsicologia da atenção que medem a “quantidade de botões apertados em um minuto”. É importante novamente alertar que mesmo que essa medida tenha um 0 absoluto (por exemplo, uma pessoa não apertou nenhum botão ao fim de um minuo), isso não significa em nada que o fenômeno psicológico subjacente seja inexistente ou ausente. 2.2.5 Síntese das características de cada escala Como exposto logo ao início, os números presentes em cada uma das escalas podem ser entendidos tanto por seus aspectos de informação como pelos procedimentos estatísticos a eles associados. Ambas as iniciativas possuem sua importância e são associadas entre si. Os gráficos expostos abaixo apresentam ambos os conceitos. 2.2.6 As escalas de Stevens e uma tentativa de agrupamento Apesar de Stevens ter, fundamentalmente, criado quatro escalas em que sempre haverá números associados a objetos a partir de sua capacidade matemática, teóricos posteriores tentaram agrupar essas quatro escalas em dois conjuntos específicos que costumam ser feitos seguindo este critério: uma vez que a escala nominal e ordinal utilizam os números de uma maneira assegurada apenas por convenção, muitos livros e autores as agrupam como “qualitativas”. Por contraste, como a escala intervalar e de razão são obtidas, majoritariamente, por processos que contam com instrumentos de medida, elas quase sempre são agrupadas como “quantitativas”. Mesmo que hoje em dia esse agrupamento seja bastante corriqueiro, origem desta iniciativa é algo incerta. Há sugestão que ela tenha começado pelo trabalho de investigação semiótica de Charles Sanders Peirce. Esse filósofo julgava que a ciência avançava em dez níveis distintos e progressivos, começando por um ícone possível (fancy), passando por um pensamento, um objeto, um símbolo numérico, uma quantidade e uma relação (Smart, 1999, p. 289). Infelizmente, essa classificação pode gerar uma divisão desnecessária dentro do próprio conceito desenvolvido por Stevens, além de gerar bastante confusão, já que o termo “pesquisa qualitativa” não costuma se referir às escalas de medida, mas sim à uma área que mais recentemente emergiu com uma forma metodológica distinta e, eventualmente, até mesmo crítica às iniciativas de medida e mensuração. Além disso, o termo “quantitativa” atribuído apenas à escala intervalar e de razão pode dar a impressão inadequada de que não se usa números nas escalas nominais ou ordinais. Finalmente, é importante frisar que há livros que utilizam o termo “categórica” para “qualitativa” e “propriamente numérico” para “quantitativa”, aumentando algo mais os cenários de confusão. A imagem a seguir apresenta esta tentativa. 2.2.7 Variáveis discretas ou contínuas A iniciativa de classificar as variáveis e, consequentemente, escalas de medida não foi apenas feita em estudos psicológicos. Evidentemente, áreas como matemática, probabilidade e estatística também tiveram (e ainda possuem) interesse em classificar as variáveis e uma das maneiras pelas quais isso é feito diz respeito à forma como os valores se apresentam, especialmente em sua capacidade informacional (Morettin &amp; Bussab, 2010). Qualquer variável cujo resultado só possa descreve uma quantidade contável, em que os valores potenciais podem ser enumerados em uma ordem é chamada de discreta e é caracterizada por uma função de massa probabilidade (em inglês, probability mass function). Por sua vez, uma variável cujos valores potenciais não podem ser enumerados em uma ordem inequívoca é chamada de contínua e tem uma função de densidade de probabilidade (em inglês probability density function). Um atalho cognitivo bastante frequente apesar de apenas parcialmente correto pode auxiliar: variáveis discretas costumam ter valores inteiros, tal como número de filhos, caixas de remédios vendidas por uma farmácia e vezes que um paciente buscou auxílio médio; por sua vez, as variáveis continuar reúnem números fracionários, tal como a altura dos filhos, o retorno financeiro em Reais que a venda dos remédios e o tempo gasto em cada em cada consulta média. Quando se tenta fazer uma comparação entre a classificação de escalas de medida desenvolvida por Stevens e a classificação das variáveis em discretas e contínuas, é possível considerar que a escala intervalar e de razão podem também ser entendidas como discretas e continuas. Excepcionalmente e apenas para fins de modelagem estatística, as variáveis classificadas como nominais e ordinais podem ser entendidas também como discreta (Borgatta &amp; Bohrnstedt, 1980; Privitera, 2016, p. 20) 2.2.8 Hierarquia da classificação e a importância desses conceitos hoje em dia Uma vez que as escalas dependem das capacidades matemáticas associadas, uma escala de maior nível pode ser convertida em uma escala hierarquicamente inferior. Isso foi previamente apresentado na escala ordinal com o exemplo de tempo de resposta. Esse processo de transformação costuma ser chamado de “categorização” e pode ser facilmente visto em outros exemplos. Por exemplo, a altura das pessoas (razão, contínua) pode ser classificada em baixas ou altas e a temperatura em Kelvin (razão, contínua) pode tanto ser entendida de maneira intervalar (Celsius, por exemplo), ordinal (muito frio, frio, quente, muito quente) ou (agradável e desagradável). Apesar dessas classificações de escalas/níveis de medida terem importância acadêmica, em situações de análise de dados, quase nunca a diferenciação entre os 4 níveis de medida tem relevância ou utilidade. Além disso, o próprio Stevens, tempos depois, em 1959, reviu algo de sua classificação e reconheceu que as regras de invariância também permitiam uma nova escala, chamada de “log-intervalar” (Stevens, 1959). Essa escala quase nunca presente em livros didáticos. Além disso, como programas estatísticos são frequentemente utilizados para realizar procedimentos de análises de dados, eventualmente eles sequer utilizam as mesmas nomenclaturas ou apenas entendem as variáveis como discretas ou contínuas. Mesmo na academia, autores como D. Howell consideram que esse aspecto da medida tem apenas relevância histórica, sendo irrelevante hoje em dia (David C. Howell, 2011, p. 18). Finalmente, a partir da tentativa de desenvolver ou aperfeiçoar o isomorfismo entre relações empíricas e relações algébricas, em que houvessem regras bem definidas articulando os números às coisas (tal como visto em Campbell), e que tivessem propriedades matemáticas específicas e bem definidas (tal como visto em Stevens) outras classificações foram surgindo. Entre eles, a Teoria representacional da medição (Patrick Suppes) e a Teoria da Medida Aditiva Conjunta (TMAC) (Michell, 1993). 2.2.9 Em qual escala devemos classificar os testes psicológicos Psicólogos e outros cientistas comportamentais utilizam com frequência instrumentos de medida para acessar variáveis como atenção, memória, personalidade e inteligência. De maneira análoga às outras áreas empíricas, esses instrumentos geram resultados numéricos que, por sua vez, são utilizados para as mais diferentes finalidades. Da mesma forma que para maioria dos fenômenos medidos, o nível de medida não é inerente aos dados (Velleman &amp; Wilkinson, 1993). Com isso, o debate sobre qual nível de medida devem ser entendido os números obtidos por instrumentos psicológicos parece estar sempre aberto. Uma primeira resposta veio do próprio Stevens, que assumindo que as operações possíveis em cada escala devem ser invariantes comentou que: A maioria das escalas usadas amplamente e efetivamente por psicólogos são ordinais. De maneira estrita, médias e desvios-padrão não devem ser utilizados nessas escalas, uma vez que para essas estatísticas se deva saber algo mais do que a ordem relativa dos dados. Por outro lado, pode-se evocar uma espécie de confirmação pragmática para esse uso ‘ilegal’ da estatística: em inúmeras situações o seu uso conduziu a resultados frutuosos (Stevens, 1946, p. 679, aspas do autor original). Já no meio acadêmico, é bem possível que ninguém consideraria que os resultados obtidos por um processo de testagem psicológica sejam nominais ou de razão. Entretanto, há bastante divergência em relação quanto ao nível ordinal ou intervalar. Excetuando os que julgam que os resultados estão entre esses dois níveis, há aqueles que julgam que a escala ordinal é a adequada para qualquer instrumento psicológico. Para esses autores, não seria possível sequer somar ou diminuir os valores obtidos em itens de um teste de inteligência ou inventário de atitude. Eventualmente, decisões como essa são bastante rígidas e só mais recentemente, principalmente pelo incremento do poder computacional, essas decisões tiveram contrapartida analítica (Análise Rasch e Teoria de Resposta ao Item, por exemplo). Apesar de rígida, essa consideração tem fundamento, já que pela hierarquia dos níveis de medida, só é possível um processo descendente (razão para intervalar, etc) e não ascendente (intervalar para razão, por exemplo). Isso também pode tanto ser visto em instrumentos do tipo questionários e instrumentos com respostas certas e erradas. Uma vez que a escala intervalar assume equidistância entre os valores, considerar que as distâncias de itens Likert (concordo totalmente a discordo totalmente) ou Tipo-Likert (nada a muito) são iguais é uma justificativa bastante frágil. Já em instrumentos de inteligência, também seria pouco adequado assumir que a diferença de 1 ponto traria a mesma informação isomórfica entre uma pessoa que teve 80 pontos e outra 79 pontos em um teste de inteligência e entre uma pessoa que obteve 130 pontos e outra que obteve 129 pontos neste mesmo teste. Em outro sentido, um grupo maior de acadêmicos consideram os resultados obtidos por um processo de testagem como intervalares e, consequentemente, utilizam técnicas estatísticas mais robustas para os dados. Essa condição quase sempre era justificada de maneira pragmática, vem ganhando maior sustentação hoje em dia, especialmente em estudos de simulação, em que os pesquisadores criam a possibilidade de comparar resultados estatísticos obtidos considerando os dados ou como ordinais ou como intervalares (Wu &amp; Leung, 2017). Dessa forma, uma vez que esse tema ainda reflete uma questão em aberta, respostas definitivas não são possíveis (nem desejáveis), colocando sobre o pesquisador a justificativa analítica e teórica das decisões por ele tomadas. References "],
["o-r-e-o-tidyverse.html", "Capítulo 3 O R e o Tidyverse 3.1 Tidyverse 3.2 Verbos do dplyr 3.3 Resumo", " Capítulo 3 O R e o Tidyverse Este livro é totalmente feito no R, com utilização do RStudio e diversos pacotes para otimizar as análises estatísticas apresentadas. Muito provavelmente, esta escolha é ainda uma excessão no universo da Psicologia, que utiliza o SPSS e outros programas point and click com frequência. Uma série de razões motivaram a minha escola e, entre elas: o R é uma linguagem de programação desenvolvida especificamente para Estatística. Diferente de uma linguagem mais geral (por exemplo, Python) ou de um programa point and click, que serve como uma ponte entre estatística e a usabilidade (SPSS ou STATA), o R é feito para que a pessoa tenha controle total das ações estatísticas. Apesar disso poder assustar no início, julgo que essa característica do R é essencial, inclusive, para que o usuário planeje adequadamente as análises de interesse, em vez de apenas selecionar parte de um output padronizado, como ocorre com o SPSS. Além disso, como o R tem um nicho em Estatística, ele é absolutamente mais adaptado para o dia-a-dia em estatística do que o Python, que tem vantagem em aplicações variadas. o R e todas as suas otimizações são gratuitas Todo ambiente R é gratuito e isso inclui o Rstudio (que é uma IDE, Integrated Development Environment) e seus pacotes. Pacotes A comunidade R tem um exército de pacotes que foram desenvolvidos para otimizar análises estatísticas e foram verificados publicamente e estão disponíveis no CRAN (The Comprehensive R Archive Network). Todos os capítulos deste livro contam com pacotes e eles permitem realizar ações altamente complexas com poucos comandos. Comunidade de apoio Os usuários do R formam uma rede muito dinâmica e que oferece grande apoio em caso das mais diversas dúvidas. Um grande exemplo é o stackoverflow, que funciona como um grande centro de suporte e auxílio. 3.1 Tidyverse O Tidyverse é um ambiente de pacotes que, além de funcionarem de maneira totalmente integrada, permitem que as linhas de código que fazemos para programar no R se tornem mais intuitivas e mais próximas à forma que temos de pensar, em que primeiro vem o sujeito e depois o verbo. Será possível notar que durante este livro, frequentemente eu vou utilizar uma função de ligação (o pipe, %&gt;%) em vez da estrutura do R-Base, que será usada apenas minoritariamente aqui. Ao instalar o tidyverse install.package(\"tidyvese\"), os pacotes abaixo ficam disponíveis no R. No entanto, nem tudo são flores. Apesar do R e seus pacotes oferecem excelentes ferramentas para análise de dados, algumas condições descritivas são demasiadamente custosas. Por exemplo, enquanto realizar algumas tabelas e gráficos no Excel é tremendamente fácil, as vezes o R exige diversas linhas de código. Nesse sentido, na relação entre dificuldade e complexidade, o R sai na frente em tarefas complexas (como exemplo, estimar os coeficientes de um modelo não-linear), mas talvez perca em tarefas fáceis (por exemplo, gerar uma tabela de contingência). A Figura a seguir apresenta esta relação. Uma outra barreira muito importante que o R traz é que ele é uma linguagem de programação e isso gera uma dificuldade a mais na docência de estatística, especialmente aos alunos de graduação. Tendo em vista que é muito esperado que estes estudantes tenham algum receio a priori em relação à estatística, apresentar o R traria ainda uma outra dificuldade, que é entender e aprender a programar. Em situações como esta, talvez o ideal seja começar motivando o estudante a entender como a estatística é uma ferramenta importante para tomar decisões em relação às pergutas de pesquisa para, só depois e lentamente, apresentar aspectos matemáticos e computacionais. 3.2 Verbos do dplyr O dplyr funciona de maneira muito intuitiva. O padrão original do R considera que as operações são realizadas a partir de uma lógica do tipo verbo(sujeito, complemento) enquanto o ambiente tidyverse opta por sujeito %&gt;% verbo(complemento), tornando-se o ato de programar mais natural e associado à maneira que organizamos as ideias. Os verbos principais do pacote estão listados na tabela a seguir e as sintaxes deixadas no decorrer deste capítulo (e do livro) permitem uma melhor apreensão das funcionalidades. É importante lembrar que, em alguns momentos, em função da praticidade computacional, algumas sintaxes vão contar com o formato base do R. Verbo Ação glimpse Inspeciona os dados count Conta os níveis de uma variável select seleciona uma variável específica filter Filtra os resultados por um nível específico de uma variável group_by Agrupa os resultados por níveis de uma variávei específica summarise Apresenta sumários (com medidas estatísticas) mutate Cria novas variáveis ou altera as existentes arrange Organiza a apresentação dos resultados left_join Junta bases ou colunas pivot_longer Transforma uma base larga em longa pivot_wider Transforma uma base longa em larga É também importante ficar atento às atualizações do dplyr e do sistema tidyverse como um todo. Eventualmente, mudanças podem ocorrer e impossibilitar (ou dificultar) a reprodução de rotinas antigas. O site é o local ideal para acompanhar as atualizações. 3.3 Resumo Este livro irá apresentar todas as rotinas utilizadas em estatística a partir de linhas de código do R. O ambiente de programação tidyverse servirá como base principal para programação. Entre as principais vantagens do R, estão a gratuidade de seu acesso e uso Entre as principais desvantagens do R, estão a necessidade de programação e algumas análises descritivas "],
["estatística-descritiva.html", "Capítulo 4 Estatística Descritiva 4.1 Pesquisa 4.2 Condições gerais 4.3 Tabelas 4.4 Gráficos 4.5 1 variável discreta 4.6 1 variável contínua 4.7 2 variáveis com VI discreta (e VD contínua) 4.8 2 variáveis com VI contínua (e VD contínua) 4.9 Outros gráficos e configurações 4.10 Resumo", " Capítulo 4 Estatística Descritiva Objetivos do capítulo 1. Apresentar tabelas e gráficos 2. Introduzir os verbos do dplyr e funções do ggplot. 3. Oferecer heurísticas ou regras gerais para criação de gráficos 4.1 Pesquisa Base: Base R - Pesquisa mapfre.RData Neste capítulo (e em alguns outros), vamos utilizar a pesquisa intitulada “Depression and Anxiety Symptoms in a Representative Sample of Undergraduate Students in Spain, Portugal, and Brazil”. Nessa pesquisa, sou o coautor e o pesquisador responsável para correspondência. O objetivo deste estudo foi fazer um mapa epidemiológico de sintomas de ansiedade e depressão em universitários em três países, bem como investigar possíveis relações entre tais condições de saúde e fatores sociodemográficos. Um diferencial importante do trabalho foi a seleção amostral. Partiu-se de uma amostra estratificada (probabilística) dos estudantes de três universidades, PUC-Rio (Brasil), Universidade de Extremadura (Espanha) e Universidade de Coimbra (Portugal). Isso permitiu ter maior validade externa dos resultados. 4.2 Condições gerais Todo documento acadêmico e científico é composto de aspectos textuais, tabulares e gráficos que devem caminhar na mesma direção e serem sempre associados às perguntas e objetivos traçados na pesquisa. É fácil perceber, dessa maneira, que a parte principal de qualquer trabalho acadêmico não são necessariamente os aspectos estatísticos, mas sim os objetivos e as possíveis hipóteses investigadas pelos pesquisadores. A estatística, neste sentido, é uma valiosa ferramenta de trabalho (ou uma atividade de meio) para que as perguntas sejam respondidas de forma adequada e válida. Frequentemente, as primeiras análises descritivas começam pela apresentação de tabelas e gráficos. Da mesma forma que a construção de um prédio depende que andaimes sejam colocados, um relatório técnico depende dessas condições. Ainda neste sentido, assim como a conclusão do prédio cursa com a retirada destes andaimes, é bem possível que as versões finais de artigos científicos ou relatórios aproveitem apenas parte dos gráficos e tabelas desenvolvidos. 4.3 Tabelas Tabelas apresentam os sumários informacionais de uma pesquisa de maneira reunida e objetiva. As tabelas precisam ter um título informativo, bem como colunas e linhas. Com frequência, apenas as linhas superiores e inferiores recebem bordas e números decimais são arredondados até a segunda casa decimal. Como os verbos do dplyr possibilitam que os mesmos resultados sejam encontrados por vias diferentes, os códigos a seguir tentarão manter uma uniformidade lógica. Em alguns momentos, para ampliar as possibilidades de codificação, sintaxes extras serão oferecidas. A tabela a seguir apresenta a quantidade de participantes em cada país. Dataset &lt;- Dataset %&gt;% ungroup() Dataset %&gt;% group_by(country) %&gt;% summarise(n=n()) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) ## `summarise()` ungrouping output (override with `.groups` argument) country n SPAIN 1216 PORTUGAL 426 BRAZIL 315 É também possível adicionar proporções relativas percentuais à tabela, o que é uma escolha adequada para apresentação dos resultados. Dataset %&gt;% group_by(country) %&gt;% summarise(n=n(), Prop = n/nrow(.)) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) ## `summarise()` ungrouping output (override with `.groups` argument) country n Prop SPAIN 1216 0.62 PORTUGAL 426 0.22 BRAZIL 315 0.16 O pacote janitor oferece complementos úteis à família tidyverse e um deles justamente adiciona os totais, de maneira mais rápida e, em função disso, os exemplos também irão acessar as funções deste pacote. Dataset %&gt;% tabyl(country) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country n percent SPAIN 1216 0.62 PORTUGAL 426 0.22 BRAZIL 315 0.16 Total 1957 1.00 O mesmo que foi realizado com os países, pode também ser realizado com o sexo do participante. Dataset %&gt;% tabyl(sex) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) sex n percent valid_percent M 736 0.38 0.38 F 1214 0.62 0.62 NA 7 0.00 NA Total 1957 1.00 1.00 É possível notar casos ausentes na variável sexo. Isso acontece com muita frequência e antes de formalmente discutirmos o que fazer neste caso, é possível adequar a tabela para não apresentar tais condições.A adição do argumento para filtrar os participantes com dados ausentes sobre sexo auxilia a apresentar melhor os resultados. É importante atentar que essa análise tem finalidade descritiva e que omitir a apresentação de variáveis ausentes não significa excluir ou remover os participantes das análises que serão feitas posteriormente. Somente em possibilidades remotas se retira participantes das análises de maneira definitiva. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(sex) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) sex n percent M 736 0.38 F 1214 0.62 Total 1950 1.00 Para fazer uma tabela cruzada, em que seja possível apresentar a quantidade de homens e mulheres por país, épossível utilizar função pivot_wider: Dataset %&gt;% filter(!is.na(sex)) %&gt;% count(country,sex) %&gt;% pivot_wider(names_from = sex, values_from = n) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country M F SPAIN 384 825 PORTUGAL 203 223 BRAZIL 149 166 Da mesma maneira como continuar com o tabyl, mas agora adicionando uma variável. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(country, sex) %&gt;% adorn_totals() %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) country M F SPAIN 384 825 PORTUGAL 203 223 BRAZIL 149 166 Total 736 1214 Finalmente, para apresentar a quantidade de participantes totais, bem como separar a quantidade e a porcentagem de homens e mulheres por país, a codificação torna-se mais densa. O código abaixo apresenta os comentários para auxiliar no entendimento da rotina e reproduz parcialmente a tabela 1 do artigo. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(country, sex) %&gt;% adorn_totals(c(&quot;row&quot;, &quot;col&quot;)) %&gt;% adorn_percentages(&quot;row&quot;) %&gt;% adorn_pct_formatting(rounding = &quot;half up&quot;, digits = 0) %&gt;% adorn_ns() %&gt;% adorn_title(&quot;combined&quot;) %&gt;% kable(., digits = 2, booktabs = T) %&gt;% kable_styling(position = &quot;center&quot;, full_width = F, bootstrap_options = &quot;striped&quot;) country/sex M F Total SPAIN 32% (384) 68% (825) 100% (1209) PORTUGAL 48% (203) 52% (223) 100% (426) BRAZIL 47% (149) 53% (166) 100% (315) Total 38% (736) 62% (1214) 100% (1950) 4.4 Gráficos A máquina gráfica do tidyverse é o ggplot. Pelo menos 3 argumentos são necessários para criação de gráficos, que são: O banco dados (data = ), que pode ser omitido da sintaxe, O aspecto estético, que permite diferentes complementos aes(x = , y = , fill = , color = ), O aspecto geométrico, que varia em função do gráfico a ser apresentado geom_ É também possível adicionar outros argumentos, como: 4. Transformações estatísticas stat_summary 5. Facetas para dividir a visualização facet_ 6. Sistema de coordenadas coord_ 7. Temas específicos theme_ É importante notar que apesar dos argumentos utilizados na sintaxe serem similares aos utilizados em toda família tidyverse, a ligação %&gt;% é substituída pelo +. Quando bem feitos, os gráficos são extremamente úteis. Como aponta Morettin e Bussab (Morettin &amp; Bussab, 2010), eles possibilitam: (a) buscar padrões e relações; (b) confirmar (ou não) certas expectativas que se tinha sobre os dados; (c) descobrir novos fenômenos; (d) confirmar (ou não) suposições feitas sobre os procedimentos estatísticos usados; e (e) apresentar resultados de modo mais rápido e fácil. É sempre bom que o gráfico tenha um título e uma escala. A maioria dos gráficos são apresentados em um plano com um eixo horizontal (abcissas) e um vertical (ordenadas), que se referem aos níveis da variável que está sendo medida (eixo x) e as contagens ou proporções encontradas (eixo y) ou aos níveis da variável independente (eixo x) e os resultados médios da variável dependente (eixo y). Para eleger que gráfico será realizado, é necessário responder a duas perguntas que são atreladas às pesquisas em Psicologia e áreas congêneres: Quantas variáveis serão apresentadas ? Qual o nível de medida da variával independente ? O diagrama abaixo oferece uma árvore de decisão funcional. É importante atentar que variáveis categóricas são operacionalmente entendidas como discretas aqui. 4.5 1 variável discreta Quando há apenas uma variável discreta (incluindo aqui as categóricas), os gráficos são criados para apresentar as contagens e/ou suas proporções. Nesse caso, é recomendado utilização de um gráfico de barras ou gráfico de setor. Apesar de ser possível apresentar as frequências absolutas, esses resultados podem gerar distorção da informação e, portanto, é preferível sempre apresentar as proporções de ocorrência de uma determinada variável ou valor. Por definição, quando se trabalha com proporções, o valor máximo da soma das proporções é 100. O gráfico de barras abaixo apresenta a contagem absoluta dos participantes pesquisados em cada país. ggplot(Dataset, aes(x = country)) + geom_bar() + labs(x = &quot;País&quot;, title = &quot;Número de participantes nos países investigados&quot;) Já abaixo, as barras são utilizadas considerando os resultados proporcionais. Para isso, um recurso do pacote scales foi utilizado para adequar o eixo y e também para adicionar o valor às colunas. ggplot(Dataset, aes(x = country, y = ..prop.., group = 1)) + geom_bar(stat = &quot;count&quot;) + geom_text(aes(label=scales::percent(round(..prop..,2)), y=..prop..), stat= &quot;count&quot;, color = &quot;white&quot;, size = 3, position = position_stack(vjust = 0.5)) + scale_y_continuous(labels = scales::percent_format()) + labs(x = &quot;País&quot;, title = &quot;Proporção de participantes em cada país investigado&quot;) O gráfico de setor (as vezes chamado de polar, pizza ou torta) pode também ser utilizado. O aspecto principal desse gráfico é apresentar os setores de maneira proporcional às frequências. ggplot(Dataset, aes(x=factor(1), fill=country))+ geom_bar(width = 1) + coord_polar(&quot;y&quot;) + labs(title = &quot;Proporção de participantes em cada país&quot;) A adição de porcentagens costuma deixar o gráfico mais informativo Dataset %&gt;% count(country) %&gt;% mutate(pct = n/sum(n)) %&gt;% ggplot(., aes(x=&quot;&quot;, y= pct, fill=country)) + geom_col() + geom_text(aes(label = scales::percent(round(pct,3))), position = position_stack(vjust = 0.5))+ coord_polar(theta = &quot;y&quot;) + labs(title = &quot;Proporção de participantes em cada país&quot;) 4.6 1 variável contínua Quando uma única variável é apresentada no gráfico e ela é continua, os gráficos adequados são o histograma, densidade (kernel) e o boxplot. Abaixo um histograma da idade dos participantes: ggplot(Dataset, aes(x = age)) + geom_histogram(bins = 30, color = &quot;black&quot;, fill = &quot;lightgrey&quot;) + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_bin). Abaixo um gráfico de densidade da idade: ggplot(Dataset, aes(x = age)) + geom_density(fill = &quot;lightgray&quot;) + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_density). Esses dois gráficos apresentam bem o formato da distribuição. Neste caso, existe uma assimetria à direita, que é para onde a cauda dos dados se arrasta. Por sua vez, abaixo o boxplot dessa mesma variável: ggplot(Dataset, aes(y = age, x = &quot;&quot;)) + geom_boxplot() + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_boxplot). O boxplot tem vantagens em comparação com os outros gráficos apresentados até agora. Além de apresentar o formato da distribuição, a área da caixa reúne 50% da distribuição (Q1, Q2 ou Mediana e Q3) e os bigodes são construídos com base em Q1 - 1.5*IQR e Q3 + 1.5*IQR. Apesar de algo difícil de visualizar ao início, a informação apresentada no boxplot e no gráfico de densidade são iguais. gridExtra::grid.arrange( #Grafico 1 ggplot(Dataset, aes(x = age)) + geom_density(fill = &quot;lightgray&quot;), #Grafico 2 ggplot(Dataset, aes(y = age, x = &quot;&quot;)) + geom_boxplot() + coord_flip(), top = &quot;Distribuição da idade dos participantes&quot; #título ) ## Warning: Removed 28 rows containing non-finite values (stat_density). ## Warning: Removed 28 rows containing non-finite values (stat_boxplot). 4.7 2 variáveis com VI discreta (e VD contínua) Gráficos de barras ou colunas (considerando aqui as barras de erro) e o boxplot são adequados para apresentar essa relação. Basicamente, esses gráficos permitem verificar a diferença entre os grupos. Como exemplo, o gráfico abaixo mostra os resultados do Inventário Beck de Ansiedade entre 3 países investigados. As barras de erro são importantes para verificar, inicialmente, as possíveis diferenças significativas entre os países. ggplot(Dataset, aes(x = country, y = bai_sum)) + geom_bar(stat = &quot;summary&quot;, fun = mean) + stat_summary(geom = &quot;errorbar&quot;,fun.data = mean_se, width = .5) ## Warning: Removed 5 rows containing non-finite values (stat_summary). ## Warning: Removed 5 rows containing non-finite values (stat_summary). O boxplot a seguir também é um gráfico indicado: ggplot(Dataset, aes(x = country, y = bai_sum)) + geom_boxplot() ## Warning: Removed 5 rows containing non-finite values (stat_boxplot). 4.8 2 variáveis com VI contínua (e VD contínua) Assumindo que a VI é contínua e a VD também, o gráfico de pontos e de dispersão são virtualmente identicos e indicados. Esses gráficos permitem verificar a associação entre as variáveis. No ggoplot, o argumento geom_point (à esquerda) e geom_jitter (à direita) são possíveis. gridExtra::grid.arrange( #Grafico 1 ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_point(), #Grafico 2 ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_jitter(), nrow=1 ) ## Warning: Removed 33 rows containing missing values (geom_point). ## Warning: Removed 33 rows containing missing values (geom_point). Tradicionalmente, de maneira análoga às barras de erros apresentadas em gráficos cujas VIs são discretas, adiciona-se uma reta de regressão amostral (FRA) quando a VI é contínua, tal como apresentado a seguir. É importante atentar que o capítulo sobre modelos de regressão irá trabalhar melhor este conceito. ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 33 rows containing non-finite values (stat_smooth). ## Warning: Removed 33 rows containing missing values (geom_point). 4.9 Outros gráficos e configurações Evidentemente, é possível apresentar mais informações nos gráficos com mais de um variável apresentada, desde que elas sejam relacionadas ao problema de pesquisa estudado e não sobrecarreguem a visualização dos resultados. Frequentemente, as informações adicionais são feitas pela inclusão de clusters ou agrupamentos. Isso é tanto possível em gráficos cuja VI seja discreta quanto contínua. No exemplo abaixo, o gráfico dos resultados do Inventário Beck de Ansiedade entre os 3 países investigados (VI discreta) agora está agrupado pelo sexo do participante. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = country, y = bai_sum, fill = sex)) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;) + stat_summary(geom=&quot;errorbar&quot;, fun.data = mean_se, position = position_dodge(0.95), width = .5) ## Warning: Removed 5 rows containing non-finite values (stat_summary). ## No summary function supplied, defaulting to `mean_se()` ## Warning: Removed 5 rows containing non-finite values (stat_summary). Já no exemplo abaixo, a relação entre idade e pontuação no Inventário Beck de Ansiedade está agora agrupada pelo sexo do participante. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 29 rows containing non-finite values (stat_smooth). ## Warning: Removed 29 rows containing missing values (geom_point). Em situações onde existe uma grande quantidade de informação para ser apresentada, os resultados começam a se tornar difíceis de serem entendidos. O gráfico abaixo, por exemplo, é excessivamente carregado de informação e, consequentemente, inadequado. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex, shape = country)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 29 rows containing non-finite values (stat_smooth). ## Warning: Removed 29 rows containing missing values (geom_point). Em outro sentido, o gráfico a seguir quebra a apresentação dos resultados por país e, com isso, potencializa que a informação seja melhor compreendida. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) + facet_wrap( ~ country) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 29 rows containing non-finite values (stat_smooth). ## Warning: Removed 29 rows containing missing values (geom_point). 4.10 Resumo Este capítulo apresentou os aspectos tabulares e gráficos corriqueiramente encontrados em pesquisas de Psicologia e áreas congêneres. Entre os pontos principais, a heurística típica de construção de gráficos é um conteúdo importante para ser sempre lembrado e tem as seguintes condições: O gráfico deve ser sempre informativo e não oferecer distorções dos resultados A quantidade e a natureza (escala ou nível de medida) das variáveis definem o gráfico a ser feito Quando bem feitos, gráficos permitem um primeiro resultado inferencial References "],
["qui-quadrado.html", "Capítulo 5 Qui quadrado 5.1 Pesquisa 5.2 Execução no R 5.3 Tamanho do efeito 5.4 Execução no JASP 5.5 Escrita dos resultados 5.6 Resumo", " Capítulo 5 Qui quadrado Objetivos do capítulo 1. Apresentar o teste Qui-quadrado 2. Diferenciar o qui-quadrado de aderência, homogeneidade e independência 3. Realizar gráficos relacionados à distribuição de porcentagens 4. Apresentar e interpretar métricas de tamanho do efeito 5. Dar exemplos relacionados à escrita dos resultados O Teste Qui-quadrado é um conjunto de testes não-paramétricos utilizados para (1) verificar as distribuições de probabilidades de cada categoria de uma variável em relação a um valor teórico esperado (aderência), (2) verificar se as distribuições das categorias são as mesmas para diferentes subpopulações (homogeneidade) e (3) verificar se duas variáveis categóricas são independentes (independência). Apesar da diferenças em relação às perguntas analíticas, o sistema matemático é o mesmo: \\[\\chi^2=\\sum_{k=1}^{n} \\frac{(O_k - E_k)^2}{E_k}\\] onde: K se refere a quantidade de classes O é o valor observado de uma determinada classe E é o valor esperado desta classe Pela fórmula, é possível deduzir que quanto maior for a discrepância entre as frequências observadas empiricamente (O) e as frequências esperadas (E), maior será a estatística de teste e, consequentemente, menor será o valor de P. Se assume os seguintes pressupostos funcionais à execução de um Qui-quadrado: (i) Os dados são aleatórios e representativos da população (ii) as variáveis analisadas são categóricas (e.g., sexo, nível de escolaridade, grau de uma doença) (iii) Todas as frequências esperadas são maiores ou iguais a 1 (iv) No máximo, apenas 20% das frequências esperadas são inferiores a 5. uma curiosidade que remonta a história e explica parte da desavença que Pearson tinha com Fisher. O qui-quadrado foi originalmente desenvolvido em 1900 e 1904 por Karl Pearson (Pearson, 1900). Ronald Fisher detectou um erro no cálculo dos graus de liberdade e rapidamente divulgou isso, para descontentamento de Pearson (BAIRD, 1983). A tabela abaixo descreve as condições de análise, com exemplos ilustrativos: Versão do teste Variáveis Exemplo Aderência 1 categórica Verificar se a proporção de caras e coroas é de 50% cada Homogeneidade 2 categóricas Verificar se a proporção de homens e mulheres que gostam de uma marca de celular é similar Independência 2 categóricas Verificar se o sexo e a escolha do curso de graduação são independentes Algumas notas: O Qui-quadrado de aderência também é chamado de “qualidade do ajuste” ou “bondade”. Estas são traduções tipicamente para goodnes of fit. Como todas as análises são realizadas de uma maneira virtualmente idêntica, essas distinções são mais teóricas do que práticas. O Qui-quadrado de aderência tem uma proposta parecida com a ANOVA de uma via. 5.1 Pesquisa Base: Base R TDAH Arruda.Rdata Neste capítulo, vamos utilizar a pesquisa intitulada “Parent-reported diagnosis of Attention Deficit Hyperactivity Disorder and psychostimulant use among children and adolescents: a population-based nationwide study”, que está em avaliação pela revista “Social Psychiatry and Psychiatric Epidemiology (SPPE)”. Neste trabalho, tivemos o objetivo de verificar aspectos epidemiológicos do Transtorno do Déficit de Atenção com Hiperatividade (TDAH) em uma amostra representativa de crianças e adolescentes brasileiros, bem como explorar eventuais associações entre características sociodemográficas, especialmente os sexo do participante, e possíveis fatores e risco e TDAH. Neste momento, vamos seguir apenas com o qui-quadrado de independência, que foi o utilizado neste artigo. Como exposto no decorrer de outros capítulos, o teste de hipóteses começa pela formulação conceitual das hipóteses. Apesar de ser possível estipular \\(H_0\\) e \\(H_a\\) a partir de equações específicas,a apresentação será textual/substantiva. \\[H_0 = Não\\ há\\ associação\\ entre\\ sexo\\ e\\ TDAH \\\\ H_a = Há\\ associação\\ entre\\ sexo\\ e\\ TDAH \\\\ \\alpha = 0.05\\] Uma característica colateral a esta apresentação textual do teste de hipóteses do Qui-quadrado é evitar confusões que ocorrem em relação ao conceito do teste e sua formulação matemática. Com muita frequência, dividimos os testes de hipóteses naqueles que verificam “associação” e naqueles que verificam “diferenças”. Conceitualmente, o Qui-quadrado investiga associação entre variáveis. No entanto, sua formulação matemática é feita pela diferença entre um valor observado e um valor esperado (tal como ilustrado na equação ao início do capítulo). Assim, acredito que a formulação apenas textual evita criar confusões e ainda tornar o conteúdo mais palatável. 5.2 Execução no R O gráfico de barras é sempre um bom início para visualizar os dados. Repare que a barra azul (que representa a porcentagem de TDAH) parece se comportar de maneira diferente nos grupos. ggplot(ds_selected, aes(x= sex_male, fill = adhd_parent)) + geom_bar(position = &quot;fill&quot;) + coord_flip() + labs(x = &quot;sexo&quot;, y = &quot;Proporção&quot;, fill = &quot;TDAH&quot;) Em seguida, a tabela de contingência traz informações sobre o relacionamento das variáveis. Apesar do qui-quadrado não eleger uma VI e uma VD, Com bastante frequência utilizamos as linhas para apresentar a variável de maior interesse (neste caso, sexo) e as colunas para indicar o critério ou o eventual desfecho (neste caso, ter ou não TDAH). A porcentagem nas linhas e o valor esperado (em caso de independência entre as variáveis) auxiliam bastante na descrição dos resultados. gmodels::CrossTable(ds_selected$sex_male,ds_selected$adhd_parent, expected = T, chisq = T, prop.c = F, prop.t = F, prop.chisq = F) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Expected N | ## | N / Row Total | ## |-------------------------| ## ## ## Total Observations in Table: 7114 ## ## ## | ds_selected$adhd_parent ## ds_selected$sex_male | no | yes | Row Total | ## ---------------------|-----------|-----------|-----------| ## female | 3379 | 183 | 3562 | ## | 3309.145 | 252.855 | | ## | 0.949 | 0.051 | 0.501 | ## ---------------------|-----------|-----------|-----------| ## male | 3230 | 322 | 3552 | ## | 3299.855 | 252.145 | | ## | 0.909 | 0.091 | 0.499 | ## ---------------------|-----------|-----------|-----------| ## Column Total | 6609 | 505 | 7114 | ## ---------------------|-----------|-----------|-----------| ## ## ## Statistics for All Table Factors ## ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 41.60464 d.f. = 1 p = 1.117279e-10 ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ------------------------------------------------------------ ## Chi^2 = 41.01118 d.f. = 1 p = 1.513606e-10 ## ## O cálculo do qui-quadrado apresentado abaixo deixa claro que que é possível rejeitar a Hipótese nula, uma vez que o valor de P é menor do que o nível de significância previamente estipulado (0.05). 5.3 Tamanho do efeito Como tenho apresentado no decorrer dos outros capítulos, os valores de P quase nunca são informativos sobre a relevância dos resultados. O tamanho do efeito mais utilizado no ambiente das análises de Qui quadardo é o V de Cramer. Esta estatística gera valores 0-1 e é dada da seguinte maneira: \\[V=\\sqrt\\frac{\\chi^2}{n*df^`}\\] Em que: \\(\\chi^2\\) = valor do Qui quadrado obtido n = tamanho da amostra \\(df^`\\) menor valor entre (Linhas - 1) ou (Colunas - 1) da tabela de contingências que pode tem interpretação baseada nos graus de liberdade e é feita da seguinte maneira: Graus de liberdade Pequeno Médio 1 0.1 0.3 2 0.07 0.21 3 0.06 0.17 rcompanion::cramerV(ds_selected$sex_male,ds_selected$adhd_parent) ## Registered S3 method overwritten by &#39;DescTools&#39;: ## method from ## reorder.factor gdata ## Cramer V ## 0.07647 5.4 Execução no JASP Da mesma forma que foi feita no R, a apresentação de gráficos auxiliam o pesquisador a verificar padrões diferentes nos dados. A seção Descriptives é a mais relacionada a isso e será utilizada: O gráfico de barras a seguir apresenta a informação do sexo e do diagnóstico da criança. Para execução do Qui-quadrado (de associação), a tabela de contingência deve ser feita. Isso é acessado clicando em Frequencies e, em seguida, Contigency tables. O teste inferencial e o tamanho do efeito é acessado clicando em Statistics e o valor esperado de cada célula é obtido em cells. 5.5 Escrita dos resultados Como escrever os resultados A associação entre o sexo do participante e sua condição clínica (ter ou não TDAH) foi investida por um Teste Qui-quadrado de independência. Os resultados indicarma que ambas as variáveis são associadas (X2(1) = 41.605). O tamanho do efeito foi calculado pelo V de Cramer, que se mostrou pequeno 0.07. 5.6 Resumo O Qui-quadrado não é apenas um teste, mas um conjunto de análises realizadas em variáveis categóricas. Apesar de diferenças conceituais, o formato matemático é virtualmente o mesmo. O tamanho do efeito apresenta interpretações que podem variar em função dos graus de liberdade References "],
["teste-t.html", "Capítulo 6 Teste T 6.1 Pesquisa 6.2 Execução no R 6.3 Tamanho do efeito 6.4 Execução no JASP 6.5 Escrita dos resultados 6.6 Versão robusta do teste T 6.7 Mann-whitney 6.8 Teste T e regressão 6.9 Resumo", " Capítulo 6 Teste T Objetivos do capítulo 1. Apresentar o teste T 2. Discutir os pressupostos de execução do teste T 3. Realizar gráficos relacionados à comparação de médias 4. Apresentar e interpretar métricas de tamanho do efeito 5. Dar exemplos relacionados à escrita dos resultados 6. Apresentar versões não paramétricas do teste T (Wilcoxon-Mann-Whitney) O Teste T é um teste estatístico frequentemente utilizado para testar hipóteses sobre diferenças entre médias. Por utilizar dados amostrais para estimar um parâmetro (\\(\\mu\\)), ele é um teste parâmetrico. Apenas por um preâmbulo histórico, a origem do Teste T remonta o artigo publicado em 1908 por William Gosset. Na época, em função de seu trabalho na cervejaria Guiness, ele não assinou o artigo, mas apenas usou seu pseudônimo Student, motivo pelo qual o teste T também é chamado de Teste T de Student. É importante notar que estudantes de Psicologia e profissionais que trabalham com avaliação psicológica costumam ser deparados com uma métrica chamada “T score” (Escore T, as vezes), desenvolvido em 1939 por um professor de Psicologia (William Anderson McCall). Tenha em mente que essa métrica não tem relação com os procedimentos inferenciais relacionados ao teste T a não ser uma similaridade de nome (Krus &amp; Krus, 1977). É possível usar o Teste T para comparar a média de uma amostra com a média populacional (one sample t test), para comparar duas médias amostrais (two sample t test) ou para comparar duas médias de uma mesma amostra que foi investigada em dois momentos do tempo (paired ou matched t test). Se assume os seguintes pressupostos funcionais à execução de um Teste T: (i) Os dados são aleatórios e representativos da população (ii) a variável dependente é contínua (iii) A distribuição dos resultados populacionais é assumida como normal Quando há o interesse de utilizar o Teste T para comparar os resultados de dois grupos, é também necessário que: (iv) As variâncias dos grupos seja homogênea (princípio da homocedasticidade) (v) ambos os grupos sejam independentes Quando se utiliza o Teste T pareado, se viola o princípio da independência, mas é necessário que: (vi) o tamanho amostral seja o mesmo Eventualmente, quando os pressupostos são violados, testes não-paramétricas com propostas parecidas podem ser implementadas. A tabela abaixo concatena os testes estatísticos relacionados e, para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida “ordinal”. Versão do teste Um grupo Dois grupos independentes Grupos pareados Paramétrica One-sample t test Two-samples t test Paired t test Não-paramétrica Signed rank test Mann-whitney Wilcoxon Nota: Existe um intenso debate sobre a utilização de testes paramétricos e não-paramétricos em Psicologia. Algo pouco comentado, apesar de ser o aspecto mais importante em minha opinião, é que a hipótese testada em um teste paramétrico é diferente da testeda em um não-paramétrico. Ou seja, a substituição de um teste estatístico por outro, necessariamente, muda a hipótese de pesquisa investigada. 6.1 Pesquisa Base: Livro - R - ASQ SE 12 e 18 Neste capítulo, vamos utilizar a pesquisa intitulada “Confirmatory analysis and normative tables for the Brazilian Ages and Stages Questionnaires: Social–Emotional”, publicada em 2019 na Child Care Health Development. Esse trabalho teve dois objetivos. O primeiro visou confirmar a estrutura fatorial de um instrumento utilizado para avaliar possíveis atrasos no desenvolvimento de competências sociais e emocionais (ASQ:SE) e o segundo visou desenvolver tabelas normativas para comparar meninos e meninas. Essa é uma pesquisa muito importante, visto que conta com uma base de dados robusta (mais de 50 mil participantes) e faz interface entre psicometria, avaliação psicológica e políticas públicas. Neste capítulo, nosso o interesse será é o de comparar os resultados médios obtidos por meninos e meninas aos 12 e 18 meses. Assim, é necessário a escrita adequada das hipóteses e o nível de significância adotado na análise. Dessa maneira: \\[H_0: \\mu_{meninos} - \\mu_{meninas} = 0 \\\\ H_a: \\mu_{meninos} - \\mu_{meninas} \\neq 0 \\\\ \\alpha = 0.05\\] 6.2 Execução no R A primeira etapa importante é assegurar que a base de dados tenha o resultado relacionado às competências sociais e emocionais das crianças. Esse valor será computado pela soma de todos os itens da escala. No dplyr, isso é feito pela integração da função mutate com a select e será executado às crianças com 12 e 18 meses. asq_12months &lt;- asq_12months %&gt;% mutate(total_12 = rowSums(select(., starts_with(&quot;q_&quot;)), na.rm = TRUE)) asq_18months &lt;- asq_18months %&gt;% mutate(total_18 = rowSums(select(., starts_with(&quot;q_&quot;)), na.rm = TRUE)) Em seguida, iremos começar pelos 12 meses. O processo de testagem da hipótese é feito preliminarmente de maneira gráfica e, em seguida, pela implementação do teste específico. Apesar do gráfico não ser decisivo na tomada de decisão, ele auxilia a visualilzação da distribuição da variável que temos interesse, bem como oferece já um entendimento inicial dos resultados. Posto que a VI é discreta e a VD é continua (exposta no capítulo @ref(01-estatistica_descritiva)) tanto o gráfico de colunas/barras como o de densidade são úteis. O gráfico de barras tem uma vantagem de ser possível adicionar barras de erros, que já apresentam uma primeira evidência inferencial. gridExtra::grid.arrange( #plot 1 ggplot(asq_12months, aes(x = sex, y = total_12, fill = sex)) + geom_bar(stat = &quot;summary&quot;, fun = mean) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width = .2), #plot 2 ggplot(asq_12months, aes(x = total_12, fill = sex)) + geom_density(color = NA, alpha=.6) ) Feito isso, o próximo passo é a testagem formal da hipótese. Como exposto, o teste T de duas amostras independentes assume que os resultados da variável de interesse se distribua normalmente e que variância entre os grupos seja homocedástica. Tecnicamente, como o teste T é um caso especial de um modelo de regressão, a normalidade da variável de interesse se refere aos resíduos do modelo. Neste caso pode, isso pode ser aproximado testando a distribuição marginal dos resultados de ambos os grupos. A normalidade pode ser avaliada graficamente por QQ-plots e por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera. O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis conta os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade. ggplot(asq_12months, aes(sample = total_12)) + stat_qq() + stat_qq_line() + facet_wrap(~sex) Apesar do gráfico já ter sido bastante claro e sugerir fortemente desvio da normalidade em ambos os grupos, o teste formal é importante. O Shapiro-wilk costuma ser utilizado neste caso, uma vez que ele reúne diferentes características positivas no balanço entre erro do tipo 1 e 2 (Yap &amp; Sim, 2011). A Hipótese nula desse teste assume que a variável de interesse tem distribuiÇào (aproximadamente) normal. Assim, rejeitar a hipótese nula sugere que esse princípio foi violado e, com isso, o teste T pode ter resultados distorcidos. asq_12months %&gt;% group_by(sex) %&gt;% summarise(shapiro = shapiro.test(total_12)$p.value) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 2 x 2 ## sex shapiro ## &lt;fct&gt; &lt;dbl&gt; ## 1 M 1.98e-19 ## 2 F 4.80e-17 De maneira convergente ao gráfico, o Shapiro-wilk também apontou que o princípio da normalidade foi violado. Entretanto, por finalidades didáticas, as análises continuarão. A homogeneidade das variâncias pode ser testada visualmente e pelo teste de Bartlett ou Levene. De maneira análoga ao Shapiro-wilk, esses testes assumem como Hipótese nula a homogeneidade das variâncias. Consequemente, a rejeição desse pressuposto pode também trazer resultados distorcidos ao resultado do teste T. bartlett.test(total_12 ~ sex, data = asq_12months) ## ## Bartlett test of homogeneity of variances ## ## data: total_12 by sex ## Bartlett&#39;s K-squared = 1.1357, df = 1, p-value = 0.2866 Diferentemente do pressuposto da normalidade, o pressuposto da homocedasticidade foi preservado. Agora, finalmente, o teste T. (t_test_12m &lt;- t.test(total_12 ~ sex, var.equal = T, data = asq_12months)) ## ## Two Sample t-test ## ## data: total_12 by sex ## t = 0.36787, df = 1039, p-value = 0.713 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.077671 3.036424 ## sample estimates: ## mean in group M mean in group F ## 24.91713 24.43775 Os resultados trazem a média de ambos os grupos (24.9171271 e 24.437751), a estatística do teste (0.3678679, as vezes chamada de T calculado), os graus de liberdade (1039) e o valor de p 0.7130467. Repare que como o valor de p é superior ao valor estipulado do nível de significância (0.05), falha-se em rejeitar a Hipótese nula, indicando que, apesar de numericamente distintos, os resultados não são estatisticamente significativos (na população). Com isto concluído, é também possível verificar se existem diferenças em idades mais avançadas, tal como 18 meses. A sintaxe é customizável e torna-se fácil testar a hipótese da diferença apenas customizando a hipótese e a sintaxe. O gráfico a seguir é a primeira parte a ser feita e apresenta o padrão dos resultados aos 18 meses. gridExtra::grid.arrange( ggplot(asq_18months, aes(x = sex, y = total_18, fill = sex)) + geom_bar(stat = &quot;summary&quot;, fun=mean) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width = .2), ggplot(asq_18months, aes(x = total_18, fill = sex)) + geom_density(color = NA, alpha=.6)) Tal como feito aos 12 meses, é necessário verificar o pressuposto de normalidade e homocedasticidade antes de realizar o teste formal. Assumindo pedagogicamente ambas as condições, os resultados teste formal é apresentado seguir. (t_test_18m &lt;- t.test(total_18 ~ sex, var.equal = T,data = asq_18months)) ## ## Two Sample t-test ## ## data: total_18 by sex ## t = 4.6185, df = 5725, p-value = 3.949e-06 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 1.484680 3.674581 ## sample estimates: ## mean in group M mean in group F ## 27.52685 24.94722 Diferentemente do anterior, agora o resultado foi significativo (p &lt; 0.01), trazendo evidências que permitem concluir pela rejeição da hipótese nula. É importante ter uma atenção especial à significância estatística. De forma alguma, um resultado que rejeita a hipótese nula deve ser entendido como “aceitação da hipótese alternativa”, tampouco como evidência de causalidade. É fundamental lembrar que o valor de P se refere à probabilidade de encontrar a estatística de teste calculada, ou uma ainda mais exterma, assumindo que a hipótese nula é verdadeira (Wasserstein &amp; Lazar, 2016). Apesar de algo contra-intuitivo (e talvez desanimador), é assim que a estatística frequentista funciona. 6.3 Tamanho do efeito Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Assim, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde. Existem duas famílias principais no ambiente do tamanho do efeito, que são a família “d” e a família “r”. Tecnicamente, quando comparamos médias, usamos o d de Cohen para calcular a distância entre as médias das distribuições normais sobrepostas. A interpretação é a seguinte: Cohen’s d Interpretação d &lt; 0.2 Irrelevante d \\(\\geq\\) 0.2 Pequeno d \\(\\geq\\) 0.5 Moderado d \\(\\geq\\) 0.8 Grande effsize::cohen.d(total_18 ~ sex, data = asq_18months) ## ## Cohen&#39;s d ## ## d estimate: 0.12216 (negligible) ## 95 percent confidence interval: ## lower upper ## 0.07025972 0.17406037 6.4 Execução no JASP Da mesma forma que foi feita no R, a apresentação de gráficos auxiliam o pesquisador a verificar padrões diferentes nos dados. Nesta parte, apenas a base de crianças com 18 meses será utilizada. Após carregar tal base, a seção Descriptives apresentará o gráfico inicial dos resultados. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista Variables irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção Split. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Isto posto, será necessário arrastar as variáveis de interesse aos seus respectivos locais. Neste caso, o total_18 para parte das VDs, enquanto sexo para a VI. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. Em seguida, ao clicar na opção Plots, será possível selecionar o Boxplot. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados das crianças de 18 meses em função do sexo. Para execução do Teste T, deve-se clicar em T-Test e, em seguida, Independent samples T-test. Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir: Repare que a Grouping variable é o local onde a VI deverá ser colocada, enquanto a Variables é o local onde a VD irá ser inserida. É possível ter apenas uma VI, enquanto diferentes vDs podem ser inseridas na seção Variables para serem analisadas independentemente. Neste caso de agora, a VI é sexo enquanto a VD é o total_18. Ao fazer isso, o JASP automaticamente irá fazer o Teste T e apresentar os resultados. Pragmaticamente, o valor de P costuma ser utilizado para decisões estatísticas e ele está marcado pelo quadrado roxo. Entretanto, da mesma forma como apresentado antes, a interpretação deste resultado não pode ser feita de uma forma automática. É necessário saber se os pressupostos foram ou não atendidos, bem como calcular o tamanho do efeito. Estas opções estão dispostas na parte inferior à esquerda do programa. Os resultados são os mesmos já obtidos pelo R. Ambos os pressupostos foram violados, sugerindo uma interpretação bastante cautelosa dos achados. Finalmente, o resultado inicialmente calculado (Teste t) e o tamanho do efeito podem ser analisados em conjunto. O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença. Os resultados obtidos pelo JASP são identicos aos do R. Eventualmente, a diferença em relação ao sinal (+ ou -) é devida à codificação feita pelos programas e nada interfere na interpretação dos resultados. 6.5 Escrita dos resultados O primeiro resultado obtido foi que meninos e meninas não apresentaram diferenças em seus resultados médios quando tinham 12 meses. Abaixo uma sugestão de escrita. Como escrever os resultados Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 12 meses de idade. Os resultados mostraram que os valores médios de meninos e meninas não são significativamente diferentes (t(1039) = 0.37, p = 0.71). Dessa maneira, as diferenças encontradas podem ser mais bem explicadas por outras fontes de variações. Em seguida, verificamos que essa diferença é significativa aos 18 meses e abaixo uma outra sugestão de escrita. Como escrever os resultados Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 2 anos de idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, DP = 21.8) e meninas (M = 24.9, DP = 20.3) são significativamente diferentes (t(5725) = 4.62, p &lt; 0.01), apesar do tamanho do efeito ser irrelevante (d = 0.12). 6.6 Versão robusta do teste T Em muitas situações, os pressupostos do teste T são violados e parte da literatura argumenta que o teste T é robusto o suficiente para lidar com isso (Lumley et al., 2002), equanto outra parte sugere que é melhor optar por versões com médias aparadas ou não-paramétricas (Field &amp; Wilcox, 2017). No entanto, o que não costuma ser discutido com tanta frequência é que a modificação do teste estatístico utilizado, necessariamente, modifica a hipótese da pesquisa. Nesse sentido, a decisão de alterar o teste estatístico deve ser feito com justificativa teórica por parte do pesquisador. O pacote WRS apresenta versões robusta do Teste T. Ainda, o próprio R base oferece uma solução para condições em que a homogeneidade dos grupos não é aceita, que é o Welch-test. Esse teste é feito assumindo estipulando var.equal = F na sintaxe previamente exposta ou removendo este argumento por completo. No JASP, é possível acessar a versão robusta clicando em Welch, embaixo do Student, que já é previamente marcado. 6.7 Mann-whitney O teste de Wilcoxon-Mann-Whitney costuma ser chamado de versão não-paramétrica do Teste T. Na verdade, isso não é totalmente verdadeiro, já que eles testam elemento diferentes. Assim, quando os pressupostos do teste T são violados, o Mann-Whitney é um forte candidato para sua substituição. Se de um lado esse teste supera tais pressupostos, por outro ele responde a uma hipótese diferente daquela que o teste T trabalha, conforme mencionado. Enquanto o teste T compara médias, o Mann-whitney compara os valores ranqueados (postos). Nota-se que ele não é um teste para comparar medianas e que isso só ocorre em condições restritas. 6.7.1 Execução No R A sintaxe a seguir apresenta os resultados. Repare que as conclusões estatística são virtualmente identicas às obtidas previamente, em que foi possível rejeitar a hipótese nula. (mann_whiyney_18m &lt;- wilcox.test(total_18 ~ sex, data = asq_18months)) ## ## Wilcoxon rank sum test with continuity correction ## ## data: total_18 by sex ## W = 4368187, p-value = 9.902e-06 ## alternative hypothesis: true location shift is not equal to 0 6.7.2 Tamanho do efeito O tamanho do efeito também pode ser calculado ao implementar \\(Z/\\sqrt{(n)}\\). O output padrão do R não oferece a informação de Z, mas o pacote coin dispõe dessa métrica. coin::statistic(coin::wilcox_test(total_18 ~ sex, data = asq_18months)) ## [1] 4.41932 Assim, implementando a fórmula, o tamanho do efeito seria aproximadamete 0.06. 6.7.3 Escrita dos resultados A literatura não é muito concordante em como escrever os resultados do Mann-Whitney e abaixo há uma sugestão. Como escrever os resultados Os dados foram analisados pelo teste Wilcoxon-Mann-Whitney para investigar as diferenças nos resultados do desenvolvimento entre meninos (Mdn = 25, IQR = 30, M = 27.53, SD = 21.61) e meninas (Mdn = 20, IQR = 25, M = 24.95, SD = 20.34) com 18 meses de idade. Os resultados indicaram que os resultados foram significativos (W = 4368187, p &lt; 0.01), mas com efeito negligenciável (0.12). 6.7.4 Execução no JASP No JASP, é necessário marcar a opÇão Mann-Whitney no lugar da opção Student, já previamente definida. O JASP utiliza a Correlação rank-bisserial como método padrão para relatar o tamanho do efeito para o teste de Mann-Whitney 6.8 Teste T e regressão Conforme alertado, o Teste T é um caso particular de um modelo de regressão que assume que a variável independente é uma dummy. Assim, \\(b_0\\) (intercepto) é o grupo que recebeu o valor 0 e \\(b_1\\) (inclinação) é o grupo que recebeu o valor 1. Caso isso não tenha sido definido inicialmente, ao se usar o R, basta estipular que a variável é um fator. Nesse caso, o R atribuiu os meninos como intercepto o valor médio dos meninos e a inclinação \\(b_1\\) é justamente a diferença entre os valores (24.95-27.53). Nesse caso, -2.58. A estatística F é equivalente a \\(t^2\\) do teste t em sua versão tradicional, que assume variâncias iguais entre grupos. lm(total_18 ~ sex, data = asq_18months) %&gt;% olsrr::ols_regress() ## Model Summary ## --------------------------------------------------------------- ## R 0.061 RMSE 21.117 ## R-Squared 0.004 Coef. Var 80.324 ## Adj. R-Squared 0.004 MSE 445.920 ## Pred R-Squared 0.003 MAE 16.152 ## --------------------------------------------------------------- ## RMSE: Root Mean Square Error ## MSE: Mean Square Error ## MAE: Mean Absolute Error ## ## ANOVA ## ------------------------------------------------------------------------- ## Sum of ## Squares DF Mean Square F Sig. ## ------------------------------------------------------------------------- ## Regression 9511.801 1 9511.801 21.331 0.0000 ## Residual 2552890.199 5725 445.920 ## Total 2562401.999 5726 ## ------------------------------------------------------------------------- ## ## Parameter Estimates ## ---------------------------------------------------------------------------------------- ## model Beta Std. Error Std. Beta t Sig lower upper ## ---------------------------------------------------------------------------------------- ## (Intercept) 27.527 0.387 71.160 0.000 26.769 28.285 ## sexF -2.580 0.559 -0.061 -4.619 0.000 -3.675 -1.485 ## ---------------------------------------------------------------------------------------- Assim, quando se comenta sobre o princípio da normalidade no teste T, o que se está falando é sobre a normalidade dos resíduos deste modelo. Isso pode ser visualmente pela análise de um QQ plot: olsrr::ols_plot_resid_qq(lm(total_18 ~ sex, data = asq_18months)) Há também testes estatísticos formais, tal como o Anderson-Darling. Neste, a hipótese nula é de que os resíduos são normalmente distribuídos. nortest::ad.test(lm(total_18 ~ sex, data = asq_18months)$residuals) ## ## Anderson-Darling normality test ## ## data: lm(total_18 ~ sex, data = asq_18months)$residuals ## A = 116.57, p-value &lt; 2.2e-16 Os resultados foram convergentes ao alcançados durante o capítulo, indicando pela violação da normalidade. 6.9 Resumo O Teste T é um teste paramétrico e alguns pressupostos devem ser checados antes da interpretação dos resultados Com frequência, os pressupostos são violados e o pesquisador deverá tomar decisões sobre a manutenção, modificação ou substituição deste teste por outro O Teste T é um caso particular de um modelo de regressão O tamanho do efeito é uma métrica importante e deve ser apresentada References "],
["anova.html", "Capítulo 7 ANOVA 7.1 Legenda 7.2 Pesquisa 7.3 ANOVA de 1 via 7.4 ANOVA de 2 vias 7.5 ANOVA Fatorial 7.6 Resumo", " Capítulo 7 ANOVA Objetivos do capítulo 1. Apresentar a ANOVA 2. Discutir os pressupostos de execução da ANOVA 3. Realizar gráficos relacionados à comparação de médias 4. Apresentar e interpretar métricas de tamanho do efeito 5. Dar exemplos relacionados à escrita dos resultados 6. Discutir os testes post-hoc 7. Apresentar o teste Kruskal-Wallis A ANOVA é um teste estatístico desenvolvimento para verificar diferenças médias entre diversos grupos. Pragmaticamente, é possível entender ANOVA como um super teste T ou também um caso particular de um modelo de regressão. Assim, de maneira similar ao teste T, a ANOVA e todas as suas extensões (e.g., ANCOVA e MANOVA) são casos especiais de um modelo de regressão que lidam com variáveis independentes categóricas. Alguns autores indicam que a ANOVA é a técnica inferencial mais utilizada em Psicologia (Chartier &amp; Faulkner, 2008; David C Howell, 2011). Se por um aspecto, isso é extremamente vantajoso por estreitar a relação entre Psicologia e Estatística, por outro, isso parece ter contribuído para criação e manutenção de diferentes conceitos equivocados sobre a ANOVA. Conceitualmente, a ANOVA é um modelo linear, tal que: \\[y_i = b_0 + b_1X{_1}_i + \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) é a inclinação (coeficiente angular) \\(X_1\\) é a variável independente em questão \\(\\epsilon_{i}\\) é o erro/resíduo Todos os pressupostos dos modelos linares são mantidos e o mnemônico LINE auxilia a resgatar todos eles. Assume-se que o erro é independente e identicamente distribuído (\\(iid\\)), distribuído normalmente com média 0 e variância constante \\(\\sigma^2\\), ou seja: \\[ \\epsilon\\stackrel{iid}{\\sim} \\mathcal{N}(0,\\,\\sigma^{2})\\,\\] Além de homocedástico: \\[ VAR(\\epsilon |x_1,x_2,...,x_k)=\\sigma^2 \\]. iidainda signica erros descorrelatados \\[ COV(\\epsilon_i,\\epsilon_j)=0 \\]. É importante atentar que assumir média 0, também implica que a correlação do erro com as variáveis é nula. Operacionalmente, o erro representa todos os fatores de pesquisa e problemas de medição que afetam o resultado além das variáveis independentes consideradas na modelagem. Da mesma forma que feito em outros capítulos, a tabela abaixo concatena os testes estatísticos relacionados quando os pressupostos são violados. Para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida “ordinal”. Versão do teste Um ou mais fatores Momentos repetidos Paramétrica Anova de k via(s) Anova de medidas repetidas Não-paramétrica Kruskal-Wallis Teste de Friedman ou Page Test A ANOVA tem diversas características de modelagem que serão descritas na seção a seguir, 7.1 Legenda Diferentes termos são empregados em uma ANOVA e em modelos próximos. A legenda a seguir visa auxiliar no entendimento de cada um deles e aproximar o leitor a conceitos amplos utilizados em modelos lineares: Via: Variável independente, variável fonte, variável preditora, tratamento Fator: Sinônimo de via Desfecho: Variável dependente, variável critério Níveis: Grupos, classes, condições, categorias da variável independente Efeito principal: Efeito da variável independente em questão (controlanddo pelas outras no modelo) Efeito de interação: Efeito do termo de interação entre duas ou mais variáveis independentes. Quando significativo, não se interpreta os efeitos principais. Efeito simples: Efeito de uma variável independente em um nível (específico) de outra variável independente. ANCOVA: Análise de covariância, onde se controla os resultados por uma variável contínua MANOVA: Análise multivariada de variância, onde se extende a ANOVA para incluir duas variáveis dependentes. É um modelo multivariado. Por heurística, se escreve os delinementos estudados por uma ANOVA com \\(\\eta\\). Por exemplo, se o interesse for verificar o efeito do sexo (masculino ou feminino) e da escolaridade (fundamental, médio e superior), a representação será \\(\\eta = 2 \\times 3\\). Isso significa que a ANOVA tem dois fatores (sexo e escolaridade) e o primeiro fator tem dois níveis e o segundo tem 3 níveis. A tabela a seguir resume as denominações encontradas na literatura: VD / VI Uma VI 2 ou mais VIs (sem interação) 2 ou mais VIs (com interação) Uma VD Anova de 1 via (one way) Anova 2 (ou mais) vias (multi way) Anova fatorial &gt; uma VD MANOVA 7.2 Pesquisa Base: Livro - R - TEG Neste capítulo, vamos utilizar a pesquisa intitulada “A relação entre o nível de Empreendedorismo (TEG) e os aspectos sociodemográficos dos Taxistas cooperados da cidade de Santo André/São Paulo, Brasil”, publicada em 2016 na Revista Eletrônica de Gestão e Serviços, em que sou co-autor. O objetivo dessa pesquisa foi identificar o nível de empreendedorismo em 147 taxistas de Santo André/SP, bem como averiguá-lo em associação aos aspectos sociodemográficos. A base contém 14 variáveis, sendo 6 variáveis da escala utilizada para avaliação do empreendedorismo e 8 variáveis gerais, incluindo aqui os aspectos sociodemográficos, como sexo e escolaridade. Essa base será utilizada para realizar uma ANOVA de 1 via, 2 vias e uma ANOVA fatorial. 7.3 ANOVA de 1 via A pergunta que temos agora é sobre o possível efeito da escolaridade na Tendência Empreendedora Geral (teg). Trata-se de uma ANOVA de 1 via, dado que existe apenas uma VI, com mais de 2 níveis. 7.3.1 Execução no R Ao trabalhar no R, é fundamental se certificar que os tipos das variáveis estão corretamente definidos em função da escala de medida utilizada. Erros nessa etapa podem gerar resultados absolutamente incorretos. A escolaridade é uma variável categórica (ordinal, tratada como discreta) e é necessário definir claramente isso ao R antes da análise propriamente dita. Isso pode ser feito pela função case_when e levels. O case_when irá usar os valores originalmente presentes nessa variável na criação de uma variável categórica e o levels deixará claro a ordem de cada categoria, o que é útil para que os gráficos sejam feitos corretamente. dados_teg &lt;- dados_teg %&gt;% mutate(escolaridade_fct = factor(case_when( escolaridade == 1 ~ &quot;primario&quot;, escolaridade == 2 ~ &quot;ginasio&quot;, escolaridade == 3 ~ &quot;Colegial&quot;, escolaridade == 4 ~ &quot;superior&quot;), levels=c(&quot;primario&quot;,&quot;ginasio&quot;,&quot;Colegial&quot;,&quot;superior&quot;))) Uma vez que os itens de um instrumento sociodemográfico devem levar em consideração o contexto das pessoas avaliadas e, as categorias de escolaridade foram definidas como as apresentadas. Primário significa escolaridade até o 5º ano, ginásio significa escolaridade até o 9º ano e colegial é equivalente ao ensino médio. As hipóteses precisam ser formalmente descritas: \\[H_0 = \\mu_{escolaridade_i} - \\mu_{escolaridae_j} = 0 \\\\ H_a = c.c \\\\ \\alpha = 0.05\\] Aqui, o subscrito \\(i\\) e \\(j\\) foi utilizado de maneira liberal para apresentar a diferença entre todas as combinações lineares possíveis. Em seguida, a apresentação tabular das médias e desvios-padrão pode ser realizada. dados_teg %&gt;% group_by(escolaridade_fct) %&gt;% summarise_at(vars(teg), lst(n=~n(),mean,sd)) %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) escolaridade_fct n mean sd primario 6 24.67 4.63 ginasio 33 26.76 3.86 Colegial 85 28.87 4.11 superior 23 31.83 5.23 Tal como ilustrado no decorrer dos outros capítulos, gráficos são fundamentais para entendimento do relacionamento entre as variáveis. Uma vez que a escolaridade (VI) é tratada como discreta e a TEG (VD) é contínua, um gráfico de barras é adequado. A inclusão das barras de erro permite uma compreensão inferencial inicial. ggplot(dados_teg, aes(x=escolaridade_fct, y = teg, fill = escolaridade_fct)) + geom_bar(stat = &quot;summary&quot;, fun = mean) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;) + theme(legend.position = &quot;none&quot;) A visualização dos resultados já permite identificar algumas caracteríticas gerais. Primeiro, quão maior a escolaridade, maior o o valor obtido na escala. Segundo, algumas barras de erros estão superpostas e outras não, o que nos leva à conclusão preliminar de que resultados significativos estarão presentes na próxima etapa, que é a modelagem formal dessa hipótese. A modelagem formal irá contemplar n-1 níveis dos preditores e estipulará no intercepto o nível de referência. Dessa maneira: \\[y_{i} = b_{0} + b_1Esc_{ginasio} + b_2Esc_{colegial} + b_1Esc_{superior} + \\epsilon_{i}\\] \\(b_0\\) representa o intercepto, que aqui é o valor médio da Escolaridade primária \\(b_i\\) representa os outros preditores \\(\\epsilon_{i}\\) representa o erro A função lm será utilizada e o objeto mod_escolaridade será armazenado. É também possível utilizar a função aov e a escolha da lm foi apenas por conveniência. mod_escolaridade &lt;- lm(teg ~ escolaridade_fct, dados_teg) Antes de checar os resultados, é necessário verificar se os pressupostos da ANOVA foram atendidos. Esses pedem que os resíduos sejam normalmente distribuídos e homocedásticos. Tal como previamente exposto no teste T, a investigação dessas condições é tanto feita por gráficos e testes formais e ambos são muito úteis. A análise da normalidade dos resíduos será inicialmente feita. O gráfico abaixo apresenta a distribuição dos resíduos: ggplot(fortify(mod_escolaridade), aes(.resid)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;grey&quot;) + geom_density(aes(y= ..count..)) O teste formal pode ser feito via shapiro-wilk. Tal como no teste T, a \\(H_0\\) desse teste assume normalidade e, idealmente, não deve ser rejeitada. shapiro.test(residuals(mod_escolaridade)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod_escolaridade) ## W = 0.97502, p-value = 0.008721 Uma vez que o valor foi menor do que o previamente estipulado ao \\(\\alpha\\), é possível concluir que o pressuposto da normalidade foi violado. situações como essa são muito frequentes. Na literatura, são presentes recomendações de ajuste dos dados por alguma função g(.) ou tornar mais severo o valor de p na interpretação dos resultados. Por exemplo, em vez de 0.05, usar 0.01. A homocedasticidade pode ser verificada por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico. ggplot(fortify(mod_escolaridade), aes(x=.fitted, y=.resid)) + geom_point() + geom_hline(yintercept = 0) Além do teste de Bartlett ou Levene, em que estipulam \\(H_0\\) como homocedasticidade e, idealmente, não deve ser rejeitada. car::leveneTest(mod_escolaridade) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 1.1372 0.3362 ## 143 A homocedasticidade foi assumida. Dessa maneira, mesmo com a violação da normalidade, o modelo será utilizado e seu sumário geral será apresentado pela função apa.aov do pacote apaTables. Isso é importante para garantir resultados programas tipicamente utilizados, como o SPSS e o STATA. Essa tabela é padronizada e muito similar na maioria dos programas estatísticos. Ela traz as seguintes informações principais: Preditor Soma dos Quadrados Graus de liberdade Quadrado médio Estat. F Fator Entre (SSB) K-1 MSB = SSB/K-1 F = MSB/MSW Resíduo Dentro (SSW) N-K MSW = SSW/N-K Total Total (SQT) N-1 Aqui, K significa quantidade de categorias dentro de um fator e N significa a quantidade de observações consideradas. As siglas em inglês são comumeiramente utilizadas falar falar da “Soma dos quadrados entre os grupos” (SSB), “Soma dos quadrados dentro dos grupos” (SSW), “Quadrado médio entre grupos” (MSB) e “Quadrado médio dentro dos grupos” (MSW). Repare também que,a este momento, os aspectos são apenas apresentados conceitualmente e não matematicamente. Em outro momento, aspectos da decomposição da variância serão também descritos. apaTables::apa.aov.table(mod_escolaridade) ## ## ## ANOVA results using teg as the dependent variable ## ## ## Predictor SS df MS F p partial_eta2 ## (Intercept) 3650.67 1 3650.67 200.61 .000 ## escolaridade_fct 449.33 3 149.78 8.23 .000 .15 ## Error 2602.27 143 18.20 ## CI_90_partial_eta2 ## ## [.06, .22] ## ## ## Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared A leitura desse resultado é similar a de um modelo de regressão e a de outros modelos lineares e, em linhas gerais, em relatório ou publicações quase sempre apenas se diz que o modelo foi significativo, indicando as principais estatísticas obtidas da seguinte maneira: F(3,143) = 8.23, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]. No entanto, o que essa constatação está realmente dizendo é que houve uma comparação entre dois modelos, um que usou os resultados da variável “escolaridade” para prever os resultados obtidos pelo TEG (chamado de Modelo aumentado) e outro que usou apenas a média que o TEG (chamado de modelo compacto ou nulo neste caso). O resultado significativo indica que a inclusão da “escolaridade” no modelo testado foi significativamente capaz de reduzir o erro de previsão que o modelo nulo obteve (em ingles Proportional Reduction in Error ou PRE). Ainda nesse caso, o ηp2 (eta parcial quadrado) indica a proporção da variabilidade dos resultados do TEG que pode ser atribuídos à escolaridade e é uma métrica de tamanho do efeito, cuja interpretação se recomenda da seguinte maneira: ηp2 | Interpretação | :—– :—– | ηp2 &lt; 0.01 | Irrelevante | ηp2 \\(\\geq\\) 0.01 | Pequeno | ηp2 \\(\\geq\\) 0.06 | Moderado | ηp2 \\(\\geq\\) 0.14 | Grande De fato, quando isso ocorre, a busca por possíveis diferenças entre todas as comparações possíveis costuma ser feita por testes post hocs. Entretanto, é importante mencionar que que se uma ANOVA é significativa, isso não significa necessariamente que haverá alguma diferença entre as médias dos grupos. Tecnicamente, a diferença pode ocorrer em qualquer comparação possível, como grupo 1 contra grupos 2 + grupo 3 ou grupo 2 contra grupo 1+3. Dessa forma, o resultado geral da ANOVA e testes post hoc respondem questões diferentes e é possível realizar qualquer comparação múltipla sem sequer realizar a ANOVA, desde que os resultados sejam devidamente corrigidos caso se assuma alguns pressupostos sobre os constrastes. Uma vez que realizar uma ANOVA não é tecnicamente necessário para realização de comparações pareadas, é possível que alguém se pergunte qual é, então, a necessidade da realização deste primeiro teste. De fato, hoje em dia, a realização da ANOVA ocorre mais para que o pesquisador (i) consiga realizar computacionalmente todas as comparações pareadas entre as categorias da variável e, em seguida, (ii) corrigir adequadamente o valor de P obtido em cada computação. Isso dito, uma vez que a escolaridade foi significativa, as principais comparações serão testadas dois a dois.Sempre que múltiplas que comparações são realizadas, é esperado que haja uma inflação do erro do tipo 1 e, por isso, é necessário ajustar o valor de P. Repare que a quantidade de comparações pode ser calculada da seguinte forma: \\[ J*(\\frac{J-1}2) \\] \\(J\\) é a quantidade de níveis da variável Nesse caso: \\[ 4*(\\frac{3}2) = 6 \\]. Para a comparação pareada, o pacote emmeans será utilizado. 7.3.2 Post hoc A mecanica do por detrás do post hoc é a comparação pareada de todos os níveis presentes no fator, seguido pelo ajuste do valor de P. Existem muitas técnicas para tal ajuste e elas costumam ser agrupadas em função da sua robustez à violação da homocedasticidade. Para fins práticos, vamos utilizar uma técnica considerada bastante conservadora, chamada de Bonferroni, que multiplica o valor de p encontrado pela quantidade de comparações. O resultado das comparações dois a dois será armazenado em um objeto específico, nomeado como post_hoc_escolaridade. Isso será útil para apresentar sumários e gráficos. post_hoc_escolaridade &lt;- emmeans(mod_escolaridade, &quot;escolaridade_fct&quot;) %&gt;% pairs(., reverse = TRUE, adjust = &quot;bonferroni&quot;) Tal como feito até agora, o gráfico inicial das comparações será realizado. A adição das barras de erro gera interpretação mais rápida e simples para todas as comparações. CI &lt;- confint(post_hoc_escolaridade) ggplot(mapping = aes(contrast, estimate)) + geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) + geom_point(data = summary(post_hoc_escolaridade)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_size(trans = &quot;reverse&quot;) + coord_flip() A apresentação tabular é fundamental e apresenta as estatísticas inferenciais de interesse: post_hoc_escolaridade %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) contrast estimate SE df t.ratio p.value ginasio - primario 2.09 1.89 143 1.10 1.00 Colegial - primario 4.20 1.80 143 2.33 0.13 Colegial - ginasio 2.11 0.87 143 2.42 0.10 superior - primario 7.16 1.96 143 3.66 0.00 superior - ginasio 5.07 1.16 143 4.37 0.00 superior - Colegial 2.96 1.00 143 2.95 0.02 Os resultados são significativos na comparação Superior - Primário, Superior - Ginásio e Superior - Colegial. Em todos, os resultados do TEG foi mais elevado naqueles participantes que haviam concluído o ensino superior. A esse momento, a escrita é fundamental: Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de uma via investigando o efeito da escolaridade no empreendedorismo, medido por um escala específica. Foi possível concluir que a escolaridade é significativa (F(3, 143) = 8.23, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]). As comparações pareadas foram ajustadas pela técnica de Bonferroni e mostraram que os participantes com ensino superior apresentam pontuação mais alta do que àqueles com o primário (Δ = 7.16, p &lt; 0.01), ginásio (Δ = 5.07, p &lt; 0.01) e colegial (Δ = 2.96, p &lt; 0.05). 7.4 ANOVA de 2 vias Frequentemente, o interesse do pesquisador está em investigar como múltiplos fatores afetam a variável de interesse. Ao aumentar o número de variáveis independentes no modelo, se aumenta a quantidade de vias que a ANOVA possui. Se, por exemplo, a investigação visasse testar o efeito da escolaridade e do sexo no empreendedorismo, teríamos, por definição, uma ANOVA de duas vias. É fundamental atentar que essa modelagem inicialmente considera apenas os efeitos principais dos fatores e não assume ou modela uma possível interação entre os preditores. 7.4.1 Execução no R Após a escrita adequada da hipótese, a modelagem segue o mesmo padrão da feita anteriormente, iniciando pela definição correta do tipo de variável em relação à sua escala de medida. dados_teg &lt;- dados_teg %&gt;% mutate(sexo_fct = factor(case_when( sexo == 1 ~ &quot;masculino&quot;, sexo == 2 ~ &quot;feminino&quot;), levels=c(&quot;masculino&quot;,&quot;feminino&quot;))) Tabelas e gráficos também devem ser apresentadas. dados_teg %&gt;% group_by(escolaridade_fct, sexo_fct) %&gt;% mutate(rn = row_number()) %&gt;% summarise_at(vars(teg), lst(n=~n(), mean, sd)) %&gt;% pivot_wider(names_from = sexo_fct, #indexador unico names_sep = &quot;_&quot;, #pode ser removido values_from = c(n:sd)) %&gt;% #organizar valores kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) escolaridade_fct n_masculino n_feminino mean_masculino mean_feminino sd_masculino sd_feminino primario 6 NA 24.67 NA 4.63 NA ginasio 30 3 27.03 24.00 3.91 2.00 Colegial 73 12 28.63 30.33 3.83 5.48 superior 22 1 31.59 37.00 5.23 NA Repare que não há desvio-padrão para mulheres com o ensino superior. Isso ocorre pela quantidade de participantes que satisfazem essas condições. Tecnicamente, isso ou impossibilitaria essa análise ou tornaria a interpretação altamente viesada. No entanto, por condição pedagógica, vamos seguir com o procedimento. Como o objetivo é verificar duas variáveis isoladamente, os gráficos também podem ser isolados. gridExtra::grid.arrange( ggplot(dados_teg, aes(x=escolaridade_fct, y = teg, fill = escolaridade_fct)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;) + theme(legend.position = &quot;none&quot;), ggplot(dados_teg, aes(x = sexo_fct, y = teg, fill = sexo_fct)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;) + theme(legend.position = &quot;none&quot;)) Agora, formalmente a modelagem será feita. Os passos devem ser exatamente os mesmos, incluindo a verificação de pressupostos e interpretação dos resultados. A esse momento, a tabela padronizada da ANOVA é a seguinte: Preditor Soma dos Quadrados Graus de liberdade Quadrado médio Estat. F Fator (A) Entre (SS(A)) K(A)-1 MS(A) = SS(A)/K-1 F = MS(A)/MSW Fator (B) Entre (SS(B)) K(B)-1 MS(B) = SS(B)/K-1 F = MS(B)/MSW Resíduo Dentro (SSW) N-1-(df(A)+df(B)) MSW = SSW/N-1-(df(A)+df(B)) Posto isso, os resultados obtidos são: mod_escolaridade_sexo &lt;- lm(teg ~ escolaridade_fct + sexo_fct, dados_teg) apaTables::apa.aov.table(mod_escolaridade_sexo) ## ## ## ANOVA results using teg as the dependent variable ## ## ## Predictor SS df MS F p partial_eta2 ## (Intercept) 3650.67 1 3650.67 200.36 .000 ## escolaridade_fct 450.51 3 150.17 8.24 .000 .15 ## sexo_fct 14.93 1 14.93 0.82 .367 .01 ## Error 2587.34 142 18.22 ## CI_90_partial_eta2 ## ## [.06, .22] ## [.00, .04] ## ## ## Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared Os resultados continuam constantando o efeito da escolaridade (F(3,142) = 8.24, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]) no empreendedorismo, mas também concluiu que o efeito do sexo não é significativo (F(1, 142) = 0.816, p = 0.36, ηp2 = 0.01, 90% CI [.00, .04]). É importante ter atenção à forma de reportar os resultados, uma vez que delineamentos de dois fatores quase sempre produz coeficientes são diferentes do delineamento anterior. A análise post hoc que seria feita agora seria a mesma feita anteriormente e, em função disso, será suprimida. Uma sugestão de escrita desses resultados é a seguinte: Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de duas vias investigando o efeito da escolaridade e do sexo no empreendedorismo. Foi possível concluir que a escolaridade é um fator significativo aos resultados (F(3, 142) = 8.24, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]), mas que o sexo não é significativo nessa relação (F(1, 142) = 0.81, p = 0.36, ηp2 = 0.01, 90% CI [.00, .04]). 7.5 ANOVA Fatorial A ideia da ANOVA fatorial é provavelmente uma das mais frequentes em perguntas de pesquisas, que consistem em tentar saber se os fatores tem alguma interação entre si. Nesse sentido, a modelagem envolve o cálculo de um terceiro parâmetro para investigar essa relação. Dessa maneira: \\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + b_3(X{_1}_i * X{_2}_i) + \\epsilon_{i}\\] Os coeficientes \\(b_1\\) e \\(b_2\\) estimam os efeitos principais, enquanto o \\(b_3\\) estima o efeito da interação. Dessa vez, é importante ressaltar alguns aspectos: Apesar de efeitos de interação poderem ser exploratórios, a ideia de adicioná-lo é fortemente relacionada à teoria. Ou seja, a modelagem é frequentemente confirmatória; A análise gráfica que é especialmente útil a todas as análises é ainda mais necessária nessa técnica; A interpretação dos resultados sempre começa pela interação. Caso ela seja significativa, não se interpreta os efeitos principais. Nessa pesquisa, tivemos o interesse em saber se o nível de empreendedorismo varia em função de uma interação entre sexo e estado civil (solteiro ou casado) dos participantes e, mais especificamente, se o estado civil impactaria o empreendedorismo de maneira diferente em homens e mulheres. Em áreas comportamentais, a interação entre o efeito estado civil e do sexo em características sociais é bastante estudado. 7.5.1 Execução no R Como mencionado, é fundamental ajustar todas as características da base para que os resultados não sejam distorcidos em função de definições computacionais. Como nessa pesquisa, também permitimos que pessoas divorciadas e viuvas, uma opção para deixar as análises totalmente pareadas com a pergunta da pesquisa é criar uma base contendo apenas solteiros (originalmente codificados com 1) e casados (originalmente codificados como 2). base_interacao &lt;- dados_teg %&gt;% filter(civil == 1 | civil == 2) base_interacao &lt;- base_interacao %&gt;% mutate(estado_civil_fct = factor(case_when( civil == 1 ~ &quot;solteiro&quot;, civil == 2 ~ &quot;casado&quot;), levels=c(&quot;solteiro&quot;,&quot;casado&quot;))) Agora o gráfico apresentado deve combinar as duas variáveis independentes, uma no eixo de X e outro no agrupamento. A escolha de como apresentar estas variáveis não deve ser aleatória, mas ser atrelada à forma da pergunta de pesquisa. Se o interesse for responder “Quanto o estado civil depende do sexo para gerar os resultados do TEG” sugere que em X coloque-se a variável “estado civíl” e no agrupamento a variáel \"sexo. ggplot(base_interacao, aes(x = estado_civil_fct, y = teg, group = sexo_fct, col = sexo_fct)) + geom_line(stat = &quot;summary&quot;, fun = mean, size=1) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width=0.1, size=1) O gráfico sugere que existe um efeito de interação, uma vez que as linhas se cruzam. No entanto, o teste formal deve ser feito. Da mesma forma do realizado anteriormente, a modelagem omitirá a verificação dos pressupostos, que foi apresentada em etapa inicial. mod_int_sexo_civil &lt;- lm(teg ~ sexo_fct * estado_civil_fct, base_interacao) apaTables::apa.aov.table(mod_int_sexo_civil) ## ## ## ANOVA results using teg as the dependent variable ## ## ## Predictor SS df MS F p partial_eta2 ## (Intercept) 35206.10 1 35206.10 1696.99 .000 ## sexo_fct 113.84 1 113.84 5.49 .021 .04 ## estado_civil_fct 13.04 1 13.04 0.63 .429 .00 ## sexo_fct x estado_civil_fct 87.89 1 87.89 4.24 .042 .03 ## Error 2676.27 129 20.75 ## CI_90_partial_eta2 ## ## [.00, .11] ## [.00, .04] ## [.00, .10] ## ## ## Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared A leitura da tabela começa de cima para baixo, ou seja, pela interação. Neses caso, ela é significativa (F(1,129) = 4.24, p = 0.042, ηp2 = 0.03, 90% CI [.00, .10]). Quando isso acontece, não se deve interpretar os efeitos principais, mesmo que eles sejam significativos. 7.5.2 Post hoc No caso, à pergunta “o sexo tem efeito no empreendedorismo”, a resposta adequada seria “depende”, uma vez que ele varia em função do estado civil do participante. O post hoc vez será também feito pelo pacote emmeans, que já foi carregado anteriormente. Para deixar a rotina clara, vamos armazenar os resultados no objeto post_hoc_int e, em seguida, explorar os coeficientes.Repare que dessa vez, os valores de p ajustados ou não são os mesmos, dado que há apenas duas categorias em cada grupo. post_hoc_int &lt;- emmeans(mod_int_sexo_civil, pairwise ~ sexo_fct * estado_civil_fct) O resultado deve ser acessado via contrastes. post_hoc_int$contrasts %&gt;% kable(digits = 2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) contrast estimate SE df t.ratio p.value masculino,solteiro - feminino,solteiro -5.05 2.15 129 -2.34 0.09 masculino,solteiro - masculino,casado 0.69 0.87 129 0.79 0.86 masculino,solteiro - feminino,casado 1.17 1.67 129 0.70 0.90 feminino,solteiro - masculino,casado 5.74 2.10 129 2.73 0.04 feminino,solteiro - feminino,casado 6.22 2.54 129 2.45 0.07 masculino,casado - feminino,casado 0.48 1.60 129 0.30 0.99 Repare que as informações repetem aquilo já visualizado no gráfico anterior, mas com as correções para evitar a inflação do erro do tipo 1. Neste momento, a interpretação torna-se menos visual e mais detalhada. Os resultados indicam que o empreededorismo depende tanto do estado civil como do sexo do participante. Quando solteiros, há uma tendência das mulheres empreenderem mais do que os homens (Δ = -5.048, p = 0.09). Entretanto, essa diferença não ocorre quando os participantes são casados, já que homens e mulheres casadas tem, em media, o mesmo nível de empreendedorismo (Δ = 0.482, p = 1). No entanto, especialmente nas mulheres casadas, o nível de empreendedorismo é significativamente menor do que nas solteiras (Δ = -6.222, p = 0.07). Em linhas gerais, parece que o empreendedorismo diminui em pessoas casadas e isso é especialmente válido às mulheres. É importante também atentar que a correção do valor de P deve ser feita para proteger falsos positivos (erro do tipo 1), mas que, idealmente, não devem também gerar falsos negativos (erro do tipo 2), o que talvez pudesse ser sugerido se aqui não tivéssemos interpretado os valores entre 0.05 e 0.1 dos resultados. 7.6 Resumo A ANOVA pode tanto ser entendida como um super teste T, como um caso particular de um modelo de regressão Testes post hoc e resultados globais da ANOVA não respondem às mesmas perguntas As comparações pareadas devem proteger a inflação do erro do tipo 1, sem gerar o erro do tipo 2 References "],
["anova-de-medidas-repetidas.html", "Capítulo 8 ANOVA de medidas repetidas 8.1 Pesquisa 8.2 Execução no R 8.3 Resumo", " Capítulo 8 ANOVA de medidas repetidas Objetivos do capítulo 1. Apresentar a ANOVA de Medidas Repetidas. 2. Realizar passo-a-passo a modelagem analítica. 3. Verificar os pressupostos e implementar as correções sugeridas. 4. Escrever os resultados. A ANOVA de medidas repetidas é oferece uma moelagem analítica para a análise de dados longitudinais pareados, isto é, relacionados. Esta técnica pode ser entendida como uma expansão da ANOVA ou um caso especial do Modelo Linear de Efeitos Mistos (LMM) (???), que é realizada quando se deseja verificar se os resultados de vários grupos variam significativamente com o tempo. Os pressupostos são similares aos discutidos em outros testes inferenciais: (i) Os dados são aleatórios e representativos da população (ii) a variável dependente é contínua (iii) Os resíduos do modelo são normalmente distribuídos (iv) há esfericidade dos grupos 8.1 Pesquisa A esse momento, vamos ter como referência de análise a pesquisa intitulada “Avaliação psicométrica em português do indicador de dor crônica de Helsinki em cães com sinais crônicos de osteoartrite”, que tem como primeira autora Lídia Matsubara e eu sou co-autor. Essa pesquisa foi publicada no “Arquivo Brasileiro de Medicina Veterinária e Zootecnia” em 2019. Nessa pesquisa, temos um grupo controle e um grupo experimental e todos os participantes foram avaliados em 5 momentos diferentes do tempo: 1 semana antes do início do tratamento (W2), imediatamente antes (W0), duas semanas e quatro semanas após o tratamento ter iniciado (S2 e s4) e após uma semana da retirada do tratamento (s6). Dessa forma, trata-se de um delineamento 2x5, considerando os 2 grupos e as 5 medições ao longo do tempo. A base dados reúne as varáveis da pesquisa em formato largo (wide) Entretanto, o formato longo é o mais tipicamente encontrado para análises longitudinais e, por isso, será implementado a seguir. tratamento &lt;- dados %&gt;% mutate(id = row_number()) %&gt;% select(id, grupo_dummy,starts_with(&quot;total_&quot;)) %&gt;% pivot_longer(-c(id,grupo_dummy), names_to = &quot;tempo&quot;, values_to= &quot;resultado&quot;) %&gt;% rename(grupo = grupo_dummy) %&gt;% filter(grupo &lt; 3) %&gt;% mutate(grupo = factor(if_else(grupo == 1, &quot;Placebo&quot;, &quot;Experimental&quot;))) %&gt;% mutate(tempo = factor(case_when( tempo == &quot;total_w4&quot; ~ &quot;antes&quot;, tempo == &quot;total_w0&quot; ~ &quot;no_dia&quot;, tempo == &quot;total_s2&quot; ~ &quot;semana_2&quot;, tempo == &quot;total_s4&quot; ~ &quot;semana_4&quot;, tempo == &quot;total_s6&quot; ~ &quot;semana_6&quot;, ))) As variávies neste conjunto de dados são: tratamento %&gt;% names() ## [1] &quot;id&quot; &quot;grupo&quot; &quot;tempo&quot; &quot;resultado&quot; Dessa forma: id refere-se a uma identificação única de cada participante. grupo refere-se ao grupo em que o participante foi alocado, tal como previamente apresentado (controle ou experimental). tempo diz respeito aos 5 pontos de medida e resultado é uma variável aleatória contínua do valor obtido na escala utilizada. 8.2 Execução no R A modelagem estatística envolve definir claramente que o resultado é uma função do tempo, do grupo e da interação tempo x grupo. Conforme exposto, a primeira etapa consiste na apresentação de tabelas e gráficos. Essas técnicas descritivas são muito informativas e permitem uma rápida compreensão dos resultados. A tabela a seguir apresenta a quantidade de participantes nas condições com o passar do tempo. tratamento %&gt;% group_by(grupo, tempo) %&gt;% count() %&gt;% pivot_wider(names_from=grupo, values_from = n) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) tempo Experimental Placebo antes 19 21 no_dia 19 21 semana_2 19 21 semana_4 19 21 semana_6 19 21 Nota-se que apesar de não ter havido perda amostral, os grupos não tiveram a mesma quantidade de participantes, gerando o que é classicamente entendido como desbalanceamento amostral. Em seguida, a tabela abaixo apresenta os valores da média e do desvio-padrão para todas as condições: tratamento %&gt;% #base de dados group_by(grupo,tempo) %&gt;% #agrupar summarise_at(vars(resultado),lst(mean, sd)) %&gt;% #tirar estatisticas pivot_longer(-c(grupo, tempo), names_to = &quot;medida&quot;) %&gt;% mutate(key = paste0(medida,&quot;=&quot;, value)) %&gt;% #criar um unico inexador select(grupo, tempo, key) %&gt;% #selecionar apenas as 3 variaveis importantes separate(key, into=c(&quot;medida&quot;,&quot;resultado&quot;),sep = &quot;=&quot;, convert = TRUE) %&gt;% #dividir media e desvio pivot_wider(names_from = tempo, values_from = resultado) %&gt;% #alargar kable(., digits=2) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) grupo medida antes no_dia semana_2 semana_4 semana_6 Experimental mean 15.11 15.95 14.89 14.00 14.11 Experimental sd 7.92 7.83 7.87 7.24 8.67 Placebo mean 17.71 17.38 16.38 14.48 16.62 Placebo sd 4.58 5.53 5.59 6.42 8.24 O gráfico abaixo também apresenta as mesmas informações, mas insere uma barra com o erro padrão da média. Isso é útil para interpretação inferencial. ggplot(tratamento, aes(x=tempo, y=resultado, group=grupo, color=grupo)) + #variaveis stat_summary(fun = mean, geom = &quot;line&quot;, size=1.5, aes(linetype = grupo)) + #linha stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, size=5, aes(shape = grupo)) + #pontos stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;,size=1) #barra de erro É possível ver que as barras de erro estão superpostas, isto é, uma dentro da outra. Isso ocorre quando não há diferença significativa entre as condições. No entanto, o teste formal estatístico deve ser realizado. Isso pode ser feito por algumas funções do pacote ez, descritas abaixo: library(ez) Sua sintaxe envolve as seguintes características: data refere-se à base de dados (lembre-se que ela deve estar no formato longo) dv refere-se à variável dependente (contínua) wid refere-se à variável com a identificação única de cada aprticipante within refere-se à variável independente com efeito dentro do tratamento, ou seja, a variável que se repete. Nesse caso, cada uma das semanas between refere-se à variável independente com efeito entre os tratamentos, ou seja, cada um dos grupos type refere-se à forma pela qual a soma dos quadrado será calculada. O tipo 3 emula os resultados dos programas típicos e quase sempre é a melhor opção para finalidade de comparação entre resultados detailed refere-se à apresentação detalhada dos resultados return_aov refere-se à criação de um objeto no formato aov que tem utilidade para análises comparadas posteriores Visando facilitar a comunicação, criaremos um objeto (ez_outcome) para armazenar os resultados e, em seguida, iremos acionar a função summary para apresenta-los. ez_outcome &lt;- ezANOVA( data = tratamento, dv = resultado, wid = id, within = tempo, between = grupo, type = 3, detailed = TRUE, return_aov = TRUE) ## Warning: Converting &quot;id&quot; to factor for ANOVA. ## Warning: Data is unbalanced (unequal N per group). Make sure you specified a ## well-considered value for the type argument to ezANOVA(). A mensagem de aviso informa que os grupos estão desbalenceados em relação à quantidade de participantes, o que foi mencionado acima. Antes de interpretar os resultados, é necessário verificar os pressupostos já que a validade dessa interpretação é atrelada à manutenção (ou sua ausência) dos pressupostos que a técnica solicita. No caso da ANOVA de Medidas Repetidas, é necessário verificar a normalidade e a esfericidade. A normalidade pode ser feita via gráficos e testes estatísticos formais. A esfericidade é verificada resgatando o objeto anteriormente definido (ez_outcome) e o examinando passo a passo. A principal novidade dos pressupostos está na esfericidade, que guarda um princípio similar à homogeneidade e pode ser entendida como sua extensão. A esfericidade se refere às variâncias das diferenças entre todos os pares de medidas serem similares e a homogeneidade se refere à constância das variâncias entre os grupos (Quené &amp; Bergh, 2004). A normalidade dos resíduos é vista pelo gráfico a seguir. Repare que a função mutate foi utilizada para adicionar uma coluna com os resíduos do modelo à base de dados antes de plotá-los. tratamento %&gt;% mutate(residuos = proj(ez_outcome$aov)[[3]][, &quot;Residuals&quot;]) %&gt;% ggplot(aes(x=residuos)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;grey&quot;) + geom_density(aes(y= ..count..)) É possível argumentar que a normalidade dos resíduos foi relativamente mantida. Caso o interesse fosse um teste formal, ele seria feito pelo Shapiro Wilk, que assume \\(H_0\\) de normalidade. shapiro.test(proj(ez_outcome$aov)[[3]][, &quot;Residuals&quot;]) ## ## Shapiro-Wilk normality test ## ## data: proj(ez_outcome$aov)[[3]][, &quot;Residuals&quot;] ## W = 0.95677, p-value = 8.986e-06 Por esse último resultado, como o valor de p foi inferior ao alfa tipicamente estabelecido (0.05), não seria possível manter o pressuposto da normalidade e algo deveria ser feito, como transformação dos dados ou implementação de outra técnica analítica. No entanto, desde a década de 1960 é sabido que o valor de p é inversamente associado ao tamanho da amostra (???; ???). Nessa análise, há 200 observações (40 participantes em cada um dos 5 pontos de medida), o que influencia na redução do valor de p (???). Dessa maneira, o resultado exposto previamente no gráfico é considerado nessa análise. Já a esfericidade é testada pelo teste de Mauchly. Esse teste define a hipótese nula como presença da esfericidade e idealmente a não rejeição da \\(H_0\\) é desejada. No entanto, quando o pressuposto da esfericidade é rejeitado, é necessário aplicar algum ajuste, como a correção de Greenhouse-Geisser ou a de Huynh-Feldt. Ambas as técnicas ajustam os graus de liberdade a partir de um coeficiente particular. Abaixo esta o ez_outcome, que é dividido em 4 blocos diferentes: $ANOVA, $Mauchly's Test for Sphericity, $Sphericity Corrections e $aov. Como são muitas informações, os resultados serão especificamente comentados. ez_outcome %&gt;% pander::pander() ANOVA: Effect DFn DFd SSn SSd F p p&lt;.05 ges (Intercept) 1 38 48940 7789 238.8 5.697e-18 * 0.8377 grupo 1 38 144.8 7789 0.7063 0.4059 0.01504 tempo 4 152 146.9 1689 3.304 0.01254 * 0.01526 grupo:tempo 4 152 30.95 1689 0.6962 0.5957 0.003255 Mauchly’s Test for Sphericity: Effect W p p&lt;.05 3 tempo 0.2561 1.322e-07 * 4 grupo:tempo 0.2561 1.322e-07 * Sphericity Corrections: Effect GGe p[GG] p[GG]&lt;.05 HFe p[HF] p[HF]&lt;.05 3 tempo 0.5739 0.0351 * 0.6129 0.03191 * 4 grupo:tempo 0.5739 0.5201 0.6129 0.529 aov: Df Sum Sq Mean Sq F value Pr(&gt;F) grupo 1 144.8 144.8 0.7063 0.4059 Residuals 38 7789 205 NA NA tempo 4 151.2 37.79 3.4 0.01075 grupo:tempo 4 30.95 7.738 0.6962 0.5957 Residuals 152 1689 11.11 NA NA A primeira parte que se olha é o Mauchly’s Test for Sphericity. Caso haja rejeição da hipótese nula, deve-se olhar inicialmente todos os resultados dispostos no Sphericity Corrections para depois olhar a parte ANOVA. Caso não haja rejeição da hipótese nula, basta os resultados já na parte ANOVA, que fica ao início do output. Nessa pesquisa, se rejeitou a esfericidade para o efeito principal do tempo (w = 0.26, p &lt; 0.05) e da interação tempo x grupo (w = 0.26, p &lt; 0.05). Dessa forma, as correções devem ser implementadas nos graus de liberdade de ambos os coeficientes. Duas correções são possíveis, a Greenhouse-Geisser (p[GG]) e a de Huynh-Feldt e existe uma regra prática (rule of thumb) para isso: Quando o valor de Greenhouse-Geisser (ϵ ou GGe) é inferior a 0.75, os valores dos graus de liberdade do numerador e do denominador são ajustados pela correção de Greenhouse-Geisser quando é superior a 0.75, o ajuste é feito pela de Huynh-Feldt. Nessa pesquisa, o ajuste será feito via Greenhouse-Geisser. Antes de iniciar a interpretação dos resultados, lembre-se que toda interpretação deve ser sempre iniciada pela interação. Caso ela seja significativa, não se deve interpretar os efeitos principais. Repare que a parte Sphericity Corrections tem informações sobre a interação tempo x grupo e da semana. Esses efeitos devem ser interpretados aqui nessa seção, em vez da seção ANOVA. A interação tempo x grupo não é significativa. O valor de p é de 0.52. Manualmente, esse valor pode ser obtido computando a região crítica da cauda à direita da densidade da distribuição F. Para isso, é necessário plugar o valor de F obtido (0.696), encontrado na primeira parte do output (ANOVA), e ajustar o numerador para 2.29 (DFn = 4 x 0.5739 = 2.29) e o denominador para 87.24 (DFd=152 x 0.5739 = 87.24). Assim: 1-pf(0.69, 4 * 0.57, 152 * 0.57) ## [1] 0.5224581 O efeito principal do tempo é significativo, com valor de p = 0.03. 1-pf(3.30, 4 * 0.57, 152 * 0.57) ## [1] 0.03558152 O efeito principal do grupo deve ser visto diretamente na parte ANOVA e não é significativo. O valor de p é de 0.40, que pode ser manualmente computado assim: 1-pf(0.71, 1, 38) ## [1] 0.4047162 Assim, é possível concluir que o passar do tempo gerou uma diferença significativa no resultado da dor dos animais (VD), mas que isso não é relacionado a nenhum grupo específico. Em outras palavras, esse efeito não depende do grupo em que o animal se encontra. Frequentemente, os resultados corrigidos e os não-corrigidos concluem na mesma direção. Isso é verdadeiro nesse caso. Repare que os resultados não corrigidos: summary(ez_outcome$aov) %&gt;% pander::pander() Df Sum Sq Mean Sq F value Pr(&gt;F) grupo 1 144.8 144.8 0.7063 0.4059 Residuals 38 7789 205 NA NA tempo 4 151.2 37.79 3.4 0.01075 grupo:tempo 4 30.95 7.738 0.6962 0.5957 Residuals 152 1689 11.11 NA NA Chegariam as mesmas conclusões dos corrigidos: ez_outcome$`Sphericity Corrections`%&gt;% pander::pander() Effect GGe p[GG] p[GG]&lt;.05 HFe p[HF] p[HF]&lt;.05 3 tempo 0.5739 0.0351 * 0.6129 0.03191 * 4 grupo:tempo 0.5739 0.5201 0.6129 0.529 O valor de P do efeito do tempo saiu de 0.01 (sem correção) para 0.03 (com correção). Já a interação grupo x semana saiu de 0.59 (sem correção) para 0.52 (com correção). Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de medidas repetidas investigando o efeito fixo do grupo e do tempo, bem como a interação entre ambos. O teste de Mauchly indicou a violação da esfericidade (w = 0.26, p &lt; 0.01) e, portanto, os graus de liberdade foram corrigidos pelo ajuste de Greenhouse-geisser (ϵ = 0.57). Não houve interação significativa entre o grupo e o tempo (F(2.29, 87.24) = 0.69), nem efeito do grupo (F(1, 38) = 0.71, p &lt; 0.40). O passar de tempo foi significativo no resultado, apesar de apresentar um efeito pequeno (F(2,29, 87.24) = 3.30, p = 0.035, np2 = 0.01). 8.3 Resumo A ANOVA de medidas repetidas é um teste bastante utilizado quando participantes de mesmos grupos são avaliados longitudinalmente Este modelo pode ser entendido como uma expansão de uma ANOVA ou um caso particular de uma regressão linear de efeitos mistos A execução deste teste no R solicita que a base seja transformada para o formato longo A interpretação dos resultados é, inicialmente, complicada e precisa ser feita de maneira cautelosa References "],
["modelo-linear-misto.html", "Capítulo 9 Modelo linear misto 9.1 Pesquisa 9.2 execução no R 9.3 Resumo", " Capítulo 9 Modelo linear misto Objetivos do capítulo 1. Apresentar a ANOVA de Medidas Repetidas. 2. Realizar passo-a-passo a modelagem analítica. 3. Verificar os pressupostos e implementar as correções sugeridas. 4. Escrever os resultados. O modelo linear misto (LMM) é um modelo linear, frequentemente utilizado para trabalhar dados longitudinais ou de medidas repetidas, que possibilita definir tanto parâmetros populacionais (efeitos fixos), como coeficientes individuais (efeitos aleatórios), além do erro experimental. Pragmaticamente, este modelo oferece mais flexibildiade à ANOVA de medidas repetidas e sua utilização vem ganhando mais espaço em Psicologia (Gueorguieva &amp; Krystal, 2004). É importante atentar que os efeitos fixos são compatilhados por todos os indivíduos, enquanto os aleatórios são especificos de cada um dos participantes. Com isso, cada indivíduo tem a sua própria trajetória média (tanto intercepto como inclinação) e um subconjunto dos parâmetros de regressão são tomados como aleatórios. A tabela a seguir compara a ANOVA de medidas repetidas e o LMM Característica ANOVA (MR) Modelo Linear Misto Sujeitos medidos em vários momentos Sim Sim Dados completos em todos os segmentos Sim Não Estimativas de tendências individuais Não Sim Covariáveis tempo-depenentes Não Sim Complexidade computacional Baixa Alta 9.1 Pesquisa A esse momento, vamos ter como referência de análise a pesquisa intitulada “Avaliação psicométrica em português do indicador de dor crônica de Helsinki em cães com sinais crônicos de osteoartrite”, que tem como primeira autora Lídia Matsubara e eu sou co-autor. Essa pesquisa foi previamente utilizada no capítulo de ANOVA de medidas repetidas. Nessa pesquisa, temos um grupo controle e um grupo experimental e todos os participantes foram avaliados em 5 momentos diferentes do tempo: 1 semana antes do início do tratamento (W2), imediatamente antes (W0), duas semanas e quatro semanas após o tratamento ter iniciado (S2 e s4) e após uma semana da retirada do tratamento (s6). Dessa forma, trata-se de um delineamento 2x5, considerando os 2 grupos e as 5 medições ao longo do tempo. A base dados reúne as varáveis da pesquisa em formato largo (wide) Entretanto, o formato longo é o mais tipicamente encontrado para análises longitudinais e, por isso, será imeplementado a seguir. tratamento &lt;- dados %&gt;% mutate(id = row_number()) %&gt;% select(id, grupo_dummy,starts_with(&quot;total_&quot;)) %&gt;% pivot_longer(-c(id,grupo_dummy), names_to = &quot;tempo&quot;, values_to= &quot;resultado&quot;) %&gt;% rename(grupo = grupo_dummy) %&gt;% filter(grupo &lt; 3) %&gt;% mutate(grupo = factor(if_else(grupo == 1, &quot;Placebo&quot;, &quot;Experimental&quot;))) %&gt;% mutate(tempo = factor(case_when( tempo == &quot;total_w4&quot; ~ &quot;antes&quot;, tempo == &quot;total_w0&quot; ~ &quot;no_dia&quot;, tempo == &quot;total_s2&quot; ~ &quot;semana_2&quot;, tempo == &quot;total_s4&quot; ~ &quot;semana_4&quot;, tempo == &quot;total_s6&quot; ~ &quot;semana_6&quot;, ))) As variávies neste conjunto de dados são: tratamento %&gt;% names() ## [1] &quot;id&quot; &quot;grupo&quot; &quot;tempo&quot; &quot;resultado&quot; Dessa forma: id refere-se a uma identificação única de cada participante. grupo refere-se ao grupo em que o participante foi alocado, tal como previamente apresentado (controle ou experimental). tempo diz respeito aos 5 pontos de medida e resultado é uma variável aleatória contínua do valor obtido na escala utilizada. 9.2 execução no R A modelagem será feita via LMM. O pacote lme4 e seu complemento lmerTest serão utilizados. library(lme4) ## Loading required package: Matrix ## ## Attaching package: &#39;Matrix&#39; ## The following objects are masked from &#39;package:tidyr&#39;: ## ## expand, pack, unpack library(lmerTest) ## Warning: package &#39;lmerTest&#39; was built under R version 4.0.2 ## ## Attaching package: &#39;lmerTest&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## lmer ## The following object is masked from &#39;package:stats&#39;: ## ## step A estrutura computacional agora permite incluir tanto efeitos fixos como aleatórios. Quando eles são definidos como correlacionados, se utiliza uma barra verticail (|); quando descorrelacionados, duas barras verticais (||) são utilizadas. Nesta pesquisa, pode-se entender que cada participante tem seu próprio intercepto, ou seja, seu próprio valor de início. A sintaxe a seguinte específica o modelo e o armazena sob nome de mod_lme. mod_lme &lt;- lmer(resultado ~ tempo*grupo + (1|id) , data = tratamento) Repare que esse modelo é composto pelo se seguintes componentes: 1. efeito fixo do tempo 2. efeito fixo do grupo, 3. efeito fixo da interação tempo x grupo 4. efeito aleatório do id, indicando um intercepto aleatório e específico por participante A visualização dessa modelagem é bastante útil para compreender o que significa a ideia de intercepto aleatório. ggplot(tratamento, aes(x=tempo, y=resultado, group=id, color=id, linetype=grupo)) + geom_line(size=1) + geom_hline(yintercept = mean(tratamento$resultado[tratamento$tempo == &quot;antes&quot;]), linetype=&quot;dashed&quot;) + annotate(geom = &quot;text&quot;, x=0.5, y = mean(tratamento$resultado[tratamento$tempo == &quot;antes&quot;])+1, label = &quot;Média&quot;,hjust = 0) Repare que cada participante (id) inicia em um ponto específico e tem uma trajetória específica no decorrer do tratamento. O valor médio antes do tratamento está apresentado pela linha pontilhada. Apesar de informativo, esse gráfico tem pouca aplicação pedagógica e, por isso, não deve ser relatado. Uma vez que o modelo já foi criado, agora é necessário recuperar seus resultados. É importante notar que O pressuposto da normalidade é necessário e ele já foi acessado (e aceito) anteriormente. Conforme dito ao início do capítulo, O LMM relaxa o pressuposto esfericidadde e, por consequência, também o da homogeneidade (Quené &amp; Bergh, 2004). Inicialmente, a anova permite uma visualização de todos os coeficientes do modelo. Isso é importante para verificar cada um dos preditores estipulados e sua significância. A interpretação dos resultados é similar à realizada em modelos de regressão e totalmente convergente ao resultado obtido na ANOVA. Novamente, a leitura da tabela deve começar pela interação. anova(mod_lme) %&gt;% pander::pander() Type III Analysis of Variance Table with Satterthwaite’s method Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) tempo 146.9 36.72 4 152 3.304 0.01254 grupo 7.851 7.851 1 38 0.7063 0.4059 tempo:grupo 30.95 7.738 4 152 0.6962 0.5957 Verifique que a tabela apresenta três os resultados: tempo x grupo, grupo e tempo. A técnica de Satterthwaite’s method é utilizada para corrigir os valores do grau de liberdade e, consequentemente, os valores de p. Os resultados são virtualmente identicos aos obtidos pela ANOVA, com a diferença que os graus de liberdade do numerador de do denominador não foram corrigidos. Para obter as informações completas do modelo, é necessário solicitar o summary. Essa função retorna 4 informações calculadas: Scaled residuals, Random effects, Fixed effects e Correlation of Fixed Effect e serve para aprofundar a interpretação dos resultados. Uma particular diferença entre esse relatório e o da ANOVA de Medidas Repetidas é o np2, que não faz parte do LMM. summary(mod_lme) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: resultado ~ tempo * grupo + (1 | id) ## Data: tratamento ## ## REML criterion at convergence: 1137.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4365 -0.4386 -0.0476 0.4571 3.8758 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 38.77 6.227 ## Residual 11.11 3.334 ## Number of obs: 200, groups: id, 40 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 15.10526 1.62039 55.61796 9.322 5.83e-13 *** ## tempono_dia 0.84211 1.08166 152.00000 0.779 0.437 ## temposemana_2 -0.21053 1.08166 152.00000 -0.195 0.846 ## temposemana_4 -1.10526 1.08166 152.00000 -1.022 0.308 ## temposemana_6 -1.00000 1.08166 152.00000 -0.925 0.357 ## grupoPlacebo 2.60902 2.23636 55.61796 1.167 0.248 ## tempono_dia:grupoPlacebo -1.17544 1.49284 152.00000 -0.787 0.432 ## temposemana_2:grupoPlacebo -1.12281 1.49284 152.00000 -0.752 0.453 ## temposemana_4:grupoPlacebo -2.13283 1.49284 152.00000 -1.429 0.155 ## temposemana_6:grupoPlacebo -0.09524 1.49284 152.00000 -0.064 0.949 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) tmpn_d tmps_2 tmps_4 tmps_6 grpPlc tmp_:P tm_2:P tm_4:P ## tempono_dia -0.334 ## temposemn_2 -0.334 0.500 ## temposemn_4 -0.334 0.500 0.500 ## temposemn_6 -0.334 0.500 0.500 0.500 ## grupoPlaceb -0.725 0.242 0.242 0.242 0.242 ## tmpn_d:grpP 0.242 -0.725 -0.362 -0.362 -0.362 -0.334 ## tmpsmn_2:gP 0.242 -0.362 -0.725 -0.362 -0.362 -0.334 0.500 ## tmpsmn_4:gP 0.242 -0.362 -0.362 -0.725 -0.362 -0.334 0.500 0.500 ## tmpsmn_6:gP 0.242 -0.362 -0.362 -0.362 -0.725 -0.334 0.500 0.500 0.500 Como escrever os resultados Os dados foram analisados através de um Modelo Linear de Efeitos Mistos, que verificou o efeito do tempo, do grupo, a interação entre esses dois preditores e permitiu um intercepto aleatório para cada participante. Dessa maneira, esse modelo levou em consideração tanto efeitos fixos quanto aleatórios, além de relaxar alguns pressupostos tradicionais dos modelos de regressão. Os resultados permitem concluir que Não há interação significativa tempo x grupo (F(4, 152 = 0.696), p = 0.696), bem como não há efeito significativo do grupo (F(1, 38 = 0.706), p = 0.706). Em outra direção, o efeito o tempo foi significativo (F(4, 152 = 3.304), p = 0.013) 9.3 Resumo O Modelo Linear de Efeitos Mistos (LMM) oferece maior versatilidade à ANOVA de medidas repetidas A ANOVA tem como pressuposto Normalidade e Esfericidade, enquanto o LMM apenas Normalidade dos resíduos Os resultados frequentemente encontrados em ambos os modelos vão na mesma direção A implementação computacional é mais trabalhosa A escrita apresenta algumas particularidades relacionadas à cada modelo. References "],
["correlação.html", "Capítulo 10 Correlação 10.1 Pesquisa 10.2 Execução no R 10.3 Resumo", " Capítulo 10 Correlação A análise de correlação é um procedimento estatístico para verificar a relação entre duas variáveis. Existem diferentes formas para realizar tal análise e a maioria busca medir a força e a direção da associação linear entre duas variáveis aleatórias. A tabela a seguir descreve alguns dos métodos. Nível de medida Correlação / Coeficiente Intervalar Correlação Produto momento de Pearson Ordinal Correlação de Spearman Nominal Coeficiente Phi A Correlação de Pearson é apresentado por \\(\\rho\\) ou r, é uma das mais frequentemente calculadas em Psicologia e será demonstrada neste capítulo. Entretanto, tenha em mente que algumas áreas específicas costumam utilizar outras correlações. Como exemplo, é bem típico em Psicometria utilizar indicadores categóricos e, com isso, realizar correlações tetracóricas ou policóricas, o que não será abordado aqui. O coeficiente de correlação é formado por um valor numérico e um sinal e o gráfico de dispersão é uma excelente forma de apresentar o relacionamento bivariado. A tabela abaixo descreve as possíveis interpretações (Cohen, 1988) Valor/ Sinal Positivo (+) Negativo (-) 0.1 Fraca positiva Fraca negativa 0.3 Moderada positiva Moderada negativa 0.5 Forte positiva Forte negativa As imagens abaixo demonstram tais conceitos. grid.arrange( ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .1, .1, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;Y&quot;) + geom_text(aes(label=paste(&quot;r=+0.1 - fraca&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .3, .3, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;X&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=+0.3 - moderada&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .5, .5, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=+0.5 - forte&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.1, -.1, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;Y&quot;) + geom_text(aes(label=paste(&quot;r=-0.1 - fraca&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.3, -.3, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;X&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=-0.3 - moderada&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.5, -.5, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=-0.5 - forte&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), nrow = 2) Para realização da Correlação de Pearson, é necessário que ambas as variáveis sejam contínuas e apresentem relacionamento linear. As seguintes propriedades existem no coeficiente de correlação: É limitado entre -1 e +1, com 0 indicando ausência de correlação O sinal indica a natureza, enquanto o número a força É simétrico, ou seja, r(x,y) = r(y,x) É adimensional e invariante em transformações lineares Sensível aos outliers Não indica causalidade 10.1 Pesquisa Base: Livro - Dados - Eating disorders Vamos utilizar a pesquisa intitulada “Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students”, publicada em 2018 no Global Journal of Educational Studies, que sou co-autor. O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e aspectos da percepção da imagem corporal, bem como verificar a capacidade que uma medida possuia em predizer os resultados de outra. Esse artigo contou com a utilização de escalas aplicadas em 219 participantes no Brasil. Para acessar aspectos relacionados aos Transtornos alimentares, a escala EAT-26 foi aplicada. Para verificar aspectos da imagem corporal, a escala BSQ-34 foi aplicada. Segue abaixo uma tabela inicial com dados descritivos dos resultados. dados_brasil %&gt;% select(sexo,eat_soma, bsq_soma, imc, faz_esporte, familia_esporte) %&gt;% psych::describeBy(.,group = &quot;sexo&quot;) %&gt;% pander::pander() ## Warning in pander.default(.): No pander.method for &quot;psych&quot;, reverting to ## default.No pander.method for &quot;describeBy&quot;, reverting to default. 1: Table continues below vars n mean sd median trimmed mad sexo 1 126 1 0 1 1 0 eat_soma 2 126 18.48 10.09 17 17.9 11.86 bsq_soma 3 126 94.17 34.87 91 92.64 40.77 imc 4 124 22.58 3.151 21.95 22.24 2.542 faz_esporte 5 126 0.4524 0.4997 0 0.4412 0 familia_esporte 6 126 0.4762 0.5014 0 0.4706 0 min max range skew kurtosis se sexo 1 1 0 NA NA 0 eat_soma 0 47 47 0.4929 -0.5091 0.8988 bsq_soma 32 182 150 0.3512 -0.4573 3.107 imc 16.85 32.87 16.02 0.9764 0.8725 0.2829 faz_esporte 0 1 1 0.1891 -1.98 0.04452 familia_esporte 0 1 1 0.09421 -2.007 0.04467 2: Table continues below vars n mean sd median trimmed mad sexo 1 93 2 0 2 2 0 eat_soma 2 93 12.65 8.189 11 11.55 5.93 bsq_soma 3 93 64.24 32.87 55 59.32 19.27 imc 4 90 24.1 3.99 23.41 23.65 2.829 faz_esporte 5 93 0.3978 0.4921 0 0.3733 0 familia_esporte 6 92 0.4783 0.5023 0 0.473 0 min max range skew kurtosis se sexo 2 2 0 NA NA 0 eat_soma 1 50 49 1.688 4.262 0.8491 bsq_soma 0 188 188 1.504 2.799 3.408 imc 17.56 39.21 21.66 1.269 2.073 0.4206 faz_esporte 0 1 1 0.4107 -1.851 0.05103 familia_esporte 0 1 1 0.08562 -2.014 0.05236 10.2 Execução no R Inicialmente, a escrita da hipótese é: \\[H_0: \\rho_{(x,y)} = 0 \\\\ H_a: \\rho_{(x,y)} \\neq 0 \\\\ \\alpha = 0.05\\] O gráfico de dispersão auxilia na visualização da relação entre as variáveis e permite verificar se o relacionamento é ou não linear. ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + labs(x = &quot;Resultados da Escala BSQ-34&quot;, y = &quot;Resultados da Escala EAT-26&quot;, title = &quot;Correlação entre o BSQ-34 e o EAT-26&quot;) O gráfico indica que as duas variáveis são relacionadas. Apesar do padrão deste relacionamento não ser estritamente linear, é possível verificar formalmente a correlação entre ambas as variáveis, cor.test(dados_brasil$eat_soma, dados_brasil$bsq_soma) ## ## Pearson&#39;s product-moment correlation ## ## data: dados_brasil$eat_soma and dados_brasil$bsq_soma ## t = 13.523, df = 218, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.5964405 0.7414562 ## sample estimates: ## cor ## 0.6754262 Os resultados permitem concluir que a correlação é positiva e forte (r = 0.675), além de significativa (p &lt; 0.001). Isso indica que ambas as variáveis covariam de maneira proporcional, em que valores altos em uma tendem a acompanhar valores altos em outra. É importante atentar que esse relacionamento não indica causalidade e, dessa forma, essa covariação pode ser explicada por diferentes fatores não analisados neste método. Como escrever os resultados A correlação entre o comportamento alimentar (EAT-26) e a percepção corporal (BSQ-34) foi calculada pelo Coeficiente Produto-Momento de Pearson. Os resultados concluíram que existe uma correlação positiva, forte e significativa entre ambas as variáveis (r = 0.675, p &lt; 0.001), indicando que as duas variáveis covariam de maneira proporcional. 10.3 Resumo O termo correlação diz respeito a um conjunto de métodos que visa verificar a direção e a força do relacionamento entre duas variáveis A correlação de Pearson assume que ambas as variáveis são linearmente correlacionadas O coeficiente sempre indicará a direção (por um sinal) e a força (por um número entre -1 e +1) do relacionamento bivariado Correlação não indica causalidade References "],
["regressão-linear-simples.html", "Capítulo 11 Regressão linear simples 11.1 Legenda 11.2 Explicação conceitual 11.3 Pesquisa 11.4 Execução no R 11.5 Resumo", " Capítulo 11 Regressão linear simples Os modelos de regressão são modelos estatísticos que visam predizer o comportamento de uma variável resposta (Y) como uma função de uma ou mais variáveis independentes (X). Em larga escala, eles substituem os outros testes paramétricos vistos até agora. Assim, quase tudo o que foi visto durante os capítulos anteriores são casos especiais de modelos de regressão. Existem diferentes nomenclaturas utilizadas para classificar tais modelos e a tabela abaixo apresenta uma classificação funcional. VI e VD VD Discreta VD Contínua VI Discreta Reg. logística Reg. linear (Teste T/ANOVA) VI Contínua Reg. logística Reg. linear Algumas conclusões são possíveis: 1. A variável dependente irá definir se a regressão será linear ou logística. Quando linear, a VD é continua (peso, tempo de resposta, inteligência); quando logística, a VD é discreta (acidente fatal - sim ou não; orientação política - direita ou esquerda). 2. Caso haja uma única VI, dá-se o nome de regressão simples. Quando há duas ou mais VIs, dá-se o nome de regressão múltipla. 3. Se houver mais de uma VD, o modelo será chamado de multivariado (em inglês, path analysis). 4. Teste T e ANOVA são casos de regressão linear simples 5. ANCOVA, ANOVA de k vias e ANOVA fatorial são casos de regressão múltipla 6. O qui-quadrado pode ser aproximado pela regressão logística simples e vice-versa Isso posto, é possível definir a Regressão linear como uma técnica estatística que modela o relacionamento funcional entre duas variáveis, por uma equação que permite estimar o quanto os valores de uma variável variam em função de outra. Há, ao menos, duas utilidades diretas em uma pesquisa, que são: Predizer os valores da variável dependente (Y) em função dos valores da variável dependente (X); Explicar a variabilidade da variável dependente (Y) em função da variável independente (X). Abas as utilidades são virtualmente iguais e como a Regressão linear simples pode ser vista a partir de um incremento ou avanço dos modelos de correlação, os aspectos correlacionais devem (e podem) ser inicialmente investigados. É possível estudar tais modelos tanto de uma maneira operacional, com foco totalmente pragmático e aderente às recomendações tradicionais dos livros de estatística, ou de uma forma detalhada, em que ao estudar os modelos de regressão, quase que muitos conceitos da estatística inferencial e estatística matemática são revisitados. Nesse capítulo, o foco será dado na capacidade operacional. Conceitualmente, a regressão linear é apresentada como:: \\[y_i = b_0 + b_1X{_1}_i + \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) é a inclinação (coeficiente angular) \\(\\epsilon_{i}\\) é o erro/resíduo Os seguintes pressupostos devem ser avaliados: A relação entre as variáveis é linear Os resíduos são independentes Os resíduos são normalmente distribuídos A variância dos resíduos é constante O mnemônico LINE (linearity, independence, normality, equal variance) talvez ajude a lembrar destes pressupostos. 11.1 Legenda Diferentes termos são empregados em modelos de regressão A legenda a seguir visa auxiliar no entendimento de cada um deles e aproximar o leitor aos principais conceitos amplos utilizados em modelos lineares: intercepto - \\(b_0\\): Valor previsto de Y quando X = 0 Inclinação - \\(b_i\\): A diferença média em unidades da variável dependente quando se altera uma unidade de X. SSR: Soma dos Quadrados da Regressão SSE: Soma dos Quadrados dos Erros SST: Soma dos Quadrados Total \\(R^2\\) ou Coeficiente de Determinação: A porcentagem de variação da variável dependente (Y) que pode ser atribuída à variabilida da(s) variável (is) independente(s) (X) \\(R^2_{adj}\\) ou Coeficiente de Determinação ajustado: Coeficiente que pondera a \\(R^2\\) pelo número de variáveis explicativas e pelo número de observações da amostra. É particularmente útil quando deseja-se comparar modelos de regressão múltipla que prevêem a mesma variável dependente, pois penaliza aquele modelo com maior número de variáveis independentes. RMSEA (\\(Res. St. Error\\)): Desvio padrão dos valores previstos da variável dependente ao redor da linha de regressão estimada O conhecimento das fórmulas fechadas também auxilia no entendimento da modelagem. Soma dos Quadrados da Regressão: \\(SSR = \\sum_{i=1}^{n}(\\hat{y} - \\bar{y})^2\\) Soma dos Quadrados dos Erros: \\(SSE = \\sum_{i=1}^{n}(y_i - \\hat{y})^2\\) Soma dos Quadrados Total: \\(SST = \\sum_{i=1}^{n}(y_i - \\bar{y})^2\\) Variabilidade total: \\(SST = SSR + SSE\\) \\(R^2\\): \\(\\frac{SSR}{SST} = 1- \\frac{SSE}{SST}\\) Erro quadrático médio: \\(MSE = \\sum_{i=1}^{n}(y_i - \\hat{y})^2 /(N-K)\\) \\(R^2_{adj}\\): \\(1-\\frac{MSE}{MSR}\\) \\(Res. St. Error = \\sqrt\\frac{SSE}{N-K}\\): É possível citar ao menos três formas de explicar modelos de regressão. Evidentemente, todas são interligadas, mas cada qual apresenta uma ênfase didática diferente. Nesse sentido, a forma mais “conceitual” conta com conjuntos para explicitar o tema, a forma “correlacional” parte de um gráfico de dispersão e a forma “analítica” traz conceitos matemático. 11.2 Explicação conceitual Inicialmente, é necessário atentar que a variável dependente (Y) e a variável independente (X) podem ser vistas como conjuntos. No caso: Neste exemplo, ambas as variáveis estão afastadas e não há nenhuma relação entre elas. No entanto, o que frequentemente ocorre é que existe algum grau de relacionamento entre elas, tal como exposto abaixo: Caso se assuma que X é um fator de causalidade à realização de Y, isso significa que uma parte da realização de Y, necessariamente, depende de X. Essa área de interseção é entendida como a parte de Y que pode ser atribuída ou explicada por X. Analiticamente, essa área precisa de algumas transformações algébricas e, em função delas, recebe o nome de Soma dos Quadrados da Regressão (SSR, em inglês). No entanto, nem toda a variabilidade de Y pode ser atribuída à X. Essa região também sofrerá transformações algébricas e receberá o nome de Soma dos Quadrados dos Erros (SSE, em inglês). Essa área representa a variabilidade de Y que não pode ser atribuída/explicada por X. Nesse caso: É também possível verificar que Y possui uma variabilidade total, que também pode ser vista como o somatório da área explicada pela regressão (SSR) com a área não explicada (SSE). Essa região total também passará por transformações algébricas e é chamada de Soma dos Quadrados Total (SST, em inglês). Vendo todas as partições de uma única vez, temos o seguinte: Com isso, torna-se claro que a porcentagem de variação de Y que pode ser atribuída à variabilidade de X é uma razão entre a Soma dos Quadrados da Regressão (SSR) pela Soma dos Quadrados Total (SST). O coeficiente obtido por essa razão recebe o nome de Coeficiente de Determinação ou \\(R^2\\). Isso é equivalente a subtração do espaço máximo de variabilidade (100%) pela razão entre a Soma dos Quadrados dos Erros (SSE) pela Soma dos Quadrados Total (SST): 11.3 Pesquisa Base: Livro - Dados - Eating disorders Vamos utilizar a pesquisa intitulada “Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students”, publicada em 2018 no Global Journal of Educational Studies, que sou co-autor. O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e aspectos da percepção da imagem corporal, bem como verificar a capacidade que uma medida possuia em predizer os resultados de outra. Esse artigo contou com a utilização de escalas aplicadas em 219 participantes no Brasil. Para acessar aspectos relacionados aos Transtornos alimentares, a escala EAT-26 foi aplicada. Para verificar aspectos da imagem corporal, a escala BSQ-34 foi aplicada. Segue abaixo uma tabela inicial com dados descritivos dos resultados. dados_brasil %&gt;% select(sexo,eat_soma, bsq_soma, imc, faz_esporte, familia_esporte) %&gt;% psych::describeBy(.,group = &quot;sexo&quot;) %&gt;% pander::pander() ## Warning in pander.default(.): No pander.method for &quot;psych&quot;, reverting to ## default.No pander.method for &quot;describeBy&quot;, reverting to default. 1: Table continues below vars n mean sd median trimmed mad sexo 1 126 1 0 1 1 0 eat_soma 2 126 18.48 10.09 17 17.9 11.86 bsq_soma 3 126 94.17 34.87 91 92.64 40.77 imc 4 124 22.58 3.151 21.95 22.24 2.542 faz_esporte 5 126 0.4524 0.4997 0 0.4412 0 familia_esporte 6 126 0.4762 0.5014 0 0.4706 0 min max range skew kurtosis se sexo 1 1 0 NA NA 0 eat_soma 0 47 47 0.4929 -0.5091 0.8988 bsq_soma 32 182 150 0.3512 -0.4573 3.107 imc 16.85 32.87 16.02 0.9764 0.8725 0.2829 faz_esporte 0 1 1 0.1891 -1.98 0.04452 familia_esporte 0 1 1 0.09421 -2.007 0.04467 2: Table continues below vars n mean sd median trimmed mad sexo 1 93 2 0 2 2 0 eat_soma 2 93 12.65 8.189 11 11.55 5.93 bsq_soma 3 93 64.24 32.87 55 59.32 19.27 imc 4 90 24.1 3.99 23.41 23.65 2.829 faz_esporte 5 93 0.3978 0.4921 0 0.3733 0 familia_esporte 6 92 0.4783 0.5023 0 0.473 0 min max range skew kurtosis se sexo 2 2 0 NA NA 0 eat_soma 1 50 49 1.688 4.262 0.8491 bsq_soma 0 188 188 1.504 2.799 3.408 imc 17.56 39.21 21.66 1.269 2.073 0.4206 faz_esporte 0 1 1 0.4107 -1.851 0.05103 familia_esporte 0 1 1 0.08562 -2.014 0.05236 11.4 Execução no R Inicialmente, o gráfico de dispersão auxilia na visualização da relação entre as variáveis.A correlação entre ambas as medidas expressa a força e a direção que elas possuem. Enquanto a força é interpretada em fraca (0.1), moderada (0.3) ou forte (0.5) (Cohen, 1988), a direção pode ser positiva ou negativa, a depender do sinal. ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + labs(x = &quot;Resultados da Escala BSQ-34&quot;, y = &quot;Resultados da Escala EAT-26&quot;, title = &quot;Correlação entre o BSQ-34 e o EAT-26&quot;) O gráfico deixa claro que existe um padrão linear entre ambas as variáveis. O coeficiente de correlação pode ser calculado pelo Produto momento de Pearson, com resultado de 0.6754262, indicando uma alta correlação entre ambos os resultados. Com isso, é natural que o interesse seja verificar o quanto os resultados do EAT-26 variam em função do BSQ-34, uma vez que alguns achados da literatura comentam que a alterações da alimentação ocorrem em função da percepção da imagem corporal. Dando a este objetivo uma leitura estatística, o interesse é o de prever os valores do EAT-26 a partir dos valores do BSQ-34 ou o quanto a variabilidade dos resultados do EAT-26 pode ser atribuída pelos resultados do BSQ-34. Fazer isso pede que se retorne ao gráfico correlacional feito ainda pouco e que tente se ajustar / traçar uma reta que tente tocar na maioria dos pontos. Milhões de retas podem ser traçadas e todas acertarão alguns pontos, mas errarão outros. Por exemplo: ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + labs(x = &quot;Resultados da Escala BSQ-34&quot;, y = &quot;Resultados da Escala EAT-26&quot;, title = &quot;Correlação entre o BSQ-34 e o EAT-26&quot;) + xlim(10,200) + geom_abline(slope = c(rnorm(10,0.4,0.6), rnorm(10,0.2,0.2)),color = 1:20) ## Warning: Removed 2 rows containing missing values (geom_point). A necessidade agora é conseguir encontrar o melhor modelo estatístico que descreva essa relação. Assim, obter uma função que possa gerar uma reta que esteja bem perto dos pontos reais e, consequentemente, minimize os erros. Isso é feito justamente resgatando o conceito de função afim, exposto no ensino médio (e ilustrado ao início do capítulo): \\[\\hat{y} = a + bX\\] Repare que agora o valor previsto (\\(\\hat{y}\\)) depende de duas constantes (a: intercepto ou coeficiente linear e b: inclinação ou coeficiente angular) e uma variável (X). Apenas por uma questão de simbologia, três alterações são feitas com a equação: Os símbolos são alterados. Agora \\(a = b_0\\) e \\(b = b_1\\). A alteração de simbologia não altera em nada os cálculos. Como se sabe que essa reta vai estimar os valores reais de \\(Y\\), letras minúsculas ou um chapéu sobre as letras será utilizado em vez das letras maiúsculas ou gregas. Para que cada valor estimado seja associado a um participante a letra \\(i\\) será adicionada abaixo do \\(y\\) e do \\(b_1\\). Assim, temos que os valores estimados de y, agora \\(\\hat{y}\\), são obtidos pelo \\(b_0\\) e \\(b_1\\): \\[\\hat{y}_i = b_0 + b_1X{_1}_i\\] A equação visa minimizar os erros e não anulá-los. Oy seja, entre o valor real de y (os pontos que estão no gráfico) e os valores obtidos minha equação, haverá sempre uma certa quantidade de erro de estimativa (\\(e_i\\)). Qualquer que seja o valor estimado de cada participante (\\(i\\)), sempre haverá uma quantidade de erro (\\(e_i\\)). Dessa forma, é possível descrever que os valores reais possuem uma porção de erro: \\[y_i = a + b_1X{_1}_i+\\underbrace{e_i}_\\text{aleatório}\\] uma vez que é possível traçar milhões de retas, para encontrar a reta que minimize os erros será necessário discriciona-lo. \\[e_i = y_i - \\hat{y_i}\\] \\[e_i = y_i - (b_0 + b_1X{_1}_i) \\\\ = y_i - b_0 - b_1X{_1}_i\\] O método mais frequentemente utilizado para minimizar os erros é o Mínimos Quadrados Ordinários (em inglês, Ordinary Least Squares – OLS). Isso é realizado minimizando a soma dos quadrados das diferenças entre os valores estimados de Y por meio da reta de regressão (\\(\\hat{Y}\\)). Para isso, o procedimento consiste em derivar a soma dos quadrados dos erros em relação a \\(b_0\\) e e \\(b_1\\) e, em seguida, igualando a 0: \\[\\frac{\\partial \\epsilon}{\\partial b_0} = 0,\\\\ \\frac{\\partial \\epsilon}{\\partial b_1} = 0\\] Com isso, os resultados permitem concluir que a inclinação da reta (slope) é dada por: \\[\\begin{aligned} b_1 &amp;= \\frac{\\sum_{i = 1}^{n} x_i y_i - \\frac{(\\sum_{i = 1}^{n} x_i)(\\sum_{i = 1}^{n} y_i)}{n}}{\\sum_{i = 1}^{n} x_i^2 - \\frac{(\\sum_{i = 1}^{n} x_i)^2}{n}} = \\frac{COV(xy)}{VAR(x)}\\end{aligned}\\] Enquanto o intercepto é dado por: \\[\\begin{aligned}b_0 &amp;= \\bar{y} - b_1 \\bar{x} \\end{aligned}\\] Agora é possível traçar a melhor reta para descrever o relacionamento entre as variáveis, tal como abaixo: b1 &lt;- cov(dados_brasil$bsq_soma, dados_brasil$eat_soma)/var(dados_brasil$bsq_soma) b0 &lt;- mean(dados_brasil$eat_soma)-(b1*mean(dados_brasil$bsq_soma)) ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + labs(x = &quot;Resultados da Escala BSQ-34&quot;, y = &quot;Resultados da Escala EAT-26&quot;, title = &quot;Correlação entre o BSQ-34 e o EAT-26&quot;) + geom_abline(intercept = b0, slope = b1) Essa reta passará necessariamente pela média de ambas as variáveis. ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + labs(x = &quot;Resultados da Escala BSQ-34&quot;, y = &quot;Resultados da Escala EAT-26&quot;, title = &quot;Correlação entre o BSQ-34 e o EAT-26&quot;) + geom_abline(intercept = b0, slope = b1) + geom_vline(xintercept = mean(dados_brasil$bsq_soma), size=1.5, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + geom_hline(yintercept = mean(dados_brasil$eat_soma), size=1.5, color = &quot;red&quot;, linetype = &quot;dashed&quot;) Aproveitando o gráfico, agora é possível apresentar os dados reais, a linha de regressão e as distâncias (resíduos) entre os pontos reais e os previstos. Enquanto o modelo foi preciso em alguns pontos, em outros ele não se saiu assim tão bem. No entanto, como essa reta foi construída pela minimização da soma dos quadrados dos resíduos, isso nos deixa confortável com os resultados. transform(dados_brasil, Fitted = fitted(mod_linear_simples)) %&gt;% ggplot(., aes(y = bsq_soma, x = eat_soma)) + geom_point(aes(y = bsq_soma, x = eat_soma, shape = &quot;real&quot;), color=&quot;black&quot;) + #plot real geom_point(aes(y = Fitted, shape = &quot;previsto&quot;), color=&quot;1&quot;) + #plot previsto geom_smooth(se=FALSE, method = &quot;lm&quot;, color = &quot;black&quot;) + geom_segment(aes(x = eat_soma, y = bsq_soma, xend = eat_soma, yend = Fitted), color= &quot;red&quot;) + #erro ligado scale_colour_manual(name = &quot;Legenda&quot;, labels = c(&quot;Estimados/Previstos&quot;, &quot;Reais dos dados&quot;), values = c(&quot;green&quot;, &quot;black&quot;)) + scale_shape_manual(name = &quot;Legenda&quot;, labels = c(&quot;Estimados/Previstos&quot;, &quot;Reais dos dados&quot;), values = c(1, 5)) + labs(x = &quot;Escala BSQ-34&quot;, y = &quot;Escala EAT-26&quot;, title = &quot;Resultados previstos vs. reais&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Posto isso, agora vamos, computacionalmente e analiticamente, realizar passo a passo a regressão linear simples. A função lm é a nativa para isso. Ela precisa da variável dependente e da variável independente, tal como abaixo. É importante sempre atentar para o nível de medida das variáveis para que os resultados sejam adequados. mod_linear_simples &lt;- lm(eat_soma ~ bsq_soma, data = dados_brasil) Existem diferentes maneiras de apresentar o resultado. Tipicamente, uma tabela que apresenta características gerais seguida por específicas é o mais vantajoso. Assim: ols_regress(mod_linear_simples) ## Model Summary ## -------------------------------------------------------------- ## R 0.675 RMSE 7.209 ## R-Squared 0.456 Coef. Var 45.196 ## Adj. R-Squared 0.454 MSE 51.966 ## Pred R-Squared 0.445 MAE 5.565 ## -------------------------------------------------------------- ## RMSE: Root Mean Square Error ## MSE: Mean Square Error ## MAE: Mean Absolute Error ## ## ANOVA ## ----------------------------------------------------------------------- ## Sum of ## Squares DF Mean Square F Sig. ## ----------------------------------------------------------------------- ## Regression 9503.775 1 9503.775 182.883 0.0000 ## Residual 11328.675 218 51.966 ## Total 20832.450 219 ## ----------------------------------------------------------------------- ## ## Parameter Estimates ## -------------------------------------------------------------------------------------- ## model Beta Std. Error Std. Beta t Sig lower upper ## -------------------------------------------------------------------------------------- ## (Intercept) 1.466 1.176 1.246 0.214 -0.852 3.784 ## bsq_soma 0.178 0.013 0.675 13.523 0.000 0.152 0.204 ## -------------------------------------------------------------------------------------- Os resultados do intercepto (\\(b_0\\)) e da inclinação \\(b_1\\) já foram analisados anteriormente, mas agora há 3 outros resultados que serão descritos. Em primeiro momento, é necessário verificar o ajuste do modelo e isso é feito na seção ANOVA. Esse resultado compara o modelo em questão contra um modelo em que apenas o intercepto é utilizado para prever todos os valores. Tecnicamente, o modelo em questão é chamado de irrestrito (ou Aumentado) e o modelo que tem apenas o intercepto é chamado de restrito ou nulo. Valores significativos são necessários nesta etapa. O segundo momento se relaciona à interpretação do \\(R^2\\). Essa medida mensura o quanto a variação total da variável dependente (Y) pode ser atribuída às variáveis independentes do modelo (X). Repare que ele é computado pela razão entre o SSR e o SST e indica que cerca de 46% dos resultados do EAT-26 podem ser explicados pelo modelo. O terceiro momento é a análise do \\(R^2 ajustado\\). Em modelos de regressão, modelos com mais parâmetros/preditores sempre vão sempre ter \\(R^2\\) maior do que modelos mais compactos, independente da relevância destes parâmetros extras. O \\(R^2 ajustado\\) é uma medida que considera a complexidade do modelo. Neste modelo, há dois preditores \\(b_0\\) e \\(b_1\\), gerando: \\[Adjusted R^2 = 1 - \\frac{SSE/(N-K)}{SST/(N-1)} = 1-\\frac{11328.675/(220-2)}{20832.45/(220-1)} = 1-\\frac{51.97}{95.13} = 0.454\\] Isso posto, a tabela inicial da regressão abaixo é exatamente igual a que foi exposta no capítulo sobre a ANOVA (de uma via) e é muito encontrada em outros livros técnicos: Source SS df MS F-Value P-Value Regressão SSR (Regressão) K-1 MSR SSR/K-1 MSR/MSE Erro SSE (Erro) N-K MSE SSE/N-K – Total SST (Total) N-1 – – – Com tais resultados descritos, agora é possível retornar aos coeficientes obtidos na regressão. O intercepto é chamado de constante na maior parte dos programas. Ele se refere ao valor médio (esperado) de Y quando X=0. Ou seja, se alguém tivesse tirado o valor 0 na escala BSQ-34, o valor previsto para os resultados da Escala EAT-26 seria de 1.55, tal como apresentado abaixo: predict(mod_linear_simples, data.frame(bsq_soma=c(0))) ## 1 ## 1.465899 É importante notar que frequentemente o intercepto não tem interpretação lógica e, por isso, costuma ser desconsiderado. No entanto, é possível centralizar os valores do preditor \\((x_i-\\bar{x})\\) para que o intercepto se torne o valor médio da variável dependente e tenha melhor capacidade de interpretação. É também importante atentar que o valor do intercepto não é significativo, indicando que ele não é significativamente diferente de 0. Já o coeficiente do bsq_soma se refere os resultados obtidos a partir da Escala BSQ-34 é 0.178 e significativo. Isso significa que 1 unidade de mudança nos resultados da BSQ-34 geram 0.177 unidade de mudança, em média, nos resultados da Escala EAT-26. A significância deste coeficiente é dada pelo Erro Padrão (Std. Error) e segue uma T com n-2 graus de liberdade. Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. Estes testes são os mesmos realizados em outros modelos e podem ser feitos tanto de forma gráfica, como de maneira formal. O relacionamento linear já havia sido investigado no gráfico de dispersão ao início deste capítulo. A Normalidade dos resíduos pode ser vista pelo QQ-Plot (abaixo): ols_plot_resid_qq(mod_linear_simples) Caso os pontos e a reta diagonal estejam superpostos, se considera que este pressuposto foi atendido. Testes estatísticos formais também podem ser utilizados. Apesar dos resultados obtidos por tais testes serem algo discordantes, os achados sugerem violação deste pressuposto. ols_test_normality(mod_linear_simples) ## Warning in ks.test(y, &quot;pnorm&quot;, mean(y), sd(y)): ties should not be present for ## the Kolmogorov-Smirnov test ## ----------------------------------------------- ## Test Statistic pvalue ## ----------------------------------------------- ## Shapiro-Wilk 0.9597 0.0000 ## Kolmogorov-Smirnov 0.0816 0.1072 ## Cramer-von Mises 17.066 0.0000 ## Anderson-Darling 2.4137 0.0000 ## ----------------------------------------------- A independência dos resíduos depende bastante do delineamento utilizado e transversal ou longitudinal. O teste de Durbin Watson pode ser utilizado e a Hipótees nula é de que os resíduos não são correlacionados. Este pressuposto foi atendido, o que já era esperado. car::durbinWatsonTest(mod_linear_simples) ## lag Autocorrelation D-W Statistic p-value ## 1 0.07254389 1.845067 0.256 ## Alternative hypothesis: rho != 0 As homocedasticidade, ou seja, variâncias constantes pode ser vista em um gráfico de dispersão dos resíduos (residual) contra os valores previstos (fitted). ols_plot_resid_fit(mod_linear_simples) Caso haja padrões neste gráfico, isso sugere que este pressuposto foi violado. A visualização costuma ser um pouco complicada e abaixo há três exemplos: include_graphics(&quot;img/cap_reg_homocedasticidade.png&quot;) Existem também testes formais, como o Bartlett e o Breusch-Pagan. Os resultados costumam convergir e, em função da praticidade computacional, o teste de Breusch-Pagan será utilizado. Nesse teste, os resultados tem distribuição qui-quadrado e a Hipótese nula assume homocedasticidade. Portanto, a estatística de teste deveria ser insignificante para que a homocedasticidade pudeSSR ser aceita, o que não é o caso aqui. ols_test_breusch_pagan(mod_linear_simples) ## ## Breusch Pagan Test for Heteroskedasticity ## ----------------------------------------- ## Ho: the variance is constant ## Ha: the variance is not constant ## ## Data ## ------------------------------------ ## Response : eat_soma ## Variables: fitted values of eat_soma ## ## Test Summary ## ------------------------------ ## DF = 1 ## Chi2 = 9.002614 ## Prob &gt; Chi2 = 0.002695937 Isso posto, os diagnósticos executados indicaram que o modelo violou a normalidade e a homocedasticidade e preservou a linearidade e a independência dos resíduos. Apesar desse tipo de resultado ser frequente em Psicologia, a interpretação dos resultados é limitada e deve ser feita de forma apenas preliminar. Abaixo uma orientação de como escrever os resultados. Como escrever os resultados Um modelo de regressão foi calculado para verificar os resultados dos comportamentos alimentares (EAT-26) em função da percepção de imagem corporal (BSQ-34). Os resultados indicaram que cerca de 45% da variância do EAT-26 pode ser atribuída ao BSQ-34 (R2 = 0.456, F(1,218) = 182.88, p &lt; 0.001). Cada ponto a mais no BSQ-34 impacta, em média, em 0.178 no EAT-26 (b = 0.178, p &lt; 0.001). 11.5 Resumo Existem diferentes modelos de regressão e eles sempre visam prever um resultado a partir de uma ou um conjunto de variáveis O tipo de modelagem depedente tanto da natureza e quantidade das VIs e VDs, sempre possível entender grande parte dos testes estatísticos estudados como casos particulares dos modelos de regressão Os principais indicadores de um modelo de regressão são sua significância geral, o \\(R^2\\),o o \\(R^2_{adj}\\), bem como o coeficiente e a significância dos preditores o diagnóstico é uma parte essencial desta modelagem e o mnemônico LINE pode ajudar na lembrança dos pressupostos References "],
["regressão-linear-múltipla.html", "Capítulo 12 Regressão linear múltipla 12.1 Pesquisa 12.2 Execução no R 12.3 Técnicas automáticas de seleção de variáveis 12.4 Resumo", " Capítulo 12 Regressão linear múltipla Os modelos de regressão linear múltipla são desenvolvidos para predizer os valores médios de uma variável resposta (Y) em função de duas ou mais variáveis independentes (X). Nestes modelos, a VD deve ser contínua e as VIs podem ser tanto contínuas como categóricas. Tecnicamente, a família da ANOVA vista anteriormente são casos particulares de modelos de regressão múltipla. Conceitualmente, neste modelo, se adiciona um outro preditor à equação vista no capítulo de regressão linear simples. Assim: \\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i+ \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) e \\(b_2\\) indicam a inclinação dos preditores (coeficiente angular) \\(\\epsilon_{i}\\) é o erro/resíduo Os seguintes pressupostos devem ser avaliados: A relação entre as variáveis é linear Os resíduos são independentes Os resíduos são normalmente distribuídos A variância dos resíduos é constante O mnemônico LINE (linearity, independence, normality, equal variance) talvez ajude a lembrar destes pressupostos. 12.1 Pesquisa Base: Livro - Dados - Eating disorders Vamos utilizar a pesquisa intitulada “Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students”, publicada em 2018 no Global Journal of Educational Studies, que sou co-autor. O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e aspectos da percepção da imagem corporal, bem como verificar a capacidade que uma medida possuia em predizer os resultados de outra. Esse artigo contou com a utilização de escalas aplicadas em 219 participantes no Brasil. Para acessar aspectos relacionados aos Transtornos alimentares, a escala EAT-26 foi aplicada. Para verificar aspectos da imagem corporal, a escala BSQ-34 foi aplicada. Segue abaixo uma tabela inicial com dados descritivos dos resultados. dados_brasil %&gt;% select(sexo,eat_soma, bsq_soma, imc, faz_esporte, familia_esporte) %&gt;% psych::describeBy(.,group = &quot;sexo&quot;) %&gt;% pander::pander() ## Warning in pander.default(.): No pander.method for &quot;psych&quot;, reverting to ## default.No pander.method for &quot;describeBy&quot;, reverting to default. 1: Table continues below vars n mean sd median trimmed mad sexo 1 126 1 0 1 1 0 eat_soma 2 126 18.48 10.09 17 17.9 11.86 bsq_soma 3 126 94.17 34.87 91 92.64 40.77 imc 4 124 22.58 3.151 21.95 22.24 2.542 faz_esporte 5 126 0.4524 0.4997 0 0.4412 0 familia_esporte 6 126 0.4762 0.5014 0 0.4706 0 min max range skew kurtosis se sexo 1 1 0 NA NA 0 eat_soma 0 47 47 0.4929 -0.5091 0.8988 bsq_soma 32 182 150 0.3512 -0.4573 3.107 imc 16.85 32.87 16.02 0.9764 0.8725 0.2829 faz_esporte 0 1 1 0.1891 -1.98 0.04452 familia_esporte 0 1 1 0.09421 -2.007 0.04467 2: Table continues below vars n mean sd median trimmed mad sexo 1 93 2 0 2 2 0 eat_soma 2 93 12.65 8.189 11 11.55 5.93 bsq_soma 3 93 64.24 32.87 55 59.32 19.27 imc 4 90 24.1 3.99 23.41 23.65 2.829 faz_esporte 5 93 0.3978 0.4921 0 0.3733 0 familia_esporte 6 92 0.4783 0.5023 0 0.473 0 min max range skew kurtosis se sexo 2 2 0 NA NA 0 eat_soma 1 50 49 1.688 4.262 0.8491 bsq_soma 0 188 188 1.504 2.799 3.408 imc 17.56 39.21 21.66 1.269 2.073 0.4206 faz_esporte 0 1 1 0.4107 -1.851 0.05103 familia_esporte 0 1 1 0.08562 -2.014 0.05236 12.2 Execução no R Para crir o modelo no R, basta adicionar uma nova variável à equação. Neste caso, além de verificar o efeito da percepção de imagem corporal, o peso também irá ser utilizado como preditor. É importante notar que, por padrão, o R não usa linhas com dados ausentes e isso pode reduzir o poder do teste. mod_linear_multiplo &lt;- lm(eat_soma ~ bsq_soma + peso_atual, data = dados_brasil) A apresentação segue o mesmo formato da realizada no capítulo específico de regressão linear simples. ols_regress(mod_linear_multiplo) ## Model Summary ## -------------------------------------------------------------- ## R 0.697 RMSE 7.082 ## R-Squared 0.486 Coef. Var 44.265 ## Adj. R-Squared 0.481 MSE 50.160 ## Pred R-Squared 0.472 MAE 5.434 ## -------------------------------------------------------------- ## RMSE: Root Mean Square Error ## MSE: Mean Square Error ## MAE: Mean Absolute Error ## ## ANOVA ## ----------------------------------------------------------------------- ## Sum of ## Squares DF Mean Square F Sig. ## ----------------------------------------------------------------------- ## Regression 10099.820 2 5049.910 100.675 0.0000 ## Residual 10684.180 213 50.160 ## Total 20784.000 215 ## ----------------------------------------------------------------------- ## ## Parameter Estimates ## ---------------------------------------------------------------------------------------- ## model Beta Std. Error Std. Beta t Sig lower upper ## ---------------------------------------------------------------------------------------- ## (Intercept) 9.331 2.755 3.386 0.001 3.899 14.762 ## bsq_soma 0.180 0.013 0.678 13.811 0.000 0.155 0.206 ## peso_atual -0.121 0.037 -0.158 -3.221 0.001 -0.195 -0.047 ## ---------------------------------------------------------------------------------------- Os resultados devem ser analisados de maneira cuidadosa. Inicialmente, é possível concluir que o modelo foi globalmente significativo (F(2, 213) = 100.675, p &lt; 0.001) e que cerca de 48% da variabilidade do EAT-26 pode ser atribuída aos valores do BSQ-34 e do peso do participante. Cada um dos preditores tem um comportamento específico. Em relação ao BSQ-34, cada unidade a mais em seu resultado impacta, em média, 0.18 pontos a mais no EAT-26, controlando pelo peso do participante (p &lt; 0.001). Além disso, cada 1 kg a mais no peso do participante impacta em -0.121 (p &lt; 0.001), em média, nos resultados do EAT-26, controlando pelos valores do BSQ-34. A ideia de verificar o efeito de uma variável controlando por outra tem um significado particular. Assumindo duas pessoas que tem o peso atual igual ao peso médio do grupo ou o mesmo peso, cada ponto extra no BSQ gera, em média, 0.18 pontos a mais no EAT-26. Assim, o valor estimado no EAT-26 de Um participante que teve 45 pontos no BSQ e peso de 66.51 (o peso médio) é de 9.41. Já o valor estimado no EAT-26 de um outro participante com 46 pontos no BSQ e mesmo peso do primeiro participante (66.51) é de 9.59. A diferença entre os valores é exatamente igual ao coeficiente calculado na regressão (b = 0.18). Abaixo há duas linhas de código apresentando esses resultados. peso_medio &lt;- mean(dados_brasil$peso_atual, na.rm=T) predict(mod_linear_multiplo, data.frame(bsq_soma=c(45), peso_atual=peso_medio)) ## 1 ## 9.416621 predict(mod_linear_multiplo, data.frame(bsq_soma=c(46), peso_atual=peso_medio)) ## 1 ## 9.596919 predict(mod_linear_multiplo, data.frame(bsq_soma=c(46), peso_atual=peso_medio))-predict(mod_linear_multiplo, data.frame(bsq_soma=c(45), peso_atual=peso_medio)) ## 1 ## 0.1802979 Tal como apresentado anteriores, a interpretação dos resultados depende da adequação de seus pressupostos. O relacionamento linear já havia sido investigado no gráfico de dispersão nos capítulos anteriores. A Normalidade dos resíduos pode ser vista pelo QQ-Plot (abaixo): ols_plot_resid_qq(mod_linear_multiplo) ols_plot_resid_stud_fit(mod_linear_multiplo) e por testes estatísticos formais. De forma análoga ao que aconteceu no capítulo de regressão linear simples, apesar de algo discordantes, o pressuposto de normalidade foi rejeitado. ols_test_normality(mod_linear_multiplo) ## Warning in ks.test(y, &quot;pnorm&quot;, mean(y), sd(y)): ties should not be present for ## the Kolmogorov-Smirnov test ## ----------------------------------------------- ## Test Statistic pvalue ## ----------------------------------------------- ## Shapiro-Wilk 0.9607 0.0000 ## Kolmogorov-Smirnov 0.0689 0.2567 ## Cramer-von Mises 17.7972 0.0000 ## Anderson-Darling 2.2135 0.0000 ## ----------------------------------------------- A independência dos resíduos pode ser avaliada pelo Durbin Watson. É importante lemrbar que a Hipótees nula é de que os resíduos não são correlacionados. car::durbinWatsonTest(mod_linear_multiplo) ## lag Autocorrelation D-W Statistic p-value ## 1 0.02410462 1.947272 0.642 ## Alternative hypothesis: rho != 0 As homocedasticidade, ou seja, variâncias constantes pode ser vista em um gráfico de dispersão dos resíduos (residual) contra os valores previstos (fitted). ols_plot_resid_fit(mod_linear_multiplo) O teste Breusch-Pagan também é um indicador importante e a Hipótese nula assume homocedasticidade. Portanto, a estatística de teste deveria ser insignificante para que a homocedasticidade pudeSSR ser aceita, o que não é o caso aqui. ols_test_breusch_pagan(mod_linear_multiplo) ## ## Breusch Pagan Test for Heteroskedasticity ## ----------------------------------------- ## Ho: the variance is constant ## Ha: the variance is not constant ## ## Data ## ------------------------------------ ## Response : eat_soma ## Variables: fitted values of eat_soma ## ## Test Summary ## ----------------------------- ## DF = 1 ## Chi2 = 5.723583 ## Prob &gt; Chi2 = 0.01673854 Como esse modelo pode reunir diversas variáveis independentes, é importante verificar o quanto elas são correlacionadas entre si. Isso é feito pela análise de Variance Inflaction Factor (VIF). Valores de VIF superiores a 4 indicam que as variáveis indepenentes são fortemente correlacionadas e, com isso, as estimativas podem ser distorcidas. Neste caso, isso não aconteceu. ols_coll_diag(mod_linear_multiplo) ## Tolerance and Variance Inflation Factor ## --------------------------------------- ## Variables Tolerance VIF ## 1 bsq_soma 0.9999925 1.000007 ## 2 peso_atual 0.9999925 1.000007 ## ## ## Eigenvalue and Condition Index ## ------------------------------ ## Eigenvalue Condition Index intercept bsq_soma peso_atual ## 1 2.85848875 1.000000 0.003656276 0.01908105 0.004257786 ## 2 0.12424761 4.796498 0.027440631 0.92248915 0.062344260 ## 3 0.01726365 12.867732 0.968903094 0.05842980 0.933397954 Com isso realizado, os diagnósticos indicaram que a normalidade e a homocedasticidade foram violadas, novamente sugerindo uma interpretação cautelosa dos resultados. Abaixo uma orientação de como escrever os resultados. Como escrever os resultados Um modelo de regressão múltipla foi calculado para verificar os resultados dos comportamentos alimentares (EAT-26) em função da percepção de imagem corporal (BSQ-34) e do peso do participante. Os resultados indicaram que cerca de 48% da variância do EAT-26 pode ser atribuída aos preditores (R2 = 0.486, F(2,213) = 100.675, p &lt; 0.001). Cada ponto a mais no BSQ-34 impacta, em média, em 0.180 no EAT-26 (p &lt; 0.001), controlando pelo peso do participante. 12.3 Técnicas automáticas de seleção de variáveis Os critérios para composição dos modelos costuma despertar um grande interesse nos debates estatísticos e quantas, quais e como eleger as variáveis independentes é um dos mais intensos. A seleção destas variáveis visa otimizar a acurácia do modelo, mas sem perder sua parcimônia, ou seja, simplicidade (Gaudio &amp; Zandonade, 2001; Unger &amp; Hansch, 1973). Métodos com justificativa teórica costumam ser chamados de entrada bruta, enquanto métodos em que se implementa algum algorítimo computadorizado para tal seleção tendem a ser denominados de métodos automáticos. Apesar do detalhamento destas técnicas ser fora do escopo dete capítulo, a seguir são listadas as principais técnicas: Backward selection Forward selection Stepwise selecion Lasso selection 12.4 Resumo O termo regressão múltipla se refere a um modelo de regressão com duas ou mais variáveis independentes As VIs podem ser de qualquer natureza, o que significa que toda família da ANOVA pode ser entendida como casos particulares de regressão Os diagnósticos são os mesmos dos modelos simples, mas agora é necessário também testar a multicolinearidade do modelo Existem diferentes métodos para adicionar preditores e maneiras manuais e automáticas são disponíveis "]
]
