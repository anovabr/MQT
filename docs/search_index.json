[
["index.html", "Métodos quantitativos em Psicologia com R Cap. 1 Prefácio 1.1 A proposta 1.2 Objetivo 1.3 Público-alvo 1.4 Formato do livro 1.5 Bases 1.6 O R 1.7 Pacotes e sintaxes 1.8 Outros recursos 1.9 Capa 1.10 Agradecimentos", " Métodos quantitativos em Psicologia com R Luis Anunciação (PUC-Rio), PhD 2021-01-13 Cap. 1 Prefácio 1.1 A proposta Este livro tem como proposta a de ser um manual técnico, focado na apresentação e realização de um conjunto de conceitos de pesquisa e análises estatísticas no R e no JASP. Em cada capítulo, será apresentada uma pesquisa, o artigo publicado com os resultados, a base de dados utilizada e o conjunto de procedimentos analíticos e computacionais desenvolvidos para analisar os dados. A discussão de conceitos de pesquisa, bem como o desenvolvimento matemático, são implementados de maneira colateral durante o livro. 1.2 Objetivo O livro tem como objetivos (1) apresentar, (2) discutir e (3) operacionalizar conceitos de pesquisa e análises estatística de dados. Espera-se que qualquer leitor/usuário de estatística consiga realizar todas as ações descritas no decorrer dos capítulos de maneira guiada e intuitiva. Dessa forma, tanto as sintaxes utilizadas no ambiente R como as telas de execução do JASP estão integralmente disponíveis. 1.3 Público-alvo Este livro foi desenvolvido de maneira mais focada a estudantes de pós-graduação em Psicologia. O conteúdo surgiu das aulas da disciplina de Métodos Quantitativos na PUC-Rio, Análise de Dados na UFRJ e Estatística Aplicada na ANOVA. Apesar dos exemplos serem mais relacionados à Psicologia, grande parte dos conceitos e análises estatísticas implementadas no livro é interdisciplinar. Com isso, acredito que estudantes de áreas como educação, administração e economia poderão também ter proveito do livro. 1.4 Formato do livro O livro foi pensando para ter uma estrutura linear formada por capítulos autossuficientes e desenvolvidos para responder questões específicas, particulares e pontuais. Dessa maneira, acredito que o livro atenda tanto aqueles leitores com interesse em ler a obra inteira, como aqueles que buscam apenas informações mais específicas de um tópico particular. Esse formato adotado tende a gerar uma percepção diferente entre aqueles que consultarem apenas um capítulo ou outro e aqueles que lerem o conteúdo por completo. Isso ocorre pois como muitos testes estatísticos são entendidos como casos particulares de outros, alguns fragmentos que podem parecer destoantes durante uma leitura inicial, tornam-se mais fáceis e articulados àqueles que lerem o trabalho inteiro e se dispuserem a fazer uma releitura de partes específicas. Para ilustrar, o capítulo sobre o Teste T expõe uma pequena parte sobre modelos de regressão, conteúdo que somente é abordado posteriormente. Se em um primeiro momento isso provavelmente pode gerar alguma (pequena) confusão, a releitura do capítulo após o término da sequência do livro poderá gerar, além de um conhecimento mais profundo por parte do leitor, a percepção da integração tanto da estrutura do livro, como da relação existente entre diferentes modelos estatísticos. 1.5 Bases Todas as bases de dados utilizadas neste livro são frutos de pesquisas empíricas que apresentam artigos publicados. Visando otimização, alguns ajustes foram feitos às bases para torná-las mais acessíveis. Nenhuma alteração foi realizada nos dados, mas apenas em mudanças em relação a nomes de variáveis e quantidade de vetores. Todo material pode ser acessado livre e gratuitamente em https://github.com/anovabr/mqt/tree/master/bases 1.6 O R O livro é feito integralmente no R, utilizando o Rmarkdown e funções nativas e do Tidyverse. Caso alguém apresente o interesse em reproduzir as análises, será necessário seguir todas as linhas de código disponíveis no decorrer dos capítulos. A parte textual e a parte de programação do texto se sobrepõem frequentemente e isso foi feito de maneira intencional, visando deixar todo o desenvolvimento deste livro o mais próximo o possível do cotidiano de pesquisadores e estatísticos. 1.7 Pacotes e sintaxes Este livro utiliza majoritariamente o ambiente tidyverse para realização das análises. Entretanto, sempre que necessário, funções R-base e uso de outros pacotes serão utilizados. Toda codificação utilizada no livro é exibida nos capítulos e integralmente disponível gratuitamente neste (GitHub)[https://github.com/anovabr/mqt] O tidyverse costuma ter atualizações frequentes e espero que as funções utilizadas durante o livro não sejam descontinuadas (deprecated) com o tempo. 1.8 Outros recursos Tão importante como saber como saber estatística e programação, é saber onde buscar ajuda (de qualidade) para as questões que, naturalmente, aparecem no decorrer das atividades. Eu recomendo fortemente a comunidade stackoverflow neste sentido. 1.9 Capa Com muita frequência, livros de Ciência de Dados utilizam a imagem de algum animal na capa. Há livros com cachorros, papagaios, peixes e veados. Esse livro não foge dessa regra e tem como capa a Jolie, a cachorrinha da Anna e minha. 1.10 Agradecimentos Nenhum homem é uma ilha. Este livro só foi possível graças a um conjunto de pessoas que auxiliaram. Meus sinceros agradecimentos a (ao): Professor J. Landeira-Fernandez Professor Cristiano Fernandes Anna Carolina de Almeida Portugal Alunos da PUC-Rio, UFRJ e UFRJ "],
["aspectos-gerais.html", "Cap. 2 Aspectos gerais 2.1 Principais áreas da estatística 2.2 Considerações sobre escalas de medida e o processo de mensuração em Psicologia", " Cap. 2 Aspectos gerais Os subtópicos a seguir ilustram um conjunto de conceitos importantes que tendem a ser apresentados antes mesmo de introduzir conceitos em Estatística. Como os conceitos são transversais, eles podem também ser úteis em métodos e técnicas de pesquisa em geral. 2.1 Principais áreas da estatística A estatística pode ser dividida em duas áreas interligadas: estatística descritiva e estatística inferencial. O objetivo da estatística descritiva é apresentar sínteses e resumos dos resultados de uma pesquisa pela utilização de gráficos e tabelas. Não é intenção dessa área fazer generalizações ou extrapolar os resultados obtidos a pessoas (ou objetos) não investigadas durante a coleta de dados. Por contraste, a estatística inferencial visa extrapolar os dados e fazer generalizações que toquem toda população de onde aquela mostra foi retirada e é representativa. Dessa maneira, o principal objetivo da estatística inferencial é, de fato, fazer inferências. Essa divisão é certamente mais didática do que pragmática e, com muita frequência, ambas as áreas estão presentes em uma pesquisa. No entanto, alguns pontos merecem destaque: A estatística descritiva surgiu antes que a inferencial. A etimologia da palavra talvez ajude a entender. Estatística vem da palavra estado e este sempre teve interesse em saber quantos eram os cidadãos de um determinado local para, entre outras atividades, taxá-los. Assim, aspectos descritivos antecedem os inferenciais. Por sua vez, a estatística inferencial guarda origem e proximidade com a teoria dos jogos e, consequentemente, isso ajuda a entender o motivo pelo qual a maioria dos exemplos inferenciais envolvem jogos de azar. A estatística tem duas “escolas” ou “formas de pensamento”. A estatística frequentista e a estatística bayesiana. Aspectos fundamentais que tocam à definição de probabilidade são diferentes, bem como a definição de dados e parâmetros também o são. Pela perspectiva histórica, a estatística bayesiana é mais antiga que a frequentista. No entanto, se for comparado a proporção de uso entre os pesquisadores, a estatística frequentista é ainda a mais frequente e justifica a ênfase deste livro nesta área. A relação entre estatística e Machine Learning (ML) e seus derivados é relativamente recente. Apesar de grande interface e do fato que as análises realizadas em estatística e ML encontram resultados virtualmente idênticos, há diferentes argumentos apontando que as áreas têm objetivos diferentes, o que eu não necessariamente concordo. Ainda sob perspectiva histórica, a estatística, como uma área do conhecimento, é anterior à ML, que não será abordada neste livro. 2.2 Considerações sobre escalas de medida e o processo de mensuração em Psicologia L. Anunciação &amp; J. Landeira-Fernandez A existência de um fenômeno é condicionada à uma determinada quantidade. Como atribuído à Thorndike (1914), “Se algo existe, ele tem de existir em uma certa quantidade e se uma determinada quantidade existe, ela pode ser mensurada”. Assim, tal como em outras ciências, o processo de mensuração é absolutamente vital à Psicologia. Isso pode ser demonstrado tanto pela implementação de técnicas estatísticas para modelar fenômenos psicológico, como pelas lentes de uma das áreas mais voltadas ao desenvolvimento de instrumentos, que é a Psicometria. Entretanto, nunca faltaram céticos de diferentes locais questionando se fenômenos psicológicos poderiam, de fato, ser medidos e uma das primeiras e mais estáveis respostas sobre esse questionamento ocorreu em 1946, com a publicação intitulada “On the theory of scales of measurement” do psicólogo e psicofísico Stanley Stevens. Este trabalho apresentou algumas conclusões que até hoje são importantes e que tocam, principalmente (1) à definição de medida, (2) o conceito de escalas (níveis) de medida e (3) à condição da mensuração de fenômenos psicológicos. Inicialmente, Stevens parafraseou N.R. Campbell ao entender que a “mensuração, em sentido mais amplo, é definida como a atribuição de números a objetos ou eventos de acordo com algumas regras” (Stevens, 1946, p. 677). Uma vez feito isso, ele concluiu que esses números são atribuídos (ou existem) em função da possibilidade de realização de operações estatísticas e matemáticas com eles. Duas regras gerais são subjacentes neste conceito: a primeira é que a as operações possíveis para cada escala são as que se mantêm invariantes para as transformações matemáticas que cada um dos níveis de mensuração aceita e a segunda é que é necessário que haja um isomorfismo (as vezes, apresentado como s(x)) entre os entre os objetos que estão sendo medidos e os números atribuídos a eles. Em função destas condições, Stevens descreve quatro escalas que se apresentam hierarquicamente como: (i) nominal, (ii) ordinal, (iii) intervalar e (iv) de razão. Desde o trabalho de Stevens, essa relação entre o valor numérico e o objeto para o qual este valor foi utilizado atraiu ao menos dois grupos de pesquisadores, que são aqueles que possuem um interesse mais voltado à análise de informação que este número ou esta escala traz e, neste sentido, tentam responder à pergunta “O que este número está informando” e os que possuem um maior interesse em desenvolver tratamentos estatísticos a tais números ou escalas e, analogamente, tentam responder à pergunta “Como que se trata estatisticamente tais números?”. Posto isso, este seção realiza uma síntese deste conceito, bem como apresenta as descrições de cada uma das escalas, especialmente a partir de uma orientação mais pragmática, suas condições de uso e uma breve contextualização atual. 2.2.1 Escala nominal Essa escala é a mais primitiva de todas e a única regra relacionada ao processo de mensuração é que o número atribuído a um determinado objeto ou evento deve ser exclusivo, não sendo possível atribuir um mesmo número a diferentes eventos ou objetos. É importante destacar que os números aqui são arbitrários e, além disso, não refletem grandezas ou magnitudes. Nessa escala, só é possível contagens e proporções. Em relação a aspectos estatísticos, é possível obter apenas a moda dos valores. Exemplos concretos são: o número da camisa dos jogadores de futebol, atribuir o valor 1 para homens e 2 para mulheres ou 1 para psicólogos, 2 para geógrafos e 3 para pedagogos. É importante notar existem livros e manuais que consideram que quando há apenas dois valores possíveis para o objeto ou evento, o ideal é chamar essa escala de “dicotômica”, “binária” ou “dummy”, mas isso varia bastante em função da área e o consenso não é fácil. Por exemplo, em estudos em ciências sociais, é possível encontrar autores chamando a classificação de sexo biológico (por exemplo, 1 para homens e 2 para mulheres) de variável binária; já em estudos epidemiológicos, é frequente à atribuição do valor “1” para um grupo de pessoas com uma determinada doença e “0” para um grupo de pessoas sem esta doença (apesar disso poder ser entendido como ordinal em alguns casos) e, finalmente, em estudos em economia, por vezes os pesquisadores utilizam o valor “1” para indicar algo de interesse (por exemplo, desempregado) e “0” para caso contrário. Tirando essas particularidades, é fundamental entender que os números atribuídos à essa escala são arbitrários e apenas identificam objetos ou eventos. 2.2.2 Escala ordinal Nessa escala, os números respeitam uma relação de ordem ranqueada e essa é a regra pela qual os números são atribuídos aos eventos ou objetos. É importante ter em perspectiva que essa escala pode ser utilizada pragmaticamente em uma pesquisa mesmo quando o fenômeno que está sendo estudado é facilmente compreendido dentro de uma escala superior, como será visto. Por exemplo, é plenamente possível que um psicólogo meça o tempo de reação de um grupo de pessoas e depois tenha criado categorias ordenadas, como “lento (1)”, “esperado (2)” e “rápido (3)”. Em função disso, alguns livros tentam dividir essa escala a partir de uma origem objeto ou evento que está sendo medido e utilizam de termos como “origem natural” e “origem não natural”, que não serão utilizados aqui (Pasquali, 1998). Nessa escala, além da contagem, proporções e moda, é também possível identificar mínimo, máximo e amplitude. Exemplos concretos são a Escala de dureza dos metais (Escala de Mohs), o nível de satisfação de uma empresa, onde 1 é baixo, 2 é moderadamente satisfeito e 3 é alto e a posição ao fim de uma corrida, podendo ser o primeiro lugar, segundo ou terceiro. 2.2.3 Escala intervalar Os números aqui assumem um aspecto propriamente quantitativo e, em outras palavras, quase sempre o número não segue nem uma relação arbitrária (por exemplo, 1 para homens e 2 para mulheres), nem tampouco uma convenção informal (por exemplo, 1 para ensino fundamental e 2 para ensino médio), mas é obtido a partir de um processo em que se contou com a utilização de instrumentos de medida. Nessa escala, as distâncias entre as categorias são iguais, apesar do valor zero ser uma conveniência. Dessa maneira, a diferença entre categorias será sempre relacional e jamais absoluta. Assim, nesse nível, é possível ter propriedades aditivas, mas não multiplicativas. Considerando unidades arbitrárias, é possível falar que a diferença entre 30 e 29 (1 unidade) é a mesma que entre 15 e 14 (1 unidade). No entanto, no que diz respeito à magnitude do que está sendo medido, nessa escala não é possível falar que 30 unidades é o dobro de 15 unidades. Nessa escala, além da contagem, proporções, moda, identificar mínimo, máximo e amplitude, é possível tirar diferenças e fazer adições, bem como calcular a média, a variância e o desvio-padrão dos resultados. Exemplos concretos são o calendário que utilizamos. Repare que utilizamos “AC” (antes de Cristo) e “DC” depois de Cristo, estipulando um zero arbitrário; a temperatura sendo medida por graus Célsius ou Fahrenheit, já que cada uma dessas medidas tem um ponto 0 arbitrário. Aproveitando o exemplo da temperatura para ilustrar mais detalhadamente o que significa “0” arbitrário, o valor “0o C” na escala célsius se refere à temperatura que a água congela, enquanto “100o C” se refere à temperatura em que a água entre em ebulição. Em Fahrenheit, esse valor é o “32 o F” e “212 o C”. Apesar de haver a possibilidade de conversão de uma escala para outra, repare que não é possível utilizar a propriedade multiplicativa. Por exemplo, enquanto numericamente 30 x 2 = 60, afirmar que 30º C x 2 = 60º C é incorreto. Na verdade, 30º C se refere a 86º F e 60º C se refere a 140º F. Assim, apesar de ser intuitivo pensar que se um ambiente tem 32 graus célsius, ele está o dobro de quente de um ambiente que está 16º celsius, isso não é correto. 2.2.4 Escala de razão Aqui há um 0 absoluto e todas as operações previamente podem ser feitas, bem como o produto das categorias. Escalas de razão são mais encontradas na física. Nessa escala, além das capacidades matemáticas previamente descritas, é possível implementar propriedades multiplicativas. Raramente, essa escala será utilizada em um processo de avaliação psicológica. Entretanto, algumas pesquisas costumam utilizar variáveis que pertencem à escala de razão, como pesquisas em psicofísica que medem o tempo de “tempo de reação” ou pesquisas em neuropsicologia da atenção que medem a “quantidade de botões apertados em um minuto”. É importante novamente alertar que mesmo que essa medida tenha um 0 absoluto (por exemplo, uma pessoa não apertou nenhum botão ao fim de um minuo), isso não significa em nada que o fenômeno psicológico subjacente seja inexistente ou ausente. 2.2.5 Síntese das características de cada escala Como exposto logo ao início, os números presentes em cada uma das escalas podem ser entendidos tanto por seus aspectos de informação como pelos procedimentos estatísticos a eles associados. Ambas as iniciativas possuem sua importância e são associadas entre si. Os gráficos expostos abaixo apresentam ambos os conceitos. 2.2.6 As escalas de Stevens e uma tentativa de agrupamento Apesar de Stevens ter, fundamentalmente, criado quatro escalas em que sempre haverá números associados a objetos a partir de sua capacidade matemática, teóricos posteriores tentaram agrupar essas quatro escalas em dois conjuntos específicos que costumam ser feitos seguindo este critério: uma vez que a escala nominal e ordinal utilizam os números de uma maneira assegurada apenas por convenção, muitos livros e autores as agrupam como “qualitativas”. Por contraste, como a escala intervalar e de razão são obtidas, majoritariamente, por processos que contam com instrumentos de medida, elas quase sempre são agrupadas como “quantitativas”. Mesmo que hoje em dia esse agrupamento seja bastante corriqueiro, origem desta iniciativa é algo incerta. Há sugestão que ela tenha começado pelo trabalho de investigação semiótica de Charles Sanders Peirce. Esse filósofo julgava que a ciência avançava em dez níveis distintos e progressivos, começando por um ícone possível (fancy), passando por um pensamento, um objeto, um símbolo numérico, uma quantidade e uma relação (Smart, 1999, p. 289). Infelizmente, essa classificação pode gerar uma divisão desnecessária dentro do próprio conceito desenvolvido por Stevens, além de gerar bastante confusão, já que o termo “pesquisa qualitativa” não costuma se referir às escalas de medida, mas sim à uma área que mais recentemente emergiu com uma forma metodológica distinta e, eventualmente, até mesmo crítica às iniciativas de medida e mensuração. Além disso, o termo “quantitativa” atribuído apenas à escala intervalar e de razão pode dar a impressão inadequada de que não se usa números nas escalas nominais ou ordinais. Finalmente, é importante frisar que há livros que utilizam o termo “categórica” para “qualitativa” e “propriamente numérico” para “quantitativa”, aumentando algo mais os cenários de confusão. A imagem a seguir apresenta esta tentativa. 2.2.7 Variáveis discretas ou contínuas A iniciativa de classificar as variáveis e, consequentemente, escalas de medida não foi apenas feita em estudos psicológicos. Evidentemente, áreas como matemática, probabilidade e estatística também tiveram (e ainda possuem) interesse em classificar as variáveis e uma das maneiras pelas quais isso é feito diz respeito à forma como os valores se apresentam, especialmente em sua capacidade informacional (Morettin &amp; Bussab, 2010). Qualquer variável cujo resultado só possa descreve uma quantidade contável, em que os valores potenciais podem ser enumerados em uma ordem é chamada de discreta e é caracterizada por uma função de massa probabilidade (em inglês, probability mass function). Por sua vez, uma variável cujos valores potenciais não podem ser enumerados em uma ordem inequívoca é chamada de contínua e tem uma função de densidade de probabilidade (em inglês probability density function). Um atalho cognitivo bastante frequente apesar de apenas parcialmente correto pode auxiliar: variáveis discretas costumam ter valores inteiros, tal como número de filhos, caixas de remédios vendidas por uma farmácia e vezes que um paciente buscou auxílio médio; por sua vez, as variáveis continuar reúnem números fracionários, tal como a altura dos filhos, o retorno financeiro em Reais que a venda dos remédios e o tempo gasto em cada em cada consulta média. Quando se tenta fazer uma comparação entre a classificação de escalas de medida desenvolvida por Stevens e a classificação das variáveis em discretas e contínuas, é possível considerar que a escala intervalar e de razão podem também ser entendidas como discretas e continuas. Excepcionalmente e apenas para fins de modelagem estatística, as variáveis classificadas como nominais e ordinais podem ser entendidas também como discreta (Borgatta &amp; Bohrnstedt, 1980; Privitera, 2016, p. 20) 2.2.8 Hierarquia da classificação e a importância desses conceitos hoje em dia Uma vez que as escalas dependem das capacidades matemáticas associadas, uma escala de maior nível pode ser convertida em uma escala hierarquicamente inferior. Isso foi previamente apresentado na escala ordinal com o exemplo de tempo de resposta. Esse processo de transformação costuma ser chamado de “categorização” e pode ser facilmente visto em outros exemplos. Por exemplo, a altura das pessoas (razão, contínua) pode ser classificada em baixas ou altas e a temperatura em Kelvin (razão, contínua) pode tanto ser entendida de maneira intervalar (Celsius, por exemplo), ordinal (muito frio, frio, quente, muito quente) ou (agradável e desagradável). Apesar dessas classificações de escalas/níveis de medida terem importância acadêmica, em situações de análise de dados, quase nunca a diferenciação entre os 4 níveis de medida tem relevância ou utilidade. Além disso, o próprio Stevens, tempos depois, em 1959, reviu algo de sua classificação e reconheceu que as regras de invariância também permitiam uma nova escala, chamada de “log-intervalar” (Stevens, 1959). Essa escala quase nunca presente em livros didáticos. Além disso, como programas estatísticos são frequentemente utilizados para realizar procedimentos de análises de dados, eventualmente eles sequer utilizam as mesmas nomenclaturas ou apenas entendem as variáveis como discretas ou contínuas. Mesmo na academia, autores como D. Howell consideram que esse aspecto da medida tem apenas relevância histórica, sendo irrelevante hoje em dia (David C. Howell, 2011, p. 18). Finalmente, a partir da tentativa de desenvolver ou aperfeiçoar o isomorfismo entre relações empíricas e relações algébricas, em que houvessem regras bem definidas articulando os números às coisas (tal como visto em Campbell), e que tivessem propriedades matemáticas específicas e bem definidas (tal como visto em Stevens) outras classificações foram surgindo. Entre eles, a Teoria representacional da medição (Patrick Suppes) e a Teoria da Medida Aditiva Conjunta (TMAC) (Michell, 1993). 2.2.9 Em qual escala devemos classificar os testes psicológicos Psicólogos e outros cientistas comportamentais utilizam com frequência instrumentos de medida para acessar variáveis como atenção, memória, personalidade e inteligência. De maneira análoga às outras áreas empíricas, esses instrumentos geram resultados numéricos que, por sua vez, são utilizados para as mais diferentes finalidades. Da mesma forma que para maioria dos fenômenos medidos, o nível de medida não é inerente aos dados (Velleman &amp; Wilkinson, 1993). Com isso, o debate sobre qual nível de medida devem ser entendido os números obtidos por instrumentos psicológicos parece estar sempre aberto. Uma primeira resposta veio do próprio Stevens, que assumindo que as operações possíveis em cada escala devem ser invariantes comentou que: A maioria das escalas usadas amplamente e efetivamente por psicólogos são ordinais. De maneira estrita, médias e desvios-padrão não devem ser utilizados nessas escalas, uma vez que para essas estatísticas se deva saber algo mais do que a ordem relativa dos dados. Por outro lado, pode-se evocar uma espécie de confirmação pragmática para esse uso ‘ilegal’ da estatística: em inúmeras situações o seu uso conduziu a resultados frutuosos (Stevens, 1946, p. 679, aspas do autor original). Já no meio acadêmico, é bem possível que ninguém consideraria que os resultados obtidos por um processo de testagem psicológica sejam nominais ou de razão. Entretanto, há bastante divergência em relação quanto ao nível ordinal ou intervalar. Excetuando os que julgam que os resultados estão entre esses dois níveis, há aqueles que julgam que a escala ordinal é a adequada para qualquer instrumento psicológico. Para esses autores, não seria possível sequer somar ou diminuir os valores obtidos em itens de um teste de inteligência ou inventário de atitude. Eventualmente, decisões como essa são bastante rígidas e só mais recentemente, principalmente pelo incremento do poder computacional, essas decisões tiveram contrapartida analítica (Análise Rasch e Teoria de Resposta ao Item, por exemplo). Apesar de rígida, essa consideração tem fundamento, já que pela hierarquia dos níveis de medida, só é possível um processo descendente (razão para intervalar, etc) e não ascendente (intervalar para razão, por exemplo). Isso também pode tanto ser visto em instrumentos do tipo questionários e instrumentos com respostas certas e erradas. Uma vez que a escala intervalar assume equidistância entre os valores, considerar que as distâncias de itens Likert (concordo totalmente a discordo totalmente) ou Tipo-Likert (nada a muito) são iguais é uma justificativa bastante frágil. Já em instrumentos de inteligência, também seria pouco adequado assumir que a diferença de 1 ponto traria a mesma informação isomórfica entre uma pessoa que teve 80 pontos e outra 79 pontos em um teste de inteligência e entre uma pessoa que obteve 130 pontos e outra que obteve 129 pontos neste mesmo teste. Em outro sentido, um grupo maior de acadêmicos consideram os resultados obtidos por um processo de testagem como intervalares e, consequentemente, utilizam técnicas estatísticas mais robustas para os dados. Essa condição quase sempre era justificada de maneira pragmática, vem ganhando maior sustentação hoje em dia, especialmente em estudos de simulação, em que os pesquisadores criam a possibilidade de comparar resultados estatísticos obtidos considerando os dados ou como ordinais ou como intervalares (Wu &amp; Leung, 2017). Dessa forma, uma vez que esse tema ainda reflete uma questão em aberta, respostas definitivas não são possíveis (nem desejáveis), colocando sobre o pesquisador a justificativa analítica e teórica das decisões por ele tomadas. References "],
["o-r-e-o-tidyverse.html", "Cap. 3 O R e o Tidyverse 3.1 Tidyverse 3.2 Verbos do dplyr 3.3 Resumo", " Cap. 3 O R e o Tidyverse Este livro é totalmente feito no R, com utilização do RStudio e diversos pacotes para otimizar as análises estatísticas apresentadas. Muito provavelmente, esta escolha é ainda uma excessão no universo da Psicologia, que utiliza o SPSS e outros programas point and click com frequência. Uma série de razões motivaram a minha escola e, entre elas: o R é uma linguagem de programação desenvolvida especificamente para Estatística. Diferente de uma linguagem mais geral (por exemplo, Python) ou de um programa point and click, que serve como uma ponte entre estatística e a usabilidade (SPSS ou STATA), o R é feito para que a pessoa tenha controle total das ações estatísticas. Apesar disso poder assustar no início, julgo que essa característica do R é essencial, inclusive, para que o usuário planeje adequadamente as análises de interesse, em vez de apenas selecionar parte de um output padronizado, como ocorre com o SPSS. Além disso, como o R tem um nicho em Estatística, ele é absolutamente mais adaptado para o dia-a-dia em estatística do que o Python, que tem vantagem em aplicações variadas. o R e todas as suas otimizações são gratuitas Todo ambiente R é gratuito e isso inclui o Rstudio (que é uma IDE, Integrated Development Environment) e seus pacotes. Pacotes A comunidade R tem um exército de pacotes que foram desenvolvidos para otimizar análises estatísticas e foram verificados publicamente e estão disponíveis no CRAN (The Comprehensive R Archive Network). Todos os capítulos deste livro contam com pacotes e eles permitem realizar ações altamente complexas com poucos comandos. Comunidade de apoio Os usuários do R formam uma rede muito dinâmica e que oferece grande apoio em caso das mais diversas dúvidas. Um grande exemplo é o stackoverflow, que funciona como um grande centro de suporte e auxílio. 3.1 Tidyverse O Tidyverse é um ambiente de pacotes que, além de funcionarem de maneira totalmente integrada, permitem que as linhas de código que fazemos para programar no R se tornem mais intuitivas e mais próximas à forma que temos de pensar, em que primeiro vem o sujeito e depois o verbo. Será possível notar que durante este livro, frequentemente eu vou utilizar uma função de ligação (o pipe, %&gt;%) em vez da estrutura do R-Base, que será usada apenas minoritariamente aqui. Ao instalar o tidyverse install.package(\"tidyvese\"), os pacotes abaixo ficam disponíveis no R. No entanto, nem tudo são flores. Apesar do R e seus pacotes oferecem excelentes ferramentas para análise de dados, algumas condições descritivas são demasiadamente custosas. Por exemplo, enquanto realizar algumas tabelas e gráficos no Excel é tremendamente fácil, as vezes o R exige diversas linhas de código. Nesse sentido, na relação entre dificuldade e complexidade, o R sai na frente em tarefas complexas (como exemplo, estimar os coeficientes de um modelo não-linear), mas talvez perca em tarefas fáceis (por exemplo, gerar uma tabela de contingência). A Figura a seguir apresenta esta relação. Uma outra barreira muito importante que o R traz é que ele é uma linguagem de programação e isso gera uma dificuldade a mais na docência de estatística, especialmente aos alunos de graduação. Tendo em vista que é muito esperado que estes estudantes tenham algum receio a priori em relação à estatística, apresentar o R traria ainda uma outra dificuldade, que é entender e aprender a programar. Em situações como esta, talvez o ideal seja começar motivando o estudante a entender como a estatística é uma ferramenta importante para tomar decisões em relação às pergutas de pesquisa para, só depois e lentamente, apresentar aspectos matemáticos e computacionais. 3.2 Verbos do dplyr O dplyr funciona de maneira muito intuitiva. O padrão original do R considera que as operações são realizadas a partir de uma lógica do tipo verbo(sujeito, complemento) enquanto o ambiente tidyverse opta por sujeito %&gt;% verbo(complemento), tornando-se o ato de programar mais natural e associado à maneira que organizamos as ideias. Os verbos principais do pacote estão listados na tabela a seguir e as sintaxes deixadas no decorrer deste capítulo (e do livro) permitem uma melhor apreensão das funcionalidades. É importante lembrar que, em alguns momentos, em função da praticidade computacional, algumas sintaxes vão contar com o formato base do R. Verbo Ação glimpse Inspeciona os dados count Conta os níveis de uma variável select seleciona uma variável específica filter Filtra os resultados por um nível específico de uma variável group_by Agrupa os resultados por níveis de uma variávei específica summarise Apresenta sumários (com medidas estatísticas) mutate Cria novas variáveis ou altera as existentes arrange Organiza a apresentação dos resultados left_join Junta bases ou colunas pivot_longer Transforma uma base larga em longa pivot_wider Transforma uma base longa em larga É também importante ficar atento às atualizações do dplyr e do sistema tidyverse como um todo. Eventualmente, mudanças podem ocorrer e impossibilitar (ou dificultar) a reprodução de rotinas antigas. O site é o local ideal para acompanhar as atualizações. 3.3 Resumo Este livro irá apresentar todas as rotinas utilizadas em estatística a partir de linhas de código do R. O ambiente de programação tidyverse servirá como base principal para programação. Entre as principais vantagens do R, estão a gratuidade de seu acesso e uso Entre as principais desvantagens do R, estão a necessidade de programação e algumas análises descritivas "],
["estatística-descritiva.html", "Cap. 4 Estatística Descritiva 4.1 Tabelas 4.2 Gráficos 4.3 Medidas de posição e dispersão 4.4 Média 4.5 Mediana 4.6 Moda 4.7 Amplitude 4.8 Amplitude interquartil 4.9 Variância e Desvio-padrão 4.10 Pesquisa 4.11 Execução no R 4.12 Gráficos 4.13 1 variável discreta 4.14 1 variável contínua 4.15 2 variáveis com VI discreta (e VD contínua) 4.16 2 variáveis com VI contínua (e VD contínua) 4.17 Outros gráficos e configurações 4.18 Execução no JASP 4.19 Tabelas 4.20 Gráficos 4.21 1 variável discreta 4.22 1 variável contínua 4.23 2 variáveis com VI discreta (e VD contínua) 4.24 2 variáveis com VI contínua (e VD contínua) 4.25 Outros gráficos e configurações 4.26 Resumo 4.27 Pesquisas adicionais", " Cap. 4 Estatística Descritiva Objetivos do capítulo 1. Introduzir conceitos importantes em estatística descritiva 2. Apresentar tabelas e gráficos 3. Apresentar funções do dplyr e ggplot 4. Apresentar um módulo específico do JASP 5. Sugerir heurísticas ou regras gerais na criação de gráficos Quando pesquisadores e acadêmicos fazem seus estudos, com muita frequência, eles obtêm um grande conjunto de dados, sendo pouco informativo ou até mesmo inviável apresentar detalhadamente todos os resultados. A estatística descritiva oferece uma diversidade de ferramentas que auxiliam a descrever, resumir e apresentar os dados obtidos, de forma que os resultados sejam mais fáceis de serem compreendidos e analisados e, consequentemente, que a pesquisa possa ser melhor compreendida por todos os seus leitores. Frequentemente, a massa completa de dados obtidos em uma pesquisa é resumida por alguns números específicos, que possuem certas propriedades estatísticas, e conseguem sintetizar adequadamente o volume de dados. Por sua vez, esses números são úteis em análises específicas que possam ser necessárias e serão descritos em outra seção deste capítulo. Na apresentação dos dados, é possível utilizar informações textuais, tabelas e gráficos. Cada uma dessa formas traz consigo vantagens e desvantagens. Tabelas e textos permitem agrupar e detalhar os resultados e, com isso, torná-los mais precisos e extensivos. Entretanto, esse detalhamento pode também dificultar um pouco no entendimento geral e abrangente do estudo. Por sua vez, gráficos geram sumários descritivos, em que é possível ter um entendimento rápido dos principais resultados. Eles também podem incorporar elementos adicionais que auxiliem em uma primeira análise inferencial, tal como barras de erro e intervalos de confiança. Além disso, eles também permitem evidenciar as diferenças entre grupos ou as relações entre variáveis a depender da pesquisa feita. No entanto, tendo em vista que os gráficos condensam um grande conjunto de resultados em uma apresentação mais simples, eles também podem dificultar um pouco no entendimento geral das conclusões obtidas pela pesquisa. O diagrama a seguir apresenta tais características: É importante atentar que em todas estas técnicas, mas especialmente nas gráficas, deve-se evitar gerar distorções ao entendimento e interpretação dos resultados obtidos no estudo. Há casos de pessoas e profissionais que chegaram a sofrer sanções jurídicas pela distorção (intencional) de apresentação estatísticas. Neste sentido, há recomendações nacionais e internacionais que visam auxiliar no desenvolvimento de gráficos e tabelas e, com grande frequência, periódicos e editoras também requerem que formatos específicos na apresentação dos resultados sejam seguidos. 4.1 Tabelas As tabelas são recursos estatísticos que permitem a apresentação de sumários informativos de uma pesquisa de maneira reunida e objetiva. É possível utilizá-las com apenas uma ou com múltiplas variáveis, sejam elas categóricas ou contínuas. Todas elas precisam de títulos e, eventualmente, algumas notas podem auxiliar na leitura da tabela. As tabelas apresentam os resultados obtidos em locais específicos, separados por linhas e colunas. Resultados numéricos costumam ser arredondados em uma ou duas casas decimais e as colunas não costumam ter bordas. No entanto, o diagrama padronizado para desenvolvimento de tabelas costuma variar de editora para editora. A tabela abaixo segue as recomendações da APA. 4.2 Gráficos Gráficos são representações visuais utilizadas para exibir dados. Da mesma forma que tabelas, eles podem ser formados por uma ou múltiplas variáveis. Se bem feitos, os gráficos são extremamente úteis e auxiliam o rápido entendimento dos resultados obtidos em uma pesquisa. Como aponta Morettin e Bussab (2010), gráficos possibilitam: buscar padrões e relações; confirmar (ou não) certas expectativas que se tinha sobre os dados; descobrir novos fenômenos; confirmar (ou não) suposições feitas sobre os procedimentos estatísticos usados; e apresentar resultados de modo mais rápido e fácil. É sempre importante que o gráfico tenha um título e uma escala e, quando necessário, notas complementares. A maioria dos gráficos são apresentados em um plano com um eixo horizontal (abcissas) e um vertical (ordenadas). Quando há apenas uma variável para apresentar, o eixo X irá reunir os níveis ou possíveis valores desta variável, enquanto o eixo Y irá apresentar suas contagens, proporções ou densidade. Quando há duas variáveis, o eixo X será utilizado para apresentar os níveis ou possíveis valores da variável independente, enquanto o Y apresentará os valores médios encontrados na variável dependente. Quando há mais de uma variável independente, um agrupador ou cluster deverá ser apresentado. Com frequência, o eixo X recebe a variável independente com mais níveis, enquanto o agrupador recebe as outras. Há diferentes heurísticas que auxiliam na escolha do melhor gráfico a ser desenvolvido para apresentar os resultados de uma pesquisa. De forma geral, quando é possível ter duas ou mais variáveis e a VD é continua, o desenvolvimento do gráfico vem atrelado a duas perguntas: Quantas variáveis serão apresentadas ? Qual o nível de medida da variável (ou variával independente quando há duas ou mais)? Com isso, o diagrama abaixo oferece uma árvore de decisão funcional. Nota: Nessa apresentação, pragmaticamente as variáveis categóricas são tratadas como discretas. A apresentação de gráficos costuma seguir um desenvolvimento hierárquico. Inicialmente, gráficos univariados para variáveis categóricas e contínuas são criados. Em seguida, gráficos apresentando diferenças e relações entre grupos e variáveis são feitos. Na seção Pesquisa, diferentes gráficos serão gerados para ilustrar o processo. 4.3 Medidas de posição e dispersão Uma vez que é pragamaticamente inviável apresentar detalhadamente todo o volume de dados obtidos em uma pesquisa, há um conjunto de números podem ser utilizados para resumir todo o conjunto. Eles costumam ser chamadados de números-síntese, medidas estatísticas ou apenas estatísticas e podem ser agrupados em medidas de posição e medidas de dispersão, que serão descritas a seguir. Medidas de posição: valores que representam a concentração dos dados observados. Podem ser divididas em medidas de tendência central, medidas separatrizes ou de ordenamentos e medidas de posição relativa. As medidas de tendência central (MTC) indicam o valor em torno do qual uma grande proporção de outros valores está centralizada. As MTC mais usadas são a moda, a média e a mediana. As separatrizes são valores que indicam posições em uma distribuição ordenada acumulada dos dados. Frequentemente, a mediana e os quantis são utilizados e este último é formado pelos quartis (divisão dos dados em 4 partes iguais), decis (divisão em 10 partes iguais) e percentis (divisão em 100 partes iguais). As medidas de posição relativa são valores que indicam as posições que cada valor do conjunto de dados em relação a todos os dados. Frequentemente, o Escore Z, o Escore T e o Escore QI são utilizados como medidas de posição de relativa. A verdade é que essa divisão tão detalhada sempre apresenta inconsistências e quase nunca é utilizada na prática. No dia a dia, o termo MTC é utilizado de maneira virtualmente idêntica a medidas de posição. Medidas de dispersão . Também chamadas de medidas de variabilidade ou afastamento. São Valores que indicam o quão dispersa se encontra a distribuição dos valores em relação à alguma medida de tendência central. Entre as medidas de dispersão, estão a amplitude, a amplitude (ou intervalo) interquartil, a variância, o desvio-padrão e o coeficiente de variação. Em Psicologia, o desvio-padrão e a amplitude interquartil (também chamado de intervalo interquartil) são as mais utilizada. O diagrama abaixo apresenta estas informações. É importante notar que esse conjunto de divisões tem pouco sentido prático na maioria das pesquisas e do cotidiano dos pesquisadores. Apenas em raras exceções, como em Psicometria, é que discussões sobre percentis e Escores Z serão feitas. Dessa maneira, apesar dessa apresentação representar um esforço para reunir as principais medidas estatísticas utilizadas, ela não traduz bem a realidade cotidiana da maior parte das pesquisas e, consequetemente, dos pesquisadores. Com muita frequeência, as medidas de posição e as medidas de tendência central são vistas como sinônimos, bem como utiliza-se apenas o termo “medidas de dispersão” para todas as medidas de afastamento. Dessa forma, a organização apresentada no diagrama abaixo talvez possa ser mais útil. As principais medidas serão agora apresentadas de uma maneira simples. Esse formato é proposital, uma vez que a proposta do livro é discutir tais conceitos pela apresentação de pesquisas específicas e previamente publicadas. 4.4 Média A média é a MTC mais comum e mais intuitiva. Seu valor representa o “centro de gravidade” da distribuição, descrevendo a maior concentração dos valores em torno dela. Assim, ela resume o conjunto de dados e pode ser utilizada para substituir os outros valores, o que é especialmente útil quando há casos ausentes. Imagine a seguinte situacão. 10 pacientes foram avaliados por um teste de inteligência e apresentaram os resultados abaixo descritos: set.seed(1) rnorm(11, mean = 100, sd = 15) %&gt;% pander() 90.6, 102.8, 87.47, 123.9, 104.9, 87.69, 107.3, 111.1, 108.6, 95.42 and 122.7 A média indicará o valor central da distribuição em relação à distância entre os outros valores. set.seed(1) mean(rnorm(11, mean = 100, sd = 15)) %&gt;% pander() 103.9 Repare que Caso uma tabela seja apresentada e nela seja calculado a distância de todos os valores em relação à média, os resultados seriam assim: set.seed(1) rnorm(11, mean = 100, sd = 15) %&gt;% data.frame() %&gt;% setNames(., c(&quot;Resultado&quot;)) %&gt;% mutate(media = mean(Resultado)) %&gt;% mutate(distancia = Resultado-media) %&gt;% pander() Resultado media distancia 90.6 103.9 -13.26 102.8 103.9 -1.11 87.47 103.9 -16.4 123.9 103.9 20.06 104.9 103.9 1.078 87.69 103.9 -16.17 107.3 103.9 3.447 111.1 103.9 7.211 108.6 103.9 4.772 95.42 103.9 -8.445 122.7 103.9 18.81 Somando as distâncias, o resultado será 0, indicando que elas se anulam e que a média é o centro da distribuição. set.seed(1) rnorm(11, mean = 100, sd = 15) %&gt;% data.frame() %&gt;% setNames(., c(&quot;Resultado&quot;)) %&gt;% mutate(media = mean(Resultado)) %&gt;% mutate(distancia = Resultado-media) %&gt;% mutate_if(is.numeric, round, 1) %&gt;% mutate(media = as.character(media)) %&gt;% janitor::adorn_totals() %&gt;% pander() Resultado media distancia 90.6 103.9 -13.3 102.8 103.9 -1.1 87.5 103.9 -16.4 123.9 103.9 20.1 104.9 103.9 1.1 87.7 103.9 -16.2 107.3 103.9 3.4 111.1 103.9 7.2 108.6 103.9 4.8 95.4 103.9 -8.4 122.7 103.9 18.8 Total - 3.109e-15 A tabela a seguir descreve algumas características vantajosas e possíveis limitações da média. Vantagem Limitação É intuitiva Sensível Algebricamente tratável Não adequada a dados nominais Estimador não viesado Sensível Nota: Uma medida sensível significa que ela é influenciada por todos os outros valores. Exemplo de aplicações: Praticamente, em todas as pesqusias se utiliza a média para sumarizar os resultados obtidos. Como exemplos em Psicologia, a média de valores de inventários e testes psicológicos, a média do tempo de reação que um participante demora para responder à uma atividade específica e a média de consultas clínicas que em média um profissional realiza. 4.5 Mediana A mediana é uma medida que representa o centro do conjunto de dados quando se considera a quantidade de elementos presentes. Uma vez que ela divide a distribuição em duas partes iguais com a mesma quantidade de elementos, ela pode tanto ser vista como uma medida de tendência central, como uma separatriz (5º decil e percentil 50). Comparada com a média, os resultados obtido pela mediana são mais robustos ou resistentes aos valores atípicos ou anômalos, apesar de menos intuitivos. Para dividir a distribuição em duas partes iguais, a realização da mediana precisa de alguns procedimentos. Repare que abaixo estão os mesmo resultados apresentados na seção da média: set.seed(1) rnorm(11, mean = 100, sd = 15) %&gt;% pander() 90.6, 102.8, 87.47, 123.9, 104.9, 87.69, 107.3, 111.1, 108.6, 95.42 and 122.7 Para o cálculo da mediana, é necessário organizar essa série de valores de maneira ascendente (chamado de rol) e localizar o resultado ao centro. Nesse caso, o valor ao centro é 104.9 . Note que este valor divide os dados em duas partes iguais de elementos abaixo ou acima dele. set.seed(1) rnorm(11, mean = 100, sd = 15) %&gt;% sort(.) %&gt;% pander() 87.47, 87.69, 90.6, 95.42, 102.8, 104.9, 107.3, 108.6, 111.1, 122.7 and 123.9 Caso a quantidade de elementos seja par, a mediana será a média artimética dos dois elementos centrais. A tabela a seguir descreve algumas características vantajosas e possíveis limitações da mediana. Vantagem Limitação Resistente a valor anômalos/Outliers Não representa todos os valores Adequada para dados ordinais, intervalares e de razão Não adequada a dados nominais Adequada para dados ordinais, intervalares e de razão Pouco adequada a tratamentos algébricos futuros Exemplo de aplicações: Situações em que a distribuição é muito assimétrica. Variáveis econômicas como salário e pobreza costumam trabalhar com a mediana dos dados. 4.6 Moda A moda é a realização mais frequente de um conjunto de dados. Salvo algumas excessões, a moda não costuma ser utilizada em análises estatísticas, uma vez que representa mal o conjunto de dados. Exemplo de aplicações: Situações em saúde pública, como a idade mais típica que uma menina tem o primeiro filho, dia e/ou horário modal de Admissão em um hospital. Situações economômicas de determinação de salários mínimos, eventualmente, também pode contar com resultados modais. 4.7 Amplitude A amplitude é uma medida de dispersão que indica a variabilidade dos dados. O procedimento para seu cálculo é a subtração entre o maior e o menor valor de um conjunto de dados. 4.8 Amplitude interquartil A amplitude interquartil também é chamada de intervalo interquartil. Essa medida apresenta a variabilidade dos dados de maneira insensível a valores extremos. Ela é computada pela subtração do primeiro quartil (Q1) pelo terceiro quartil (Q3), ou seja, Q3-Q1. Os quartis são medidas que indicam posições de separação no conjunto ordenado de dados. O primeiro quartil indica o valor onde estão até 25% dos dados, o segundo quartil tem o mesmo valor da mediana e o terceiro quartil indica o valor onde estão até 75% dos dados. Como a amplitude interquartil considera apenas a variabilidade em torno do centro, ela é uma medida considerada mais estável ou robusta quando comparada a outras. 4.9 Variância e Desvio-padrão A variância e o desvio-padrão são duas medidas de dispersão frequentemente utilizadas em estatística, mas que apresentam algumas características diferentes. A variância é uma medida que indica a variabilidade (quadrática) de um conjunto de dados, considerando todos os valores da distribuição. Pela sua estrutura matemática, seu resultado expressa o desvio quadrático médio e, com isso, seu valor não está na mesma unidade dos dados originais. A variância é uma medida fundamental no estudo das famílias de distribuições de probabilidades e análises estatísticas. No entanto, na prática, ela é pouco usada para descrever a variabilidade dos dados e acaba sendo usada apenas de forma transitória para o cálculo do desvio-padrão. O desvio-padrão, por sua vez, é uma medida com melhores características descritivas. Ele indica a variação dos valores em torno da média, e como seus resultados são calculados pela raiz quadrada da variância, o desvio-padrão está na mesma unidade dos dados originais. . Em síntese, enquanto a variância tem maior importância em aspectos matemáticos relacionados às famílias de distribuições de probabilidade, o desvio-padrão tem melhor adequação descritiva de um conjunto de dados. Conceitualmente, as equações a seguir descrevem à variância amostral (à esquerda) e o desvio-padrão amostral (à direita): \\[\\begin{equation} \\begin{split} S^2 = \\sqrt\\frac{\\sum\\limits_{i=1}^N (X -\\mu)^2}{N-1} \\end{split} \\qquad\\qquad\\qquad \\begin{split} S = \\frac{\\sum\\limits_{i=1}^N (X -\\mu)^2}{N-1} \\end{split} \\end{equation}\\] Após estas apresentações teóricas, espera-se que seja possível apresentar a pesquisa a seguir, bem como implementar parte dos conceitos nos dados obtidos. 4.10 Pesquisa Base: Base R - Pesquisa mapfre.RData Neste capítulo, vamos utilizar a pesquisa intitulada “Depression and Anxiety Symptoms in a Representative Sample of Undergraduate Students in Spain, Portugal, and Brazil”. Nessa pesquisa, sou o coautor e o pesquisador responsável para correspondência. O objetivo deste estudo foi desenvolver um mapa epidemiológico de sintomas de ansiedade e depressão em universitários em três países, bem como investigar possíveis relações entre tais condições de saúde e fatores sociodemográficos. Para acessar eventuais transtornos depressivos, o Inventário Beck de Depressão (BDI) foi utilizado e para acessar condições de ansiedade, o Inventário Beck de Ansiedade (BAI) foi utilizado. Um diferencial importante do trabalho foi a seleção amostral. Partiu-se de uma amostra estratificada (probabilística) dos estudantes de três universidades, PUC-Rio (Brasil), Universidade de Extremadura (Espanha) e Universidade de Coimbra (Portugal). Isso permitiu ter maior validade externa dos resultados. 4.11 Execução no R Inicialmente, é necessário carregar a base de dados previamente descrita para o ambiente R. Este procedimento será necessário para todos os capítulos do livro. Frequentemente, Uma primeira tabela informativa começa por variáveis categóricas, que deve apresentar suas contagens e proporções. Nesta pesquisa de agora, tanto a variável countru como sex são categóricas e serão utilizadas. como três países fizeram parte da pesquisa, os dados serão agrupados por eles. O desenvolvimento desta tabela pode ser feito com pacote janitor, tal como demonstrado a seguir. Dataset %&gt;% tabyl(country) %&gt;% adorn_totals() %&gt;% pander() country n percent SPAIN 1216 0.6214 PORTUGAL 426 0.2177 BRAZIL 315 0.161 Total 1957 1 A adição de um um outro agrupador relacionado ao sexo é também importante. Note que existem casos ausentes nesta variável. Isso ocorre com bastante frequência e há diferentes estratégias para lidar com isso, que serão discutidas em momento oportuno. Para que valores ausentes não sejam apresentados, a função filter será implementada. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(sex, country) %&gt;% adorn_totals() %&gt;% pander() sex SPAIN PORTUGAL BRAZIL M 384 203 149 F 825 223 166 Total 1209 426 315 Para apresentar a quantidade de participantes totais, bem como a quantidade e a porcentagem de homens e mulheres por país, a codificação torna-se um pouco mais densa. A tabela a seguir reproduz parcialmente a tabela 1 do artigo publicado. Dataset %&gt;% filter(!is.na(sex)) %&gt;% tabyl(country, sex) %&gt;% adorn_totals(c(&quot;row&quot;, &quot;col&quot;)) %&gt;% adorn_percentages(&quot;row&quot;) %&gt;% adorn_pct_formatting(rounding = &quot;half up&quot;, digits = 0) %&gt;% adorn_ns() %&gt;% pander() country M F Total SPAIN 32% (384) 68% (825) 100% (1209) PORTUGAL 48% (203) 52% (223) 100% (426) BRAZIL 47% (149) 53% (166) 100% (315) Total 38% (736) 62% (1214) 100% (1950) Enquanto as tabelas com variáveis categóricas apresentam contagens e suas respectivas porcentagens, tabelas para variáveis contínuas costumam utilizar medidas de posição e dispersão. A média e a mediana são os sumários mais utilizados para indicar a posição ou a concentração dos dados. Por sua vez, o desvio-padrão e a amplitude ou intervalo interquartil são utilizados para indicar o afastamento dos dados dessas medidas de posição. O R oferece muitos pacotes especializados em tabelas descritivas, cada qual com características positivas e limitadoras. De maneira análoga à construção da primeira tabela deste capítuo, os valores do BDI e do BAI serão apresentados em função do país do participante. Dataset %&gt;% group_by(country) %&gt;% summarise_at(vars(bdi_sum, bai_sum), lst(n=~n(),media=mean, DP=sd), na.rm=T) %&gt;% mutate_if(is.numeric, round,2) %&gt;% t() %&gt;% pander(., split.table = Inf) country SPAIN PORTUGAL BRAZIL bdi_sum_n 1216 426 315 bai_sum_n 1216 426 315 bdi_sum_media 8.86 9.05 10.89 bai_sum_media 8.55 7.92 9.01 bdi_sum_DP 7.54 7.73 8.29 bai_sum_DP 8.06 8.04 8.40 É também possível reunir tais resultados a partir do sexo do participante. Dataset %&gt;% filter(!is.na(sex)) %&gt;% group_by(sex) %&gt;% summarise_at(vars(bdi_sum, bai_sum), lst(n=~n(),media=mean, DP=sd), na.rm=T) %&gt;% mutate_if(is.numeric, round,2) %&gt;% t() %&gt;% pander(., split.table = Inf) sex M F bdi_sum_n 736 1214 bai_sum_n 736 1214 bdi_sum_media 8.68 9.59 bai_sum_media 6.81 9.47 bdi_sum_DP 7.74 7.73 bai_sum_DP 7.14 8.45 A apresentação agrupando pelo país e sexo do participante encontra-se abaixo: Dataset %&gt;% filter(!is.na(sex)) %&gt;% group_by(country,sex) %&gt;% summarise_at(vars(bdi_sum, bai_sum), lst(n=~n(),media=mean, DP=sd), na.rm=T) %&gt;% mutate_if(is.numeric, round,2) %&gt;% t() %&gt;% pander(., split.table = Inf) ## `mutate_if()` ignored the following grouping variables: ## Column `country` country SPAIN SPAIN PORTUGAL PORTUGAL BRAZIL BRAZIL sex M F M F M F bdi_sum_n 384 825 203 223 149 166 bai_sum_n 384 825 203 223 149 166 bdi_sum_media 8.40 9.11 8.60 9.46 9.50 12.16 bai_sum_media 6.58 9.42 6.16 9.50 8.29 9.66 bdi_sum_DP 7.54 7.54 8.05 7.42 7.81 8.53 bai_sum_DP 6.68 8.40 7.19 8.45 8.02 8.71 4.12 Gráficos Tal como previamente exposto, os gráficos são excelentes recursos visuais para apresentação dos resultados obtidos em uma pesquisa. No R, a principal máquina gráfica é o ggplot. Para executar um gráfico, pelo menos 3 argumentos são necessários: O banco dados (data = ), O aspecto estético, que permite diferentes complementos aes(x = , y = , fill = , color = ), O aspecto geométrico, que varia em função do gráfico a ser apresentado geom_ É também possível adicionar outros argumentos, como: Transformações estatísticas stat_summary Facetas para dividir a visualização facet_ Sistema de coordenadas coord_ Temas específicos theme_ É importante notar que apesar dos argumentos utilizados na sintaxe serem similares aos utilizados em toda família tidyverse, a ligação %&gt;% é substituída pelo +. 4.13 1 variável discreta Quando há apenas uma variável discreta (incluindo aqui as categóricas), os gráficos são criados para apresentar as contagens e/ou suas proporções. Nesse caso, é recomendado utilização de um gráfico de barras, colunas ou setor. O gráfico de barras abaixo apresenta a contagem absoluta dos participantes pesquisados em cada país. ggplot(Dataset, aes(x = country)) + geom_bar() + labs(x = &quot;País&quot;, title = &quot;Número de participantes nos países investigados&quot;) Esse gráfico consegue auxiliar em um primeiro entendimento dos dados. No entanto, a simples contagem de valores pode gerar um entendimento diferente caso a pesquisa tenha muitos ou poucos sujeitos. Dessa forma, é apresentar as proporções em que cada valor ocorre costuma ser indicado. Por definição, quando se trabalha com proporções, o valor máximo da soma das proporções é 100. A mudança da contagem para proporções pode ser feita por um recurso do pacote scales. Além disso, a adição dos valores textuais às colunas tende e auxiliar a visualização. ggplot(Dataset, aes(x = country, y = ..prop.., group = 1)) + geom_bar(stat = &quot;count&quot;) + geom_text(aes(label=scales::percent(round(..prop..,2)), y=..prop..), stat= &quot;count&quot;, color = &quot;white&quot;, size = 3, position = position_stack(vjust = 0.5)) + scale_y_continuous(labels = scales::percent_format()) + labs(x = &quot;País&quot;, title = &quot;Proporção de participantes em cada país investigado&quot;) O gráfico de setor (as vezes chamado de polar, pizza ou torta) também pode ser utilizado. O aspecto principal desse gráfico é apresentar o tamanho dos segmentos de maneira proporcional às frequências. Dataset %&gt;% count(country) %&gt;% mutate(pct = n/sum(n)) %&gt;% ggplot(., aes(x=&quot;&quot;, y= pct, fill=country)) + geom_col() + geom_text(aes(label = scales::percent(round(pct,3))), position = position_stack(vjust = 0.5))+ coord_polar(theta = &quot;y&quot;) + labs(title = &quot;Proporção de participantes em cada país&quot;) 4.14 1 variável contínua Quando uma única variável deve ser apresentada e ela é continua, os melhor gráficos são o histograma, densidade (kernel) e o boxplot. Abaixo um histograma da idade dos participantes: ggplot(Dataset, aes(x = age)) + geom_histogram(bins = 30, color = &quot;black&quot;, fill = &quot;lightgrey&quot;) + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_bin). Abaixo um gráfico de densidade da idade: ggplot(Dataset, aes(x = age)) + geom_density(fill = &quot;lightgray&quot;) + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_density). Todas as distribuições de variáveis possuem uma localização, uma dispersão e um formato. De uma maneira mais direta, tanto o histograma como o gráfico de densidade conseguem apresentar bem o formato da distribuição. Nesse caso, trata-se de uma assimetria positiva ou à direita. Esse tipo de assimetria é reconhecido pela cauda arrastada à direita. Por sua vez, abaixo o boxplot dessa mesma variável pode ser criado: ggplot(Dataset, aes(y = age, x = &quot;&quot;)) + geom_boxplot() + labs(title = &quot;Distribuição da idade dos participantes&quot;) ## Warning: Removed 28 rows containing non-finite values (stat_boxplot). O boxplot apresenta vantagens em comparação com os outros gráficos apresentados até agora. Além de apresentar o formato da distribuição, ele também (1) apresenta no espaço da caixa a concetração em que 50% dos dados estão, (2) a mediana dos resultados, na linha interna e mais espessa da caixa, (3) os valores mínimos e máximos e (4) os eventuais outliers ou pontos anômalos. Neste gráfico, a parte inferior da caixa é formada pelo valor do primeiro quartil (Q1), a linha mais espessa interna apresenta o segundo quartil (Q2) ou a mediana e a parte superior da caixa apresenta o valor do terceiro quartil (Q3). Os bigodes são frequentemente construídos com base em Q1 - 1.5*IQR e Q3 + 1.5*IQR e valores acima ou abaixo dele são entendidos como anômalos ou outliers. Por definição, os outliers são sempre poucos, mesmo que isso possa ser um pouco contraintuitivo nesta apresentação de agora. O gráfico abaixo apresenta parte dos valores descritos. ggplot(Dataset, aes(y = age, x = &quot;&quot;)) + geom_boxplot() + stat_summary( aes(label=sprintf(&quot;%1.1f&quot;, ..y..)), geom=&quot;text&quot;, fun = function(y) boxplot.stats(y)$stats, position=position_nudge(x=0.5), size=3.5) ## Warning: Removed 28 rows containing non-finite values (stat_boxplot). ## Warning: Removed 28 rows containing non-finite values (stat_summary). Apesar de ser um pouco difícil de se visualizar ao início, a informação apresentada em um boxplot e no histograma ou gráfico densidade são virtualmente as mesmas, tal como demonstrado a seguir. gridExtra::grid.arrange( #Grafico 1 ggplot(Dataset, aes(x = age)) + geom_density(fill = &quot;lightgray&quot;) + labs(x=&quot;&quot;, y=&quot;&quot;), #Grafico 2 ggplot(Dataset, aes(y = age, x = &quot;&quot;)) + geom_boxplot() + labs(x = &quot;&quot;) + coord_flip(), top = &quot;Distribuição da idade dos participantes&quot; #título ) ## Warning: Removed 28 rows containing non-finite values (stat_density). ## Warning: Removed 28 rows containing non-finite values (stat_boxplot). 4.15 2 variáveis com VI discreta (e VD contínua) Gráficos de barras ou colunas e boxplots são adequados para apresentar essa relação. Basicamente, esses gráficos permitem verificar a diferença entre os grupos. Como exemplo, o gráfico de colunas abaixo mostra os resultados médios do Inventário Beck de Ansiedade nos 3 países investigados. ggplot(Dataset, aes(x = country, y = bai_sum)) + geom_bar(stat = &quot;summary&quot;, fun = mean) ## Warning: Removed 5 rows containing non-finite values (stat_summary). Tal como exposto no início do capítulo, é possível adicionar outros elementos ao gráfico para que uma primeira apreensão inferencial seja possível. Nesse sentido, o gráfico abaixo apresenta também as barras de erro. ggplot(Dataset, aes(x = country, y = bai_sum)) + geom_bar(stat = &quot;summary&quot;, fun = mean) + stat_summary(geom = &quot;errorbar&quot;,fun.data = mean_se, width = .5) ## Warning: Removed 5 rows containing non-finite values (stat_summary). ## Warning: Removed 5 rows containing non-finite values (stat_summary). O boxplot a seguir também é um gráfico indicado. É importante notar que esse gráfico, a priori, não traz informações sobre a média, mas sim sobre a distribuição dos resultados. No entanto, como esse gráfico é bastante compreensivo, uma primeira noção inferencial já pode também ser feita. ggplot(Dataset, aes(x = country, y = bai_sum)) + geom_boxplot() ## Warning: Removed 5 rows containing non-finite values (stat_boxplot). 4.16 2 variáveis com VI contínua (e VD contínua) Quando tanto a VI como a VD são contínuas, o gráfico de pontos e de dispersão são indicados. Eles são virtualmente identicos e ajudam a verificar a associação entre as variáveis. No ggplot, o argumento geom_point (à esquerda) e geom_jitter (à direita) são possíveis. gridExtra::grid.arrange( #Grafico 1 ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_point(), #Grafico 2 ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_jitter(), nrow=1 ) ## Warning: Removed 33 rows containing missing values (geom_point). ## Warning: Removed 33 rows containing missing values (geom_point). De maneira análoga aos elementos extras que podem ser apresentados em gráficos com VIs discretas, a reta de regressão amostral (FRA) costuma ser adicionadas em gráficos em que a VI é contínua para oferecer uma primeira apreensão inferencial. No capítulo sobre modelos de regressão, esse conceito será novamente revisitado. A seguir, segue um exemplo. ggplot(Dataset, aes(x = age, y = bai_sum)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 33 rows containing non-finite values (stat_smooth). ## Warning: Removed 33 rows containing missing values (geom_point). 4.17 Outros gráficos e configurações Os gráficos apresentados são quase sempre os principais para apresentar os resultados de uma pesquisa. Entrentanto, é possível construir gráficos com uma maior complexidade, que reunam diversas variáveis ao mesmo tempo. Evidentemente, a realização destes gráficos só tem sentido quando eles são relacionados ao problema de pesquisa estudado e não sobrecarreguem ou distorçam a visualização e entendimento dos resultados. Frequentemente, essas informações adicionais são feitas pela inclusão de clusters ou agrupamentos. Isso é tanto possível em gráficos cuja VI seja discreta quanto contínua. No exemplo abaixo, o gráfico dos resultados do Inventário Beck de Ansiedade entre os 3 países investigados (VI discreta) agora está agrupado pelo sexo do participante. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = country, y = bai_sum, fill = sex)) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;) + stat_summary(geom=&quot;errorbar&quot;, fun.data = mean_se, position = position_dodge(0.95), width = .5) ## Warning: Removed 5 rows containing non-finite values (stat_summary). ## No summary function supplied, defaulting to `mean_se()` ## Warning: Removed 5 rows containing non-finite values (stat_summary). Repare que este gráfico traz uma informação importante sobre os resultados de homens e mulheres nos três países. Além disso, as barras de erro ajudam em um primeiro entendimento de possíveis diferenças significativas. Esse conceito irá ser revisitado em capítulos subsequentes. Já no exemplo abaixo, a relação entre idade e pontuação no Inventário Beck de Ansiedade está agora agrupada pelo sexo do participante. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 29 rows containing non-finite values (stat_smooth). ## Warning: Removed 29 rows containing missing values (geom_point). Neste gráfico de agora, é possível perceber que os a relação entre a idade e os resultados do Inventário Beck de Ansiedade é muito pequena tanto para homens como para mulheres. Especialmente no capítulo de correlação, esse assunto será revisitado e parte dos termos utilizados aqui será alterado. Por sua vez, situações em que há uma grande quantidade de variáveis apresentadas tendem a tornar os resultados difíceis de serem entendidos. O gráfico abaixo tenta traduzir essa condição, criando uma visualização de difícil entendimento justamente pelo excesso de variáveis presentes. Dataset %&gt;% filter(!is.na(sex)) %&gt;% ggplot(., aes(x = age, y = bai_sum, color = sex, shape = country)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 29 rows containing non-finite values (stat_smooth). ## Warning: Removed 29 rows containing missing values (geom_point). Espera-se que seja possível constatar que este gráfico é totalmente inadequado, já que é carregado por informações, permite um baixo entendimento dos resultados da pesquisa e, eventualmente, pode gerar conclusões incorretas ou viesadas. 4.18 Execução no JASP Da mesma forma que feito no R, será necessário carregar a {base}(https://osf.io/e639b/) para o JASP. Durante todos os capítulos, esse procedimento de importação será requisitado. 4.19 Tabelas Após ter a base disposta no JASP, para gerar tabelas e gráficos, será necessário acessar a opção Descriptives. O JASP tratará todas as variáveis com um símbolo de diagrama de venn ou barras como categórias e todas as variáveis com símbolo de régua como contínuas. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, quando há duas ou mais variáveis para serem analisadas, a lista Variables irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção Split. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Isto posto, vamos reproduzir parcialmente as mesmas análises feitas no ambiente R. Inicialmente, uma tabela descrevendo os participantes em cada um dos país é importante para apresentar ao leitor algumas das principais características da amostra. Para fazer isso, será necessário levar a variável country para a seção Variables e clicar em Frequency tables (nominal and ordinal). Por padrão o JASP irá apresentar as contagens (frequências absolutas) e as proporções. A parte mais à esquerda da tabela descreverá os dados considerando todos os valores presentes na base. A parte mais à direita irá apresentar apenas os dados válidos, que não consideram casos ausentes. É importante antentar que o JASP não exclui estes casos, mas apenas não os mostra. Para verificar a frequência e a proporção de homens e mulheres na amostra, será necessário colocar também a variável sex na opção Variables. Não é preciso retirar a variável country antes de fazer isso. O JASP irá apresentar ambas as tabelas de maneira empilhada. Para fazer uma tabela agrupando tanto country, como sex, é necessário arrastar a variável que será apresentada nas linhas para o espaço Split. Em uma tabela em que se descreve a contagem e porcentagem de homens e mulheres em cada um dos três países de maneira independente, é necessário preencher o Split com a variável country. O JASP aceita que se arraste a variável de um local para o outro e, ao fazer isso, todas as contas serão automaticamente atualizadas. É possível perceber que as variáveis categóricas são descritas por suas frequências e proporções. Por sua vez, variáveis contínuas costumam ser resumidas por medidas de posição e dispersão, tal como a média e o desvio-padrão. Como exemplo, para calcular tais medidas estatísticas dos valores do BDI e do BAI em função do país do participante, é necessário deixar a variável country em Split e levar as variáveis bdi_sum e bai_sum para Variables. Dessa vez, não é necessário ativar a opção Frequency tables (nominal and ordinal). O símbolo de régua ao lado das variáveis bdi_sum e bai_sum indicadom de que elas são contínuas. O símbolo de diagrama de Venn ao lado de country, por sua vez, indica que ela é categórica. Para fazer essas análises considerando sex como agrupador, será necessário substituir country por sex no espaço de Split. Nesta versão do JASP, não é possível colocar duas variáveis como agrupadoras. Dessa maneira, a reprodução das tabelas feitas anteriormente no ambiente R é apenas parcial. 4.20 Gráficos O JASP é um exelente programa para gerar gráficos. Tal como previamente apresentado, a criação de um gráfico apropriado dependerá tanto da quantidade de variáveis que devem ser apresentadas, como do nível de medida da VI, especialmente em análises bi ou multivariadas. O JASP pode fazer gráficos tanto seção Descriptives como em após análise de dados específicas. Na seção Descriptives, será necessário primeiro arrastar as variáveis de interesse para seus respectivos lugares e, em seguida, clicar na opção Plot. 4.21 1 variável discreta Para este tipo de variável, gráfico de barras, colunas e setor são indicados. Para realizar um gráfico de barras, é necessário colocar a variável de interesse em Variables e, dentro de Plots, clicar em Distribuiton plots. O JASP organiza as barras de ordem crescente. Para realizar um gráfico de setor, basta selecionar a opção Pie Charts. A visualização ocorrerá automaticamente. Uma vantagem deste gráfico é a apresentação proporção do elementos gráficos, em vez de contagens. Infelizmente, nesta versão do JASP, não é possível adicionar um rótulo com a porcentagem de cada cateogoria. O JASP permite customizar as cores de alguns gráficos. Para fazer isso, basta clicar em Color Palette e escolher entre as opções disponíveis. Existem algumas possibilidade e recomendo optar por aquelas que permitem que pessoas com limitações visuais possam também se beneficiar. Entretanto, apenas como demonstração, o tema ggplot2 é apresentado abaixo. 4.22 1 variável contínua Histogramas, gráficos de densidade e boxplots costumam ser indicados para variáveis contínuas. Para o JASP fazer tais gráficos, é necessário que o espaço Variables seja preenchido por alguma variável que tenha o símbolo da régua ao lado. A variável age é um bom exemplo. Ao colocá-la neste local e marcar a opção Distribution plots, um histograma será automaticamente apresentado. É possível adicionar a densidade de maneira sobreposta ao histograma clicando em Display density. Por sua vez, o boxplot pode ser criado ao clicar na opção Boxplots e, em seguida, Boxplot element. Customizar o boxplot é possível, bem como adicionar outros gráficos que vem sendo mais utilizados recentemente, como o gráfico de violino. Isso não será demonstrado aqui, mas para fazer isso, basta ativar as opções desejadas na seção Customizable plots. Tal como discutido anteriormente,o boxplot apresenta vantagens em comparação com os outros gráficos apresentados até agora. Além de apresentar o formato da distribuição, ele também (1) apresenta no espaço da caixa a concetração em que 50% dos dados estão, (2) a mediana dos resultados, na linha interna e mais espessa da caixa, (3) os valores mínimos e máximos e (4) os eventuais outliers ou pontos anômalos. Neste gráfico, a parte inferior da caixa é formada pelo valor do primeiro quartil (Q1), a linha mais espessa interna apresenta o segundo quartil (Q2) ou a mediana e a parte superior da caixa apresenta o valor do terceiro quartil (Q3). Os bigodes são frequentemente construídos com base em Q1 - 1.5*IQR e Q3 + 1.5*IQR e valores acima ou abaixo dele são entendidos como anômalos ou outliers. Por definição, os outliers são sempre poucos, mesmo que isso possa ser um pouco contraintuitivo nesta apresentação de agora. 4.23 2 variáveis com VI discreta (e VD contínua) Para situações em que há duas variáveis, a VI é tratada como discreta e a VD é contínua, gráficos de barras, colunas ou boxplots são indicados. Nesta versão do JASP, apenas o boxplot pode ser feito. Para verificar, por exemplo, a distribuição dos resultados do bai_sum em função do país, é necessário levar às variáveis a seus respectivos locais e, em seguida, o JASP permite realizar o boxplot. 4.24 2 variáveis com VI contínua (e VD contínua) Quando há duas variáveis contínuas, tanto o gráfico de pontos como de dispersão são possíveis. Para fazer isso, é necessário incluir ambas as variáveis de interesse em Variables. Por exemplo, age e bai_sum. É tanto possível marcar a opção Scatter Plots, como a opção Correlation Plots. A escolha de cada opção é relacionada com os elementos que devem (ou não) serem incluídos neste gráfico. Na opção Scatter Plot, o gráfico irá exibir os pontos dos respectivos pares ordenados das variáveis x e y, suas densidade e também adicionar uma reta de regressão. Este último conceito será revisitado no capítulo de regressão. Um aspecto visualmente importante é a eleição de qual variável irá em x. Com bastante frequência, deve-se inserir a VI (mesmo que teórica) em x, enquanto a VD em y. Isso é feito alterando a ordem das variáveis em Variables. 4.25 Outros gráficos e configurações O JASP é bastante versátil na realização de gráficos e permite que mais variáveis sejam inseridas. Há também um módulo (Module) chamado Visual Modeling, que permite uma grande customização de gráficos. Para acessá-lo, é necessário clicar na cruz azul, tal como destacado abaixo no quadrado roxo. Na lista de opções, é necessário ativar Visual Modeling. Ao fazer isso, o icone será ativado na barra de ferramentas. Com isso feito, dentro de Visual Modeling, a opção Flexplot adiciona uma melhora substancial aos gráficos que o JASP executa. Agora é possível, por exemplo, fazer um gráfico incluindo um cluster ou agrupamento, em que os resultados do Inventário Beck de Ansiedade são apresentados tanto em função dos países investigados, como do sexo do participante. Uma série de outras opções e combinações podem ser feitas ao clicar em Options e Plot Labels. Elas não serão apresentadas nesta seção. 4.26 Resumo Este capítulo apresentou os aspectos tabulares e gráficos corriqueiramente encontrados em pesquisas de Psicologia e áreas congêneres. Entre os pontos principais, estão os seguintes: Medidas de posição e dispersão são fundamentais na apresentação dos resultados de uma pesquisa A média e o desvio-padrão são, respectivamente, as medidas de posição e dispersão mais utilizadas Tabelas e gráficos visam informar o leitor, sem criar viés ou distorção dos resultados As tabelas são muito úteis para uma apresentação mais detalhada dos resultados Gráficos condensam um grande volume de dados de uma forma mais facilmente interpretável A heurística típica em gráficos solicita responder a quantidade e a natureza das variáveis a serem apresenadas 4.27 Pesquisas adicionais References "],
["qui-quadrado.html", "Cap. 5 Qui quadrado 5.1 Pesquisa 5.2 Execução no R 5.3 Tamanho do efeito 5.4 Execução no JASP 5.5 Escrita dos resultados 5.6 Resumo", " Cap. 5 Qui quadrado Objetivos do capítulo 1. Apresentar o teste Qui-quadrado 2. Diferenciar o qui-quadrado de aderência, homogeneidade e independência 3. Realizar gráficos relacionados à distribuição de porcentagens 4. Apresentar e interpretar métricas de tamanho do efeito 5. Dar exemplos relacionados à escrita dos resultados O Teste Qui-quadrado é um teste não-paramétricos utilizado em três situações específicas: (1) verificar as distribuições de probabilidades de cada categoria de uma variável em relação a um valor teórico esperado (aderência), (2) verificar se as distribuições das categorias são as mesmas para diferentes subpopulações (homogeneidade) e (3) verificar se duas variáveis categóricas são independentes (independência). Apesar da diferenças em relação às perguntas analíticas, o sistema matemático é o mesmo: \\[\\chi^2=\\sum_{k=1}^{n} \\frac{(O_k - E_k)^2}{E_k}\\] onde: K se refere a quantidade de classes O é o valor observado de uma determinada classe E é o valor esperado desta classe Pela fórmula, é possível deduzir que quanto maior for a discrepância entre as frequências observadas empiricamente (O) e as frequências esperadas (E), maior será a estatística de teste e, consequentemente, menor será o valor de P. Se assume os seguintes pressupostos funcionais à execução de um Qui-quadrado: (i) Os dados são aleatórios e representativos da população (ii) as variáveis analisadas são categóricas (e.g., sexo, nível de escolaridade, grau de uma doença) (iii) Todas as frequências esperadas são maiores ou iguais a 1 (iv) No máximo, apenas 20% das frequências esperadas são inferiores a 5. A tabela abaixo descreve as condições de análise, com exemplos ilustrativos: Versão do teste Variáveis Exemplo Aderência 1 categórica Verificar se a proporção de caras e coroas é de 50% cada Homogeneidade 2 categóricas Verificar se a proporção de homens e mulheres que gostam de uma marca de celular é similar Independência 2 categóricas Verificar se o sexo e a escolha do curso de graduação são independentes Algumas notas: O Qui-quadrado de aderência também é chamado de “qualidade do ajuste” ou “bondade”. Estas são traduções tipicamente feitas para goodnes of fit. Como todas as análises são realizadas de uma maneira virtualmente idêntica, essas distinções são mais teóricas do que práticas. O Qui-quadrado de aderência tem uma proposta parecida com a ANOVA de uma via. uma curiosidade que remonta a história e explica parte da desavença que Pearson tinha com Fisher. O qui-quadrado foi originalmente desenvolvido em 1900 e 1904 por Karl Pearson (Pearson, 1900). Ronald Fisher detectou um erro no cálculo dos graus de liberdade e rapidamente divulgou isso, para descontentamento de Pearson (BAIRD, 1983). 5.1 Pesquisa Base: Base R TDAH Arruda.Rdata Neste capítulo, vamos utilizar a pesquisa intitulada “Parent-reported diagnosis of Attention Deficit Hyperactivity Disorder and psychostimulant use among children and adolescents: a population-based nationwide study”, que está em avaliação pela revista “Social Psychiatry and Psychiatric Epidemiology (SPPE)”. Neste trabalho, tivemos o objetivo de verificar aspectos epidemiológicos do Transtorno do Déficit de Atenção com Hiperatividade (TDAH) em uma amostra representativa de crianças e adolescentes brasileiros, bem como explorar eventuais associações entre características sociodemográficas, especialmente os sexo do participante, e possíveis fatores e risco e TDAH. Neste momento, vamos seguir apenas com o qui-quadrado de independência, que foi o utilizado neste artigo. Como exposto no decorrer de outros capítulos, o teste de hipóteses começa pela formulação conceitual das hipóteses. Apesar de ser possível estipular \\(H_0\\) e \\(H_a\\) a partir de equações específicas,a apresentação será textual/substantiva. \\[H_0: Não\\ há\\ associação\\ entre\\ sexo\\ e\\ TDAH \\\\ H_a: Há\\ associação\\ entre\\ sexo\\ e\\ TDAH \\\\ \\alpha = 0.05\\] Uma característica colateral a esta apresentação textual do teste de hipóteses do Qui-quadrado é evitar confusões que ocorrem em relação ao conceito do teste e sua formulação matemática. Com muita frequência, dividimos os testes de hipóteses naqueles que verificam “associação” e naqueles que verificam “diferenças”. Conceitualmente, o Qui-quadrado investiga associação entre variáveis. No entanto, sua formulação matemática é feita pela diferença entre um valor observado e um valor esperado (tal como ilustrado na equação ao início do capítulo). Assim, acredito que a formulação apenas textual evita criar confusões e ainda tornar o conteúdo mais palatável. 5.2 Execução no R O gráfico de barras é sempre um bom início para visualizar os dados. Repare que a barra azul (que representa a porcentagem de TDAH) parece se comportar de maneira diferente nos grupos. ggplot(ds_selected, aes(x= sex_male, fill = adhd_parent)) + geom_bar(position = &quot;fill&quot;) + coord_flip() + labs(x = &quot;sexo&quot;, y = &quot;Proporção&quot;, fill = &quot;TDAH&quot;) Em seguida, a tabela de contingência traz informações sobre o relacionamento das variáveis. Apesar do qui-quadrado não eleger uma VI e uma VD, Com bastante frequência utilizamos as linhas para apresentar a variável de maior interesse (neste caso, sexo) e as colunas para indicar o critério ou o eventual desfecho (neste caso, ter ou não TDAH). A porcentagem nas linhas e o valor esperado (em caso de independência entre as variáveis) auxiliam bastante na descrição dos resultados. descr::CrossTable(ds_selected$sex_male,ds_selected$adhd_parent, expected = T, prop.c = F, prop.chisq = F, prop.t = F) %&gt;% pander::pander() ds_selected$sex_male ds_selected$adhd_parent no yes Total female N Expected N Row(%) 3379 3309.1451 94.8624% 183 252.8549 5.1376% 3562 50.0703% male N Expected N Row(%) 3230 3299.8549 90.9347% 322 252.1451 9.0653% 3552 49.9297% Total 6609 505 7114 Os pressupostos relacionados à inexistência de células com valores esperados iguais a 0 e de no máximo 20% dos valores esperados serem inferiores a 5 podem ser investigados na tabela exposta anteriormente e foram atendidos. O cálculo do qui-quadrado apresentado abaixo deixa claro que que é possível rejeitar a hipótese nula, uma vez que o valor de P é menor do que o nível de significância previamente estipulado (0.05). descr::CrossTable(ds_selected$sex_male,ds_selected$adhd_parent,chisq = T)$CST %&gt;% pander::pander() Pearson’s Chi-squared test: tab Test statistic df P value 41.6 1 1.117e-10 * * * Quando os pressupostos são violados, há sugestão de colapsar categorias, fazer correções nos resultados ou contar com outros testes, tal como o Fisher’s Exact Test. 5.3 Tamanho do efeito Como apresentado no decorrer dos outros capítulos, os valores de P quase nunca são informativos sobre a relevância dos resultados. O tamanho do efeito mais utilizado no ambiente das análises de Qui quadrado é o V de Cramer. Esta estatística gera valores 0-1 e é dada da seguinte maneira: \\[V=\\sqrt\\frac{\\chi^2}{n*df^`}\\] Em que: \\(\\chi^2\\) = valor do Qui quadrado obtido n = tamanho da amostra \\(df^`\\) menor valor entre (Linhas - 1) ou (Colunas - 1) da tabela de contingências A função CramerVdo pacote rcompanion gera esses resultados. rcompanion::cramerV(ds_selected$sex_male,ds_selected$adhd_parent) ## Cramer V ## 0.07647 A interpretação é baseada nos graus de liberdade e é feita da seguinte maneira: Graus de liberdade Pequeno Médio 1 0.1 0.3 2 0.07 0.21 3 0.06 0.17 5.4 Execução no JASP Da mesma forma que foi feita no R, a apresentação de gráficos auxiliam o pesquisador a verificar padrões diferentes nos dados. A seção Descriptives é a mais relacionada a isso e será utilizada: Em seguida, é necessário inserir ambas as variáveis e marcar a opção Frequency tables, para indicar o nível de medida que está sendo trabalhado. O gráfico de barras pode ser acessado clicando na opção Plots e, em seguida, indicando Basic plots. Esse resultado é um recurso a mais para sondar os dados. Para execução do Qui-quadrado (de associação), a tabela de contingência deve ser feita. Isso é acessado clicando em Frequencies e, em seguida, Contigency tables. Nesta seção, será necessário indicar a variável que irá nas linhas e nas colunas. Apesar do qui-quadrado não trabalhar com os conceitos de VI e VD, quase sempre se utiliza as linhas para inserir a variável que é, teoricamente, a VI, enquanto a VD teórica é inserida na parte colunas. Ao inserir a variável sexo para as linhas e a variável diagnóstico para as colunas, a tabela de contigência será novamente feita e o qui-quadrado será automaticamente calculado. Os resultados inferenciais de interesse estão na parte inferior da apresentação e são os mesmos obtidos na etapa de execução com o R. A estatística qui-quadrado foi 41.6, com 1 grau de liberdade e p &lt; 0.001. Estes valores estão dispostos no retângulo roxo na imagem a seguir. A validade dos resultados depende dos pressupostos e o tamanho do efeito precisa também ser calculado para indicar a relevância dos achados. Para verificar se existem células cujos valores esperados sejam iguais a 0 e se no máximo 20% dos valores esperados são inferiores a 5, é necessário clicar em Cells. Em seguida, ao marcar a opção Expected e Row em Percentages, os resultados poderão ser melhor analisados. Com isso feito, a opção Statistics deverá ser acessada para que seja possível calcular o tamanho do efeito. Neste caso, deve-se clicar em Cramer's V. Com estas etapas concluídas, agora é possível analisar integralmente os resultados, em que o valor de P e o tamanho do efeito podem ser interpretados. Caso os pressupostos tenham sido violados, o JASP oferece algumas saídas, tal como a correção de Yates. 5.5 Escrita dos resultados Como escrever os resultados A associação entre o sexo do participante e sua condição clínica (ter ou não TDAH) foi investigada por um Teste Qui-quadrado de independência. Os resultados indicaram que ambas as variáveis são associadas (X2(1) = 41.605). O tamanho do efeito foi calculado pelo V de Cramer, que se mostrou pequeno 0.07. 5.6 Resumo O Qui-quadrado pode ser utilizado para um conjunto de análises realizadas em variáveis categóricas. Apesar de diferenças conceituais, o formato matemático é o mesmo. O tamanho do efeito apresenta interpretações que podem variar em função dos graus de liberdade. References "],
["teste-t.html", "Cap. 6 Teste T 6.1 Pesquisa 6.2 Execução no R 6.3 Tamanho do efeito 6.4 Execução no JASP 6.5 Escrita dos resultados 6.6 Versão robusta do Teste T 6.7 Mann-whitney 6.8 Teste T e regressão 6.9 Resumo 6.10 Pesquisas adicionais", " Cap. 6 Teste T Objetivos do capítulo 1. Apresentar o Teste T 2. Discutir os pressupostos de execução do Teste T 3. Realizar gráficos relacionados à comparação de médias 4. Apresentar e interpretar métricas de tamanho do efeito 5. Dar exemplos relacionados à escrita dos resultados 6. Apresentar testes robustos e não paramétricos O Teste T é um teste estatístico frequentemente utilizado para testar hipóteses sobre diferenças entre médias. Por utilizar dados amostrais para estimar um parâmetro (\\(\\mu\\)), ele é um teste parâmetrico. Apenas por um preâmbulo histórico, a origem do Teste T remonta o artigo publicado em 1908 por William Gosset. Na época, em função de seu trabalho na cervejaria Guiness, ele não assinou o artigo, mas apenas usou seu pseudônimo Student, motivo pelo qual o Teste T também é chamado de Teste T de Student. É importante notar que estudantes de Psicologia e profissionais que trabalham com avaliação psicológica costumam ser deparados com uma métrica chamada “T score” (Escore T, as vezes), desenvolvido em 1939 por um professor de Psicologia (William Anderson McCall). Tenha em mente que essa métrica não tem relação com os procedimentos inferenciais relacionados ao Teste T a não ser uma similaridade de nome (Krus &amp; Krus, 1977). É possível usar o Teste T para comparar a média de uma amostra com a média populacional (one sample t test), para comparar duas médias amostrais (two sample t test) ou para comparar duas médias de uma mesma amostra que foi investigada em dois momentos do tempo (paired ou matched t test). Se assume os seguintes pressupostos funcionais à execução de um Teste T: (i) Os dados são aleatórios e representativos da população (ii) a variável dependente é contínua (iii) A distribuição dos resultados populacionais é assumida como normal Quando há o interesse de utilizar o Teste T para comparar os resultados de dois grupos, é também necessário que: (iv) As variâncias dos grupos seja homogênea (princípio da homocedasticidade) (v) ambos os grupos sejam independentes Quando se utiliza o Teste T pareado, o princípio da independência não é mais solicitado, mas é necessário que: (vi) o tamanho amostral seja o mesmo nos grupos Eventualmente, quando os pressupostos são violados, testes não-paramétricas com propostas parecidas podem ser implementadas. A tabela abaixo concatena os testes estatísticos relacionados e, para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida “ordinal”. Versão do teste Um grupo Dois grupos independentes Grupos pareados Paramétrica One-sample t test Two-samples t test Paired t test Não-paramétrica Signed rank test Mann-whitney Wilcoxon Nota: Existe um intenso debate sobre a utilização de testes paramétricos e não-paramétricos em Psicologia. Algo pouco comentado, apesar de ser o aspecto mais importante em minha opinião, é que a hipótese testada em um teste paramétrico é diferente da testeda em um não-paramétrico. Ou seja, a substituição de um teste estatístico por outro, necessariamente, muda a hipótese de pesquisa investigada. 6.1 Pesquisa Base: Livro - R - ASQ SE 12 e 18 Neste capítulo, vamos utilizar a pesquisa intitulada “Confirmatory analysis and normative tables for the Brazilian Ages and Stages Questionnaires: Social–Emotional”, publicada em 2019 na Child Care Health Development. Esse trabalho teve dois objetivos. O primeiro visou confirmar a estrutura fatorial de um instrumento utilizado para avaliar possíveis atrasos no desenvolvimento de competências sociais e emocionais (ASQ:SE) e o segundo visou desenvolver tabelas normativas para comparar meninos e meninas. Essa é uma pesquisa muito importante, visto que conta com uma base de dados robusta (mais de 50 mil participantes) e faz interface entre psicometria, avaliação psicológica e políticas públicas. Abaixo, há a escrita de hipóteses utilizada para comparar os resultados de meninos e meninas, bem como o nível de significância adotado na análise. \\[H_0: \\mu_{meninos} - \\mu_{meninas} = 0 \\\\ H_a: \\mu_{meninos} - \\mu_{meninas} \\neq 0 \\\\ \\alpha = 0.05\\] 6.2 Execução no R No ambiente R, a primeira etapa importante é assegurar que a base de dados tenha o resultado relacionado às competências sociais e emocionais das crianças. Esse valor será computado pela soma de todos os itens da escala. No dplyr, isso é feito pela integração da função mutate com a select e será executado às crianças com 12 (asq_12months) e 18 meses (asq_18months). asq_12months &lt;- asq_12months %&gt;% mutate(total_12 = rowSums(select(., starts_with(&quot;q_&quot;)), na.rm = TRUE)) asq_18months &lt;- asq_18months %&gt;% mutate(total_18 = rowSums(select(., starts_with(&quot;q_&quot;)), na.rm = TRUE)) Em seguida, iremos começar pelos 12 meses. O processo de testagem da hipótese é feito preliminarmente de maneira tabular e gráfica e, em seguida, pela implementação do teste específico e seus pressupostos. A tabela a seguir apresenta as principais características estatísticas dos resultados: asq_12months %&gt;% group_by(sex) %&gt;% summarise_at(vars(total_12), lst(n=~n(),media=mean, DP=sd)) %&gt;% pander() sex n media DP M 543 24.92 21.47 F 498 24.44 20.48 Em seguida, a realização de um gráfico é bastante informativa para apresentação dos resultados. Apesar desse recurso não ser decisivo na tomada de decisão, ele auxilia a visualilzação da distribuição da variável que temos interesse, bem como oferece um entendimento inicial dos resultados. Uma vez que a VI é tratada como discreta e a VD é continua, tanto o gráfico de colunas/barras como o histograma/densidade são úteis. O gráfico de barras tem uma vantagem de ser possível adicionar barras de erros, que já apresentam uma primeira evidência inferencial. Por sua vez, histogramas e gráficos de densidade descrevem bem o formato da distribuição de dados. gridExtra::grid.arrange( #plot 1 ggplot(asq_12months, aes(x = sex, y = total_12, fill = sex)) + geom_bar(stat = &quot;summary&quot;, fun = mean) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width = .2), #plot 2 ggplot(asq_12months, aes(x = total_12, fill = sex)) + geom_density(color = NA, alpha=.6) ) Feito isso, o próximo passo é a testagem formal da hipótese. A função t.test é nativa do R o vetor t_test_12_m será criado. t_test_12m &lt;- t.test(total_12 ~ sex, var.equal = T, data = asq_12months) A tabela a seguir apresenta os resultados. t_test_12m %&gt;% pander::pander(., split.table = Inf) Two Sample t-test: total_12 by sex Test statistic df P value Alternative hypothesis mean in group M mean in group F 0.3679 1039 0.713 two.sided 24.92 24.44 Os achados trazem a média de ambos os grupos (24.92 e 24.44), a estatística do teste (0.37), chamada de T calculado, os graus de liberdade (1039) e o valor de p 0.71. Repare que como o valor de p é superior ao valor estipulado do nível de significância (0.05), falha-se em rejeitar a hipótese nula. Nesse sentido, apesar dos resultados serem numericamente distintos, eles não são estatisticamente significativos (na população). Um aspecto importante é que a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer (Barker &amp; Shaw, 2015; Ernst &amp; Albers, 2017; Lix et al., 1996). Corriqueiramente, testar os pressupostos é uma etapa anterior à própria realização do teste inferencial. Entretanto, pedagogicamente a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir. Normalidade: O Teste T de duas amostras independentes assume que os resultados da variável de interesse se distribuam normalmente. É importante relembrar que o Teste T é um caso especial de um modelo de regressão, o que significa que a normalidade se refere aos resíduos do modelo. Neste caso, isso pode ser aproximado testando a distribuição marginal dos resultados de ambos os grupos. A normalidade pode ser avaliada graficamente por QQ plots e por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera. O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis contra os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade. ggplot(asq_12months, aes(sample = total_12)) + stat_qq() + stat_qq_line() + facet_wrap(~sex) Apesar do gráfico já ter sido bastante claro e sugerir fortemente desvio da normalidade em ambos os grupos, o teste formal é importante. O Shapiro-wilk costuma ser utilizado neste caso, uma vez que ele reúne diferentes características positivas no balanço entre erro do tipo 1 e 2 (Yap &amp; Sim, 2011). A hipótese nula desse teste assume que a variável de interesse tem distribuição (aproximadamente) normal. Assim, rejeitar a hipótese nula sugere que esse princípio foi violado e, com isso, o Teste T pode gerar resultados distorcidos. asq_12months %&gt;% group_by(sex) %&gt;% summarise(shapiro = shapiro.test(total_12)$p.value) %&gt;% pander::pander() ## `summarise()` ungrouping output (override with `.groups` argument) sex shapiro M 1.976e-19 F 4.798e-17 De maneira convergente ao gráfico, o Shapiro-wilk também apontou que o princípio da normalidade foi violado. Homocedasticidade: A homogeneidade ou igualdade das variâncias pode ser testada visualmente, pelo teste Breusch-pagan, Levene ou Bartlett. De maneira análoga ao Shapiro-wilk, estes últimos assumem como hipótese nula a homogeneidade das variâncias. Consequemente, a rejeição desse pressuposto pode também trazer resultados distorcidos ao resultado do Teste T. Diferentemente do pressuposto da normalidade, o pressuposto da homocedasticidade foi preservado, tal como apresentado abaixo: car::leveneTest(total_12 ~ sex, data = asq_12months) %&gt;% pander::pander() Levene’s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 1 0.02315 0.8791 1039 NA NA Após testar estes pressupostos, é importante avaliar o quanto a interpretação originalmente deve ser mantida. Existem diferentes recomendações sobre o que fazer quando os pressupostos são violados. Entre elas, transformar a distribuição da variável de interesse, usar versões robustas do Teste T, usar testes não-paramétricos com objetivos próximos ao Teste T ou eleger algum modelo estatístico mais adequado à distribuição empírica obtida pelos dados. Parte dessas recomendações serão demonstradas a seguir. Com este teste inicial concluído, é também possível verificar se existem diferenças em idades mais avançadas, tal como 18 meses. A sintaxe é customizável e torna-se fácil testar a hipótese da diferença apenas modificando a hipótese e a sintaxe. A tabela a seguir apresenta as principais medidas estatísticas: asq_18months %&gt;% group_by(sex) %&gt;% summarise_at(vars(total_18), lst(n=~n(),media=mean, DP=sd)) %&gt;% pander() sex n media DP M 2980 27.53 21.81 F 2747 24.95 20.34 Por sua vez, o gráfico a seguir traz o padrão dos resultados aos 18 meses. gridExtra::grid.arrange( ggplot(asq_18months, aes(x = sex, y = total_18, fill = sex)) + geom_bar(stat = &quot;summary&quot;, fun=mean) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width = .2), ggplot(asq_18months, aes(x = total_18, fill = sex)) + geom_density(color = NA, alpha=.6)) Tal como feito anteriormente, a realização do Teste T e a verificação de seus pressupostos devem ser realizadas. Em relação aos resultados do Teste T, eles indicaram que ambos os grupos tem resultados médios significativamente diferentes. Meninos apresentam resultados mais elevados (M = 27.53, DP = 21.81) do que meninas (M = 24.95, DP = 21.81). t_test_18m &lt;- t.test(total_18 ~ sex, var.equal = T,data = asq_18months) t_test_18m %&gt;% pander::pander(., split.table = Inf) Two Sample t-test: total_18 by sex Test statistic df P value Alternative hypothesis mean in group M mean in group F 4.619 5725 3.949e-06 * * * two.sided 27.53 24.95 Diferentemente do anterior, agora o resultado foi significativo (p &lt; 0.01), trazendo evidências que permitem concluir pela rejeição da hipótese nula. Da mesma forma que feito anteriormente, a verificação dos pressupostos é um elemento fundamental para validade da interpretação dos resultados. Uma vez que tais testes foram demonstrados na seção anterior, eles não serão repdroduzidos agora. No entanto, dessa vez, a normalidade e a homocedasticidade foram violadas, fazendo que com as interpretações tornem-se frágeis, apesar de possíveis. Isso posto, é importante ter uma atenção especial ao conceito subjacente à significância estatística. Um resultado que rejeita a hipótese nula, de forma alguma, deve ser entendido como “aceitação da hipótese alternativa” ou como evidência de causalidade, especialmente em delineamentos transversais. É fundamental lembrar que o valor de P se refere à probabilidade de encontrar a estatística de teste calculada, ou uma ainda mais exterma, assumindo que a hipótese nula é verdadeira (Wasserstein &amp; Lazar, 2016). Apesar de algo contra-intuitivo (e talvez desanimador), é assim que a estatística frequentista funciona. 6.3 Tamanho do efeito Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde. Existem duas famílias principais no ambiente do tamanho do efeito, que são a família “d” e a família “r”. Tecnicamente, quando comparamos médias, usamos o d de Cohen para calcular a distância entre as médias das distribuições sobrepostas. A interpretação é a seguinte: Cohen’s d Interpretação d &lt; 0.2 Irrelevante d \\(\\geq\\) 0.2 Pequeno d \\(\\geq\\) 0.5 Moderado d \\(\\geq\\) 0.8 Grande Para executar este teste no R, é possível contar com o pacote effsize, tal como demonstrado abaixo: effsize::cohen.d(total_18 ~ sex, data = asq_18months) ## ## Cohen&#39;s d ## ## d estimate: 0.12216 (negligible) ## 95 percent confidence interval: ## lower upper ## 0.07025972 0.17406037 Com esse conjunto de dados, o tamanho do efeito foi irrelevante, indicando que a diferença dos resultados não apresenta uma relevância clínica importante. 6.4 Execução no JASP Nesta parte, apenas a base de crianças com 18 meses será utilizada. Da mesma forma que foi feito no R, a apresentação de tabelas e gráficos auxiliam o pesquisador a verificar padrões nos dados. Após carregar a base de agora, a seção Descriptives deverá ser acessada para apresentar os resultados iniciais. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista Variables irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção Split. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Isto posto, será necessário arrastar as variáveis de interesse aos seus respectivos locais. Neste caso, o total_18 para parte das VDs, enquanto sexo para a VI. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização. Em seguida, ao clicar na opção Plots, será possível selecionar o Boxplot. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados das crianças de 18 meses em função do sexo. Para execução do Teste T, deve-se clicar em T-Test e, em seguida, Independent samples T-test. Ao realizar tais ações, a tela a ser exibida será próxima à imagem a seguir: Repare que a Grouping variable é o local onde a VI deverá ser colocada, enquanto a Variables é o local onde a VD irá ser inserida. É possível ter apenas uma VI, enquanto diferentes VDs podem ser inseridas na seção Variables para serem analisadas independentemente . Neste caso de agora, a VI é sexo e a VD é total_18. Ao fazer isso, o JASP automaticamente irá fazer o Teste T e apresentar os resultados. Pragmaticamente, o valor de P costuma ser utilizado para decisões estatísticas e ele está destacado pelo quadrado roxo na imagem a seguir. Entretanto, da mesma forma como apresentado no ambiente R, a interpretação deste resultado não pode ser feita de uma forma automática. É necessário saber se os pressupostos foram ou não atendidos, bem como calcular o tamanho do efeito. Para verificar os pressupostos, será necessário utilizar as opções dispostas na parte inferior à esquerda do programa. Na imagem abaixo, elas foram destacadas pelo retângulo roxo. É necessário marcar as duas opções para que os testes sejam realizados. Os resultados são os mesmos já obtidos pelo R e indicam que ambos os pressupostos foram violados, sugerindo uma interpretação bastante cautelosa dos achados. Para inserir o tamanho do efeito ao lado do Teste T, é necessário clicar em Effect size e Cohen's d, ambos localizados na parte superior do JASP. Com estas informações marcadas, agora os resultados podem ser analisados em conjunto. O valor de P irá indicar se a hipótese nula foi rejeitada ou não. O tamanho do efeito indicará a relevância ou importância prática dos resultados. Os resultados obtidos pelo JASP são identicos aos do R. Eventualmente, a diferença em relação ao sinal (+ ou -) é devida à codificação feita pelos programas e nada interfere na interpretação dos resultados. 6.5 Escrita dos resultados O primeiro achado foi que meninos e meninas não apresentaram diferenças em seus resultados médios quando tinham 12 meses. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA). Como escrever os resultados Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 12 meses de idade. Os resultados mostraram que os valores médios de meninos e meninas não são significativamente diferentes (t(1039) = 0.37, p = 0.71). Dessa maneira, as diferenças encontradas podem ser mais bem explicadas por outras fontes de variações. Em seguida, verificamos que essa diferença é significativa aos 18 meses e abaixo uma outra sugestão de escrita. Como escrever os resultados Os dados foram analisados por um Teste T de amostras independentes para investigar as diferenças médias nos resultados do desenvolvimento entre meninos e meninas com 18 meses de idade. Os resultados mostraram que os valores médios de meninos (M = 27.5, DP = 21.8) e meninas (M = 24.9, DP = 20.3) são significativamente diferentes (t(5725) = 4.62, p &lt; 0.01), apesar do tamanho do efeito ser irrelevante (d = 0.12). 6.6 Versão robusta do Teste T Em muitas situações, os pressupostos do Teste T são violados. Parte da literatura argumenta que o Teste T é robusto o suficiente para lidar com isso (Lumley et al., 2002), enquanto outra parte sugere que é melhor optar por versões com médias aparadas, técnicas não-paramétricas (Field &amp; Wilcox, 2017) ou outros modelos estatísticos. O Welch test é considerado uma versão robusta do Teste T, uma vez que não assume homocedasticidade, ou seja, lida bem com variâncias distintas nos grupos. O tamanho do efeito do Welch test é também o d de Cohen e, por isso, não será novamente calculado nesta seção. Um aspecto importante e que não costuma ser discutido com tanta frequência é que a modificação do teste estatístico utilizado pode modificar a hipótese da pesquisa. Nesse sentido, a decisão de alterar ou não o teste inferencial deve ser feita com justificativa teórica por parte do pesquisador. 6.6.1 Execução no R Para executar o O Welch-test no R, deve-se alterar a sintaxe, estipulando var.equal = F na sintaxe previamente exposta. Na verdade, o R executa o Welch test de maneira automática quando faz o Teste T. Dessa maneira, ao se remover este argumento por completo, o Teste T robusto será calculado. Existem outras soluções disponíveis no pacote WRS, que não serão implementadas neste livro. O Welch-test será calculado considerando as crianças com 18 meses. t.test(total_18 ~ sex,data = asq_18months) %&gt;% pander::pander(., split.table = Inf) Welch Two Sample t-test: total_18 by sex Test statistic df P value Alternative hypothesis mean in group M mean in group F 4.632 5724 3.707e-06 * * * two.sided 27.53 24.95 Repare que a estatística de teste e os graus de liberdade são diferentes. No entanto, os resultados são virtualmente os mesmos obtidos anteriormente, indicando que os grupos apresentam valores significativamente distintos. 6.6.2 Execução no JASP No JASP, é possível acessar a versão robusta clicando em Welch, embaixo do Student, que já é previamente marcado. A interpretação dos achados é a mesma realizada anteriormente. 6.7 Mann-whitney O teste de Wilcoxon-Mann-Whitney costuma ser chamado de versão não-paramétrica do Teste T. No entanto, isso não é totalmente verdadeiro, já que eles testam hipóteses diferentes. Enquanto o Teste T compara médias, o Mann-whitney compara os valores ranqueados (postos). Nota-se que ele não é um teste para comparar medianas e que isso só ocorre em condições restritas. De maneira pragmática, quando os pressupostos do Teste T são violados, o Mann-Whitney costuma ser eleito como um forte candidato para sua substituição. O pesquisador tem de sempre ter em mente que, se de um lado esse teste supera tais pressupostos, por outro ele responde a uma hipótese diferente daquela que o Teste T trabalha. 6.7.1 Execução No R A sintaxe a seguir apresenta os resultados utilizando a função wilcox.test. Repare que as conclusões estatística são virtualmente identicas às obtidas previamente, em que foi possível rejeitar a hipótese nula. mann_whiyney_18m &lt;- wilcox.test(total_18 ~ sex, data = asq_18months) mann_whiyney_18m %&gt;% pander::pander() Wilcoxon rank sum test with continuity correction: total_18 by sex Test statistic P value Alternative hypothesis 4368187 9.902e-06 * * * two.sided 6.7.2 Tamanho do efeito O tamanho do efeito também pode ser calculado por \\(Z/\\sqrt{(n)}\\). O output padrão do R não oferece a informação de Z, mas o pacote coin dispõe dessa métrica. coin::statistic(coin::wilcox_test(total_18 ~ sex, data = asq_18months)) ## [1] 4.41932 Assim, implementando a fórmula, o tamanho do efeito seria aproximadamete 0.06. 6.7.3 Execução no JASP No JASP, é necessário marcar a opção Mann-Whitney no lugar da opção Student, que é a definida por padrão. O JASP utiliza a Correlação rank-bisserial como método padrão para relatar o tamanho do efeito para o teste de Mann-Whitney. 6.7.4 Escrita dos resultados A literatura não é muito concordante em como escrever os resultados do Mann-Whitney e abaixo há uma sugestão. Como escrever os resultados Os dados foram analisados pelo teste Wilcoxon-Mann-Whitney para investigar as diferenças nos resultados do desenvolvimento entre meninos (Mdn = 25, IQR = 30, M = 27.53, DP = 21.61) e meninas (Mdn = 20, IQR = 25, M = 24.95, DP = 20.34) com 18 meses de idade. Os resultados indicaram que os resultados foram significativos (W = 4368187, p &lt; 0.01), mas com efeito negligenciável (0.12). 6.8 Teste T e regressão Conforme alertado ao início do capítulo, o Teste T é um caso particular de um modelo de regressão que assume que a variável independente é uma dummy, ou seja, uma variável categórica com dois níveis. Isso significa que ao realizar um Teste T, o pesquisador está fazendo um modelo de regressão, mesmo que isso não lhe seja intuitivo em primeiro momento. Neste modelo, \\(b_0\\) (intercepto) é o grupo referência que recebeu o valor 0. Já \\(b_1\\) (inclinação) é a diferença entre os valores do grupo definido para o intercepto e o outro grupo, que recebeu o valor de 1 e é chamado de comparação. Caso isso não tenha sido explicitamente definido, ao se usar o R, será necessário codificar a variável como fator. O exemplo abaixo ilustra os resultados utilizando a base asq_18months. lm(total_18 ~ sex, data = asq_18months) %&gt;% olsrr::ols_regress() ## Model Summary ## --------------------------------------------------------------- ## R 0.061 RMSE 21.117 ## R-Squared 0.004 Coef. Var 80.324 ## Adj. R-Squared 0.004 MSE 445.920 ## Pred R-Squared 0.003 MAE 16.152 ## --------------------------------------------------------------- ## RMSE: Root Mean Square Error ## MSE: Mean Square Error ## MAE: Mean Absolute Error ## ## ANOVA ## ------------------------------------------------------------------------- ## Sum of ## Squares DF Mean Square F Sig. ## ------------------------------------------------------------------------- ## Regression 9511.801 1 9511.801 21.331 0.0000 ## Residual 2552890.199 5725 445.920 ## Total 2562401.999 5726 ## ------------------------------------------------------------------------- ## ## Parameter Estimates ## ---------------------------------------------------------------------------------------- ## model Beta Std. Error Std. Beta t Sig lower upper ## ---------------------------------------------------------------------------------------- ## (Intercept) 27.527 0.387 71.160 0.000 26.769 28.285 ## sexF -2.580 0.559 -0.061 -4.619 0.000 -3.675 -1.485 ## ---------------------------------------------------------------------------------------- Em função da ordem alfabética, o R atribuiu os meninos (male) como intercepto e, consequentemente, grupo referência. Assim, o valor de \\(b_0\\) será o valor médio obtido pelos dos meninos, que foi de 27.53. A inclinação \\(b_1\\) é justamente a diferença entre os valores dos meninos e das meninas (24.95-27.53) e, nesse caso, -2.58. A estatística F é equivalente a \\(t^2\\) do Teste T em sua versão tradicional, que assume variâncias iguais entre grupos. Agora torna-se mais intuitivo mostrar que a normalidade no Teste T se refere à normalidade dos resíduos deste modelo de regressão. Isso pode ser visualmente pela análise de um QQ plot, tal como a seguir. olsrr::ols_plot_resid_qq(lm(total_18 ~ sex, data = asq_18months)) Há também testes estatísticos formais, como o Shapiro-Wilk ou o Anderson-Darling. Nestes, a hipótese nula é de que os resíduos são normalmente distribuídos e idealmente não se deve rejeitá-la. Abaixo segue a execução do Anderson-Darling, uma vez que o Shapiro-wilk não lida bem mais de 500 valores residuais. nortest::ad.test(lm(total_18 ~ sex, data = asq_18months)$residuals) ## ## Anderson-Darling normality test ## ## data: lm(total_18 ~ sex, data = asq_18months)$residuals ## A = 116.57, p-value &lt; 2.2e-16 Os resultados foram convergentes ao alcançados durante o capítulo, indicando pela violação da normalidade. A homocedasticidade pode ser investigada também por um gráfico, em que os resíduos são plotados contra os valores ajustados, tal como abaixo. olsrr::ols_plot_resid_fit(lm(total_18 ~ sex, data = asq_18months)) O teste de Levene, de Bartlett ou de Breusch-Pagan também oferecem recursos para tal análise. Todos estes indicam pela hipótese nula a homocedasticidade. olsrr::ols_test_breusch_pagan(lm(total_18 ~ sex, data = asq_18months)) ## ## Breusch Pagan Test for Heteroskedasticity ## ----------------------------------------- ## Ho: the variance is constant ## Ha: the variance is not constant ## ## Data ## ------------------------------------ ## Response : total_18 ## Variables: fitted values of total_18 ## ## Test Summary ## ------------------------------- ## DF = 1 ## Chi2 = 13.89602 ## Prob &gt; Chi2 = 0.0001932067 Os achados também concluem pela rejeição da homocedasticidade, tal como foi previamente apresentado. Mais detalhes sobre modelos de regressão são apresentados em capítulos específicos. 6.9 Resumo O Teste T é um teste paramétrico que visa comparar duas médias Gráfico de barras ou boxplots são extremamente úteis para verificar os resultados O Teste T é um caso particular de um modelo de regressão Os pressupostos do Teste T devem ser checados antes da interpretação dos resultados Quando os pressupostos são violados, o pesquisador deverá tomar decisões sobre a manutenção, modificação ou substituição deste teste por outro O tamanho do efeito é uma métrica importante e realizada pelo d de Cohen 6.10 Pesquisas adicionais Are Women Really More Talkative Than Men? (DOI: 10.1126/science.1139940) Nesta pesquisa, 96 participantes (210 mulheres and 186 homens) foram investigados entre 1998 e 2004. Os pesquisadores deram para todos um tipo de gravador de voz que eles deveriam utilizar diariamente. Ao fim, a média de palavras produzidas por homens e mulheres foram comparadas. References "],
["anova.html", "Cap. 7 ANOVA 7.1 Legenda 7.2 Pesquisa 7.3 ANOVA de 1 via 7.4 Execução no R 7.5 Tamanho do efeito 7.6 Execução no JASP 7.7 Escrita dos resultados 7.8 Post hoc 7.9 Execução no R 7.10 Execução no JASP 7.11 Escrita dos resultados 7.12 Resumo 7.13 Pesquisas adicionais 7.14 Pesquisa 7.15 ANOVA de 2 vias 7.16 Execução no R 7.17 Execução no JASP 7.18 Escrita dos resultados 7.19 Post hoc 7.20 Execução no R 7.21 Execução no JASP 7.22 Escrita dos resultados 7.23 Resumo 7.24 ANOVA Fatorial 7.25 Execução no R 7.26 Execução no JASP 7.27 Escrita dos resultados 7.28 Resumo 7.29 Post hoc 7.30 Execução no JASP 7.31 Escrita dos resultados", " Cap. 7 ANOVA Objetivos do capítulo 1. Apresentar a ANOVA 2. Discutir seus diferentes tipos, incluindo ANOVA de 1 via, 2 vias e Fatorial 3. Apresentar gráficos e tabelas com comparações de grupos 4. Apresentar e discutir testes Post hoc 5. Dar exemplos relacionados à escrita dos resultados A ANOVA é um teste estatístico desenvolvimento para verificar diferenças médias entre diversos grupos. Pragmaticamente, é possível entender ANOVA como um super Teste T ou também um caso particular de um modelo de regressão. Na verdade, toda a família de modelos estatísticos estudados pela ANOVA (e.g., ANCOVA e MANOVA) são casos especiais de um modelo de regressão, em que as variáveis independentes podem ser categóricas ou contínuas. Alguns autores indicam que a ANOVA é a técnica inferencial mais utilizada em Psicologia (Chartier &amp; Faulkner, 2008; David C Howell, 2011). Se por um aspecto, isso é extremamente vantajoso, uma vez que estreita a relação entre Psicologia e Estatística; por outro, isso parece ter contribuído para criação e manutenção de diferentes conceitos equivocados sobre a ANOVA. De maneira geral, a ANOVA é um modelo linear, tal que: \\[y_i = b_0 + b_1X{_1}_i + ... + b_pX{_p}_i + \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_p\\) é a inclinação (coeficiente angular) \\(X_p\\) é a variável independente em questão \\(\\epsilon_{i}\\) é o erro/resíduo Os seguintes pressupostos dos modelos lineares são mantidos, que são: (i) A variável dependente é contínua (ii) Os resíduos são independentes (iii) Os resíduos são normalmente distribuídos (iv) A variância dos resíduos é constante A linearidade dos resíduos não é formalmente um pressuposto a ser testado, especialmente quando a VI é categórica em vez de contínua. Operacionalmente, o erro representa todos os fatores de pesquisa e problemas de medição que afetam o resultado, além das variáveis independentes consideradas na modelagem. Da mesma forma que feito em outros capítulos, a tabela abaixo concatena os testes estatísticos relacionados quando os pressupostos são violados. Para fins de comparação com outros trabalhos, há autores que sugerem que se use sempre as versões não-paramétricas em resultados obtidos por processos de avaliação psicológica, arguindo que os dados têm nível de medida “ordinal”. Estatística Um ou mais fatores Medidas repetidas Paramétrica ANOVA de k via(s)/Fatorial ANOVA de medidas repetidas Não-paramétrica Kruskal-Wallis Teste de Friedman ou Page Test A ANOVA tem diversos termos bastante específicos e utilizados em sua modelagem que serão descritos a seguir, 7.1 Legenda Diferentes termos são empregados em uma ANOVA e em modelos próximos. A legenda a seguir visa auxiliar no entendimento de cada um deles e aproximar o leitor a conceitos amplos utilizados em modelos lineares. Via: Variável independente, variável fonte, variável preditora, tratamento Fator: Sinônimo de via Desfecho: Variável dependente, variável critério Níveis: Grupos, classes, condições, categorias da variável independente Efeito principal: Efeito da variável independente em questão (controlanddo pelas outras no modelo) Efeito de interação: Efeito do termo de interação entre duas ou mais variáveis independentes. Quando significativo, não se interpreta os efeitos principais. Efeito simples: Efeito de uma variável independente em um nível (específico) de outra variável independente. ANCOVA: Análise de covariância, onde se controla os resultados por uma variável contínua MANOVA: Análise multivariada de variância, onde se estende a ANOVA para incluir duas variáveis dependentes. É um modelo multivariado. Por heurística, se escreve os delineamentos estudados por uma ANOVA com \\(\\eta\\). Por exemplo, se o interesse for verificar o efeito da escolaridade (fundamental, médio e superior) e do sexo (masculino ou feminino), a representação será \\(\\eta = 3 \\times 2\\). Isso significa que a ANOVA tem dois fatores (escolaridade e sexo), o primeiro fator tem três níveis e o segundo tem 2 níveis. A tabela a seguir resume as denominações encontradas na literatura: Quantas VDs Uma VI 2 ou mais VIs (sem interação) 2 ou mais VIs (com interação) Uma VD ANOVA de 1 via (one way) ANOVA 2 (ou mais) vias (multi way) ANOVA Fatorial + de uma VD MANOVA 7.2 Pesquisa Base: Livro - R - TEG Neste capítulo, vamos utilizar a pesquisa intitulada “A relação entre o nível de Empreendedorismo (TEG) e os aspectos sociodemográficos dos Taxistas cooperados da cidade de Santo André/São Paulo, Brasil”, publicada em 2016 na Revista Eletrônica de Gestão e Serviços, em que sou coautor. O objetivo dessa pesquisa foi identificar o nível de empreendedorismo em 147 taxistas de Santo André/SP, bem como averiguá-lo em associação aos aspectos sociodemográficos. Muitas perguntas teóricas foram feitas neste trabalho e uma foi verificar o quanto os níveis de escolaridade poderiam impactar o empreendedorismo. 7.3 ANOVA de 1 via Em uma ANOVA de 1 via, há apenas um fator com três ou mais níveis. Dessa forma, conceitualmente temos: \\[y_i = b_0 + b_1X{_1}_i +\\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) é a inclinação (coeficiente angular) \\(X_1\\) é a variável independente em questão \\(\\epsilon_{i}\\) é o erro/resíduo A pergunta que temos neste trabalho é sobre o possível efeito da escolaridade (fundamental, médio, etc) na Tendência Empreendedora Geral (teg). Dessa maneira, esse sistema fechado de equação ilustra bem essa ANOVA., 7.4 Execução no R Ao trabalhar no R, é fundamental se certificar que os tipos das variáveis estão corretamente definidos em função da escala de medida utilizada. Erros nessa etapa podem gerar resultados absolutamente incorretos. A escolaridade é uma variável categórica (ordinal, tratada como discreta) e é necessário definir claramente isso ao R antes da análise propriamente dita. Isso pode ser feito pela função case_when e levels. O case_when irá usar os valores originalmente presentes nessa variável para computar uma nova variável categórica. O levels deixará claro a ordem de cada categoria, o que é útil para que os gráficos sejam feitos corretamente. Uma vez que os itens de um instrumento sociodemográfico devem levar em consideração o contexto das pessoas avaliadas as categorias de escolaridade foram definidas como da seguinte maneira: Primário significa escolaridade até o 5º ano, ginásio significa escolaridade até o 9º ano e colegial é equivalente ao ensino médio. dados_teg &lt;- dados_teg %&gt;% mutate(escolaridade_fct = factor(case_when( escolaridade == 1 ~ &quot;primario&quot;, escolaridade == 2 ~ &quot;ginasio&quot;, escolaridade == 3 ~ &quot;Colegial&quot;, escolaridade == 4 ~ &quot;superior&quot;), levels=c(&quot;primario&quot;,&quot;ginasio&quot;,&quot;Colegial&quot;,&quot;superior&quot;))) Os resultados descritivos devem ser calculados. A média irá apresentar a concentração dos dados, enquanto o desvio-padrão o afastamento dos valores em torno da respectiva média. dados_teg %&gt;% group_by(escolaridade_fct) %&gt;% summarise_at(vars(teg), lst(n=~n(),mean,sd)) %&gt;% pander() escolaridade_fct n mean sd primario 6 24.67 4.633 ginasio 33 26.76 3.857 Colegial 85 28.87 4.108 superior 23 31.83 5.228 Tal como ilustrado no decorrer dos outros capítulos, gráficos são fundamentais para entendimento do relacionamento entre as variáveis. Uma vez que a escolaridade (VI) é tratada como discreta e a TEG (VD) é contínua, um gráfico de barras é adequado. A inclusão das barras de erro permite uma compreensão inferencial inicial. ggplot(dados_teg, aes(x=escolaridade_fct, y = teg, fill = escolaridade_fct)) + geom_bar(stat = &quot;summary&quot;, fun = mean) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;) + theme(legend.position = &quot;none&quot;) A visualização dos resultados já permite identificar algumas caracteríticas gerais. Primeiro, quão maior a escolaridade, maior o valor obtido na escala. Segundo, algumas barras de erros estão superpostas e outras não, o que nos leva à conclusão preliminar de que resultados significativos estarão presentes na próxima etapa, que é a modelagem formal dessa hipótese. Para realizar a ANOVA, é possível contar com a função lm ou aov. Aqui, a escolha da lm foi apenas por conveniência e o vetor mod_escolaridade irá armazenar os resultados. mod_escolaridade &lt;- lm(teg ~ escolaridade_fct, dados_teg) Para apresentação, a função apa.aov.table do pacote apatables pode ser utilizada. Este pacote gera uma tabela parecida com a dos principais pacotes estatísticos comerciais e apresenta os principais elementos interpretáveis de uma ANOVA. A tabela a seguir sintetiza tais características. Fonte de variação Soma dos Quadrados Graus de liberdade Quadrado médio Estatística F Fator Entre (SSB) K-1 MSB = SSB/K-1 F = MSB/MSW Resíduo Dentro (SSW) N-K MSW = SSW/N-K Total Total (SQT) N-1 Aqui, K significa quantidade de categorias dentro de um fator e N significa a quantidade de observações consideradas. As siglas em inglês são utilizadas para apresentar a “Soma dos quadrados entre os grupos” (SSB), “Soma dos quadrados dentro dos grupos” (SSW), “Quadrado médio entre grupos” (MSB) e “Quadrado médio dentro dos grupos” (MSW). apaTables::apa.aov.table(mod_escolaridade) %&gt;% pander(., split.table = Inf) ## Warning in pander.default(., split.table = Inf): No pander.method for ## &quot;apa_table&quot;, reverting to default. table_number: NA table_title: ANOVA results using teg as the dependent variable table_body: Table continues below Predictor SS df MS F p partial_eta2 (Intercept) 3650.67 1 3650.67 200.61 .000 escolaridade_fct 449.33 3 149.78 8.23 .000 .15 Error 2602.27 143 18.20 CI_90_partial_eta2 [.06, .22] table_note: Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared A escrita e leitura desse resultado traz as principais estatísticas obtidas. O padrão a seguir costuma ser utilizado: \\[F(df_{between}, \\, df_{within}) = F, P, \\eta^2, 90\\% \\,CI \\, [min, \\, max]\\] Neste caso: F(3,143) = 8.23, p &lt; 0.01, \\(\\eta_p^2\\) = 0.15, 90% CI [.06, .22]. Nota-se de jamais apresentar p = 0.0. A última parte do resultado é uma medida de tamanho do efeito, que terá a interpretação apresentada e discutida na próxima seção. Um aspecto importante é que a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer (Barker &amp; Shaw, 2015; Ernst &amp; Albers, 2017; Lix et al., 1996). Corriqueiramente, testar os pressupostos é uma etapa anterior à própria realização do teste inferencial. Entretanto, pedagogicamente a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir. Normalidade: A ANOVA tem como um dos pressupostos a normalidade da distribuição dos resíduos. Isso pode ser feito de diferentes maneiras e abaixo há um QQ plot. Caso ambas as linhas estejam sobrepostas, isso gera evidências que o pressuposto foi atendido. Neste caso, isso parece ocorrer. olsrr::ols_plot_resid_qq(mod_escolaridade) Apesar do gráfico ter sido bastante claro, testes como o Shapiro-wilk, Anderson-Darling e Jarque Bera também podem ser utilizado neste caso. A hipótese nula desses testes assumem que os resíduos são normalmente distribuídos. shapiro.test(residuals(mod_escolaridade)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod_escolaridade) ## W = 0.97502, p-value = 0.008721 De maneira diferente à conclusão gráfica, o teste concluiu pela rejeção da normalidade. Homocedasticidade: Este pressuposto pode ser testado por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico, tal como o gráfico a seguir. olsrr::ols_plot_resid_fit(mod_escolaridade) O teste de Levene, de Bartlett ou de Breusch-Pagan podem também serem utilzados de maneira formal. Eles estipulam \\(H_0\\) como homocedasticidade e, idealmente, não deve ser rejeitada. car::leveneTest(mod_escolaridade) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 1.1372 0.3362 ## 143 Os resultados indicaram que a homocedasticidade foi preservada. Independência: Esse pressupostos frequentemente não é testado na ANOVA, apesar de ser uma exigência dos modelos lineares. De fato, uma vez que espera-se que os grupos sejam mutuamente excludentes, teria pouco sentido acreditar que os resíduos não fossem independentes. 7.5 Tamanho do efeito Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde. No ambiente da ANOVA, 3 medidas costumem ser utilizadas para tamanho do efeito, que são o eta quadrado (\\(\\eta^2\\)), o eta quadrado parcial (\\(\\eta_p^2\\)) e o ômega quadrado (\\(\\omega^2\\)). Em uma ANOVA de uma via, como é o caso aqui, o \\(\\eta^2\\) e o \\(\\eta_p^2\\) possuem o mesmo valor. A ideia de ambas as medidas é verificar a variância explicada que o modelo testado apresenta quando comparado com um modelo simples, que contou apenas com a média. Esse conceito será melhor descrito no capítulo de regressão linear. No caso de agora, o \\(\\eta^2\\) e o \\(\\eta_p^2\\) indicam a proporção da variabilidade dos resultados do TEG que pode ser atribuídos à escolaridade. A interpretação pode ser feita da seguinte maneira: ηp2 Interpretação ηp2 &lt; 0.01 Irrelevante ηp2 \\(\\geq\\) 0.01 Pequeno ηp2 \\(\\geq\\) 0.06 Moderado ηp2 \\(\\geq\\) 0.14 Grande O tamanho do efeito foi calculado e apresentado na tabela anterior. 7.6 Execução no JASP A base utilizada será a base_csv_teg_processed. A primeira etapa é a adequação dos níveis da variável a ser trabalhada, o que será importanta para tabelas e gráficos. Para ajustar a ordenação dos níveis de Escolaridade, será necessário clicar no centro da variável escolaridade_fct, selecionar o grupo desejado (no caso, primário) e clicar na seta para que ele seja o primeiro grupos. A ordem dos níveis deve ser a utilizada durante a pesquisa: primário, ginásio, colegial e superior. É importante relembrar que esses termos foram utilizados em função do público que foi avaliado nessa pesquisa. Para fechar esta parte superior, basta clicar no X embaixo das setas, destacado no quadrado roxo. Após feito isso, da mesma forma que foi feita no R, a apresentação de gráficos auxiliam o pesquisador a verificar padrões diferentes nos dados. Para fazer os gráficos, é necessário clicar em Descriptives. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista Variables irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção Split. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Agora é necessário arrastar as variáveis de interesse aos seus respectivos locais. Neste caso, o teg para parte das VDs, enquanto escolaridade_fct para a VI. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização. Em seguida, ao clicar na opção Plots, será possível selecionar o Boxplot e Boxplot element. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados de empreendedorismo em função dos níveis de escolaridade. Para execução da ANOVA, deve-se clicar em ANOVA e, em seguida, Classical e ANOVA. Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir: O espaço de Fixed factors é o local onde a VI deverá ser colocada, enquanto o Dependent Variable é o local onde a VD irá ser inserida. Para realizar a ANOVA de uma via, é necessário inserir a escolaridade_fct e o teg, respectivamente, em Fixed factors e Dependent Variable. O JASP automaticamente irá realizar as contas e apresentar os resultados. Pragmaticamente, o valor de P é o indicador costumeiramente utilizado para tomar decisões inferenciais. Neste caso, como o valor de p foi menor do que o nível de significância escolhido, rejeita-se a hipótese nula. Apesar de importante, este resultado será apenas interpretado ao fim desta seção. Da mesma forma como apresentado antes, a interpretação deste achado não pode ser feita de uma forma automática. É necessário saber se os pressupostos do modelo foram ou não atendidos, bem como calcular o tamanho do efeito. Estas opções estão dispostas na parte inferior à esquerda do programa, intitulada como Assumptions checks. A normalidade é feita por um QQ plot. Idealmente, as linhas devem estar sobrepostas no QQ plot para assumir a normalidade da distribuição dos resíduos. A homocedasticidade é formalmente testada pelo Teste de Levene. O valor de p deve ser superior ao nível de significância eleito (quase sempre, 0.05) para considerar a homogeneidade das variâncias. Neste caso, há a impressão visual de que a normalidade está mantida, bem como a homocedasticidade. [Nota: Esta versão do JASP não oferece um teste formal para testar a normalidade dos resíduos de uma ANOVA, tal como feito no R na seção anterior]. Após testar estes pressupostos, é importante avaliar o quanto a interpretação originalmente deve ser mantida. Existem diferentes recomendações sobre o que fazer quando os pressupostos são violados. Entre eles, transformar a distribuição da variável de interesse, usar versões robustas da ANOVA, usar testes não-paramétricos com objetivos próximos à ANOVA ou eleger algum modelo estatístico mais adequado à distribuição empírica obtida pelos dados. No JASP, as técnicas Brown-Forsythe e Welch são disponíveis para corrigir a violação do pressuposto de homocedasticidade. Para inserir o tamanho do efeito é necessário clicar em Estimatives of effect size e, em seguida, no eta quadrado (\\(\\eta^2\\)). O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença. 7.7 Escrita dos resultados O principal achado foi que os resultados médios de empreendedorismo foram significativamente influenciados pelo nível de escolaridade dos participantes. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA). Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de uma via investigando o efeito da escolaridade no empreendedorismo, medido por um escala específica. Foi possível concluir que a escolaridade tem efeito significativo (F(3, 143) = 8.23, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]) nos níveis de empreendedorismo. Repare que este resultado é bastante informativo, mas não deixa claro quais os níveis de escolaridade que impactam significativamente a escolaridade. Para responder à esta questão mais específica, é necessário realizar uma análise chamada de Post hoc. Este tipo de análise busca por possíveis diferenças significativas entre todas as comparações possíveis nos níveis da VI. 7.8 Post hoc Quando uma ANOVA é significativa, é possível investigar todas as comparações entre os níveis da VI por análises post hoc. É importante alertar que os resultados significativos da ANOVA não significam, necessariamente, que haverá alguma diferença entre as médias dos grupos. Tecnicamente, a diferença pode ocorrer em qualquer comparação possível, como grupo 1 contra grupos 2 + grupo 3 ou grupo 2 contra grupo 1+3. Com isso, é possível perceber que o resultado geral da ANOVA e a execução de testes post hoc respondem questões diferentes. Na verdade, é inclusive possível realizar qualquer comparação múltipla sem sequer realizar a ANOVA, desde que os resultados sejam devidamente corrigidos e alguns pressupostos sobre os contrastes sejam previamente assumidos. Tendo em vista vez que realizar uma ANOVA não é tecnicamente necessário para comparações pareadas, é possível se perguntar qual é, então, a necessidade da realização da ANOVA? Historicamente, a ANOVA era um recurso muito importante em uma época em que o poder computacional era mais limitado. Seus resultados iriam indicar se comparações múltiplas deveriam ser feitas ou não. Hoje em dia, sua realização ocorre mais para que o pesquisador (i) consiga implementar todas as comparações pareadas entre as categorias da variável e, em seguida, (ii) possa corrigir adequadamente o valor de P obtido em cada comparação. Isso dito, uma vez que a escolaridade foi significativa, as principais comparações serão testadas dois a dois. Sempre que múltiplas que comparações são realizadas, é esperado que haja uma inflação do erro do tipo 1 e, por isso, é necessário ajustar o valor de P. Repare que a quantidade de comparações pode ser calculada da seguinte forma: \\[ J*(\\frac{J-1}2) \\] onde \\(J\\) é a quantidade de níveis da variável Nesse caso: \\[ 4*(\\frac{3}{2}) = 6 \\]. 7.9 Execução no R Para a comparação pareada, o pacote emmeans será utilizado. A mecânica do por detrás do post hoc é a comparação pareada de todos os níveis presentes no fator, seguido pelo ajuste do valor de P. Existem muitas técnicas para tal ajuste e elas costumam ser agrupadas em função da sua robustez à violação da homocedasticidade. Para fins práticos, vamos utilizar uma técnica considerada bastante conservadora, chamada de Bonferroni, que multiplica o valor de p encontrado pela quantidade de comparações. O resultado das comparações dois a dois será armazenado em um objeto específico, nomeado como post_hoc_escolaridade. Isso será útil para apresentar sumários e gráficos. post_hoc_escolaridade &lt;- emmeans(mod_escolaridade, &quot;escolaridade_fct&quot;) %&gt;% pairs(., reverse = TRUE, adjust = &quot;bonferroni&quot;) A apresentação tabular é fundamental e apresenta as estatísticas inferenciais de interesse. A principal vantagem desta tabela é a correção do valor de P apresentado na coluna p.value. Este é o valor ajustado pelas comparações feitas. post_hoc_escolaridade %&gt;% data.frame() %&gt;% pander() contrast estimate SE df t.ratio p.value ginasio - primario 2.091 1.893 143 1.104 1 Colegial - primario 4.204 1.802 143 2.333 0.1263 Colegial - ginasio 2.113 0.8749 143 2.415 0.102 superior - primario 7.159 1.956 143 3.661 0.002116 superior - ginasio 5.069 1.159 143 4.374 0.00014 superior - Colegial 2.955 1.003 143 2.948 0.02244 O gráfico das comparações com barras de erro proporciona uma conclusão mais rápida e simples para todas as comparações. Para interpretar o gráfico, é necessário ter como referência o valor 0 no eixo horizontal e, em seguida, verificar todas as comparações no eixo vertical. Quando alguma comparação toca o valor 0, isso indica que os grupos não são significativamente diferentes. Quando isso não ocorre, é possível sugerir que há diferença nos grupos. CI &lt;- confint(post_hoc_escolaridade) ggplot(mapping = aes(contrast, estimate)) + geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) + geom_point(data = summary(post_hoc_escolaridade)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_size(trans = &quot;reverse&quot;) + coord_flip() No geral, as comparações Superior - Primário, Superior - Ginásio e Superior - Colegial são significativas. Em todas elas, os resultados da TEG foram mais elevados nos participantes com ensino superior. No início desta seção, foi comentando que o controle do erro do tipo 1 era uma vantagem da realização deste procedimento que inclui fazer uma ANOVA, verificar quantas comparações serão feitas e corrigir os resultados dos valores de P. Um exemplo pode ser útil a este momento. Repare que a correção implementada no teste post hoc concluiu que a comparação entre colegial - primário não é significativa. Nesta comparação, o valor de p foi de 0.102. No entanto, caso um Teste T tivesse sido realizado selecionando apenas esta comparação, os resultados seriam significativos (0.01), tal como demonstrado a seguir: dados_teg %&gt;% filter(escolaridade_fct == &quot;Colegial&quot; | escolaridade_fct == &quot;ginasio&quot;) %&gt;% {t.test(teg ~ escolaridade_fct, data = .)$p.value} %&gt;% pander() 0.01099 Caso um Teste T tivesse sido feito no lugar do procedimento demonstrado nesta seção, essa conclusão seria fortemente sugestiva de um erro do tipo 1 ou falso positivo. 7.10 Execução no JASP Para executar o post hoc no JASP, é necessário clicar em Post Hoc tests, na parte esquerda inferior do programa. Ao fazer isso, um conjunto de novas opções ficará disponível logo abaixo da opção. Em seguida, basta colocar ao lado direito a variável de interesse (escolaridade_fct). O JASP automaticamente irá realizar todas as comparações principais e corrigir o valor de P. O padrão do JASP é a correção de Tukey, que pode ser alterada clicando em Correction. Mesmo sem implementar a correção de Bonferroni, os achados são virtualmente idênticos aos obtidos anteriormente pelo R. Possíveis diferenças de sinal (+ ou -) ocorrem pela codificação das variáveis e não impactam em nada a interpretação dos achados A interpretação dos resultados agora pode ser feita considerando o valor de P, o tamanho do efeito e as comparações pareadas. Eventualmente, a apresentação de um gráfico de diferenças oferece um recurso visual adicional (e importante) para auxiliar no entendimento dos achados. Para fazer isso, é necessário clicar em Descriptive plots. Em seguida, é necessário levar a variável escolaridade_fct para o Horizontal axis, marcar a opção Display Error bars e Standard error. O resultado será como abaixo. 7.11 Escrita dos resultados Os resultados serão escritos apresentado os achados principais da ANOVA e as comparações pareadas com seus valores de P corrigidos. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA). Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de uma via investigando o efeito da escolaridade no empreendedorismo, medido por um escala específica. Foi possível concluir que a escolaridade é significativa (F(3, 143) = 8.23, p &lt; 0.01, ηp2 = 0.15, 90% CI [.06, .22]). As comparações pareadas foram ajustadas pela técnica de Bonferroni e mostraram que os participantes com ensino superior apresentam pontuação mais alta do que àqueles com o primário (Δ = 7.16, p &lt; 0.001), ginásio (Δ = 5.07, p &lt; 0.001) e colegial (Δ = 2.96, p &lt; 0.05). 7.12 Resumo A ANOVA de uma via pode tanto ser entendida como um super Teste T, como um caso particular de um modelo de regressão Testes post hoc e resultados globais da ANOVA não respondem às mesmas perguntas As comparações pareadas devem proteger a inflação do erro do tipo 1, sem gerar o erro do tipo 2 7.13 Pesquisas adicionais Cognitive Processes and Memory Differences in Recall and Recognition in Adults Nesta pesquisa, cerca de 150 estudantes foram apresentados a um filme e depois tiveram que lembrar algumas cenas. Três grupos distintos foram formados. Em um grupo, uma recordação com pistas foi implementada, em outro, técnicas de reconhecimento foram utilizadas e o terceiro grupo teve de fazer uma recordação livre, sem nenhum suporte adicional. 7.14 Pesquisa Base: Base - MEMORE 2020 Automated model selection Nas próximas seções, vamos usar parcialmente a pesquisa intitulada “Propriedades psicométricas de instrumento de Memória Visual de Curto Prazo (MEMORE)”, publicada em 2020, em que sou o principal autor. Nesta pesquisa, apresentamos algumas propriedades psicométricas de um teste psicológico desenvolvido para avaliar aspectos da memória de curto prazo (MEMORE), bem como análises estatísticas para investigar o efeito de atributos psicológicos nos resultados obtidos pelos participantes neste teste específico. 7.15 ANOVA de 2 vias Em grande parte das vezes, o interesse do pesquisador é o de investigar como múltiplos fatores impactam a variável de desfecho. Quando se aumenta o número de variáveis independentes no modelo, consequentemente se aumenta a quantidade de vias ou fatores que a ANOVA possui. Na pesquisa de agora, como o interesse foi investigar o efeito da escolaridade e da faixa etária, trata-se de uma ANOVA de 2 vias. Na ANOVA de 2 vias, dois modelos principais podem ser calculados. O primeiro é chamado de “modelo aditivo”, em que não se estipulam interações entre os fatores. O segundo modelo é denominado como “não aditivo” ou “saturado” e ocorre quando uma interação entre os fatores é definida. Nesta seção, será apresentado o modelo aditivo, enquanto na seção ANOVA fatorial, o modelo saturado será descrito. Conceitualmente, na ANOVA de duas vias sem interação, temos: \\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) é a inclinação da primeira VI \\(X_1\\) é a primeira variável independente \\(b_2\\) é a inclinação da segunda VI \\(X_2\\) é a segunda variável independente \\(\\epsilon_{i}\\) é o erro/resíduo 7.16 Execução no R A modelagem no R segue o mesmo padrão da feita anteriormente, iniciando pela codificação dos dados. É importante frisar que erros nesta etapa podem distorcer totalmente os resultados. Na variável faixa etária há rótulos para cada intervalo, tornando a interpretação bastante fácil e intuitiva. Na variável escolaridade, se utilizou valores de 1 a 3 para identificar o ensino fundamental, médio e superior. ds &lt;- ds %&gt;% mutate(escolaridade_grupo = factor(escolaridade_grupo), faixa_etaria = factor(faixa_etaria)) Os dados apresentam casos ausentes na variável faxa etária e escolaridade. Muitas ações devem ser feitas para lidar com esta condição. No entanto, apenas para finalidade pedagógica, esses valores não serão utilizados nestas análises de agora. ds &lt;- ds %&gt;% filter(!is.na(faixa_etaria) &amp; !is.na(escolaridade_grupo)) A apresentação de tabelas e gráficos que possibilitem uma primeira descrição dos dados é importante e deve ser realizado. Na tabela a seguir, as linhas irão reunir a faixa etária, enquanto as colunas reunirão a escolaridade. ds %&gt;% group_by(escolaridade_grupo, faixa_etaria) %&gt;% summarise_at(vars(memore_total), lst(n=~n(), mean, sd)) %&gt;% pivot_wider(names_from = escolaridade_grupo, #indexador unico names_sep = &quot;_&quot;, #pode ser removido values_from = c(n:sd)) %&gt;% #organizar valores pander(., split.table = Inf) faixa_etaria n_1 n_2 n_3 mean_1 mean_2 mean_3 sd_1 sd_2 sd_3 Entre 14 e 24 2 240 580 5 12.94 11.8 1.414 5.377 5.81 Entre 25 e 34 13 112 189 6.308 12.62 11.77 7.25 7.088 6.066 Entre 35 e 44 26 93 69 5.769 6.882 9.246 6.308 5.128 6.251 Entre 45 e 54 15 50 28 4.8 5.92 7.643 4.057 4.517 6.843 Entre 55 e 64 3 5 9 5.333 5.6 6.667 6.11 3.847 8.544 Gráficos específicos com relações bivariadas ajudam em uma primeira sondagem dos padrões. gridExtra::grid.arrange( ggplot(ds, aes(x=escolaridade_grupo, y = memore_total, fill = escolaridade_grupo)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;) + theme(legend.position = &quot;none&quot;), ggplot(ds, aes(x = faixa_etaria, y = memore_total, fill = faixa_etaria)) + geom_bar(stat = &quot;summary&quot;) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;) + theme(legend.position = &quot;none&quot;)) Por sua vez, gráficos mais complexos, que reúnem mais informações, também são úteis. ggplot(ds, aes(x = faixa_etaria, y = memore_total, fill = escolaridade_grupo)) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;, fun = mean) + theme(legend.position = &quot;bottom&quot;) É importante ter atenção que este gráfico não é necessariamente o melhor para uma ANOVA de 2 vias (aditiva), uma vez que pode sugerir algum relacionamento entre as variáveis independentes. Esse aspecto será melhor debatido na seção de ANOVA Fatorial. Agora, formalmente a modelagem poderá será feita. Os passos devem ser exatamente os mesmos aos performados anteriormente, incluindo a verificação de pressupostos e interpretação dos resultados. Para realizar a ANOVA de duas vias, é possível contar com a função lm ou aov. Aqui, a escolha da lm foi apenas por conveniência e o vetor mod_escolaridade_faixa_etaria irá armazenar os resultados. mod_escolaridade_faixa_etaria &lt;- lm(memore_total ~ escolaridade_grupo + faixa_etaria, ds) A tabela padronizada da ANOVA de duas vias, disponível na maioria dos pacotes comerciais, é a seguinte: Preditor Soma dos Quadrados Graus de liberdade Quadrado médio Estat. F Fator (A) Entre (SS(A)) K(A)-1 MS(A) = SS(A)/K-1 F = MS(A)/MSW Fator (B) Entre (SS(B)) K(B)-1 MS(B) = SS(B)/K-1 F = MS(B)/MSW Resíduo Dentro (SSW) N-1-(df(A)+df(B)) MSW = SSW/N-1-(df(A)+df(B)) Posto isso, os resultados obtidos são: apaTables::apa.aov.table(mod_escolaridade_faixa_etaria) %&gt;% pander() ## Warning in pander.default(.): No pander.method for &quot;apa_table&quot;, reverting to ## default. table_number: NA table_title: ANOVA results using memore_total as the dependent variable table_body: Table continues below Predictor SS df MS F p partial_eta2 (Intercept) 4088.33 1 4088.33 117.73 .000 escolaridade_grupo 526.43 2 263.21 7.58 .001 .01 faixa_etaria 4579.98 4 1144.99 32.97 .000 .08 Error 49554.34 1427 34.73 CI_90_partial_eta2 [.00, .02] [.06, .11] table_note: Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared Os achados concluem que o efeito da escolaridade (F(2,1427) = 7.58, p = 0.001, ηp2 = 0.01, 90% CI [.00 .02]) e o efeito da faixa etária são significativos (F(4,1427) = 32.97, p &lt; 0.001, ηp2 = 0.08, 90% CI [.06 .11]). Isso indica que ambas as variáveis tem efeito nos resulatados obtidos na avaliação psicológica. Note que a tabela já reúne a métrica do tamanho do efeito, que é dada pelo eta quadrado parcial. Uma vez que agora a ANOVA apresenta dois fatores, o valor do \\(\\eta_p^2\\) é diferente do \\(\\eta^2\\), mas a interpretação é a mesma da apresentada na ANOVA de 1 via. Da mesma forma que apresentado na ANOVA de 1 via, a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer (Barker &amp; Shaw, 2015; Ernst &amp; Albers, 2017; Lix et al., 1996). Normalidade: O QQ plot abaixo apresenta os valores teóricos e empíricos. Caso ambas as linhas estejam sobrepostas, isso apoia que o pressuposto da normalidade foi atendido. Neste caso, isso não parece ocorrer. olsrr::ols_plot_resid_qq(mod_escolaridade_faixa_etaria) O Shapiro-wilk, Anderson-Darling e Jarque Bera também podem ser utilizado neste caso. A hipótese nula desses testes assumem que os resíduos são normalmente distribuídos. shapiro.test(residuals(mod_escolaridade_faixa_etaria)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod_escolaridade_faixa_etaria) ## W = 0.99336, p-value = 4.896e-06 Os resultados de ambas as técnicas foram similares, indicando a violação da normalidade dos resíduos. Homocedasticidade: Este pressuposto pode ser testado por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico. olsrr::ols_plot_resid_fit(mod_escolaridade_faixa_etaria) O teste de Levene, de Bartlett ou de Breusch-Pagan podem também serem utilzados de maneira formal. Eles estipulam \\(H_0\\) como homocedasticidade e, idealmente, não deve ser rejeitada. olsrr::ols_test_breusch_pagan(mod_escolaridade_faixa_etaria) ## ## Breusch Pagan Test for Heteroskedasticity ## ----------------------------------------- ## Ho: the variance is constant ## Ha: the variance is not constant ## ## Data ## ---------------------------------------- ## Response : memore_total ## Variables: fitted values of memore_total ## ## Test Summary ## ---------------------------- ## DF = 1 ## Chi2 = 0.2612151 ## Prob &gt; Chi2 = 0.6092866 Os resultados indicaram que a homocedasticidade foi preservada. Independência: Esse pressupostos frequentemente não é testado na ANOVA, apesar de ser uma exigência dos modelos lineares. De fato, uma vez que espera-se que os grupos sejam mutuamente excludentes, teria pouco sentido acreditar que os resíduos não fossem independentes. 7.17 Execução no JASP Para executar a ANOVA de 2 vias no JASP, será necessário baixar a base CSV file - MEMORE Cognitive measurement.csv. Após carregar os dados no programa, a seção Descriptives apresentará o gráfico inicial dos resultados. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista Variables irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção Split. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Em seguida, ao clicar na opção Plots, será possível selecionar o Boxplot e Boxplot element. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados da avaliação psicológica em função dos níveis de escolaridade. Uma visualização preliminar indica que pessoas com escolaridade mais elevada (níveis 2 e 3) apresentam resultados maiores do que pessoas com o primeiro nível de escolaridade. Para alterar esta descrição, basta modificar as variáveis de interesse, colocando a faixa_etária, por exemplo. A visualização sugere um padrão, em que pessoas mais velhas apresentam menor desempenho. Por padrão, o JASP não permite integrar os gráficos nesta seção. Isso será realizado posteriormente. Para executar a ANOVA, será necessário clicar na opção ANOVA, Classical e ANOVA. Essa etapa é similar a que foi feita na ANOVA de 1 via. Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir. O espaço de Fixed factors é o local onde as duas VIs deverão ser inseridas. O espaço Dependent Variable é o local onde a VD contínua irá ser inserida. Para realizar a ANOVA de duas vias, as variáveis escolaridade e faixa_etaria deverão ser arrastadas para Fixed factors. A variável memore_total deverá ser colocada em Dependent Variable. O JASP automaticamente irá realizar as contas e apresentar os resultados. No entanto, estes resultados não são estritamente de uma ANOVA de 2 vias aditiva. Repare que, diferente do modelo que planejamos, existe um outro preditor escolaridade x faixa_etaria. Isso ocorre pois, por padrão, o JASP realiza uma ANOVA fatorial, que será discutida a seguir. Para ajustar a modelagem, será necessário clicar em Model, na parte inferior esquerda do programa. Nesta tela, basta clicar em escolaridade x faixa_etaria e transferir do lado direito para o lado esquerdo clicando na seta destacada na imagem. Ao fazer isso, o JASP automaticamente irá realizar as contas e apresentar os resultados. Pragmaticamente, o valor de P é o indicador costumeiramente utilizado para tomar decisões inferenciais. Os valores são exatamente os mesmos obtidos anteriormente na modelagem pelo R, indicando que ambas as variáveis são significativas. Repare que esta tabela inicial não apresenta o tamanho do efeito que deverá ser calculado em seguida, bem como não indica se o modelo respeitou ou violou os pressupostos, que também deverá ser testado Para verificar se os pressupostos de normalidade e homocedasticidade foram respeitados, é necessário clicar em Assumption checks. As opções Homogeneity tests e Q-Q plot of residuals deverão ser marcadas. Repare que pela impressão visual, a normalidade não foi mantida. Além disso, a homocedasticidade foi também violada. É importante ter uma atenção que os resultados do JASP foram divergentes dos resultados do R. Isso se dá pelo teste de homocedasticidade utilizado. No R, o teste foi o breusch Pagan, enquanto no JASP foi o de Levene. Existem algumas saídas para isso, que vão desde modificar a modelagem até não corrigir tais condições e justificar metodologicamente esta escolha. No ambiente JASP, ambas as correções propostas para violação da homocedasticidade não são possíveis para uma ANOVA de 2 vias. Assim, mesmo com ambas as violações, o modelo utilizado não apresentará nenhum ajuste. Antes de voltar à interpretação da ANOVA, é necessário inserir o tamanho do efeito. Para isso, basta clicar em Estimatives of effect size e, em seguida, no eta quadrado parcial (\\(η_p^2\\)). Diferente de uma ANOVA de 1 via, os resultados do \\(η_p^2\\) serão diferentes do (\\(η^2\\)). Uma vez que a ANOVA de 2 vias apresenta dois preditores, o \\(η_p^2\\) informa a variância explicada por cada uma das variáveis após excluir a variância explicada pelas outras. Agora, a interpretação agora pode ser feita integralmente. O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença, com interpretação disposta na tabela precedente neste capítulo. Gráficos específicos são recursos úteis para descrição destes resultados. Eles podem ser feitos clicando em Descriptives Plots, arrastando a faixa_etaria para Horizontal axis e a escolaridade para Separated lines. Para colocar o erro padrão, é necessário clicar em Display error bars e Standard error. Notas: Infelizmente, o JASP não realiza um gráfico completo dessa maneira na seção Descriptives, tal como apresentado. Por vezes, será necessário primeiro rodar integralmente a ANOVA para depois gerar esta apresentação. Quase sempre, o eixo X recebe a variável com maior quantidade de níveis. 7.18 Escrita dos resultados Após a execução de uma ANOVA de duas vias, foi possível concluir que ambas as variáveis foram significativas aos resultados da avaliação psicológica. Abaixo uma sugestão de escrita baseado nas recomendações da American Psychological Association (APA). Como escrever os resultados Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA de duas vias para investigar o efeito da escolaridade e faixa etária nos resultados. Os achados permitiram concluir que tanto a escolaridade (F(2, 1427) = 7.58, p = 0.001, n2p = 0.01), como a faixa etária (F(4, 1427) = 32.972, p &lt; 0.001, n2p = 0.08) tiveram efeito significativo nos resultados. De forma análoga ao que aconteceu na ANOVA de 1 via, os resultados não indicam os níveis em que as diferenças podem existir. Testes post hoc são, novamente, necessários para responder à esta pergunta. 7.19 Post hoc Na ANOVA de duas vias, o post hoc será realizado para cada um dos níveis ou fatores do modelo. Neste caso, escolaridade e faixa_etaria. 7.20 Execução no R O pacote emmeans será utilizado para, inicialmente, verificar cada uma das comparações entre os níveis de escolaridade. É bom notar que os resultados são ajustados pelas outras variáveis que integram o modelo. O vetor post_hoc_twoway_escolaridade reunirá os resultados. post_hoc_twoway_escolaridade &lt;- emmeans(mod_escolaridade_faixa_etaria, &quot;escolaridade_grupo&quot;) %&gt;% pairs(.,adj = &quot;bonferroni&quot;) A apresentação formal ocorre por tabelas, tal como a exposta a seguir. A última coluna p.value apresenta o valor de P corrigido pela técnica de Bonferroni. post_hoc_twoway_escolaridade %&gt;% data.frame() %&gt;% pander() contrast estimate SE df t.ratio p.value 1 - 2 -3.23 0.8339 1427 -3.873 0.0003374 1 - 3 -2.84 0.8368 1427 -3.394 0.002125 2 - 3 0.3898 0.3394 1427 1.149 0.7527 O gráfico a seguir apresenta um resultado mais fácil de interpretar em relação às comparações e também foi realizado também na ANOVA de 1 via. O eixo horizontal tem destaque ao valor 0 e o eixo vertical apresenta todas as comparações. Caso alguma das comparações passe pelo valor 0, isso indica que ela não é significativa. CI &lt;- confint(post_hoc_twoway_escolaridade) ggplot(mapping = aes(contrast, estimate)) + geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) + geom_point(data = summary(post_hoc_twoway_escolaridade)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_size(trans = &quot;reverse&quot;) + coord_flip() É possível concluir que pessoas com nível fundamental, quando comparadas às pessoas de nível médio (Δ = 3.23) e superior (Δ = 2.84), apresentam performance significativamente menor. Pessoas com ensino médio e ensino superior não tem resultados significativamente diferentes. Para comparar os resultados em função de todos os níveis de faixa_etaria, basta customizar um pouco a função. post_hoc_twoway_faixaetaria &lt;- emmeans(mod_escolaridade_faixa_etaria, &quot;faixa_etaria&quot;) %&gt;% pairs(.,adj = &quot;bonferroni&quot;) Agora, a tabela apresenta os resultados das comparações etárias de maneira detalhada. post_hoc_twoway_faixaetaria %&gt;% data.frame() %&gt;% pander() contrast estimate SE df t.ratio p.value Entre 14 e 24 - Entre 25 e 34 0.1818 0.3933 1427 0.4622 1 Entre 14 e 24 - Entre 35 e 44 4.212 0.4979 1427 8.459 6.59e-16 Entre 14 e 24 - Entre 45 e 54 5.501 0.667 1427 8.247 3.654e-15 Entre 14 e 24 - Entre 55 e 64 5.503 1.451 1427 3.792 0.001556 Entre 25 e 34 - Entre 35 e 44 4.03 0.5529 1427 7.289 5.148e-12 Entre 25 e 34 - Entre 45 e 54 5.319 0.7074 1427 7.519 9.698e-13 Entre 25 e 34 - Entre 55 e 64 5.322 1.472 1427 3.616 0.003093 Entre 35 e 44 - Entre 45 e 54 1.289 0.7475 1427 1.724 0.8483 Entre 35 e 44 - Entre 55 e 64 1.292 1.494 1427 0.8644 1 Entre 45 e 54 - Entre 55 e 64 0.002391 1.556 1427 0.001536 1 Conforme previamente descrito, O gráfico é um recurso útil à visualização dos resultados, permitindo que as conclusões tornem-se mais fáceis de serem obtidas. CI &lt;- confint(post_hoc_twoway_faixaetaria) ggplot(mapping = aes(contrast, estimate)) + geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), data = CI) + geom_point(data = summary(post_hoc_twoway_faixaetaria)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + scale_size(trans = &quot;reverse&quot;) + coord_flip() As conclusões indicam que pessoas mais novas (Entre 14 e 24) tem resultados mais elevados do que pessoas Entre 35 e 44 , Entre 45 e 54 e Entre 55 e 64. Participantes Entre 25 e 34 também apresentam resultados maiores do que Entre 35 e 44, Entre 45 e 54 e Entre 55 e 64. Não houve diferença significativa Entre 14 e 24 e Entre 25 e 34, bem como Entre 35 e 44 e Entre 45 e 54 e Entre 55 e 64. Finalmente, participantes Entre 45 e 54 e Entre 55 e 64 também não tiveram resultados significativamente diferentes. 7.21 Execução no JASP Para executar o post hoc no JASP, é necessário clicar em Post Hoc tests na parte esquerda inferior do programa. Em seguida, selecionar ambas as variáveis e clicar na seta para deslocá-las para o lado direito. O JASP apresentará todas as comparações feitas em escolaridade e faixa_etaria, ajustando os resultados por todas as variáveis no modelo e corrigindo o valor de P. Por padrão, a correção de P é feita pelo método de Tukey, que pode ser alterada na seção Correction. Mesmo sem implementar a correção de Bonferroni, os achados são virtualmente idênticos aos obtidos anteriormente pelo R. Possíveis diferenças de sinal (+ ou -) ocorrem pela codificação das variáveis e não impactam em nada a interpretação dos achados. O gráfico feito anteriormente é um forte candidato a também ser inserido para auxiliar a visualização dos achados. A interpretação dos resultados pode ser feita considerando o valor de P, o tamanho do efeito e as comparações pareadas. 7.22 Escrita dos resultados Os resultados serão escritos apresentado os achados principais da ANOVA e as comparações pareadas de ambos os fatores, destacando os valores de P corrigidos. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA). Como escrever os resultados Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA de duas vias para investigar o efeito da escolaridade e faixa etária nos resultados. Os achados permitiram concluir que tanto a escolaridade (F(2, 1427) = 7.58, p = 0.001, n2p = 0.01), como a faixa etária (F(4, 1427) = 32.972, p &lt; 0.001, n2p = 0.08) tiveram efeito significativo nos resultados. Comparações pareadas foram realizadas e os valores de P foram corrigidos pela técnica de Bonferroni. Em relação à escolaridade, pessoas com nível fundamental, quando comparadas às pessoas de nível médio (Δ = -3.23, p &lt; 0.001) e superior (Δ = -2.84, p &lt; 0.001) apresentam performance significativamente menor. Não houve diferença entre participantes com ensino médio e ensino superior. Em relação à faixa etária, participantes entre 14 e 24 anos apresentam performance significativamente maior do que participantes entre 35 e 44 (Δ = 4.21, p &lt; 0.001), entre 45 e e 54 (Δ = 5.50, p &lt; 0.001) e entre 55 e 64 anos (Δ = 5.50, p &lt; 0.001). Participantes entre 25 e 34 anos também apresentam performance significativamente superior do que participantes entre 35 e 44 anos (Δ = 4.03, p &lt; 0.001), entre 45 e 54 (Δ = 5.32, p &lt; 0.001) e entre 55 e 64 anos (Δ = 5.32, p &lt; 0.001). Não houve diferença significativa na performance do grupo entre 14 e 24 anos do grupo entre 25 e 34, bem como entre o grupo entre 35 e 44 e 55 e 64, bem como os participantes com idades entre 45 e 54 daqueles com idade entre 55 e 64. É importante ter em mente que as comparações e os sinais podem ser invertidos para que os resultados tornem-se mais facilmente interpretáveis. 7.23 Resumo A ANOVA de duas vias pode ser feita por um modelo aditivo ou não-aditivo Gráficos costumam ser feitos antes das análises para auxiliar na interpretação dos resultados O modelo aditivo não define interação entre os fatores, enquanto o não-aditivo sim A interpretação dos resultados de um fator é ajustada pelo outro Os post hocs devem ser feitos individualmente para cada fator 7.24 ANOVA Fatorial A ANOVA Fatorial é uma ANOVA de 2 (ou mais) vias, em que se estipulam interações entre os fatores. O conceito de interação se aplica em condições em que o modelo apresenta dois ou mais fatores e o efeito de um fator no desfecho depende do nível dos outros fatores. Assi, é possível perceber que eeste tipo de modelagem estatística costuma vir mais por perguntas específicas e teóricas do que por análises puramente exploratórias. Na prática, na maior parte do tempo que um pesquisador pensa em uma ANOVA de 2 vias, o interesse justamente é o de testar se os fatores apresentam (ou não) uma interação. Talvez seja por isso que a maioria dos programas comerciais realizam, por padrão, uma ANOVA Fatorial quando se solicita uma ANOVA de 2 vias. Conceitualmente, na ANOVA Fatorial, temos: \\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i + b_3(X{_1}_i * X{_2}_i) + \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) é a inclinação da primeira VI \\(X_1\\) é a primeira variável independente \\(b_2\\) é a inclinação da segunda VI \\(X_2\\) é a segunda variável independente \\(b_3\\) é a inclinação da interação \\(\\epsilon_{i}\\) é o erro/resíduo 7.25 Execução no R Desta vez, a modelagem no R deverá contar com a alteração dos contrastes para assegurar que os valores obtidos serão os mesmos dos programas comerciais e, consequentemente, irão ter a mesma interpretação. Para isso, basta rodar a linha de código a seguir: options(contrasts = c(&quot;contr.helmert&quot;, &quot;contr.poly&quot;)) Após esta etapa, todo o restante segue o mesmo padrão da feita anteriormente, iniciando pela codificação dos dados. É importante frisar que erros nesta etapa podem distorcer totalmente os resultados. Na variável faixa etária há rótulos para cada intervalo, tornando a interpretação bastante fácil e intuitiva. Na variável escolaridade, se utilizou valores de 1 a 3 para identificar o ensino fundamental, médio e superior. ds &lt;- ds %&gt;% mutate(escolaridade_grupo = factor(escolaridade_grupo), faixa_etaria = factor(faixa_etaria)) Os dados apresentam casos ausentes na variável faxa etária e escolaridade. Muitas ações devem ser feitas para lidar com esta condição. No entanto, apenas para finalidade pedagógica, esses valores não serão utilizados nestas análises de agora. ds &lt;- ds %&gt;% filter(!is.na(faixa_etaria) &amp; !is.na(escolaridade_grupo)) A apresentação de tabelas e gráficos que possibilitem uma primeira descrição dos dados é importante e deve ser realizado. Na tabela a seguir, as linhas irão reunir a faixa etária, enquanto as colunas reunirão a escolaridade. ds %&gt;% group_by(escolaridade_grupo, faixa_etaria) %&gt;% summarise_at(vars(memore_total), lst(n=~n(), mean, sd)) %&gt;% pivot_wider(names_from = escolaridade_grupo, #indexador unico names_sep = &quot;_&quot;, #pode ser removido values_from = c(n:sd)) %&gt;% #organizar valores pander(., split.table = Inf) faixa_etaria n_1 n_2 n_3 mean_1 mean_2 mean_3 sd_1 sd_2 sd_3 Entre 14 e 24 2 240 580 5 12.94 11.8 1.414 5.377 5.81 Entre 25 e 34 13 112 189 6.308 12.62 11.77 7.25 7.088 6.066 Entre 35 e 44 26 93 69 5.769 6.882 9.246 6.308 5.128 6.251 Entre 45 e 54 15 50 28 4.8 5.92 7.643 4.057 4.517 6.843 Entre 55 e 64 3 5 9 5.333 5.6 6.667 6.11 3.847 8.544 O gráfico dessa vez deve ser o mais completo o possível, indicando as três variáveis que estão sendo trabalhadas: escolaridade, faixa etária e memore_total. Tipicamente, no eixo X se coloca a VI com mais níveis, enquanto no agrupador (ou cluster), se coloca a VI com menos. ggplot(ds, aes(x = faixa_etaria, y = memore_total, fill = escolaridade_grupo)) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;, fun = mean) + theme(legend.position = &quot;bottom&quot;) O gráfico parece indicar que a performance no teste varia tanto em função da idade, como em função da escolaridade. Por exemplo, pessoas entre 14 e 24 anos, bem como entre 25 e 34 anos com ensino médio apresentam o desempenho mais elevado quando comparadas com os outros participantes. No entanto, isso começa a se alterar aos 35 anos. Para estes participantes e aqueles mais velhos, o ensino superior parece ser o principal determinante. Agora, formalmente a modelagem poderá será feita. Os passos devem ser exatamente os mesmos aos performados anteriormente, incluindo a verificação de pressupostos e interpretação dos resultados. Para realizar a ANOVA Fatorial, é possível contar com a função lm ou aov. Aqui, a escolha da lm foi apenas por conveniência e o vetor mod_escolaridade_faixa_etaria_fatorial irá armazenar os resultados. mod_escolaridade_faixa_etaria_fatorial &lt;- lm(memore_total ~ escolaridade_grupo * faixa_etaria, ds) Repare que não é preciso descrever integralmente a equação na linha de código. Ao usar o símbolo *, o R já faz o restante. A tabela padronizada da ANOVA Fatorial, disponível na maioria dos pacotes comerciais, é a seguinte: Fonte de variação Soma dos Quadrados Graus de liberdade Quadrado médio Estat. F Fator (A) Entre (SS(A)) K(A)-1 MS(A) = SS(A)/K-1 F = MS(A)/MSW Fator (B) Entre (SS(B)) K(B)-1 MS(B) = SS(B)/K-1 F = MS(B)/MSW Interação (AB) Entre (SS(AB)) (K(A)-1)*(K(B)-1) MS(AB) = SS(AB)/(K(A)-1)*(K(B)-1) F = MS(AB)/MSW Resíduo Dentro (SSW) N-(K(A)*K(B)) MSW = SSW/N-(K(A)*K(B)) Posto isso, os resultados obtidos são: apaTables::apa.aov.table(mod_escolaridade_faixa_etaria_fatorial) %&gt;% pander(., split.table = Inf) ## Warning in pander.default(., split.table = Inf): No pander.method for ## &quot;apa_table&quot;, reverting to default. table_number: NA table_title: ANOVA results using memore_total as the dependent variable table_body: Table continues below Predictor SS df MS F p (Intercept) 9803.04 1 9803.04 284.65 .000 escolaridade_grupo 335.13 2 167.56 4.87 .008 faixa_etaria 949.77 4 237.44 6.89 .000 escolaridade_grupo x faixa_etaria 684.88 8 85.61 2.49 .011 Error 48869.45 1419 34.44 partial_eta2 CI_90_partial_eta2 .01 [.00, .01] .02 [.01, .03] .01 [.00, .02] table_note: Note: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared A interpretação de uma ANOVA Fatorial tem algumas heurísticas: Sempre se começa pela interação (ou seja, de baixo para cima) Caso a interação seja significativa, não se interpreta os efeitos principais Caso a interação não seja significativa, a interpretação é a mesma da ANOVA de 1 ou 2 vias, anteriormente descritas No caso de agora, os achados indicam que o efeito da interação entre escolaridade e faixa etária é significativo (F(8, 1419) = 2.49, p = 0.011, n2p = 0.1, 90% CI [.00 .02]), bem como são também significativos os efeitos da escolaridade (F(2, 1419) = 4.87, p = 0.008, n2p = 01, 90% CI [.00 .01]) e da faixa etária (F(4, 1419) = 6.89, p &lt; 0.001, n2p = 02, 90% CI [.01 .03]). Como a interação foi significativa, deve-se evitar a interpretação dos efeitos principais, uma vez que os níveis de um fator podem impactar na interpretação de outro. Note que a métrica do tamanho do efeito é o \\(\\eta_p^2\\) e já está na tabela. Sua interpretação é a mesma dos modelos mostrados anteriormente neste capítulo. Da mesma forma que apresentado no decorrer deste capítulo, a validade da interpretação dos resultados depende dos pressupostos do modelo estatístico. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer (Barker &amp; Shaw, 2015; Ernst &amp; Albers, 2017; Lix et al., 1996). Normalidade: O QQ plot abaixo apresenta os valores teóricos e empíricos. Caso ambas as linhas estejam sobrepostas, isso apoia que o pressuposto da normalidade foi atendido. Neste caso, isso não parece ocorrer. olsrr::ols_plot_resid_qq(mod_escolaridade_faixa_etaria_fatorial) O Shapiro-wilk, Anderson-Darling e Jarque Bera também podem ser utilizado neste caso. A hipótese nula desses testes assumem que os resíduos são normalmente distribuídos. shapiro.test(residuals(mod_escolaridade_faixa_etaria_fatorial)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod_escolaridade_faixa_etaria_fatorial) ## W = 0.99412, p-value = 1.898e-05 Os resultados de ambas as técnicas foram similares, indicando a violação da normalidade dos resíduos. Homocedasticidade: Este pressuposto pode ser testado por um gráfico dos resíduos contra os valores previstos. O ideal é não encontrar padrões no gráfico. olsrr::ols_plot_resid_fit(mod_escolaridade_faixa_etaria_fatorial) O teste de Levene, de Bartlett ou de Breusch-Pagan podem também serem utilzados de maneira formal. Eles estipulam \\(H_0\\) como homocedasticidade e, idealmente, não deve ser rejeitada. olsrr::ols_test_breusch_pagan(mod_escolaridade_faixa_etaria_fatorial) ## ## Breusch Pagan Test for Heteroskedasticity ## ----------------------------------------- ## Ho: the variance is constant ## Ha: the variance is not constant ## ## Data ## ---------------------------------------- ## Response : memore_total ## Variables: fitted values of memore_total ## ## Test Summary ## ---------------------------- ## DF = 1 ## Chi2 = 2.116801 ## Prob &gt; Chi2 = 0.1456906 Os resultados obtidos pelo teste de Breusch Pagan Test indicaram que a homocedasticidade foi preservada. Independência: Esse pressupostos frequentemente não é testado na ANOVA, apesar de ser uma exigência dos modelos lineares. De fato, uma vez que espera-se que os grupos sejam mutuamente excludentes, teria pouco sentido acreditar que os resíduos não fossem independentes. 7.26 Execução no JASP Para executar a ANOVA Fatorial no JASP, será necessário baixar a base CSV file - MEMORE Cognitive measurement.csv. Após carregar os dados no programa, a seção Descriptives apresentará o gráfico inicial dos resultados. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista Variables irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção Split. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Em seguida, ao clicar na opção Plots, será possível selecionar o Boxplot e Boxplot element. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados da avaliação psicológica em função dos níveis de escolaridade. Uma visualização preliminar indica que pessoas com escolaridade mais elevada (níveis 2 e 3) apresentam resultados maiores do que pessoas com o primeiro nível de escolaridade. Para alterar esta descrição, basta modificar as variáveis de interesse, colocando a faixa_etária, por exemplo. A visualização sugere um padrão, em que pessoas mais velhas apresentam menor desempenho. Por padrão, o JASP não permite integrar os gráficos nesta seção. Isso será realizado posteriormente. Para executar a ANOVA, será necessário clicar na opção ANOVA, Classical e ANOVA. Essa etapa é similar a que foi feita na ANOVA de 1 via. Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir. O espaço de Fixed factors é o local onde as duas VIs deverão ser inseridas. O espaço Dependent Variable é o local onde a VD contínua irá ser inserida. Para realizar a ANOVA de duas vias, as variáveis escolaridade e faixa_etaria deverão ser arrastadas para Fixed factors. A variável memore_total deverá ser colocada em Dependent Variable. O JASP automaticamente irá realizar as contas e apresentar os resultados da ANOVA Fatorial. Repare que, diferente do modelo visto anteriormente, agora a ANOVA reúne os resultados de escolaridade, faixa etária e escolaridade x faixa etaria. Pragmaticamente, o valor de P é o indicador costumeiramente utilizado para tomar decisões inferenciais. Os valores são exatamente os mesmos obtidos anteriormente na modelagem pelo R, indicando que o efeito da interação entre escolaridade e faixa etária é significativo (F(8, 1419) = 2.49, p = 0.011), bem como são também significativos os efeitos da escolaridade (F(2, 1419) = 4.87, p = 0.008) e da faixa etária (F(4, 1419) = 6.89, p &lt; 0.001). Como a interação foi significativa, deve-se evitar a interpretação dos efeitos principais, uma vez que os níveis de um fator podem impactar na interpretação de outro. Esta tabela inicial não apresenta o tamanho do efeito e também não indica se o modelo respeitou ou violou os pressupostos. Para verificar se os pressupostos de normalidade e homocedasticidade foram respeitados, é necessário clicar em Assumption checks. As opções Homogeneity tests e Q-Q plot of residuals deverão ser marcadas. Repare que pela impressão visual, a normalidade não foi mantida. Além disso, a homocedasticidade foi também violada. É importante ter uma atenção que os resultados do JASP foram divergentes dos resultados do R. Isso se dá pelo teste de homocedasticidade utilizado. No R, o teste foi o breusch Pagan, enquanto no JASP foi o de Levene. Existem algumas saídas para isso, que vão desde modificar a modelagem até não corrigir tais condições e justificar metodologicamente esta escolha. No ambiente JASP, ambas as correções propostas para violação da homocedasticidade não são possíveis para uma ANOVA de 2 vias (incluindo a Fatorial). Assim, mesmo com ambas as violações, o modelo utilizado não apresentará nenhum ajuste. Antes de voltar à interpretação da ANOVA, é necessário inserir o tamanho do efeito. Para isso, basta clicar em Estimatives of effect size e, em seguida, no eta quadrado parcial (\\(η_p^2\\)). Diferente de uma ANOVA de 1 via, os resultados do \\(η_p^2\\) serão diferentes do (\\(η^2\\)). Uma vez que a ANOVA Fatorial apresenta dois preditores, o \\(η_p^2\\) informa a variância explicada por cada uma das variáveis após excluir a variância explicada pelas outras. Agora, a interpretação agora pode ser feita integralmente. O valor de P irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença, com interpretação disposta na tabela precedente neste capítulo. Gráficos específicos são recursos úteis para descrição destes resultados. Eles podem ser feitos clicando em Descriptives Plots, arrastando a faixa_etaria para Horizontal axis e a escolaridade para Separated lines. Para colocar o erro padrão, é necessário clicar em Display error bars e Standard error. Notas: Infelizmente, o JASP não realiza um gráfico completo dessa maneira na seção Descriptives, tal como apresentado. Por vezes, será necessário primeiro rodar integralmente a ANOVA para depois gerar esta apresentação. Quase sempre, o eixo X recebe a variável com maior quantidade de níveis. 7.27 Escrita dos resultados Os resultados serão escritos apresentado os achados principais da ANOVA, destacando se o efeito da interação foi significativo ou não. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA). Como escrever os resultados Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA Fatorial para investigar o efeito da escolaridade, faixa etária, e de uma interação entre esses dois fatores nos resultados. Os resultados concluíram que a interação entre os fatores foi significativa (F(8, 1419) = 2.486, p = 0.011, n2p = 0.014), bem como a escolaridade (F(2, 1419) = 4.865, p = 0.008, n2p = 0.007) e a faixa etária (F(4, 1419) = 2.6.894, p &lt; 0.001, n2p = 0.019). 7.28 Resumo A ANOVA Fatorial é um modelo feito para testar se os fatores apresentam ou não uma interação A interpretação do modelo deve começar pela interação. Caso significativa, não se interpreta os efeitos principais Os gráficos costumam ser ótimos recursos para entender o padrão dos resultados de maneira rápida De forma análoga ao que aconteceu nos outros exemplos, os resultados até aqui obtidos não indicam quais níveis em que as diferenças podem existir. Testes post hoc são necessários para responder à esta pergunta 7.29 Post hoc As comparações Post hoc de uma ANOVA Fatorial podem ser feitas de duas maneiras, a depender do interesse do pesquisador. É possível comparar todos os níveis presentes em ambas as variáveis ou comparar todos os níveis de uma variável específica, enquanto outra é mantida constante. No primeiro caso, um exemplo seria a comparação de pessoas com ensino fundamental entre 14 e 24 anos contra pessoas com ensino superior entre 35 e 44 anos. No segundo caso, a comparação ocorreria entre todas as faixas de escolaridade em pessoas entre 14 e 24 anos ou pessoas entre 25 e 34 anos, etc. Normalmente, os post hocs são feitos após o pesquisador olhar os gráficos e os resultados obtidos podem confir ou não uma expectativa prévia. Os programas estatísticos comerciais tendem a realizar o segundo formato de análise, em que todas as interações intra-níveis são feitas após manter um nível de outro fator constante. Uma hipótese é que essa escolha ocorre para prevenir o erro do tipo 2. Uma vez que as correções para valor de P implementadas dependem da quantidade de comparações feitas, ao se comparar todos os níveis de um fator contra todos os níveis de outro fator, seria pouco provável ter resultados significativos. Neste caso, o post hoc será feito para todos os níveis de escolaridade com pessoas na faixa etária Entre 14 e 24. Em seguida, novamente todos os níveis de escolaridade serão comparados com pessoas na faixa etária Entre 25 e 34 e assim por diante. Essa escolha reflete o que foi apresentado no gráfico introdutório desta seção. O vetor post_hoc_fatorial será computado e armazenará os resultados. post_hoc_fatorial &lt;- emmeans(mod_escolaridade_faixa_etaria_fatorial, pairwise ~ escolaridade_grupo | faixa_etaria, adj = &quot;bonferroni&quot;) post_hoc_fatorial$contrasts %&gt;% data.frame %&gt;% pander() contrast faixa_etaria estimate SE df t.ratio p.value 1 - 2 Entre 14 e 24 -7.942 4.167 1419 -1.906 0.1706 1 - 3 Entre 14 e 24 -6.797 4.157 1419 -1.635 0.3068 2 - 3 Entre 14 e 24 1.145 0.4504 1419 2.542 0.03335 1 - 2 Entre 25 e 34 -6.317 1.719 1419 -3.674 0.0007432 1 - 3 Entre 25 e 34 -5.46 1.683 1419 -3.245 0.003611 2 - 3 Entre 25 e 34 0.8578 0.6998 1419 1.226 0.6614 1 - 2 Entre 35 e 44 -1.112 1.302 1419 -0.8545 1 1 - 3 Entre 35 e 44 -3.477 1.35 1419 -2.575 0.03039 2 - 3 Entre 35 e 44 -2.365 0.9324 1419 -2.536 0.03396 1 - 2 Entre 45 e 54 -1.12 1.728 1419 -0.6483 1 1 - 3 Entre 45 e 54 -2.843 1.878 1419 -1.514 0.3908 2 - 3 Entre 45 e 54 -1.723 1.385 1419 -1.244 0.6414 1 - 2 Entre 55 e 64 -0.2667 4.286 1419 -0.06222 1 1 - 3 Entre 55 e 64 -1.333 3.912 1419 -0.3408 1 2 - 3 Entre 55 e 64 -1.067 3.273 1419 -0.3259 1 O gráfico dessa vez será feito pela função emmip do pacote emmeans, que deve apresentar os mesmos resultados obtidos na tabela. emmip(mod_escolaridade_faixa_etaria_fatorial, escolaridade_grupo ~ faixa_etaria, CIs = TRUE) Entre as conclusões possíveis, se constata, de maneira contraintuitiva, que pessoas entre 14 e 24 anos com ensino médio apresentam performance maior do que pessoas com ensino superior (Δ = 1.145). Por sua vez, não há diferença na performance entre pessoas entre 25 e 34 anos que possuem o ensino médio ou ensino superior. No entanto, pessoas que tem essa idade, mas apresentam o ensino fundamental possuem performance significativamente menor do que seus pares com ensino médio (Δ = -6.317) ou superior (Δ = -5.46). Pessoas entre 35 e 44 anos com ensino superior apresentam performance mais elevada do que seus pares com ensino médio (Δ = 2.365) ou fundamental (Δ = 3.477). 7.30 Execução no JASP Para executar o post hoc no JASP, é necessário clicar em Post Hoc tests na parte esquerda inferior do programa. Em seguida, selecionar todas as variáveis e clicar na seta para deslocá-las para o lado direito. O JASP apresentará todas as comparações feitas em escolaridade, faixa_etaria e escolaridade x faixa etária, ajustando os resultados por todas as variáveis no modelo e corrigindo o valor de P. Por padrão, a correção de P é feita pelo método de Tukey, que pode ser alterada na seção Correction. A interpretação principal é para interação escolaridade x faixa etária. No entanto, diferente do R, nesta versão do JASP não é possível reproduzir a análise feita em que a comparação entre todos os níveis de um fator é realizada enquanto se mantém o outro constante. Essa condição pode impactar um pouco na interpretação dos resultados, uma vez que os valores de P serão mais altos do que os previamente encontrados. O gráfico feito anteriormente é um forte candidato a também ser inserido para auxiliar a visualização dos achados. A interpretação dos resultados pode ser feita considerando o valor de P, o tamanho do efeito e as comparações pareadas. 7.31 Escrita dos resultados Os resultados serão escritos apresentado os achados principais da ANOVA, destacando se o efeito da interação foi significativo ou não e as comparações pareadas. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA). Como os resultados do R e do JASP foram um pouco diferente nas comparações pareadas, o R será utilizado como principal. Como escrever os resultados Os dados obtidos na avaliação psicológica foram analisados por uma ANOVA Fatorial para investigar o efeito da escolaridade, faixa etária, e de uma interação entre esses dois fatores nos resultados. Os resultados concluíram que a interação entre os fatores foi significativa (F(8, 1419) = 2.486, p = 0.011, n2p = 0.014), bem como a escolaridade (F(2, 1419) = 4.865, p = 0.008, n2p = 0.007) e a faixa etária (F(4, 1419) = 2.6.894, p &lt; 0.001, n2p = 0.019). Em situações em que a interação é significativa os efeitos principais não são interpretados, já que os resultados podem depender de níveis específicos de cada uma das variáveis. As comparações pareadas foram feitas entre todos os níveis de escolaridade se mantendo a faixa etária constante e ajustando o valor de P pela técnica de Bonferroni. Pessoas entre 14 e 24 anos com ensino médio apresentam performance superior que seus pares com ensino superior (Δ = 1.145, p = 0.003). Pessoas ebtre 25 e 34 anos, com nível fundamental, têm performance significativamente mais baixa do que seus pares com ensino médio (Δ = -6.317, p &lt; 0.001) e superior (Δ = -5.46, p &lt; 0.001). Finalmente, pessoas entre 35 e 44 anos com ensino superior tem performance significativamente maior do que aquelas com ensino fundamental (Δ = 3.447, p &lt; 0.001) e médio (Δ = 2.365, p &lt; 0.001). É importante ter em mente que as comparações e os sinais podem ser invertidos para que os resultados tornem-se mais facilmente interpretáveis. References "],
["anova-de-medidas-repetidas.html", "Cap. 8 ANOVA de medidas repetidas 8.1 Pesquisa 8.2 Execução no R 8.3 Tamanho do efeito 8.4 Execução no JASP 8.5 Escrita dos resultados 8.6 Resumo", " Cap. 8 ANOVA de medidas repetidas Objetivos do capítulo 1. Apresentar a ANOVA de Medidas Repetidas 2. Realizar passo-a-passo a modelagem analítica 3. Verificar os pressupostos e implementar as correções sugeridas 4. Escrever os resultados A ANOVA de medidas repetidas é um teste estatístico para a análise de dados longitudinais pareados. Isto significa que o mesmo conjunto de participantes foi acompanhado e avaliado no decorrer do tempo. Esta técnica pode ser entendida como uma expansão da ANOVA ou um caso especial do Modelo Linear de Efeitos Mistos (LMM). Os pressupostos deste teste são próximos aos discutidos em outros testes inferenciais: (i) Os dados são aleatórios e representativos da população (ii) a variável dependente é contínua (iii) Os resíduos do modelo são normalmente distribuídos (iv) há esfericidade dos grupos 8.1 Pesquisa Base: R - Base Lidia Carprofeno A esse momento, vamos ter como referência de análise a pesquisa intitulada “Avaliação psicométrica em português do indicador de dor crônica de Helsinki em cães com sinais crônicos de osteoartrite”, que tem como primeira autora Lídia Matsubara e eu sou coautor. Essa pesquisa foi publicada no “Arquivo Brasileiro de Medicina Veterinária e Zootecnia” em 2019 e objetivou tanto verificar o efeito do medicamento Carprofeno em sintomas relacionados à dor crônica, como apresentar estudos psicométricos de uma nova medida clínica. Nessa pesquisa, utilizamos um delineamento experimental. No início, todos os participantes foram avaliados em relação a características clínicas da dor crônica e, em seguida, alocados em dois grupos independentes e de maneira aleatória. Os grupos foram chamados de “grupo experimental” e “grupo controle”. Os participantes do grupo experimental receberam o medicamento específico, enquanto os participantes do grupo controle receberam um placebo, que é uma substância que não possui o princípio ativo do medicamento. Nem os participantes, nem os profissionais sabiam quem estava em cada grupo. A cada duas semanas, durante o tempo de 6 semanas, todos os participantes foram acompanhados e diferentes medições ocorriam para verificar o efeito do medicamento na dor. Para verificar o impacto da retirada do medicamentos, na quarta semana, tanto o medicamento como o placebo foram retirados dos participantes, que foram novamente medidos ao fim da pesquisa, na sexta semana. A imagem a seguir apresenta este processo: Repare que esse tipo de delineamento contou com três elementos importantes em pesquisas experimentais, que são grupos aleatórios, com a presença de uma condição placebo e duplo-cego. 8.2 Execução no R A primeira etapa nesta análise será a consolidação da base de dados. No vetor dados, há todas as variáveis utilizadas na pesquisa em formato largo (wide). Apesar de ser possível trabalhar dessa maneira no R, o formato longo é o mais tipicamente encontrado para análises longitudinais e, por isso, será implementado a seguir. Um novo vetor será chamado de tratamento e irá armazenar os mesmos dados originais, só que agrupados neste novo formato. tratamento &lt;- dados %&gt;% mutate(id = row_number()) %&gt;% select(id, grupo_dummy,starts_with(&quot;total_&quot;)) %&gt;% pivot_longer(-c(id,grupo_dummy), names_to = &quot;tempo&quot;, values_to= &quot;resultado&quot;) %&gt;% rename(grupo = grupo_dummy) %&gt;% filter(grupo &lt; 3) %&gt;% mutate(grupo = factor(if_else(grupo == 1, &quot;Experimental&quot;, &quot;Placebo&quot;))) %&gt;% mutate(tempo = factor(case_when( tempo == &quot;total_w4&quot; ~ &quot;antes&quot;, tempo == &quot;total_w0&quot; ~ &quot;no_dia&quot;, tempo == &quot;total_s2&quot; ~ &quot;semana_2&quot;, tempo == &quot;total_s4&quot; ~ &quot;semana_4&quot;, tempo == &quot;total_s6&quot; ~ &quot;semana_6&quot;, ))) As variávies neste conjunto de dados são: tratamento %&gt;% names() %&gt;% pander() id, grupo, tempo and resultado id refere-se a uma identificação única de cada participante. gupo refere-se ao grupo em que o participante foi alocado, tal como previamente apresentado (controle ou experimental). tempo diz respeito aos 5 pontos de medida e resultado é uma variável aleatória contínua do valor obtido na escala utilizada. É importante saber se os grupos foram balanceados e se houve perda experimental no decorrer do tempo. A tabela a seguir apresenta tais informações. tratamento %&gt;% group_by(grupo, tempo) %&gt;% count() %&gt;% pander() grupo tempo n Experimental antes 21 Experimental no_dia 21 Experimental semana_2 21 Experimental semana_4 21 Experimental semana_6 21 Placebo antes 19 Placebo no_dia 19 Placebo semana_2 19 Placebo semana_4 19 Placebo semana_6 19 Nota-se que apesar de não ter havido perda amostral, os grupos não tiveram a mesma quantidade de participantes. Quando isso ocorre, chama-se de desbalanceamento amostral. A modelagem estatística envolve definir claramente que o resultado é uma função do tempo, do grupo e da interação tempo x grupo. Conforme exposto no decorrer do livro, a primeira etapa analítica consiste na apresentação de tabelas e gráficos. Essas técnicas descritivas são muito informativas e permitem uma rápida compreensão dos resultados. Dessa maneira, a tabela abaixo apresenta os valores da média e do desvio-padrão para todas as condições: tratamento %&gt;% #base de dados group_by(grupo,tempo) %&gt;% #agrupar summarise_at(vars(resultado),lst(mean, sd)) %&gt;% #tirar estatisticas pivot_longer(-c(grupo, tempo), names_to = &quot;medida&quot;) %&gt;% mutate(key = paste0(medida,&quot;=&quot;, value)) %&gt;% #criar um unico inexador select(grupo, tempo, key) %&gt;% #selecionar apenas as 3 variaveis importantes separate(key, into=c(&quot;medida&quot;,&quot;resultado&quot;),sep = &quot;=&quot;, convert = TRUE) %&gt;% #dividir media e desvio pivot_wider(names_from = tempo, values_from = resultado) %&gt;% #alargar pander() grupo medida antes no_dia semana_2 semana_4 semana_6 Experimental mean 17.71 17.38 16.38 14.48 16.62 Experimental sd 4.584 5.527 5.59 6.424 8.237 Placebo mean 15.11 15.95 14.89 14 14.11 Placebo sd 7.915 7.828 7.866 7.242 8.666 O gráfico abaixo também apresenta as mesmas informações, mas insere uma barra com o erro padrão da média. Isso é útil para interpretação inferencial. ggplot(tratamento, aes(x=tempo, y=resultado, group=grupo, color=grupo)) + #variaveis stat_summary(fun = mean, geom = &quot;line&quot;, size=1.0, aes(linetype = grupo)) + #linha stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, size=2, aes(shape = grupo)) + #pontos stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;,size=1) #barra de erro É possível notar que as barras de erro estão superpostas, isto é, uma está contida na outra. Isso ocorre quando não há diferença significativa entre as condições. No entanto, o teste formal estatístico deve ser realizado. Para realizar a ANOVA de Medidas Repetidas, o pacote ez pode ser utilizado: library(ez) Sua sintaxe envolve as seguintes características: data refere-se à base de dados (no formato longo) dv refere-se à variável dependente (contínua) wid refere-se à variável com a identificação única de cada participante within refere-se à variável independente com efeito dentro do tratamento, ou seja, a variável que se repete. Nesse caso, cada uma das semanas between refere-se à variável independente com efeito entre os tratamentos, ou seja, cada um dos grupos type refere-se à forma pela qual a soma dos quadrado será calculada. O tipo 3 emula os resultados dos programas típicos e quase sempre é a melhor opção para finalidade de comparação entre resultados detailed refere-se à apresentação detalhada dos resultados return_aov refere-se à criação de um objeto no formato aov que tem utilidade para análises comparadas posteriores Para deixar o ambiente de programação mais organizado o objeto ez_outcome será criado e irá para armazenar os resultados. ez_outcome &lt;- ezANOVA( data = tratamento, dv = resultado, wid = id, within = tempo, between = grupo, type = 3, detailed = TRUE, return_aov = TRUE) ## Warning: Converting &quot;id&quot; to factor for ANOVA. ## Warning: Data is unbalanced (unequal N per group). Make sure you specified a ## well-considered value for the type argument to ezANOVA(). A mensagem de aviso informa que os grupos estão desbalenceados em relação à quantidade de participantes, o que foi previamente descrito. Abaixo esta o ez_outcome, que é dividido em 4 blocos diferentes: ANOVA, Mauchly's Test for Sphericity, Sphericity Corrections e aov. O tamanho do efeito é calculado pelo eta quadrado generalizado (\\(\\eta^2_G\\)) e está na última coluna da primeira tabela. ez_outcome %&gt;% pander::pander() ANOVA: Effect DFn DFd SSn SSd F p p&lt;.05 ges (Intercept) 1 38 48940 7789 238.8 5.697e-18 * 0.8377 grupo 1 38 144.8 7789 0.7063 0.4059 0.01504 tempo 4 152 146.9 1689 3.304 0.01254 * 0.01526 grupo:tempo 4 152 30.95 1689 0.6962 0.5957 0.003255 Mauchly’s Test for Sphericity: Effect W p p&lt;.05 3 tempo 0.2561 1.322e-07 * 4 grupo:tempo 0.2561 1.322e-07 * Sphericity Corrections: Effect GGe p[GG] p[GG]&lt;.05 HFe p[HF] p[HF]&lt;.05 3 tempo 0.5739 0.0351 * 0.6129 0.03191 * 4 grupo:tempo 0.5739 0.5201 0.6129 0.529 aov: Df Sum Sq Mean Sq F value Pr(&gt;F) grupo 1 144.8 144.8 0.7063 0.4059 Residuals 38 7789 205 NA NA tempo 4 151.2 37.79 3.4 0.01075 grupo:tempo 4 30.95 7.738 0.6962 0.5957 Residuals 152 1689 11.11 NA NA A tabela gerada é bastante extensa e para interpretá-la adequadamente, será necessário testar os pressupostos do modelo a partir de testes estatísticos específicos. Estes testes irão tanto indicar quais são os resultados que deverão ser verificados, como se há segurança na interpretação dos achados Na ANOVA de Medidas Repetidas, é necessário verificar a normalidade e a esfericidade. Normalidade: A ANOVA de tem como um dos pressupostos a normalidade da distribuição dos resíduos. Isso pode ser feito de diferentes maneiras e abaixo há um QQ plot. Caso ambas as linhas estejam sobrepostas, isso gera evidências que o pressuposto foi atendido. Neste caso, isso não ocorre. tratamento %&gt;% mutate(residuos = proj(ez_outcome$aov)[[3]][, &quot;Residuals&quot;]) %&gt;% ggplot(aes(sample=residuos)) + stat_qq() + stat_qq_line() Apesar do gráfico ter sido bastante claro, testes como o Shapiro-wilk, Anderson-Darling e Jarque Bera também podem ser utilizado neste caso. A hipótese nula desses testes assumem que os resíduos são normalmente distribuídos. shapiro.test(proj(ez_outcome$aov)[[3]][, &quot;Residuals&quot;]) ## ## Shapiro-Wilk normality test ## ## data: proj(ez_outcome$aov)[[3]][, &quot;Residuals&quot;] ## W = 0.95677, p-value = 8.986e-06 Este último resultado foi convergente ao já visualizado na apresentação gráfica. Como o valor de p foi inferior ao alfa tipicamente estabelecido (0.05), não seria possível manter o pressuposto da normalidade. Quando isso acontece, é possível implementar ajustes nos dados, substituir o modelo analítico ou seguir a análise após justificar explicitamente essa violação. Esfericidade: A esfericidade na ANOVA de Medidas Repetidas tem um conceito próximo à Homocedasticidade nas ANOVAs vistas anteriormente. Neste delineamento pareado, a esfericidade siginfica que a variância de todas as diferenças entre cada nível de fator é constante. Esse pressuposto é bastante difícil de ser assumido e existem ajustes possíveis em casos em que isso ocorre. Na tabela da ANOVA, o Mauchly's Test for Sphericity é o local que deve ser visualizado para verificar se a esfericidade foi violada ou não. A hipótese nula é definida como presença da esfericidade e idealmente não deve ser rejeitada. Abaixo, a reprodução desta parte da tabela. ez_outcome$`Mauchly&#39;s Test for Sphericity` %&gt;% pander() Effect W p p&lt;.05 3 tempo 0.2561 1.322e-07 * 4 grupo:tempo 0.2561 1.322e-07 * É possível concluir que a esfericidade foi violada mas há algumas saídas para isso. As correções Greenhouse-Geisser (p[GG]) e de Huynh-Feldt tentam corrigir essa violação a partir de ajustes nos graus de liberdade da ANOVA. Os resultados das duas correções costumam ser próximos e, frequentemenet, a correção de Greenhouse-Geisser é utilizada para interpretar os resultados. Com ambas as verificações feitas, é possível interpretar os resultados, que começam sempre pela interação. A interação grupo x tempo não foi significativa: F(4, 152) = 0.696, p = 0.59, p ajustado = 0.52). O efeito do grupo em que o participante foi alocado também não significativo: F(1, 38) = 0.706, p = 0.406). Por sua vez, o passar do tempo foi signicativo: F(4, 152) = 3.304, p = 0.012, p ajustado = 0.035). Frequentemente, os resultados corrigidos e os não-corrigidos concluem na mesma direção. Isso é verdadeiro nesse caso. Repare que os resultados não corrigidos alcancariam as mesmas conclusões: summary(ez_outcome$aov) %&gt;% pander::pander() Df Sum Sq Mean Sq F value Pr(&gt;F) grupo 1 144.8 144.8 0.7063 0.4059 Residuals 38 7789 205 NA NA tempo 4 151.2 37.79 3.4 0.01075 grupo:tempo 4 30.95 7.738 0.6962 0.5957 Residuals 152 1689 11.11 NA NA O valor de P do efeito do tempo saiu de 0.01 (sem correção) para 0.03 (com correção). Já a interação grupo x semana saiu de 0.598 (sem correção) para 0.529 (com correção). Nota: Essa pesquisa não teve resultados significativos e, em função disso, testes post hoc não foram realizados. Entretanto, frequentemente os resultados são significativos e a mecânica das comparações pareadas é próxima ao que foi demonstrado no capítulo de ANOVA Fatorial. 8.3 Tamanho do efeito Resultados significativos não são informativos em relação ao tamanho do efeito. Esta última métrica tem mais contato com as perguntas originalmente realizadas em uma pesquisa e é entendida como uma medida objetiva e padronizada da magnitude de um efeito observado independente da significância estatística. Dessa maneira, o tamanho do efeito pode ser considerado um indicador da relevância clínica dos grupos, cujo uso é sempre importante em pesquisas em Psicologia e áreas da saúde. Na ANOVA de medidas repetidas o eta quadrado parcial (\\(\\eta_p^2\\)) e o eta quadrado generalizado (\\(\\eta^2_G\\)) podem ser calculados. A interpretação do \\(\\eta_p^2\\) é a mesma já apresentada no capítulo sobre ANOVA, enquanto o \\(\\eta^2_G\\) pode ser interpretado segundo a tabela disposta a seguir: eta quadrado generalizado Interpretação \\(\\eta^2_G\\) &lt; 0.02 Irrelevante \\(\\eta^2_G\\) \\(\\geq\\) 0.13 Pequeno \\(\\eta^2_G\\) \\(\\geq\\) 0.06 Moderado \\(\\eta^2_G\\) \\(\\geq\\) 0.26 Grande O tamanho do efeito foi calculado e apresentado na tabela da ANOVA de Medidas Repetidas. 8.4 Execução no JASP A base utilizada será a csv Lidia Carprofeno largo. Essa base reúne todas os dados da pesquisa, incluindo os grupos e as medidas de dor. Após carregar a base no JASP, será necessário apresentar tabelas e gráficos descritivos. Para fazer isso, é necessário clicar em Descriptives. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Na prática, a lista Variables irá reunir as variáveis dependentes, enquanto a variável independente será colocada na seção Split. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Será necessário arrastar a variável grupo para a VI e as variáveis relacionadas à dor para a VD. Estas últimas são total_w4, total_w0, total_s2, total_s4 e total_s6. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização. Em seguida, ao clicar na opção Plots, será possível selecionar o Boxplot e Boxplot element. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da distribuição dos resultados das variáveis da dor em função dos níveis do grupo. Por padrão, o JASP não permite integrar os gráficos nesta seção. Isso será realizado posteriormente. Para executar a ANOVA, será necessário clicar na opção ANOVA, Classical e Repeated Measures ANOVA. Ao realizar isso, a tela a ser exibida será próxima à imagem a seguir. O espaço Repeated Measures Factors é o local onde os nomes devem ser inseridos para representar quantas repetições foram feitas. É possível mudar o nome do argumento para ficar mais fácil. Por exemplo, substituir RM Factor 1 para Tempo. Nesta pesquisa, 5 medições foram feitas e, por isso, sugiro preencher os espaços que começam por level com antes, no dia, semana 2, semana 4 e semana 6. Repare que ao fazer isso, o Repeated Measures Cells também apresentará os nomes escolhidos.. Agora, será necessário levar as variáveis relacionadas à dor para cada lugar disponível em Repeated Measures Cells. Para isso, será necessário selecionar as variáveis e, em seguida, clicar na seta superior à direita, tal como abaixo: Ao fazer isso, o JASP está sendo informado da variação dentro, ou seja, do efeito do tempo em todos os participantes, independentemente dos grupos em que eles foram alocados. No entanto, nesta pesquisa há também um efeito entre os grupos e isso precisa ser estipulado no programa. Para fazer isso, basta arrastar a variaável grupo para Between Subjects Factor. A tela final será próxima à apresentada abaixo: Depois que isso tiver sido feito, o JASP automaticamente irá realizar as contas e apresentar os resultados da ANOVA de Medidas Repetidas. É possível ficar nesta tela e interpretar os resultados, começando sempre pela interação. A interação Tempo x grupo não foi significativa (F(4, 152) = 0.696, p = 0.596) e o Grupo também não (F(1, 38) = 0.706, p = 0.406). De maneira diferente, o efeito do Tempo foi significativo (F(4, 152) = 3.304, p = 0.013). Entretanto, para que a validade dessa interpretação seja assegurada, é necessário testar se os pressupostos do modelo foram respeitados ou rejeitados. Além disso, o cálculo do tamanho do efeito deve ser realizado para otimizar a interpretação dos achados. Os dois principais pressupostos da ANOVA de Medidas Repetidas são a normalidade e a esfericidade. Para verificá-los, é necessário clicar em Assumtpions checks. As opções Sphericity tests deverá ser assinaladas. Repare que o JASP não realiza a verificação da normalidade dos resíduos aqui, bem como deixa a opção de homogeneidade, que não precisa ser acessada agora, já que a esfericidade tende a indicar algo similar. Os resultados do Teste de Mauchly indicaram que o pressuposto da esfericidade foi violado. Dessa maneira, será necessário implementar alguma correção antes de interpretar os resultados. O JASP oferece a correção de Greenhouse-Geisser e a Huynh-Feldt. Ambos os resultados são próximos e, pragmaticamente, vamos optar pela correção de Greenhouse-Geisser, clicando nela. Repare que ao fazer isso, o JASP irá refazer as contas e apresentar os resultados originais e os resultados corrigidos. Antes de fazer a interpretação, será necessário inserir o tamanho do efeito. Para isso, basta clicar em Estimates of effect size, na parte superior do programa. Há quatro opções disponíveis, que são o eta quadrado(\\(\\eta^2\\)), o eta quadrado parcial (\\(\\eta^2_p\\)), o eta quadrado generalizado (\\(\\eta^2_G\\)) e o omega quadrado (\\(\\omega^2\\)). Para garantir os mesmos resultados obtidos anteriormente com o R, será necessário selecionar o \\(\\eta^2_G\\). Agora, a interpretação agora pode ser feita integralmente. O valor de P corrigido irá indicar se a hipótese nula foi rejeitada ou não e o tamanho do efeito irá indicar a relevância da possível diferença, com interpretação disposta na tabela precedente neste capítulo. Gráficos específicos são recursos úteis para descrição destes resultados. Eles podem ser feitos clicando em Descriptives Plots, arrastando o tempo para Horizontal axis e a grupo para Separated lines. Para colocar o erro padrão, é necessário clicar em Display error bars e Standard error. Esse gráfico é muito informativo, mas a impressão visual que ele traz é de que há diferença entre os grupos, o que não foi encontrado no teste de hipóteses modelado anteriormente. Notas: Infelizmente, o JASP não realiza um gráfico completo dessa maneira na seção Descriptives, tal como apresentado. Por vezes, será necessário primeiro rodar integralmente a ANOVA para depois gerar esta apresentação. Quase sempre, o eixo X recebe a variável com maior quantidade de níveis. Nota: Essa pesquisa não teve resultados significativos e, em função disso, testes post hoc não foram realizados. Entretanto, frequentemente os resultados são significativos e a mecânica das comparações pareadas é próxima ao que foi demonstrado no capítulo de ANOVA Fatorial. 8.5 Escrita dos resultados Como escrever os resultados Os dados foram analisados a partir de uma ANOVA de medidas repetidas investigando o efeito fixo do grupo e do tempo, bem como a interação entre ambos. O teste de Mauchly indicou a violação da esfericidade (w = 0.26, p &lt; 0.01) e, portanto, os resultados foram ajustados pelo método de Greenhouse-geisser. Não houve interação significativa entre o grupo e o tempo (F(4, 152) = 0.69, p ajusatdo = 0.520), nem efeito do grupo (F(1, 38) = 0.061, p = 0.406). O passar de tempo foi significativo no resultado, apesar de apresentar um efeito pequeno (F(4, 152) = 3.30, p ajustado = 0.0351, ng2 = 0.01). 8.6 Resumo A ANOVA de medidas repetidas é um teste bastante utilizado quando participantes de mesmos grupos são avaliados longitudinalmente Este modelo pode ser entendido como uma expansão de uma ANOVA ou um caso particular de uma regressão linear de efeitos mistos A execução deste teste no R solicita que a base seja transformada para o formato longo A interpretação dos resultados é, inicialmente, complicada e precisa ser feita de maneira cautelosa Os pacotes estatísticos oferecem correções automáticas para violação de alguns pressupostos Gráficos são muito informativos para uma análise inicial dos dados "],
["modelo-linear-misto.html", "Cap. 9 Modelo linear misto 9.1 Pesquisa 9.2 execução no R 9.3 Resumo", " Cap. 9 Modelo linear misto Objetivos do capítulo 1. Apresentar a ANOVA de Medidas Repetidas. 2. Realizar passo-a-passo a modelagem analítica. 3. Verificar os pressupostos e implementar as correções sugeridas. 4. Escrever os resultados. O modelo linear misto (LMM) é um modelo linear, frequentemente utilizado para trabalhar dados longitudinais ou de medidas repetidas, que possibilita definir tanto parâmetros populacionais (efeitos fixos), como coeficientes individuais (efeitos aleatórios), além do erro experimental. Pragmaticamente, este modelo oferece mais flexibildiade à ANOVA de medidas repetidas e sua utilização vem ganhando mais espaço em Psicologia (Gueorguieva &amp; Krystal, 2004). É importante atentar que os efeitos fixos são compatilhados por todos os indivíduos, enquanto os aleatórios são especificos de cada um dos participantes. Com isso, cada indivíduo tem a sua própria trajetória média (tanto intercepto como inclinação) e um subconjunto dos parâmetros de regressão são tomados como aleatórios. A tabela a seguir compara a ANOVA de medidas repetidas e o LMM Característica ANOVA (MR) Modelo Linear Misto Sujeitos medidos em vários momentos Sim Sim Dados completos em todos os segmentos Sim Não Estimativas de tendências individuais Não Sim Covariáveis tempo-depenentes Não Sim Complexidade computacional Baixa Alta 9.1 Pesquisa A esse momento, vamos ter como referência de análise a pesquisa intitulada “Avaliação psicométrica em português do indicador de dor crônica de Helsinki em cães com sinais crônicos de osteoartrite”, que tem como primeira autora Lídia Matsubara e eu sou co-autor. Essa pesquisa foi previamente utilizada no capítulo de ANOVA de medidas repetidas. Nessa pesquisa, temos um grupo controle e um grupo experimental e todos os participantes foram avaliados em 5 momentos diferentes do tempo: 1 semana antes do início do tratamento (W2), imediatamente antes (W0), duas semanas e quatro semanas após o tratamento ter iniciado (S2 e s4) e após uma semana da retirada do tratamento (s6). Dessa forma, trata-se de um delineamento 2x5, considerando os 2 grupos e as 5 medições ao longo do tempo. A base dados reúne as varáveis da pesquisa em formato largo (wide) Entretanto, o formato longo é o mais tipicamente encontrado para análises longitudinais e, por isso, será imeplementado a seguir. tratamento &lt;- dados %&gt;% mutate(id = row_number()) %&gt;% select(id, grupo_dummy,starts_with(&quot;total_&quot;)) %&gt;% pivot_longer(-c(id,grupo_dummy), names_to = &quot;tempo&quot;, values_to= &quot;resultado&quot;) %&gt;% rename(grupo = grupo_dummy) %&gt;% filter(grupo &lt; 3) %&gt;% mutate(grupo = factor(if_else(grupo == 1, &quot;Placebo&quot;, &quot;Experimental&quot;))) %&gt;% mutate(tempo = factor(case_when( tempo == &quot;total_w4&quot; ~ &quot;antes&quot;, tempo == &quot;total_w0&quot; ~ &quot;no_dia&quot;, tempo == &quot;total_s2&quot; ~ &quot;semana_2&quot;, tempo == &quot;total_s4&quot; ~ &quot;semana_4&quot;, tempo == &quot;total_s6&quot; ~ &quot;semana_6&quot;, ))) As variávies neste conjunto de dados são: tratamento %&gt;% names() ## [1] &quot;id&quot; &quot;grupo&quot; &quot;tempo&quot; &quot;resultado&quot; Dessa forma: id refere-se a uma identificação única de cada participante. grupo refere-se ao grupo em que o participante foi alocado, tal como previamente apresentado (controle ou experimental). tempo diz respeito aos 5 pontos de medida e resultado é uma variável aleatória contínua do valor obtido na escala utilizada. 9.2 execução no R A modelagem será feita via LMM. O pacote lme4 e seu complemento lmerTest serão utilizados. library(lme4) ## Loading required package: Matrix ## ## Attaching package: &#39;Matrix&#39; ## The following objects are masked from &#39;package:tidyr&#39;: ## ## expand, pack, unpack library(lmerTest) ## Warning: package &#39;lmerTest&#39; was built under R version 4.0.2 ## ## Attaching package: &#39;lmerTest&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## lmer ## The following object is masked from &#39;package:stats&#39;: ## ## step A estrutura computacional agora permite incluir tanto efeitos fixos como aleatórios. Quando eles são definidos como correlacionados, se utiliza uma barra verticail (|); quando descorrelacionados, duas barras verticais (||) são utilizadas. Nesta pesquisa, pode-se entender que cada participante tem seu próprio intercepto, ou seja, seu próprio valor de início. A sintaxe a seguinte específica o modelo e o armazena sob nome de mod_lme. mod_lme &lt;- lmer(resultado ~ tempo*grupo + (1|id) , data = tratamento) Repare que esse modelo é composto pelo se seguintes componentes: 1. efeito fixo do tempo 2. efeito fixo do grupo, 3. efeito fixo da interação tempo x grupo 4. efeito aleatório do id, indicando um intercepto aleatório e específico por participante A visualização dessa modelagem é bastante útil para compreender o que significa a ideia de intercepto aleatório. ggplot(tratamento, aes(x=tempo, y=resultado, group=id, color=id, linetype=grupo)) + geom_line(size=1) + geom_hline(yintercept = mean(tratamento$resultado[tratamento$tempo == &quot;antes&quot;]), linetype=&quot;dashed&quot;) + annotate(geom = &quot;text&quot;, x=0.5, y = mean(tratamento$resultado[tratamento$tempo == &quot;antes&quot;])+1, label = &quot;Média&quot;,hjust = 0) Repare que cada participante (id) inicia em um ponto específico e tem uma trajetória específica no decorrer do tratamento. O valor médio antes do tratamento está apresentado pela linha pontilhada. Apesar de informativo, esse gráfico tem pouca aplicação pedagógica e, por isso, não deve ser relatado. Uma vez que o modelo já foi criado, agora é necessário recuperar seus resultados. É importante notar que O pressuposto da normalidade é necessário e ele já foi acessado (e aceito) anteriormente. Conforme dito ao início do capítulo, O LMM relaxa o pressuposto esfericidadde e, por consequência, também o da homogeneidade (Quené &amp; Bergh, 2004). Inicialmente, a anova permite uma visualização de todos os coeficientes do modelo. Isso é importante para verificar cada um dos preditores estipulados e sua significância. A interpretação dos resultados é similar à realizada em modelos de regressão e totalmente convergente ao resultado obtido na ANOVA. Novamente, a leitura da tabela deve começar pela interação. anova(mod_lme) %&gt;% pander::pander() Type III Analysis of Variance Table with Satterthwaite’s method Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) tempo 146.9 36.72 4 152 3.304 0.01254 grupo 7.851 7.851 1 38 0.7063 0.4059 tempo:grupo 30.95 7.738 4 152 0.6962 0.5957 Verifique que a tabela apresenta três os resultados: tempo x grupo, grupo e tempo. A técnica de Satterthwaite’s method é utilizada para corrigir os valores do grau de liberdade e, consequentemente, os valores de p. Os resultados são virtualmente identicos aos obtidos pela ANOVA, com a diferença que os graus de liberdade do numerador de do denominador não foram corrigidos. Para obter as informações completas do modelo, é necessário solicitar o summary. Essa função retorna 4 informações calculadas: Scaled residuals, Random effects, Fixed effects e Correlation of Fixed Effect e serve para aprofundar a interpretação dos resultados. Uma particular diferença entre esse relatório e o da ANOVA de Medidas Repetidas é o np2, que não faz parte do LMM. summary(mod_lme) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: resultado ~ tempo * grupo + (1 | id) ## Data: tratamento ## ## REML criterion at convergence: 1163.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.4365 -0.4386 -0.0476 0.4571 3.8758 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 38.77 6.227 ## Residual 11.11 3.334 ## Number of obs: 200, groups: id, 40 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 15.66241 1.01364 38.00000 15.452 &lt; 2e-16 *** ## tempo1 0.12719 0.37321 152.00000 0.341 0.73372 ## tempo2 -0.29971 0.21547 152.00000 -1.391 0.16628 ## tempo3 -0.49979 0.15236 152.00000 -3.280 0.00129 ** ## tempo4 -0.07506 0.11802 152.00000 -0.636 0.52572 ## grupo1 0.85188 1.01364 38.00000 0.840 0.40593 ## tempo1:grupo1 -0.29386 0.37321 152.00000 -0.787 0.43228 ## tempo2:grupo1 -0.08918 0.21547 152.00000 -0.414 0.67954 ## tempo3:grupo1 -0.17084 0.15236 152.00000 -1.121 0.26393 ## tempo4:grupo1 0.10125 0.11802 152.00000 0.858 0.39228 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) tempo1 tempo2 tempo3 tempo4 grupo1 tmp1:1 tmp2:1 tmp3:1 ## tempo1 0.000 ## tempo2 0.000 0.000 ## tempo3 0.000 0.000 0.000 ## tempo4 0.000 0.000 0.000 0.000 ## grupo1 -0.050 0.000 0.000 0.000 0.000 ## tempo1:grp1 0.000 -0.050 0.000 0.000 0.000 0.000 ## tempo2:grp1 0.000 0.000 -0.050 0.000 0.000 0.000 0.000 ## tempo3:grp1 0.000 0.000 0.000 -0.050 0.000 0.000 0.000 0.000 ## tempo4:grp1 0.000 0.000 0.000 0.000 -0.050 0.000 0.000 0.000 0.000 Como escrever os resultados Os dados foram analisados através de um Modelo Linear de Efeitos Mistos, que verificou o efeito do tempo, do grupo, a interação entre esses dois preditores e permitiu um intercepto aleatório para cada participante. Dessa maneira, esse modelo levou em consideração tanto efeitos fixos quanto aleatórios, além de relaxar alguns pressupostos tradicionais dos modelos de regressão. Os resultados permitem concluir que Não há interação significativa tempo x grupo (F(4, 152 = 0.696), p = 0.696), bem como não há efeito significativo do grupo (F(1, 38 = 0.706), p = 0.706). Em outra direção, o efeito o tempo foi significativo (F(4, 152 = 3.304), p = 0.013) 9.3 Resumo O Modelo Linear de Efeitos Mistos (LMM) oferece maior versatilidade à ANOVA de medidas repetidas A ANOVA tem como pressuposto Normalidade e Esfericidade, enquanto o LMM apenas Normalidade dos resíduos Os resultados frequentemente encontrados em ambos os modelos vão na mesma direção A implementação computacional é mais trabalhosa A escrita apresenta algumas particularidades relacionadas à cada modelo. References "],
["correlação.html", "Cap. 10 Correlação 10.1 Pesquisa 10.2 Execução no R 10.3 Execução no JASP 10.4 Escrita dos resultados 10.5 Resumo 10.6 Pesquisas adicionais", " Cap. 10 Correlação A análise de correlação é um procedimento estatístico para verificar a relação entre duas variáveis. Existem diferentes técnicas correlacionais e a maioria busca medir a força e a direção da associação linear entre duas variáveis aleatórias. A tabela a seguir descreve algumas técnicas. Nível de medida Correlação / Coeficiente Intervalar Correlação Produto momento de Pearson Ordinal Correlação de Spearman Nominal Coeficiente Phi A Correlação de Pearson é uma das mais frequentemente calculadas em Psicologia e outras áreas empíricas e será demonstrada neste capítulo. Entretanto, tenha em mente que algumas áreas específicas costumam utilizar outras correlações. Como exemplo, é bem típico em Psicometria utilizar indicadores categóricos e, com isso, realizar correlações tetracóricas ou policóricas, que não serão abordadas aqui. O coeficiente de correlação é apresentado por \\(\\rho\\) ou r. Ele é formado por um valor numérico e um sinal. A tabela abaixo descreve as possíveis interpretações (Cohen, 1988). Valor/ Sinal Positivo (+) Negativo (-) 0.1 Fraca positiva Fraca negativa 0.3 Moderada positiva Moderada negativa 0.5 Forte positiva Forte negativa O gráfico de dispersão é uma excelente forma de apresentar o relacionamento bivariado e as imagens abaixo demonstram tais conceitos. grid.arrange( ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .1, .1, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;Y (corr. positiva)&quot;) + geom_text(aes(label=paste(&quot;r=+0.1 - fraca&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .3, .3, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;X&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=+0.3 - moderada&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, .5, .5, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=+0.5 - forte&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.1, -.1, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;Y (corr. negativa)&quot;) + geom_text(aes(label=paste(&quot;r=-0.1 - fraca&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.3, -.3, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;X&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=-0.3 - moderada&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), ggplot(data = data.frame(MASS::mvrnorm(n=200, mu=c(0, 0), Sigma=matrix(c(1, -.5, -.5, 1), nrow=2), empirical=TRUE)), aes(x = X1, y = X2)) + geom_jitter() + labs(x= &quot;&quot;, y = &quot;&quot;) + geom_text(aes(label=paste(&quot;r=-0.5 - forte&quot;)), x=-Inf, y=Inf, hjust=-0.2, vjust=1.2), nrow = 2) Para realização da Correlação de Pearson, é necessário que ambas as variáveis sejam contínuas e apresentem relacionamento linear. As seguintes propriedades existem no coeficiente de correlação: É limitado entre -1 e +1, com 0 indicando ausência de correlação O sinal indica a natureza, enquanto o número a força A correlação de uma variável com ela própria é igual a 1 É simétrico, ou seja, r(x,y) = r(y,x) É adimensional e invariante em transformações lineares Sensível aos outliers Não indica causalidade 10.1 Pesquisa Base: Livro - Dados - Eating disorders Vamos utilizar a pesquisa intitulada “Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students”, publicada em 2018 no Global Journal of Educational Studies, que sou coautor. O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e percepção da imagem corporal, bem como verificar a correlação entre eles. Esse artigo contou com a utilização de escalas aplicadas em 219 participantes no Brasil. Para acessar aspectos relacionados aos Transtornos alimentares, a escala EAT-26 foi aplicada. Já para aspectos da imagem corporal, a escala BSQ-34 foi aplicada. 10.2 Execução no R A primeira etapa da análise é orientada a fazer tabelas e gráficos que possam auxiliar na interpretação dos resultados. Abaixo há uma tabela inicial com dados descritivos dos resultados. dados_brasil %&gt;% summarise_at(vars(eat_soma, bsq_soma), lst(n=~n(),media=mean,DP=sd)) %&gt;% t() %&gt;% pander::pander(., split.table = Inf) eat_soma_n 220 bsq_soma_n 220 eat_soma_media 15.95 bsq_soma_media 81.36 eat_soma_DP 9.753 bsq_soma_DP 37 Após isso realizado, o gráfico de dispersão traz um importante auxilio na visualização da relação entre as variáveis e permite verificar se o relacionamento é ou não linear. Apesar de técnicas correlacionais não elegerem uma VI e uma VD, com muita frequência, se usa o eixo X para colocar a variável que se assume (mesmo que teoricamente) como independente. ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() O gráfico indica que as duas variáveis são relacionadas. Apesar do padrão deste relacionamento não ser estritamente linear, é possível verificar formalmente a correlação entre ambas as variáveis, Isso pode ser feito pela função cor.test, que é nativa do R. cor.test(dados_brasil$eat_soma, dados_brasil$bsq_soma) %&gt;% pander() Pearson’s product-moment correlation: dados_brasil$eat_soma and dados_brasil$bsq_soma Test statistic df P value Alternative hypothesis cor 13.52 218 1.156e-30 * * * two.sided 0.6754 Os resultados permitem concluir que a correlação é positiva e forte (r = 0.675), além de significativa (p &lt; 0.001). Isso indica que ambas as variáveis covariam de maneira proporcional, em que valores altos em uma tendem a acompanhar valores altos em outra. É importante atentar que esse relacionamento não indica causalidade e, dessa forma, essa covariação pode ser explicada por diferentes fatores não analisados neste método. A correlação de Pearson não depende estritamente da normalidade das variáveis, apesar desse tema ser bastante discutido. Dessa forma, não há pressupostos para se checar além dos já discutidos no decorrer deste capítulo. 10.3 Execução no JASP Para executar as rotinas, será necessário carregar a base csv eat bsq brasil. Após fazer isso, para realizar tabelas e gráficos descritivos, deve-se clicar em Descriptives , na parte superior do programa. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Apesar de na correlação os conceitos de VI e VD não serem formalmente empregados, a lista Variables costuma reunir as variáveis dependentes, enquanto a seção Split costuma receber a variável independente. É importante atentar à opção Frequency tables (nominal and ordinal), que deve ser marcada quando o nível de medida da variável de interesse for nominal ou ordinal. Será necessário arrastar tanto eat_soma como bsq_soma para o espaço de Variables. Ao fazer isso, o JASP automaticamente irá preencher a tabela previamente exposta com os valores estatísticos obtidos. A média e o desvio-padrão indicam a posição típica dos dados e o afastamento esperado desta localização. Apenas para melhor apresentação dos resultados, é importante que a primeira variável da lista seja bsq_soma. Em seguida, ao clicar na opção Plots, será possível selecionar o Scatter Plots. O gráfico aparecerá abaixo da tabela e irá apresentar diferentes informações estatísticas da relação entre os transtornos alimentares e aspectos da percepção da imagem corporaldo participante. Por definição, o JASP irá apresentar mais elementos no gráfico. Entretanto, para fins pedagógicos, o importante é conseguir notar o relacionamento que ambas as variáveis apresentam. Para realizar um gráfico mais simples, será necessário desmarcar (ou clicar em none) as opções Graph above scatter plot, Graph righ of scatter plot e Add regression line. Para execução da correlação, será necessário clicar em Regression e Correlation. Ao realizar isso, a tela a ser exibida será próxima à imgem abaixo. Repare que, por padrão, o JASP ativa a opção Pearson's r em Sample Correlation Coefficient com Report significance em Additional Options. O espaço Variables é o local onde todas as variáveis serão colocadas e o espaço Condition on não será utilizado no momento. Ao inserir o eat_soma e o bsq_soma, o JASP automaticamente irá realizar as contas e apresentar os resultados. O coeficiente de correlação e o valor de p serão apresentados em uma lista. No entanto, algumas condições são imoprtantes neste resultado e devem ser explicadas: As variáveis serão alocadas tanto nas linhas, como nas colunas Todas as correlação de uma variável com ela própria será igual a 1 e o JASP não apresentará A ordem das correlações não interfere no resultado e o JASP somente apresentará uma correlação A interpretação dos resultados deve ser feita com base no coeficiente de correlação e no valor de P. Há um grande debate na literatura sobre a necessidade de normalidade na Correlação de Pearson, com grande parte dos argumentos apontam que ela não depende estritamente da normalidade das variáveis. Dessa maneira, não há a necessidade de avaliar outros pressupostos além dos já discutidos no decorrer deste capítulo. 10.4 Escrita dos resultados Os resultados serão escritos apresentado os três principais ingredientes da correlação, que são o resultado e o sinal do coeficiente de correlação de Pearson, além do valor de p. O estilo da escrita é baseado nas recomendações da American Psychological Association (APA). Como os resultados do R e do JASP foram um pouco diferente nas comparações pareadas, o R será utilizado como principal. Como escrever os resultados A correlação entre o comportamento alimentar (EAT-26) e a percepção corporal (BSQ-34) foi calculada pelo Coeficiente Produto-Momento de Pearson. Os resultados concluíram que existe uma correlação positiva, forte e significativa entre ambas as variáveis (r = 0.675, p &lt; 0.001), indicando que as duas variáveis covariam de maneira proporcional. 10.5 Resumo O termo correlação diz respeito a um conjunto de métodos que visa verificar a direção e a força do relacionamento entre duas variáveis A correlação de Pearson assume que ambas as variáveis são linearmente correlacionadas O coeficiente sempre indicará a direção (por um sinal) e a força (por um número entre -1 e +1) do relacionamento bivariado Correlação não indica causalidade 10.6 Pesquisas adicionais Perception of an ambiguous figure is affected by own-age social biases (DOI: 10.1038/s41598-018-31129-7) Nesse estudo, 393 participantes de idades variadas foram recrutados e viram uma imagem ambígua em que é possível identificar tanto uma moça jovem, como uma senhora de idade. Os participantes deveriam olhar a imagem e indicar a idade a pessoa. Com estes resultados, os pesquisadores calcularam a correlação entre a idade do participante e a idade que as pessoas deram à pessoa. References "],
["regressão-linear-simples.html", "Cap. 11 Regressão linear simples 11.1 Glossário 11.2 Breve explicação conceitual 11.3 Pesquisa 11.4 Execução no R 11.5 Execução no JASP 11.6 Escrita dos resultados 11.7 Resumo", " Cap. 11 Regressão linear simples De forma geral, modelos de regressão são modelos estatísticos que visam predizer o comportamento de uma variável dependente (Y) como uma função de uma ou mais variáveis independentes (X). Em larga escala, eles substituem os outros testes paramétricos vistos até agora. Dessa maneira, quase tudo o que foi visto durante os capítulos anteriores são casos especiais de modelos de regressão (Chartier &amp; Faulkner, 2008). Existem diferentes nomenclaturas utilizadas para classificar tais modelos e a tabela abaixo apresenta uma classificação funcional. VI e VD VD Discreta VD Contínua VI Discreta Reg. logística Reg. linear (Teste T/ANOVA) VI Contínua Reg. logística Reg. linear Algumas conclusões são possíveis: A variável dependente irá definir se a regressão será linear ou logística. Quando a VD é continua (ex: peso, tempo de resposta, inteligência) trata-se de uma regressão linear. Quando a VD é discreta ou categórica (ex: acidente - sim ou não; orientação política - direita ou esquerda) trata-se de uma regressão logística. Caso haja uma única VI, a regressão é chamada de simples. Com duas ou mais VIs, ela é chamada de múltipla. Se houver mais de uma VD, o modelo será chamado de multivariado (em inglês, path analysis. Teste T e ANOVA são casos de regressão linear simples. ANCOVA, ANOVA de k vias e ANOVA fatorial são casos de regressão múltipla. O qui-quadrado pode ser aproximado pela regressão logística simples e vice-versa. Isso posto, a Regressão linear é uma técnica estatística que permite estimar o quanto os valores de uma variável dependente (Y) variam em função de uma ou mais variáveis independentes (X). Isso é feito através de uma equação específica e há, ao menos, duas utilidades diretas em uma pesquisa, que são: Predizer os valores da variável dependente (Y) em função dos valores da variável dependente (X); Explicar a variabilidade da variável dependente (Y) em função da variável independente (X). Abas as utilidades são virtualmente iguais e como a Regressão linear simples pode ser vista a partir de um incremento ou avanço dos modelos de correlação, os aspectos correlacionais devem (e podem) ser inicialmente investigados. Pela abrangência dos modelos de regressão, é possível tanto encontrar cursos completos e detahados sobre seus detalhes, como abordagens mais pragmáticas e operacionais voltadas a implementação deles em pesquisas. Nesse capítulo, o foco será dado na capacidade operacional. Conceitualmente, a regressão linear simples é apresentada como: \\[y_i = b_0 + b_1X{_1}_i + \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) é a inclinação (coeficiente angular) \\(\\epsilon_{i}\\) é o erro/resíduo A interpretação dos resultados obtidos depende dos seguintes pressupostos: A relação entre as variáveis é linear Os resíduos são independentes Os resíduos são normalmente distribuídos (com média) A variância dos resíduos é constante O mnemônico LINE talvez ajude a lembrar destes pressupostos. Ele se refere à linearity, independence, normality e equal variance . 11.1 Glossário Diferentes termos são empregados em modelos de regressão. Alguns deles são apresentados a seguir para auxiliar no entendimento e também aproximar o leitor a este tipo de modelagem. intercepto (\\(b_0\\)): Valor previsto (médio) de Y quando X = 0 Inclinação (\\(b_i\\)): Diferença média em unidades da variável dependente quando se altera uma unidade de X SSR: Soma dos Quadrados da Regressão SSE: Soma dos Quadrados dos Erros SST: Soma dos Quadrados Total Coeficiente de Determinação (\\(R^2\\)): Porcentagem de variação da variável dependente (Y) que pode ser atribuída à variabilida da(s) variável (is) independente(s) (X) Coeficiente de Determinação ajustado (\\(R^2_{adj}\\)): Coeficiente que pondera o \\(R^2\\) pelo número de variáveis explicativas e pelo número de observações da amostra. É particularmente útil quando deseja-se comparar modelos de regressão múltipla para mesma variável dependente, pois penaliza aquele modelo com maior número de variáveis independentes RMSEA (\\(Res. St. Error\\)): Desvio padrão dos valores previstos da variável dependente ao redor da linha de regressão estimada O conhecimento de algumas fórmulas fechadas também auxilia no entendimento da modelagem. Soma dos Quadrados da Regressão: \\(SSR = \\sum_{i=1}^{n}(\\hat{y} - \\bar{y})^2\\) Soma dos Quadrados dos Erros: \\(SSE = \\sum_{i=1}^{n}(y_i - \\hat{y})^2\\) Soma dos Quadrados Total: \\(SST = \\sum_{i=1}^{n}(y_i - \\bar{y})^2\\) Variabilidade total: \\(SST = SSR + SSE\\) \\(R^2\\): \\(\\frac{SSR}{SST} = 1- \\frac{SSE}{SST}\\) Erro quadrático médio: \\(MSE = \\sum_{i=1}^{n}(y_i - \\hat{y})^2 /(N-K)\\) \\(R^2_{adj}\\): \\(1-\\frac{MSE}{MSR}\\) \\(Res. St. Error = \\sqrt\\frac{SSE}{N-K}\\) 11.2 Breve explicação conceitual Conforme descrito, modelos de regressão conseguem substituir a maior parte dos testes estatísticos realizados para testar hipóteses. Neste sentido, a maior parte dos livros tenta fazer uma introdução a estes modelos de forma que tanto aspectos conceituais, como algumas características analíticas possam ser melhor entendidas. Nesta seção, essa apresentação será feita de uma forma mais intuitiva. Se pensarmos que as variáveis podem ser representadas por conjuntos, é possível imaginar que tanto Y como X podem ser independentes. Neste sentido, a realização de Y não dependente da realização de X e vice-versa. No entanto, o que frequentemente ocorre é que existe algum grau de relacionamento entre as variáveis, tal como exposto abaixo. Caso se assuma que X é um fator de causalidade à realização de Y, isso significa que uma parte da realização de Y, necessariamente, depende de X. Tecnicamente, é isso que faz com que X seja entendido como variável independente, enquanto Y seja entendido como variável dependente. A área de intersecção destacada é importante e representa a parte de Y que pode ser atribuída ou explicada por X. Analiticamente, essa área precisa de algumas transformações algébricas e, em função delas, recebe o nome de Soma dos Quadrados da Regressão (SSR, em inglês). No entanto, nem toda a variabilidade de Y pode ser atribuída à X. Essa região de Y que está fora da intersecção também sofre algumas transformações algébricas e recebe o nome de Soma dos Quadrados dos Erros (SSE, em inglês). Essa área representa a variabilidade de Y que não pode ser atribuída/explicada por X. Nesse caso: Agora, tecnicamente Y existe independentemente de X e possui uma variabilidade (interna) total. Essa variabilidade é bastante próxima do conceito de variância visto em estatística descritiva e pode ser obtida pelo somatório da área explicada pela regressão (SSR) com a área não explicada (SSE). Essa região total também passará por transformações algébricas e é chamada de Soma dos Quadrados Total (SST, em inglês). Vendo todas as partições de uma única vez, temos o seguinte: A porcentagem de variação de Y que pode ser atribuída à variabilidade de X é uma razão entre a Soma dos Quadrados da Regressão (SSR) e a Soma dos Quadrados Total (SST). O coeficiente obtido por essa razão recebe o nome de Coeficiente de Determinação ou \\(R^2\\), apresentado inicialmente. Isso é equivalente a subtração do espaço máximo de variabilidade (1 ou 100%) pela razão entre a Soma dos Quadrados dos Erros (SSE) e Soma dos Quadrados Total (SST): Evidentemente, essa explicação conceitual conta apenas uma parte da estória É igualmente possível entender os modelos de regressão a partir da ampliação de uma análise de correlação. Por exemplo, se duas variáveis aleatórias contínuas são correlacionadas de maneira linear e positiva, tal como demonstrado abaixo: ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + labs(x = &quot;X&quot;, y = &quot;Y&quot;) É possível criar um modelo estatístico que descreva o quanto os valores de Y podem ser atribuídos a X por meio de uma função que gere uma reta bem próxima aos pontos reais. Tecnicamente, quão mais próximo essa reta estiver dos pontos, menor serão os erros. No entanto, muitas retas podem ser traçadas, tal como demonstrado a seguir. ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + labs(x = &quot;X&quot;, y = &quot;Y&quot;) + xlim(10,200) + geom_abline(slope = c(rnorm(10,0.4,0.55), rnorm(10,0.2,0.15)),color = 1:20) ## Warning: Removed 2 rows containing missing values (geom_point). Repare que entre as retas, de maneira geral, todas acertam alguns pontos e erram outros. Há aquelas que parecem melhores, outras que tem um desempenho muito ruim. De fato, o que isso demonstra é que encontrar o melhor modelo estatístico para este caso é um problema de otimização. Isso pode ser feito justamente resgatando um pouco o conceito de função afim, exposto no ensino médio e ilustrado ao início do capítulo: \\[\\hat{y} = a + bX\\] No entanto, agora o valor previsto (\\(\\hat{y}\\)) depende de duas constantes (a: intercepto ou coeficiente linear e b: inclinação ou coeficiente angular) e uma variável (X). Apenas por uma questão de simbologia, três alterações são feitas com a equação: Os símbolos são alterados. Agora \\(a = b_0\\) e \\(b = b_1\\). A alteração de simbologia não altera em nada os cálculos. Como se sabe que essa reta vai estimar os valores reais de \\(Y\\), letras minúsculas ou um chapéu sobre as letras será utilizado em vez das letras maiúsculas ou gregas. Para que cada valor estimado seja associado a um participante a letra \\(i\\) será adicionada abaixo do \\(y\\) e do \\(b_1\\). Assim, temos que os valores estimados de y, agora \\(\\hat{y}\\), são obtidos pelo \\(b_0\\) e \\(b_1\\): \\[\\hat{y}_i = b_0 + b_1X{_1}_i\\] Isso é feito justamente resgatando o conceito de função afim, exposto no ensino médio (e ilustrado ao início do capítulo): é apenas inicial e serve apenas para introduzir as principais ideia da modelagem de regressão de uma maneira intuitiva. Existem excelente obras mais detalhadas e com aplicações à Psicologia, entre elas: Data Analysis: A Model Comparison Approach To Regression, ANOVA, and Beyond, de Charles M. Judd, Gary H. McClelland e Carey S. Ryan Regression, ANOVA, and the General Linear Model\": A Statistics Primer, de Paul Vik Regression and Other Stories, de Andrew Gelman 11.3 Pesquisa Base: Livro - Dados - Eating disorders Neste capítulo, vamos utilizar a pesquisa intitulada “Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students”, publicada em 2018 no Global Journal of Educational Studies, que sou coautor. O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e na percepção da imagem corporal. Os primeiros aspectos foram avaliados pela escala EAT-26, enquanto o segundo foi avaliado pela escala BSQ-34. Uma das principais hipóteses era que alterações na percepção da imagem corporal seriam preditores para possíveis transtornos alimentares. Operacionalmente, a hipótese era de que os valores da BSQ-34 poderiam predizer os valores da EAT-26 e que quão maior fossem os primeiros, maior seriam os efeitos na maximização dos segundos. Em modelos de regressão, as hipóteses costumam ser feitas em cascata. Quase sempre, se compara o modelo de desenvolvido com um modelo mais simples. Em seguida, verifica-se cada preditor de forma individual e assim sucessivamente. Uma vez que a definição de cada hipótese ocuparia um espaço grande aqui, elas serão suprimidas. 11.4 Execução no R A primeira etapa da análise é realizada pelo desenvolvimento de tabelas e gráficos que possam auxiliar na interpretação dos resultados. De maneira similar à feita em outros capítulos, abaixo há uma tabela descritiva . arsenal::tableby(~eat_soma + bsq_soma, dados_brasil) %&gt;% summary() Overall (N=220) eat_soma Mean (SD) 15.950 (9.753) Range 0.000 - 50.000 bsq_soma Mean (SD) 81.359 (37.003) Range 0.000 - 188.000 O cálculo da correlação entre ambas as variáveis também é importante, apesar de tecnicamente não ser necessário neste capítulo. Em linhas gerais, o coeficiente de correlação expressa a força e a direção do relacionamento entre as variáveis. A força pode ser interpretada como fraca (0.1), moderada (0.3) ou forte (0.5) (Cohen, 1988) e a direção pode ser positiva ou negativa, a depender do sinal. A correlação entre as variáveis foi 0.675 e significativa (p &lt; 0.001). cor.test(dados_brasil$eat_soma, dados_brasil$bsq_soma) %&gt;% pander() Pearson’s product-moment correlation: dados_brasil$eat_soma and dados_brasil$bsq_soma Test statistic df P value Alternative hypothesis cor 13.52 218 1.156e-30 * * * two.sided 0.6754 O gráfico de dispersão apresenta esse relacionamento. No eixo X deve-se inserir a VI (neste caso, os resultados da BSQ-34), enquanto a VD é inserida em Y. ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() Tanto a tabela como o gráfico deixam claro que existe um padrão (aproximadamente linear) entre ambas as variáveis que ocorre de maneira forte e significativa. Com isso, é natural que o interesse seja verificar o quanto os resultados do EAT-26 variam em função do BSQ-34. Para executar esse procedimento, o R conta com a função nativa lm. Por sua vez, o pacote olsrr oferece excelentes complementos para interpretar os achados. O vetor mod_linear_simples será criado e armazenará os resultados. Lembre-se que, no R, é importante sempre atentar para o nível de medida das variáveis para que os resultados sejam adequados. mod_linear_simples &lt;- lm(eat_soma ~ bsq_soma, data = dados_brasil) Na maioria dos programas comerciais, os resultados do modelo de regressão são apresentados em uma tabela padronizada. Essa tabela é virtualmente identica à que foi exposta no capítulo sobre a ANOVA de uma via e encontra-se abaixo descrita: Fonte de variação SS df MS F-Value P-Value Regressão SSR (Regressão) K-1 MSR SSR/K-1 MSR/MSE Erro SSE (Erro) N-K MSE SSE/N-K – Total SST (Total) N-1 – – – R2 = SSR/SST Nota: Nessa tabela, K considera dois preditores na regressão, que são o intercepto e a inclinação. É possível também encontrar N-K-1 em alguns livros que não explicitam o intercepto na tabela. Isto explicado, a função ols_regress do pacote olsrr dispoõe os resultados neste padrão: ols_regress(mod_linear_simples) ## Model Summary ## -------------------------------------------------------------- ## R 0.675 RMSE 7.209 ## R-Squared 0.456 Coef. Var 45.196 ## Adj. R-Squared 0.454 MSE 51.966 ## Pred R-Squared 0.445 MAE 5.565 ## -------------------------------------------------------------- ## RMSE: Root Mean Square Error ## MSE: Mean Square Error ## MAE: Mean Absolute Error ## ## ANOVA ## ----------------------------------------------------------------------- ## Sum of ## Squares DF Mean Square F Sig. ## ----------------------------------------------------------------------- ## Regression 9503.775 1 9503.775 182.883 0.0000 ## Residual 11328.675 218 51.966 ## Total 20832.450 219 ## ----------------------------------------------------------------------- ## ## Parameter Estimates ## -------------------------------------------------------------------------------------- ## model Beta Std. Error Std. Beta t Sig lower upper ## -------------------------------------------------------------------------------------- ## (Intercept) 1.466 1.176 1.246 0.214 -0.852 3.784 ## bsq_soma 0.178 0.013 0.675 13.523 0.000 0.152 0.204 ## -------------------------------------------------------------------------------------- É fácil notar que os resultados apresentados são muitos e se recomenda uma ordem específica para interpretá-los. Em primeiro momento, é necessário verificar o ajuste do modelo na seção ANOVA. Este teste compara o modelo em questão contra um modelo em que apenas o intercepto é utilizado para prever todos os valores. Tecnicamente, o modelo analisado é chamado de irrestrito (ou aumentado) e o modelo que tem apenas o intercepto é chamado de restrito ou nulo. Valores significativos são necessários nesta etapa. Nesta análise, o resultado foi F(1, 218) = 182.883, p &lt; 0.0001, indicando que os outros resultados podem ser interpretados. O segundo momento é a interpretação do \\(R^2\\). Como exposto no início do capítulo, essa indicador mensura a parte da variação da variável dependente (Y) que pode ser atribuída às variáveis independentes do modelo (X). Repare que ele é computado pela razão entre o SSR e o SST e indica que cerca de 46% dos resultados da variabilidade do EAT-26 podem ser explicados pelo modelo. O terceiro momento é a análise do \\(R^2 ajustado\\). Em modelos de regressão, modelos com mais parâmetros/preditores sempre vão ter \\(R^2\\) maior do que modelos mais compactos, independente da signficância destes outros parâmetros. O \\(R^2 ajustado\\) é uma medida que considera a complexidade do modelo e pune a entrada de novas variáveis. Neste caso, como há apenas dois preditores (intercepto e bsq_soma), o \\(R^2 ajustado\\) e o \\(R^2\\) são quase idênticos. Finalmente, o quarto momento é análise dos preditores, que é feito na seção Parameter Estimates. Para isso, deve-se identificar os preditores um a um, seus valores de Beta e de P (Sig). O Beta indica a diferença média em unidades da variável dependente quando se altera uma unidade de X. Por exemplo, mais 1 ponto no BSQ-34, mais 0.178 pontos, em média, no EAT-26. Esse resultado é significativo, tal como é indicado na coluna Sig. O intercepto é chamado de constante na maior parte dos programas e indica o valor médio (esperado) de Y quando X=0. Nesse caso, se alguém tivesse tirado o valor 0 na escala BSQ-34, o valor previsto para os resultados da Escala EAT-26 seria de 1.46. No entanto, o Sig indica que esse valor não é significativo, ou seja, não é diferente de 0. O indicador de beta padronizado Std. Beta traz as mesmas informações, mas trabalha em unidades de desvios-padrão em todas as variáveis presentes no modelo. Eventualmente, o Std. Beta pode ser entendido como uma medida perliminar de tamanho do efeito (Fox, 2016). É importante notar que frequentemente o intercepto não tem interpretação lógica e, por isso, costuma ser desconsiderado. Para que ele tenha melhor capacidade de interpretação, algumas estratégias são possíveis, tal como centralizar os valores do preditor \\((x_i-\\bar{x})\\). Caso isso seja feito, o intercepto irá ser o valor médio da variável dependente. Estes resultados obtidos são muito auxiliados pela apresentação de gráficos de dispersão, tal como feito no início do capítulo. Entretanto, agora estes gráficos ganham dois elementos a mais: (1) uma reta de regressão, obtida pela Função de Regressão Amostral (FRA), que irá indicar o intercepto, a inclinação e o intervalo de confiança das estimativas e (2) uma indicação textual com as equações características do modelo e seus respectivos resultados. Essas adições gráficas são feitas pelo pacote ggpubr. ggplot(dados_brasil, aes(x = bsq_soma, y = eat_soma)) + geom_jitter() + geom_smooth(method = &quot;lm&quot;) + ggpubr::stat_regline_equation(label.x = 3, label.y = 40) + ggpubr::stat_cor(method = &quot;pearson&quot;, label.x = 3, label.y = 44) ## `geom_smooth()` using formula &#39;y ~ x&#39; Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer (Barker &amp; Shaw, 2015; Ernst &amp; Albers, 2017; Lix et al., 1996). Corriqueiramente, testar os pressupostos é uma etapa anterior à própria realização do teste inferencial. Entretanto, pedagogicamente a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir. Normalidade: O pressuposto da Normalidade é atendido se os resíduos do modelo de regressão seguirem uma distribuição normal. Isso pode ser avaliado graficamente por QQ plots e também por testes específicos, como o Shapiro-wilk, Anderson-Darling e Jarque Bera. O QQ plot é um gráfico que reúne a distribuição empírica ordenada dos quantis contra os quantis da distribuição teórica (aqui, normal). Se os dados e a linha diagonal se soprepuserem, isso é uma evidencia de que a distribuição empírica é a mesma da distribuição teórica. Caso haja discrepância, isso aponta para desvio da normalidade. Caso os pontos e a reta diagonal estejam superpostos, se considera que este pressuposto foi atendido. ols_plot_resid_qq(mod_linear_simples) Testes estatísticos formais também podem ser utilizados, tal como abaixo: ols_test_normality(mod_linear_simples) ## Warning in ks.test(y, &quot;pnorm&quot;, mean(y), sd(y)): ties should not be present for ## the Kolmogorov-Smirnov test ## ----------------------------------------------- ## Test Statistic pvalue ## ----------------------------------------------- ## Shapiro-Wilk 0.9597 0.0000 ## Kolmogorov-Smirnov 0.0816 0.1072 ## Cramer-von Mises 17.066 0.0000 ## Anderson-Darling 2.4137 0.0000 ## ----------------------------------------------- Apesar dos resultados obtidos por tais testes serem algo discordantes, os achados sugerem violação deste pressuposto. Homocedasticidade: Este pressuposto de variâncias constantes pode ser analisada em um gráfico de dispersão dos resíduos (residual) contra os valores previstos (fitted). ols_plot_resid_fit(mod_linear_simples) Caso haja padrões neste gráfico, isso sugere que este pressuposto foi violado. O gráfico não sugere padrões específicos. No entanto, testes formais são recomendados para que a decisão tomada tenha maior apoio. Existem diferentes testes para isso e, entre eles, o teste de Bartlett, Levene e Breusch-Pagan. Os resultados dependem das propriedades de cada um dos modelos e, em função da praticidade computacional, o teste de Breusch-Pagan será utilizado. Em todos estes testes, a hipótese nula assume homocedasticidade. Portanto, a estatística de teste não deveria ser significativa para que a homocedasticidade fosse apoiada. ols_test_breusch_pagan(mod_linear_simples) ## ## Breusch Pagan Test for Heteroskedasticity ## ----------------------------------------- ## Ho: the variance is constant ## Ha: the variance is not constant ## ## Data ## ------------------------------------ ## Response : eat_soma ## Variables: fitted values of eat_soma ## ## Test Summary ## ------------------------------ ## DF = 1 ## Chi2 = 9.002614 ## Prob &gt; Chi2 = 0.002695937 Os resultados indicaram que a homocedasticidade foi violada. Isso vai na direção oposta da percepção gráfica, o que pode ocorrer sem nenhum problema. Independência: A independência dos resíduos depende bastante do delineamento utilizado ser transversal ou longitudinal. O teste de Durbin Watson pode ser utilizado e a hipótees nula é de que os resíduos não são correlacionados. Este pressuposto foi atendido, o que já era esperado. car::durbinWatsonTest(mod_linear_simples) ## lag Autocorrelation D-W Statistic p-value ## 1 0.07254389 1.845067 0.256 ## Alternative hypothesis: rho != 0 Isso posto, os diagnósticos executados indicaram que o modelo violou a normalidade e a homocedasticidade e preservou a linearidade e a independência dos resíduos. Apesar desse tipo de resultado ser frequente em Psicologia, a interpretação dos resultados é limitada e deve ser feita de forma apenas preliminar. 11.5 Execução no JASP Para executar as rotinas necessárias, será necessário carregar a base de dados para o ambiente JASP. A base chama-se csv eat bsq brasil. Após fazer isso, para realizar tabelas e gráficos descritivos, deve-se clicar em Descriptives , na parte superior do programa. Ao clicar nesta opção, será possível eleger as variáveis que irão ser analisadas e as variáveis que irão funcionar como agrupadores. Neste caso, será necessário colocar o bsq_soma e o eat_soma na seção Variables. É importante manter essa ordem para as apresentações gráficas futuras. Ao fazer isso, automaticamente o JASP apresentará as médias e desvios-padrão de cada uma das variáveis, além de valores mínimos e máximos. Para realizar um gráfico que descreva o relacionamento entre ambas as variáveis, é necessário clicar em Plots. Há diversas opções, mas a Scatter Plots é a mais completa. Ao selecioná-la, o JASP já irá apresentar o gráfico, bem com adicionar elementos que possam maximizar o entendimento do relacionamento entre elas. A este momento, o interesse é fazer uma primeira avaliação sobre o perfil linear no relacionamento entre os dados, o que parece ocorrer. É possível calcular a correlação entre ambas as variáveis, tal como foi realizado no R. Entretanto, essa etapa reproduziria o que foi feito no capítulo anterior e, por isso, não será apresentada. Para execução da regressão linear, será necessário clicar em Regression e Linear Regression. A tela do JASP irá apresentar algumas opções. É importante notar que a Covariates é o local onde as VIs serão colocadas e Dependent Variable é onde a VD deverá ser inserida. Enquanto é possível inserir muitas variáveis independentes (fazendo um modelo múltiplo), apenas uma VD poderá ser inserida. O JASP apenas aceitará variáveis contínuas ou definidas como contínuas nos espaços apresentados. Para realizar o modelo, será necessário levar a bsq_soma para seção Covariates e a eat_soma para Dependent variable. Ao fazer isso, o JASP irá fazer todas as principais análises e apresentar os resultados em uma tabela específica, ao lado direito da tela. É fácil notar que os resultados apresentados são muitos e se recomenda uma ordem específica para interpretá-los. Em primeiro momento, é necessário verificar o ajuste do modelo na seção ANOVA, bem ao centro dos resultados. Este teste compara o modelo em questão contra um modelo em que apenas o intercepto é utilizado para prever todos os valores. No JASP, esses modelos são descritos por H1 e H0 nas principais tabelas. Tecnicamente, o modelo analisado é chamado de irrestrito (ou aumentado, H1) e o modelo que tem apenas o intercepto é chamado de restrito ou nulo, H0. Valores significativos são necessários nesta etapa. Nesta análise, o resultado foi F(1, 218) = 182.883, p &lt; 0.0001, indicando que os outros resultados podem ser interpretados. Quando isso acontece, deve-se desconsiderar todas as linhas que o JASP apresentar resultados para o modelo nulo, simbolizado porH0, e apenas interpretar os resultados do modelo testado, que é apresentado sempre por H1. O segundo momento é a interpretação do \\(R^2\\), que está localizado na parte superior, em Model summary. Como exposto no início do capítulo, essa indicador mensura a parte da variação da variável dependente (Y) que pode ser atribuída às variáveis independentes do modelo (X). Repare que ele é computado pela razão entre o SSR e o SST e indica que cerca de 46% dos resultados da variabilidade do EAT-26 podem ser explicados pelo modelo. O terceiro momento é a análise do \\(R^2 ajustado\\), que também está localizado na parte superior, em Model summary. Em modelos de regressão, modelos com mais parâmetros/preditores sempre vão ter \\(R^2\\) maior do que modelos mais compactos, independente da signficância destes outros parâmetros. O \\(R^2 ajustado\\) é uma medida que considera a complexidade do modelo e pune a entrada de novas variáveis. Neste caso, como há apenas dois preditores (intercepto e bsq_soma), o \\(R^2 ajustado\\) e o \\(R^2\\) são quase idênticos. Finalmente, o quarto momento é análise dos preditores, que é feito na seção Coefficients. Para isso, deve-se identificar os preditores um a um, seus valores Unstandardized e de P. O Unstandardized indica a diferença média em unidades da variável dependente quando se altera uma unidade de X. Por exemplo, mais 1 ponto no BSQ-34, mais 0.178 pontos, em média, no EAT-26. Esse resultado é significativo, tal como é indicado na coluna Sig. O intercepto é chamado de constante na maior parte dos programas e indica o valor médio (esperado) de Y quando X=0. Nesse caso, se alguém tivesse tirado o valor 0 na escala BSQ-34, o valor previsto para os resultados da Escala EAT-26 seria de 1.46. No entanto, o Sig indica que esse valor não é significativo, ou seja, não é diferente de 0. O indicador de beta padronizado Standardized traz as mesmas informações, mas trabalha em unidades de desvios-padrão em todas as variáveis presentes no modelo. Eventualmente, o Standardized pode ser entendido como uma medida perliminar de tamanho do efeito (Fox, 2016). É importante notar que frequentemente o intercepto não tem interpretação lógica e, por isso, costuma ser desconsiderado. Para que ele tenha melhor capacidade de interpretação, algumas estratégias são possíveis, tal como centralizar os valores do preditor \\((x_i-\\bar{x})\\). Caso isso seja feito, o intercepto irá ser o valor médio da variável dependente. Em síntese, cada uma das etapas deve ser feita de maneira sequencial. A imagem a seguir apresenta um sumário com todos os passos expostos. Uma vez que o modelo já foi realizado, a interpretação dos resultados depende da adequação de seus pressupostos. A violação destes pressupostos distorce, limita ou invalida as interpretações teóricas propostas, uma vez que tanto o aumento do erro do tipo 1 (falso positivo), como do tipo 2 (falso negativo) podem ocorrer (Barker &amp; Shaw, 2015; Ernst &amp; Albers, 2017; Lix et al., 1996). Corriqueiramente, testar os pressupostos é uma etapa anterior à própria realização do teste inferencial. Entretanto, pedagogicamente a apresentação deles após a execução do teste parece mais adequada. Assim, eles serão testados a seguir. Para verificar os pressupostos, será necessário utilizar as opções dispostas na parte inferior à esquerda do programa. A normalidade é testada ao clicar em Plots e Q-Q plot standardized results. O JASP irá apresentar um QQ plot com duas informações principais: uma diagonal e um conjunto de pontos/círculos. Caso os círculos estejam sobrepostos à linha, isso apoia que os resíduos se distrubem normalmente. No caso abaixo, isso não foi alcançado. Diferente do R, esta versão do JASP não permite testar formalmente a hipótese de normalidade residual. Dessa forma, será necessário contar apenas com a perceção do gráfica para checar se o pressuposto foi respeitado ou violado. A homocedasticidade é também verificada graficamente. Ao clicar no Residuals vs. Predicted, o plano irá apresentar os valores dos resíduos em Y e os valores previstos em X. Nesse gráfico, é importânte não detectar nenhum padrão nos elementos apresenatdos. A disposição do gráfico indica que este pressuposto foi alcançado. A Independência dos resíduos é bastante dependente do tipo de delineamento utilizado. No entanto, o JASP permite que esse pressuposto seja formalmente testado pelo teste de Durbin Watson. Isso é feito ao clicar em Statistics, Residuals e Durbin-Watson Os resultados irão ser apresentados na parte superior do programa. Caso a hipótese nula não seja rejeitada, isso apoia que os resíduos são independentes. Nesse caso, o valor de p foi 0.242, indicando que isso ocorreu. Uma vez que nem todos os pressupostos foram atendidos, é possível proceder a algumas alterações na modelagem estatística ou, realizar a interpretação cautelosa dos resultados. Neste capítulo, a interpretação será feita. 11.6 Escrita dos resultados De uma forma geral, o principal achado do modelo de regressão é que a percepção da imagem corporal é um preditor significativo ao comportamento alimentar. Neste sentido, ao saber informações sobre como uma pessoa percebe o próprio corpo, pode-se estimar condições eventualmente disfuncionar de seu comportamento alimentar. Abaixo uma sugestão de escrita baseada nas recomendações da American Psychological Association (APA). Como escrever os resultados Um modelo de regressão foi calculado para verificar os resultados dos comportamentos alimentares (EAT-26) em função da percepção de imagem corporal (BSQ-34). Os resultados indicaram que cerca de 46% da variância do EAT-26 pode ser atribuída ao BSQ-34 (R2 = 0.456, F(1,218) = 182.88, p &lt; 0.001). Cada ponto a mais no BSQ-34 impacta, em média, em 0.178 no EAT-26 (b = 0.178, p &lt; 0.001). 11.7 Resumo Existem diferentes modelos de regressão e eles sempre visam prever um resultado a partir de uma ou um conjunto de variáveis O tipo de modelagem depedente tanto da natureza e quantidade das VIs e VDs, sempre possível entender grande parte dos testes estatísticos estudados como casos particulares dos modelos de regressão Os principais indicadores de um modelo de regressão são sua significância geral, o \\(R^2\\),o o \\(R^2_{adj}\\), bem como o coeficiente e a significância dos preditores o diagnóstico é uma parte essencial desta modelagem e o mnemônico LINE pode ajudar na lembrança dos pressupostos References "],
["regressão-linear-múltipla.html", "Cap. 12 Regressão linear múltipla 12.1 Pesquisa 12.2 Execução no R 12.3 Técnicas automáticas de seleção de variáveis 12.4 Resumo", " Cap. 12 Regressão linear múltipla Os modelos de regressão linear múltipla são desenvolvidos para predizer os valores médios de uma variável resposta (Y) em função de duas ou mais variáveis independentes (X). Nestes modelos, a VD deve ser contínua e as VIs podem ser tanto contínuas como categóricas. Tecnicamente, a família da ANOVA vista anteriormente são casos particulares de modelos de regressão múltipla. Conceitualmente, neste modelo, se adiciona um outro preditor à equação vista no capítulo de regressão linear simples. Assim: \\[y_i = b_0 + b_1X{_1}_i + b_2X{_2}_i+ \\epsilon_{i}\\] \\(y_i\\) representa a variável dependente \\(b_0\\) é o intercepto (coeficiente linear) \\(b_1\\) e \\(b_2\\) indicam a inclinação dos preditores (coeficiente angular) \\(\\epsilon_{i}\\) é o erro/resíduo Os seguintes pressupostos devem ser avaliados: A relação entre as variáveis é linear Os resíduos são independentes Os resíduos são normalmente distribuídos A variância dos resíduos é constante O mnemônico LINE (linearity, independence, normality, equal variance) talvez ajude a lembrar destes pressupostos. 12.1 Pesquisa Base: Livro - Dados - Eating disorders Vamos utilizar a pesquisa intitulada “Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students”, publicada em 2018 no Global Journal of Educational Studies, que sou co-autor. O objetivo dessa pesquisa foi explorar os fatores envolvidos em transtornos alimentares e aspectos da percepção da imagem corporal, bem como verificar a capacidade que uma medida possuia em predizer os resultados de outra. Esse artigo contou com a utilização de escalas aplicadas em 219 participantes no Brasil. Para acessar aspectos relacionados aos Transtornos alimentares, a escala EAT-26 foi aplicada. Para verificar aspectos da imagem corporal, a escala BSQ-34 foi aplicada. Segue abaixo uma tabela inicial com dados descritivos dos resultados. dados_brasil %&gt;% select(sexo,eat_soma, bsq_soma, imc, faz_esporte, familia_esporte) %&gt;% psych::describeBy(.,group = &quot;sexo&quot;) %&gt;% pander::pander() ## Warning in pander.default(.): No pander.method for &quot;psych&quot;, reverting to ## default.No pander.method for &quot;describeBy&quot;, reverting to default. 1: Table continues below vars n mean sd median trimmed mad sexo 1 126 1 0 1 1 0 eat_soma 2 126 18.48 10.09 17 17.9 11.86 bsq_soma 3 126 94.17 34.87 91 92.64 40.77 imc 4 124 22.58 3.151 21.95 22.24 2.542 faz_esporte 5 126 0.4524 0.4997 0 0.4412 0 familia_esporte 6 126 0.4762 0.5014 0 0.4706 0 min max range skew kurtosis se sexo 1 1 0 NA NA 0 eat_soma 0 47 47 0.4929 -0.5091 0.8988 bsq_soma 32 182 150 0.3512 -0.4573 3.107 imc 16.85 32.87 16.02 0.9764 0.8725 0.2829 faz_esporte 0 1 1 0.1891 -1.98 0.04452 familia_esporte 0 1 1 0.09421 -2.007 0.04467 2: Table continues below vars n mean sd median trimmed mad sexo 1 93 2 0 2 2 0 eat_soma 2 93 12.65 8.189 11 11.55 5.93 bsq_soma 3 93 64.24 32.87 55 59.32 19.27 imc 4 90 24.1 3.99 23.41 23.65 2.829 faz_esporte 5 93 0.3978 0.4921 0 0.3733 0 familia_esporte 6 92 0.4783 0.5023 0 0.473 0 min max range skew kurtosis se sexo 2 2 0 NA NA 0 eat_soma 1 50 49 1.688 4.262 0.8491 bsq_soma 0 188 188 1.504 2.799 3.408 imc 17.56 39.21 21.66 1.269 2.073 0.4206 faz_esporte 0 1 1 0.4107 -1.851 0.05103 familia_esporte 0 1 1 0.08562 -2.014 0.05236 12.2 Execução no R Para crir o modelo no R, basta adicionar uma nova variável à equação. Neste caso, além de verificar o efeito da percepção de imagem corporal, o peso também irá ser utilizado como preditor. É importante notar que, por padrão, o R não usa linhas com dados ausentes e isso pode reduzir o poder do teste. mod_linear_multiplo &lt;- lm(eat_soma ~ bsq_soma + peso_atual, data = dados_brasil) A apresentação segue o mesmo formato da realizada no capítulo específico de regressão linear simples. ols_regress(mod_linear_multiplo) ## Model Summary ## -------------------------------------------------------------- ## R 0.697 RMSE 7.082 ## R-Squared 0.486 Coef. Var 44.265 ## Adj. R-Squared 0.481 MSE 50.160 ## Pred R-Squared 0.472 MAE 5.434 ## -------------------------------------------------------------- ## RMSE: Root Mean Square Error ## MSE: Mean Square Error ## MAE: Mean Absolute Error ## ## ANOVA ## ----------------------------------------------------------------------- ## Sum of ## Squares DF Mean Square F Sig. ## ----------------------------------------------------------------------- ## Regression 10099.820 2 5049.910 100.675 0.0000 ## Residual 10684.180 213 50.160 ## Total 20784.000 215 ## ----------------------------------------------------------------------- ## ## Parameter Estimates ## ---------------------------------------------------------------------------------------- ## model Beta Std. Error Std. Beta t Sig lower upper ## ---------------------------------------------------------------------------------------- ## (Intercept) 9.331 2.755 3.386 0.001 3.899 14.762 ## bsq_soma 0.180 0.013 0.678 13.811 0.000 0.155 0.206 ## peso_atual -0.121 0.037 -0.158 -3.221 0.001 -0.195 -0.047 ## ---------------------------------------------------------------------------------------- Os resultados devem ser analisados de maneira cuidadosa. Inicialmente, é possível concluir que o modelo foi globalmente significativo (F(2, 213) = 100.675, p &lt; 0.001) e que cerca de 48% da variabilidade do EAT-26 pode ser atribuída aos valores do BSQ-34 e do peso do participante. Cada um dos preditores tem um comportamento específico. Em relação ao BSQ-34, cada unidade a mais em seu resultado impacta, em média, 0.18 pontos a mais no EAT-26, controlando pelo peso do participante (p &lt; 0.001). Além disso, cada 1 kg a mais no peso do participante impacta em -0.121 (p &lt; 0.001), em média, nos resultados do EAT-26, controlando pelos valores do BSQ-34. A ideia de verificar o efeito de uma variável controlando por outra tem um significado particular. Assumindo duas pessoas que tem o peso atual igual ao peso médio do grupo ou o mesmo peso, cada ponto extra no BSQ gera, em média, 0.18 pontos a mais no EAT-26. Assim, o valor estimado no EAT-26 de Um participante que teve 45 pontos no BSQ e peso de 66.51 (o peso médio) é de 9.41. Já o valor estimado no EAT-26 de um outro participante com 46 pontos no BSQ e mesmo peso do primeiro participante (66.51) é de 9.59. A diferença entre os valores é exatamente igual ao coeficiente calculado na regressão (b = 0.18). Abaixo há duas linhas de código apresentando esses resultados. peso_medio &lt;- mean(dados_brasil$peso_atual, na.rm=T) predict(mod_linear_multiplo, data.frame(bsq_soma=c(45), peso_atual=peso_medio)) ## 1 ## 9.416621 predict(mod_linear_multiplo, data.frame(bsq_soma=c(46), peso_atual=peso_medio)) ## 1 ## 9.596919 predict(mod_linear_multiplo, data.frame(bsq_soma=c(46), peso_atual=peso_medio))-predict(mod_linear_multiplo, data.frame(bsq_soma=c(45), peso_atual=peso_medio)) ## 1 ## 0.1802979 Tal como apresentado anteriores, a interpretação dos resultados depende da adequação de seus pressupostos. O relacionamento linear já havia sido investigado no gráfico de dispersão nos capítulos anteriores. A Normalidade dos resíduos pode ser vista pelo QQ-Plot (abaixo): ols_plot_resid_qq(mod_linear_multiplo) ols_plot_resid_stud_fit(mod_linear_multiplo) e por testes estatísticos formais. De forma análoga ao que aconteceu no capítulo de regressão linear simples, apesar de algo discordantes, o pressuposto de normalidade foi rejeitado. ols_test_normality(mod_linear_multiplo) ## Warning in ks.test(y, &quot;pnorm&quot;, mean(y), sd(y)): ties should not be present for ## the Kolmogorov-Smirnov test ## ----------------------------------------------- ## Test Statistic pvalue ## ----------------------------------------------- ## Shapiro-Wilk 0.9607 0.0000 ## Kolmogorov-Smirnov 0.0689 0.2567 ## Cramer-von Mises 17.7972 0.0000 ## Anderson-Darling 2.2135 0.0000 ## ----------------------------------------------- A independência dos resíduos pode ser avaliada pelo Durbin Watson. É importante lemrbar que a Hipótees nula é de que os resíduos não são correlacionados. car::durbinWatsonTest(mod_linear_multiplo) ## lag Autocorrelation D-W Statistic p-value ## 1 0.02410462 1.947272 0.642 ## Alternative hypothesis: rho != 0 As homocedasticidade, ou seja, variâncias constantes pode ser vista em um gráfico de dispersão dos resíduos (residual) contra os valores previstos (fitted). ols_plot_resid_fit(mod_linear_multiplo) O teste Breusch-Pagan também é um indicador importante e a Hipótese nula assume homocedasticidade. Portanto, a estatística de teste deveria ser insignificante para que a homocedasticidade pudeSSR ser aceita, o que não é o caso aqui. ols_test_breusch_pagan(mod_linear_multiplo) ## ## Breusch Pagan Test for Heteroskedasticity ## ----------------------------------------- ## Ho: the variance is constant ## Ha: the variance is not constant ## ## Data ## ------------------------------------ ## Response : eat_soma ## Variables: fitted values of eat_soma ## ## Test Summary ## ----------------------------- ## DF = 1 ## Chi2 = 5.723583 ## Prob &gt; Chi2 = 0.01673854 Como esse modelo pode reunir diversas variáveis independentes, é importante verificar o quanto elas são correlacionadas entre si. Isso é feito pela análise de Variance Inflaction Factor (VIF). Valores de VIF superiores a 4 indicam que as variáveis indepenentes são fortemente correlacionadas e, com isso, as estimativas podem ser distorcidas. Neste caso, isso não aconteceu. ols_coll_diag(mod_linear_multiplo) ## Tolerance and Variance Inflation Factor ## --------------------------------------- ## Variables Tolerance VIF ## 1 bsq_soma 0.9999925 1.000007 ## 2 peso_atual 0.9999925 1.000007 ## ## ## Eigenvalue and Condition Index ## ------------------------------ ## Eigenvalue Condition Index intercept bsq_soma peso_atual ## 1 2.85848875 1.000000 0.003656276 0.01908105 0.004257786 ## 2 0.12424761 4.796498 0.027440631 0.92248915 0.062344260 ## 3 0.01726365 12.867732 0.968903094 0.05842980 0.933397954 Com isso realizado, os diagnósticos indicaram que a normalidade e a homocedasticidade foram violadas, novamente sugerindo uma interpretação cautelosa dos resultados. Abaixo uma orientação de como escrever os resultados. Como escrever os resultados Um modelo de regressão múltipla foi calculado para verificar os resultados dos comportamentos alimentares (EAT-26) em função da percepção de imagem corporal (BSQ-34) e do peso do participante. Os resultados indicaram que cerca de 48% da variância do EAT-26 pode ser atribuída aos preditores (R2 = 0.486, F(2,213) = 100.675, p &lt; 0.001). Cada ponto a mais no BSQ-34 impacta, em média, em 0.180 no EAT-26 (p &lt; 0.001), controlando pelo peso do participante. 12.3 Técnicas automáticas de seleção de variáveis Os critérios para composição dos modelos costuma despertar um grande interesse nos debates estatísticos e quantas, quais e como eleger as variáveis independentes é um dos mais intensos. A seleção destas variáveis visa otimizar a acurácia do modelo, mas sem perder sua parcimônia, ou seja, simplicidade (Gaudio &amp; Zandonade, 2001; Unger &amp; Hansch, 1973). Métodos com justificativa teórica costumam ser chamados de entrada bruta, enquanto métodos em que se implementa algum algorítimo computadorizado para tal seleção tendem a ser denominados de métodos automáticos. Apesar do detalhamento destas técnicas ser fora do escopo dete capítulo, a seguir são listadas as principais técnicas: Backward selection Forward selection Stepwise selecion Lasso selection 12.4 Resumo O termo regressão múltipla se refere a um modelo de regressão com duas ou mais variáveis independentes As VIs podem ser de qualquer natureza, o que significa que toda família da ANOVA pode ser entendida como casos particulares de regressão Os diagnósticos são os mesmos dos modelos simples, mas agora é necessário também testar a multicolinearidade do modelo Existem diferentes métodos para adicionar preditores e maneiras manuais e automáticas são disponíveis "]
]
